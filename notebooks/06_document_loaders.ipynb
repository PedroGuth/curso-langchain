{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìÑ **M√≥dulo 6: Document Loaders e Vector Stores**\n",
        "\n",
        "## **Aula 6.1: Carregando Documentos - De PDF a YouTube**\n",
        "\n",
        "---\n",
        "\n",
        "### **T√°, mas o que s√£o Document Loaders?**\n",
        "\n",
        "Imagina que voc√™ tem uma **biblioteca digital** que pode ler qualquer tipo de documento:\n",
        "\n",
        "- üìÑ **PDFs** - Relat√≥rios, manuais, artigos\n",
        "- üìä **CSVs** - Dados, planilhas, estat√≠sticas\n",
        "- üé• **YouTube** - V√≠deos, palestras, tutoriais\n",
        "- üåê **Websites** - P√°ginas, blogs, not√≠cias\n",
        "- üìù **Word** - Documentos, contratos, propostas\n",
        "\n",
        "**Document Loaders** s√£o como **tradutores especializados** que convertem qualquer formato em texto que a IA pode entender.\n",
        "\n",
        "### **Por que Document Loaders s√£o Importantes?**\n",
        "\n",
        "**Sem Document Loaders**: IA s√≥ sabe o que voc√™ digita\n",
        "**Com Document Loaders**: IA pode ler e analisar qualquer documento!\n",
        "\n",
        "√â como a diferen√ßa entre **ler apenas um livro** vs **ter acesso a uma biblioteca inteira**! üìö\n",
        "\n",
        "---\n",
        "\n",
        "**üñºÔ∏è Sugest√£o de imagem**: Uma biblioteca digital com diferentes tipos de documentos sendo processados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Setup Inicial - Preparando o Terreno**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalando depend√™ncias para document loaders\n",
        "!!pip install pypdf python-docx beautifulsoup4 requests youtube-transcript-api\n",
        "\n",
        "# Importando bibliotecas\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.document_loaders import (\n",
        "    PyPDFLoader, \n",
        "    CSVLoader, \n",
        "    UnstructuredWordDocumentLoader,\n",
        "    WebBaseLoader,\n",
        "    YoutubeLoader\n",
        ")\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Carregando vari√°veis\n",
        "load_dotenv()\n",
        "\n",
        "# Modelo\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0.7,\n",
        "    api_key=os.getenv('OPENAI_API_KEY')  # Configure sua API key no Colab\n",
        ")\n",
        "\n",
        "print(\"üìÑ Setup completo para Document Loaders!\")\n",
        "print(f\"üöÄ Modelo: {llm.model_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Criando Documentos de Exemplo**\n",
        "\n",
        "Vamos criar alguns documentos de exemplo para testar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando arquivo CSV de exemplo\n",
        "import csv\n",
        "\n",
        "dados_produtos = [\n",
        "    ['nome', 'preco', 'categoria', 'estoque'],\n",
        "    ['iPhone 15', 'R$ 8.000', 'Smartphone', '50'],\n",
        "    ['MacBook Pro', 'R$ 15.000', 'Notebook', '30'],\n",
        "    ['AirPods Pro', 'R$ 2.500', 'Acess√≥rios', '100'],\n",
        "    ['iPad Air', 'R$ 6.000', 'Tablet', '25']\n",
        "]\n",
        "\n",
        "with open('produtos.csv', 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(dados_produtos)\n",
        "\n",
        "print(\"üìä Arquivo CSV 'produtos.csv' criado!\")\n",
        "print(\"üìù Cont√©m dados de produtos da Apple\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando arquivo de texto de exemplo\n",
        "texto_exemplo = \"\"\"\n",
        "LANGCHAIN - FRAMEWORK DE IA\n",
        "\n",
        "LangChain √© um framework poderoso para desenvolvimento de aplica√ß√µes de IA.\n",
        "Ele permite conectar diferentes modelos de linguagem e ferramentas de forma simples.\n",
        "\n",
        "PRINCIPAIS CARACTER√çSTICAS:\n",
        "- Prompts reutiliz√°veis\n",
        "- Chains modulares\n",
        "- Memory para conversas\n",
        "- Agents inteligentes\n",
        "- Document loaders\n",
        "\n",
        "CASOS DE USO:\n",
        "- Chatbots inteligentes\n",
        "- An√°lise de documentos\n",
        "- Automa√ß√£o de tarefas\n",
        "- Sistemas de recomenda√ß√£o\n",
        "\n",
        "LangChain √© especialmente √∫til para desenvolvedores que querem criar\n",
        "aplica√ß√µes de IA sem reinventar a roda.\n",
        "\"\"\"\n",
        "\n",
        "with open('langchain_info.txt', 'w', encoding='utf-8') as file:\n",
        "    file.write(texto_exemplo)\n",
        "\n",
        "print(\"üìù Arquivo de texto 'langchain_info.txt' criado!\")\n",
        "print(\"üìö Cont√©m informa√ß√µes sobre LangChain\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Testando Diferentes Document Loaders**\n",
        "\n",
        "Vamos testar como carregar diferentes tipos de documentos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando CSV Loader\n",
        "# Como ler dados estruturados\n",
        "\n",
        "print(\"üìä TESTE: CSV LOADER\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "try:\n",
        "    # Carregando CSV\n",
        "    csv_loader = CSVLoader('produtos.csv')\n",
        "    documentos_csv = csv_loader.load()\n",
        "    \n",
        "    print(f\"üìÑ Documentos carregados: {len(documentos_csv)}\")\n",
        "    \n",
        "    for i, doc in enumerate(documentos_csv[:3], 1):\n",
        "        print(f\"\\nüìã Documento {i}:\")\n",
        "        print(f\"üìù Conte√∫do: {doc.page_content[:100]}...\")\n",
        "        print(f\"üè∑Ô∏è  Metadados: {doc.metadata}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erro: {e}\")\n",
        "\n",
        "print(\"=\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando Text Loader\n",
        "# Como ler arquivos de texto simples\n",
        "\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "print(\"üìù TESTE: TEXT LOADER\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "try:\n",
        "    # Carregando arquivo de texto\n",
        "    text_loader = TextLoader('langchain_info.txt', encoding='utf-8')\n",
        "    documentos_texto = text_loader.load()\n",
        "    \n",
        "    print(f\"üìÑ Documentos carregados: {len(documentos_texto)}\")\n",
        "    \n",
        "    for i, doc in enumerate(documentos_texto, 1):\n",
        "        print(f\"\\nüìã Documento {i}:\")\n",
        "        print(f\"üìù Conte√∫do: {doc.page_content[:200]}...\")\n",
        "        print(f\"üè∑Ô∏è  Metadados: {doc.metadata}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erro: {e}\")\n",
        "\n",
        "print(\"=\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando Web Loader\n",
        "# Como ler conte√∫do de websites\n",
        "\n",
        "print(\"üåê TESTE: WEB LOADER\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "try:\n",
        "    # Carregando conte√∫do de um website\n",
        "    urls = [\"https://python.org\"]\n",
        "    web_loader = WebBaseLoader(urls)\n",
        "    documentos_web = web_loader.load()\n",
        "    \n",
        "    print(f\"üìÑ Documentos carregados: {len(documentos_web)}\")\n",
        "    \n",
        "    for i, doc in enumerate(documentos_web, 1):\n",
        "        print(f\"\\nüìã Documento {i}:\")\n",
        "        print(f\"üìù Conte√∫do: {doc.page_content[:200]}...\")\n",
        "        print(f\"üè∑Ô∏è  Metadados: {doc.metadata}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erro: {e}\")\n",
        "    print(\"üí° Pode ser necess√°rio verificar a conex√£o com a internet\")\n",
        "\n",
        "print(\"=\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Aula 6.2: Vector Stores - A Mem√≥ria de Longo Prazo**\n",
        "\n",
        "### **O que s√£o Vector Stores?**\n",
        "\n",
        "Vector Stores s√£o como um **c√©rebro organizado** que:\n",
        "1. **Converte texto em n√∫meros** (vetores)\n",
        "2. **Organiza por similaridade**\n",
        "3. **Permite busca inteligente**\n",
        "\n",
        "**Analogia**: √â como ter uma **biblioteca onde os livros se organizam sozinhos** por assunto, e voc√™ pode encontrar qualquer informa√ß√£o rapidamente!\n",
        "\n",
        "### **Por que Vector Stores s√£o Importantes?**\n",
        "\n",
        "**Sem Vector Stores**: IA esquece o que leu\n",
        "**Com Vector Stores**: IA pode buscar e lembrar de qualquer informa√ß√£o\n",
        "\n",
        "√â como a diferen√ßa entre **ler um livro e esquecer** vs **ter uma biblioteca na cabe√ßa**! üß†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalando depend√™ncias para vector stores\n",
        "!!pip install chromadb sentence-transformers\n",
        "\n",
        "# Importando bibliotecas\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "print(\"üß† Setup completo para Vector Stores!\")\n",
        "print(\"üîç Embeddings e Chroma prontos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando embeddings e vector store\n",
        "# Como organizar informa√ß√µes no c√©rebro da IA\n",
        "\n",
        "# Text splitter para dividir documentos grandes\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # Tamanho de cada peda√ßo\n",
        "    chunk_overlap=200,  # Sobreposi√ß√£o entre peda√ßos\n",
        "    length_function=len\n",
        ")\n",
        "\n",
        "# Carregando e dividindo documentos\n",
        "text_loader = TextLoader('langchain_info.txt', encoding='utf-8')\n",
        "documentos = text_loader.load()\n",
        "\n",
        "# Dividindo em peda√ßos menores\n",
        "textos_divididos = text_splitter.split_documents(documentos)\n",
        "\n",
        "print(f\"üìÑ Documentos originais: {len(documentos)}\")\n",
        "print(f\"üî™ Peda√ßos criados: {len(textos_divididos)}\")\n",
        "\n",
        "for i, texto in enumerate(textos_divididos[:2], 1):\n",
        "    print(f\"\\nüìã Peda√ßo {i}: {texto.page_content[:100]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando embeddings e vector store\n",
        "# Como organizar as informa√ß√µes no c√©rebro\n",
        "\n",
        "try:\n",
        "    # Criando embeddings\n",
        "    embeddings = OpenAIEmbeddings(\n",
        "        openai_api_key=os.getenv('OPENAI_API_KEY')  # Configure sua API key no Colab\n",
        "    )\n",
        "    \n",
        "    # Criando vector store\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=textos_divididos,\n",
        "        embedding=embeddings,\n",
        "        collection_name=\"langchain_info\"\n",
        "    )\n",
        "    \n",
        "    print(\"üß† Vector Store criado com sucesso!\")\n",
        "    print(f\"üìä Documentos armazenados: {len(textos_divididos)}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erro: {e}\")\n",
        "    print(\"üí° Verifique se sua API key est√° configurada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando busca sem√¢ntica\n",
        "# Como encontrar informa√ß√µes por similaridade\n",
        "\n",
        "print(\"üîç TESTE: BUSCA SEM√ÇNTICA\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "queries = [\n",
        "    \"O que √© LangChain?\",\n",
        "    \"Quais s√£o as caracter√≠sticas principais?\",\n",
        "    \"Para que serve LangChain?\",\n",
        "    \"Como funciona o framework?\"\n",
        "]\n",
        "\n",
        "for i, query in enumerate(queries, 1):\n",
        "    print(f\"\\nüîç Busca {i}: {query}\")\n",
        "    \n",
        "    try:\n",
        "        # Buscando documentos similares\n",
        "        docs = vectorstore.similarity_search(query, k=2)\n",
        "        \n",
        "        for j, doc in enumerate(docs, 1):\n",
        "            print(f\"\\nüìÑ Resultado {j}:\")\n",
        "            print(f\"üìù Conte√∫do: {doc.page_content[:150]}...\")\n",
        "            print(f\"üìä Similaridade: {doc.metadata}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro: {e}\")\n",
        "    \n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Sistema de Busca Inteligente Completo**\n",
        "\n",
        "Agora vamos criar um **sistema de busca inteligente** que combina document loaders com vector stores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando sistema de busca inteligente\n",
        "# Como criar uma biblioteca digital inteligente\n",
        "\n",
        "class SistemaBuscaInteligente:\n",
        "    def __init__(self):\n",
        "        self.embeddings = OpenAIEmbeddings(\n",
        "            openai_api_key=os.getenv('OPENAI_API_KEY')  # Configure sua API key no Colab\n",
        "        )\n",
        "        self.vectorstore = None\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200\n",
        "        )\n",
        "    \n",
        "    def carregar_documento(self, caminho_arquivo, tipo=\"texto\"):\n",
        "        \"\"\"Carrega um documento e adiciona ao vector store\"\"\"\n",
        "        try:\n",
        "            if tipo == \"csv\":\n",
        "                loader = CSVLoader(caminho_arquivo)\n",
        "            elif tipo == \"texto\":\n",
        "                loader = TextLoader(caminho_arquivo, encoding='utf-8')\n",
        "            else:\n",
        "                return \"Tipo de documento n√£o suportado\"\n",
        "            \n",
        "            documentos = loader.load()\n",
        "            textos_divididos = self.text_splitter.split_documents(documentos)\n",
        "            \n",
        "            if self.vectorstore is None:\n",
        "                self.vectorstore = Chroma.from_documents(\n",
        "                    documents=textos_divididos,\n",
        "                    embedding=self.embeddings,\n",
        "                    collection_name=\"biblioteca_digital\"\n",
        "                )\n",
        "            else:\n",
        "                self.vectorstore.add_documents(textos_divididos)\n",
        "            \n",
        "            return f\"‚úÖ Documento carregado! {len(textos_divididos)} peda√ßos adicionados.\"\n",
        "            \n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Erro: {e}\"\n",
        "    \n",
        "    def buscar(self, query, k=3):\n",
        "        \"\"\"Busca documentos similares\"\"\"\n",
        "        try:\n",
        "            if self.vectorstore is None:\n",
        "                return \"‚ùå Nenhum documento carregado ainda.\"\n",
        "            \n",
        "            docs = self.vectorstore.similarity_search(query, k=k)\n",
        "            return docs\n",
        "            \n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Erro na busca: {e}\"\n",
        "\n",
        "print(\"ü§ñ Sistema de Busca Inteligente criado!\")\n",
        "print(\"üìö Biblioteca digital pronta para uso\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando o sistema completo\n",
        "# Vamos ver a biblioteca digital em a√ß√£o!\n",
        "\n",
        "print(\"üìö TESTE: SISTEMA DE BUSCA INTELIGENTE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Criando inst√¢ncia do sistema\n",
        "sistema = SistemaBuscaInteligente()\n",
        "\n",
        "# Carregando documentos\n",
        "print(\"üìÑ Carregando documentos...\")\n",
        "resultado1 = sistema.carregar_documento('langchain_info.txt', 'texto')\n",
        "print(f\"üìù {resultado1}\")\n",
        "\n",
        "resultado2 = sistema.carregar_documento('produtos.csv', 'csv')\n",
        "print(f\"üìä {resultado2}\")\n",
        "\n",
        "# Fazendo buscas\n",
        "print(\"\\nüîç Fazendo buscas...\")\n",
        "buscas = [\n",
        "    \"O que √© LangChain?\",\n",
        "    \"Quais produtos da Apple est√£o dispon√≠veis?\",\n",
        "    \"Como funciona o framework?\",\n",
        "    \"Qual o pre√ßo do iPhone?\"\n",
        "]\n",
        "\n",
        "for i, busca in enumerate(buscas, 1):\n",
        "    print(f\"\\nüîç Busca {i}: {busca}\")\n",
        "    \n",
        "    try:\n",
        "        resultados = sistema.buscar(busca, k=2)\n",
        "        \n",
        "        if isinstance(resultados, str):\n",
        "            print(f\"‚ùå {resultados}\")\n",
        "        else:\n",
        "            for j, doc in enumerate(resultados, 1):\n",
        "                print(f\"\\nüìÑ Resultado {j}:\")\n",
        "                print(f\"üìù {doc.page_content[:150]}...\")\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro: {e}\")\n",
        "    \n",
        "    print(\"-\" * 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Na Pr√°tica, Meu Consagrado!** üí™\n",
        "\n",
        "**O que aprendemos sobre Document Loaders e Vector Stores:**\n",
        "\n",
        "1. ‚úÖ **Document Loaders** - Como ler diferentes tipos de arquivos\n",
        "2. ‚úÖ **Text Splitting** - Como dividir documentos grandes\n",
        "3. ‚úÖ **Vector Stores** - Como organizar informa√ß√µes por similaridade\n",
        "4. ‚úÖ **Busca Sem√¢ntica** - Como encontrar informa√ß√µes inteligentemente\n",
        "5. ‚úÖ **Sistema Completo** - Biblioteca digital inteligente\n",
        "\n",
        "### **Compara√ß√£o: Com vs Sem LangChain**\n",
        "\n",
        "**Sem LangChain**: Voc√™ teria que implementar cada loader manualmente\n",
        "**Com LangChain**: Tudo pronto, s√≥ usar!\n",
        "\n",
        "**üñºÔ∏è Sugest√£o de imagem**: Um diagrama mostrando documentos sendo processados e organizados em vector stores\n",
        "\n",
        "**üéØ Pr√≥ximo m√≥dulo**: Vamos aprender sobre **RAG** - como combinar busca com gera√ß√£o de respostas!\n",
        "\n",
        "**üí° Resumo do M√≥dulo 6**:\n",
        "- ‚úÖ Document loaders para diferentes formatos\n",
        "- ‚úÖ Vector stores para organiza√ß√£o\n",
        "- ‚úÖ Busca sem√¢ntica inteligente\n",
        "- ‚úÖ Sistema de biblioteca digital\n",
        "\n",
        "**üìö Agora voc√™ pode fazer a IA ler qualquer documento!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "06_document_loaders",
      "private_outputs": true,
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}