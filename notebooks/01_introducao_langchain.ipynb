{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸš€ **MÃ³dulo 1: IntroduÃ§Ã£o ao LangChain - O Quebra-CabeÃ§a da IA**\n",
        "\n",
        "## **Aula 1.1: O que Ã© LangChain e por que todo mundo tÃ¡ falando disso?**\n",
        "\n",
        "---\n",
        "\n",
        "### **TÃ¡, mas o que Ã© LangChain mesmo?**\n",
        "\n",
        "Imagina que vocÃª Ã© um pedreiro e tem um monte de tijolos, cimento, areia e ferramentas espalhadas pelo terreno. VocÃª **pode** construir uma casa, mas vai ser um trabalho do caralho e vai demorar uma eternidade.\n",
        "\n",
        "Agora imagina que alguÃ©m te dÃ¡ um **kit de construÃ§Ã£o** com tudo organizado, instruÃ§Ãµes claras e atÃ© uns moldes prontos. Muito mais fÃ¡cil, nÃ©?\n",
        "\n",
        "**LangChain Ã© exatamente isso para IA!** ğŸ§±\n",
        "\n",
        "Sem LangChain, vocÃª tem que:\n",
        "- Conectar APIs manualmente\n",
        "- Gerenciar memÃ³ria de conversas\n",
        "- Implementar prompts do zero\n",
        "- Fazer parsing de respostas\n",
        "- E mais um monte de coisa chata\n",
        "\n",
        "Com LangChain, vocÃª tem **componentes prontos** que se encaixam como peÃ§as de Lego. Ã‰ tipo ter um **\"Lego da IA\"** - vocÃª junta as peÃ§as e faz coisas incrÃ­veis sem reinventar a roda.\n",
        "\n",
        "### **Por que LangChain Ã© tipo um \"pedreiro inteligente\"?**\n",
        "\n",
        "LangChain nÃ£o Ã© sÃ³ uma biblioteca, Ã© um **framework completo** que te ajuda a:\n",
        "\n",
        "1. **Organizar prompts** (como ter receitas de bolo prontas)\n",
        "2. **Conectar diferentes IAs** (como ter um tradutor que fala com um analista)\n",
        "3. **Lembrar de conversas** (como um garÃ§om que nunca esquece seu pedido)\n",
        "4. **Usar ferramentas externas** (como dar superpoderes para a IA)\n",
        "5. **Processar documentos** (como ter um assistente que lÃª tudo pra vocÃª)\n",
        "\n",
        "### **ChatGPT vs LangChain - A DiferenÃ§a na PrÃ¡tica**\n",
        "\n",
        "**ChatGPT**: Ã‰ como ter um amigo super inteligente, mas que sÃ³ pode conversar. Ele nÃ£o pode:\n",
        "- Acessar internet\n",
        "- Executar cÃ³digo\n",
        "- Lembrar de conversas antigas\n",
        "- Conectar com outros sistemas\n",
        "\n",
        "**LangChain**: Ã‰ como ter um **exÃ©rcito de amigos inteligentes** cada um com uma especialidade, e vocÃª Ã© o chefe que coordena tudo!\n",
        "\n",
        "---\n",
        "\n",
        "**ğŸ’¡ Dica do Pedro**: LangChain Ã© especialmente Ãºtil quando vocÃª quer fazer algo mais complexo que uma simples conversa. Ã‰ tipo a diferenÃ§a entre pedir um Uber e ter um motorista particular que tambÃ©m Ã© seu assistente pessoal.\n",
        "\n",
        "**ğŸ–¼ï¸ SugestÃ£o de imagem**: Um diagrama mostrando ChatGPT (caixa simples) vs LangChain (caixa com vÃ¡rias conexÃµes e ferramentas saindo dela)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Aula 1.2: Setup do Ambiente - Preparando o Terreno**\n",
        "\n",
        "### **InstalaÃ§Ã£o e ConfiguraÃ§Ã£o (Sem ComplicaÃ§Ã£o)**\n",
        "\n",
        "Antes de comeÃ§ar a construir, precisamos preparar o terreno. Ã‰ como aprender a dirigir - primeiro vocÃª liga o carro, depois aprende a andar.\n",
        "\n",
        "Vamos instalar tudo que precisamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalando as dependÃªncias necessÃ¡rias\n",
        "# Execute esta cÃ©lula primeiro!\n",
        "\n",
        "!!pip install langchain openai python-dotenv\n",
        "!!pip install langchain-community langchain-core\n",
        "\n",
        "print(\"âœ… DependÃªncias instaladas com sucesso!\")\n",
        "print(\"ğŸš€ Agora vamos importar o que precisamos...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importando as bibliotecas principais\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "\n",
        "# Carregando variÃ¡veis de ambiente (vamos configurar isso depois)\n",
        "load_dotenv()\n",
        "\n",
        "print(\"ğŸ“¦ Bibliotecas importadas com sucesso!\")\n",
        "print(\"ğŸ”§ PrÃ³ximo passo: configurar a API key da OpenAI\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Configurando a API Key - O \"CartÃ£o de CrÃ©dito\" da IA**\n",
        "\n",
        "Para usar LangChain com modelos da OpenAI (como GPT), vocÃª precisa de uma API key. Ã‰ como ter um cartÃ£o de crÃ©dito para pagar pelos serviÃ§os de IA.\n",
        "\n",
        "**ğŸ’¡ Dica importante**: Nunca coloque sua API key diretamente no cÃ³digo! Sempre use variÃ¡veis de ambiente.\n",
        "\n",
        "Vamos criar um arquivo `.env` para guardar suas chaves de forma segura:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando arquivo .env (se nÃ£o existir)\n",
        "if not os.path.exists('.env'):\n",
        "    with open('.env', 'w') as f:\n",
        "        f.write('# Suas chaves de API aqui\\n')\n",
        "        f.write('OPENAI_API_KEY=sua_chave_aqui\\n')\n",
        "    print(\"ğŸ“ Arquivo .env criado!\")\n",
        "    print(\"ğŸ”‘ Adicione sua API key da OpenAI no arquivo .env\")\n",
        "else:\n",
        "    print(\"âœ… Arquivo .env jÃ¡ existe!\")\n",
        "\n",
        "# Verificando se a API key estÃ¡ configurada\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "if api_key and api_key != 'sua_chave_aqui':\n",
        "    print(\"ğŸ‰ API key configurada com sucesso!\")\n",
        "else:\n",
        "    print(\"âš ï¸  Configure sua API key no arquivo .env\")\n",
        "    print(\"ğŸ“– Tutorial: https://platform.openai.com/api-keys\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Primeiro \"Hello World\" com LangChain**\n",
        "\n",
        "Agora vamos fazer nosso primeiro teste! Ã‰ como dar a primeira volta no carro - simples, mas emocionante.\n",
        "\n",
        "Vamos criar um modelo bÃ¡sico e fazer uma pergunta simples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando nosso primeiro modelo LangChain\n",
        "# Ã‰ como \"ligar\" o motor da IA\n",
        "\n",
        "try:\n",
        "    # Inicializando o modelo (GPT-3.5-turbo por padrÃ£o)\n",
        "    llm = ChatOpenAI(\n",
        "        model=\"gpt-3.5-turbo\",  # Modelo que vamos usar\n",
        "        temperature=0.7,        # Criatividade (0 = muito focado, 1 = muito criativo)\n",
        "        api_key=os.getenv('OPENAI_API_KEY')  # Configure sua API key no Colab  # Nossa chave de API\n",
        "    )\n",
        "    \n",
        "    print(\"ğŸ¤– Modelo LangChain criado com sucesso!\")\n",
        "    print(f\"ğŸ“Š Modelo: {llm.model_name}\")\n",
        "    print(f\"ğŸŒ¡ï¸  Temperature: {llm.temperature}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Erro ao criar modelo: {e}\")\n",
        "    print(\"ğŸ”‘ Verifique se sua API key estÃ¡ configurada corretamente!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fazendo nossa primeira pergunta!\n",
        "# Ã‰ como fazer a primeira pergunta para um amigo novo\n",
        "\n",
        "try:\n",
        "    # Criando a mensagem (como escrever um WhatsApp)\n",
        "    message = HumanMessage(content=\"OlÃ¡! Pode me explicar o que Ã© LangChain em uma frase simples?\")\n",
        "    \n",
        "    # Enviando a mensagem e recebendo a resposta\n",
        "    response = llm.invoke([message])\n",
        "    \n",
        "    print(\"ğŸ’¬ Nossa primeira conversa com LangChain:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"ğŸ¤” Pergunta: {message.content}\")\n",
        "    print(f\"ğŸ¤– Resposta: {response.content}\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Erro na conversa: {e}\")\n",
        "    print(\"ğŸ’° Verifique se vocÃª tem crÃ©ditos na sua conta OpenAI!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Parou aqui e entendeu!** ğŸ¯\n",
        "\n",
        "Se vocÃª conseguiu ver a resposta da IA, **parabÃ©ns!** VocÃª acabou de fazer seu primeiro app com LangChain!\n",
        "\n",
        "**O que acabamos de fazer:**\n",
        "1. âœ… Instalamos o LangChain\n",
        "2. âœ… Configuramos a API key\n",
        "3. âœ… Criamos um modelo\n",
        "4. âœ… Fizemos uma pergunta e recebemos resposta\n",
        "\n",
        "**Por que isso Ã© diferente do ChatGPT normal?**\n",
        "- No ChatGPT, vocÃª sÃ³ conversa\n",
        "- Com LangChain, vocÃª **programa** a conversa\n",
        "- VocÃª pode automatizar, integrar, personalizar\n",
        "- Ã‰ como a diferenÃ§a entre **usar** um app e **criar** um app\n",
        "\n",
        "---\n",
        "\n",
        "### **Teste RÃ¡pido - Vamos Experimentar Mais!**\n",
        "\n",
        "Agora vamos fazer um teste mais interessante. Vamos criar um \"assistente de programaÃ§Ã£o\" que fala como o Pedro Guth:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando um assistente com personalidade\n",
        "# Ã‰ como configurar um amigo com caracterÃ­sticas especÃ­ficas\n",
        "\n",
        "try:\n",
        "    # Definindo a personalidade do assistente (System Message)\n",
        "    system_message = SystemMessage(content=\"\"\"\n",
        "    VocÃª Ã© o Pedro Guth, um instrutor de programaÃ§Ã£o descontraÃ­do e direto. \n",
        "    Use linguagem informal, faÃ§a piadas leves e use analogias do dia a dia.\n",
        "    Explique conceitos tÃ©cnicos de forma simples e engraÃ§ada.\n",
        "    Use palavrÃµes com moderaÃ§Ã£o e funÃ§Ã£o pedagÃ³gica.\n",
        "    \"\"\")\n",
        "    \n",
        "    # Pergunta do usuÃ¡rio\n",
        "    user_message = HumanMessage(content=\"\"\"\n",
        "    Explique o que Ã© uma variÃ¡vel em programaÃ§Ã£o de forma descontraÃ­da, \n",
        "    como se fosse o Pedro Guth explicando.\n",
        "    \"\"\")\n",
        "    \n",
        "    # Enviando as duas mensagens (sistema + usuÃ¡rio)\n",
        "    response = llm.invoke([system_message, user_message])\n",
        "    \n",
        "    print(\"ğŸ­ Assistente com Personalidade:\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"ğŸ¤– Pedro Guth: {response.content}\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Erro: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Na PrÃ¡tica, Meu Consagrado!** ğŸ’ª\n",
        "\n",
        "**O que vocÃª acabou de ver:**\n",
        "\n",
        "1. **System Message**: Ã‰ como dar instruÃ§Ãµes para um ator antes da peÃ§a. \"VocÃª vai interpretar o Pedro Guth\"\n",
        "2. **Human Message**: Ã‰ o que o usuÃ¡rio pergunta\n",
        "3. **Response**: Ã‰ a resposta personalizada\n",
        "\n",
        "**Por que isso Ã© poderoso:**\n",
        "- VocÃª pode criar **diferentes personalidades** para diferentes usos\n",
        "- Um assistente para crianÃ§as, outro para CEOs, outro para programadores\n",
        "- Ã‰ como ter **mÃºltiplos funcionÃ¡rios especializados** em uma IA sÃ³\n",
        "\n",
        "---\n",
        "\n",
        "### **ComparaÃ§Ã£o: Com vs Sem LangChain**\n",
        "\n",
        "**Sem LangChain (cÃ³digo manual):**\n",
        "```python\n",
        "# VocÃª teria que fazer isso tudo manualmente:\n",
        "import requests\n",
        "import json\n",
        "\n",
        "headers = {\n",
        "    'Authorization': f'Bearer {api_key}',\n",
        "    'Content-Type': 'application/json'\n",
        "}\n",
        "\n",
        "data = {\n",
        "    'model': 'gpt-3.5-turbo',\n",
        "    'messages': [\n",
        "        {'role': 'system', 'content': 'Seja o Pedro Guth...'},\n",
        "        {'role': 'user', 'content': 'Explique variÃ¡veis...'}\n",
        "    ],\n",
        "    'temperature': 0.7\n",
        "}\n",
        "\n",
        "response = requests.post('https://api.openai.com/v1/chat/completions', \n",
        "                        headers=headers, json=data)\n",
        "result = response.json()\n",
        "answer = result['choices'][0]['message']['content']\n",
        "```\n",
        "\n",
        "**Com LangChain:**\n",
        "```python\n",
        "# Tudo isso em 3 linhas:\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "response = llm.invoke([system_message, user_message])\n",
        "print(response.content)\n",
        "```\n",
        "\n",
        "**DiferenÃ§a**: 20 linhas vs 3 linhas. Ã‰ como a diferenÃ§a entre **andar a pÃ©** e **pegar um Uber**! ğŸš—\n",
        "\n",
        "---\n",
        "\n",
        "### **Resumo do que Aprendemos** ğŸ“š\n",
        "\n",
        "âœ… **O que Ã© LangChain**: Framework que simplifica o desenvolvimento com IA\n",
        "âœ… **Por que usar**: Economiza tempo, cÃ³digo e dor de cabeÃ§a\n",
        "âœ… **Setup bÃ¡sico**: InstalaÃ§Ã£o, configuraÃ§Ã£o de API key\n",
        "âœ… **Primeiro app**: Conversa simples com IA\n",
        "âœ… **PersonalizaÃ§Ã£o**: Como criar assistentes com personalidade\n",
        "\n",
        "**ğŸ–¼ï¸ SugestÃ£o de imagem**: Um diagrama mostrando a diferenÃ§a entre cÃ³digo manual (muitas linhas) vs LangChain (poucas linhas)\n",
        "\n",
        "**ğŸ¯ PrÃ³ximo mÃ³dulo**: Vamos aprender sobre **Prompts** - a arte de falar com IA de forma eficiente!\n",
        "\n",
        "---\n",
        "\n",
        "**ğŸ’¡ Desafio para casa**: Tente criar um assistente que fale como um chef de cozinha e explique como fazer um bolo de chocolate. Use a mesma tÃ©cnica que aprendemos!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "name": "01_introducao_langchain",
      "private_outputs": true,
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}