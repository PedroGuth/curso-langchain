{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ” LangSmith: O Sherlock Holmes das suas AplicaÃ§Ãµes LangChain!\n\n**MÃ³dulo 17 - Curso LangChain v0.3**\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-17_img_01.png)\n\nBora para o Ãºltimo mÃ³dulo galera! TÃ¡, jÃ¡ aprendemos a criar, agora vamos aprender a **MONITORAR** e **DEBUGGAR** nossas aplicaÃ§Ãµes!\n\n**Pedro Nunes Guth** ğŸš€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¤” TÃ¡, mas o que Ã© o LangSmith?\n\nImagina que vocÃª tem um restaurante (sua aplicaÃ§Ã£o LangChain). VocÃª sabe fazer a comida, mas como saber:\n- Quais pratos os clientes mais gostaram?\n- Onde a cozinha estÃ¡ demorada?\n- Qual garÃ§om estÃ¡ errando os pedidos?\n- Quanto estÃ¡ custando cada prato?\n\n**LangSmith Ã© seu sistema de monitoramento completo!**\n\n### O que o LangSmith faz:\n1. **Tracing**: Acompanha cada passo da sua chain\n2. **Logging**: Registra tudo que acontece\n3. **Evaluation**: Testa se sua IA estÃ¡ funcionando bem\n4. **Monitoring**: Alerta quando algo vai mal\n5. **Debugging**: Mostra onde estÃ¡ o problema\n\n**Dica!** Ã‰ tipo um Google Analytics para suas aplicaÃ§Ãµes de IA!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vamos instalar o que precisamos\n",
        "!pip install langsmith langchain-google-genai python-dotenv matplotlib seaborn -q\n",
        "\n",
        "print(\"ğŸ“¦ Pacotes instalados!\")\n",
        "print(\"ğŸ”‘ Agora vocÃª vai precisar de uma conta no LangSmith (smith.langchain.com)\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Imports necessÃ¡rios\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "\n",
        "# Configurar estilo dos grÃ¡ficos\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"ğŸ“Š Bibliotecas carregadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## âš™ï¸ Configurando o LangSmith\n\nPrimeiro, vocÃª precisa:\n1. Criar uma conta em [smith.langchain.com](https://smith.langchain.com)\n2. Pegar sua API Key\n3. Configurar as variÃ¡veis de ambiente\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-17_img_02.png)\n\n**Dica!** Ã‰ de graÃ§a para uso pessoal e pequenos projetos!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Carregando as variÃ¡veis de ambiente\n",
        "load_dotenv()\n",
        "\n",
        "# ConfiguraÃ§Ãµes do LangSmith\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"  # Habilita o tracing\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"meu-projeto-langchain\"  # Nome do projeto\n",
        "\n",
        "# Suas chaves (substitua pelos valores reais)\n",
        "# os.environ[\"LANGCHAIN_API_KEY\"] = \"sua_langsmith_api_key_aqui\"\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = \"sua_google_api_key_aqui\"\n",
        "\n",
        "print(\"ğŸ”§ ConfiguraÃ§Ãµes do LangSmith definidas!\")\n",
        "print(f\"ğŸ“‹ Projeto: {os.environ.get('LANGCHAIN_PROJECT')}\")\n",
        "print(f\"ğŸ” Tracing: {os.environ.get('LANGCHAIN_TRACING_V2')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ—ï¸ Criando uma AplicaÃ§Ã£o para Monitorar\n\nVamos criar uma aplicaÃ§Ã£o simples usando os conceitos que jÃ¡ aprendemos no curso:\n- **ChatModel** (MÃ³dulo 2)\n- **PromptTemplate** (MÃ³dulo 4)\n- **Chains** (MÃ³dulo 6)\n- **RAG** (MÃ³dulo 10)\n\n### Fluxo da Nossa AplicaÃ§Ã£o:\n```mermaid\ngraph TD\n    A[Pergunta do UsuÃ¡rio] --> B[Chain de AnÃ¡lise]\n    B --> C[Modelo Gemini]\n    C --> D[Resposta Processada]\n    D --> E[LangSmith Monitoring]\n    E --> F[Dashboard]\n```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "# Criando o modelo (lembrando do MÃ³dulo 2)\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# Criando o prompt template (lembrando do MÃ³dulo 4)\n",
        "prompt_template = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    VocÃª Ã© um assistente especializado em anÃ¡lise de sentimentos.\n",
        "    \n",
        "    Analise o texto abaixo e forneÃ§a:\n",
        "    1. Sentimento (Positivo/Neutro/Negativo)\n",
        "    2. ConfianÃ§a (0-100%)\n",
        "    3. Palavras-chave que influenciaram sua decisÃ£o\n",
        "    \n",
        "    Texto: {texto}\n",
        "    \n",
        "    Resposta:\n",
        "    \"\"\",\n",
        "    input_variables=[\"texto\"]\n",
        ")\n",
        "\n",
        "print(\"ğŸ¤– Modelo e template criados!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Criando a chain (lembrando do MÃ³dulo 6)\n",
        "chain_analise_sentimento = (\n",
        "    {\"texto\": RunnablePassthrough()}\n",
        "    | prompt_template\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"â›“ï¸ Chain criada!\")\n",
        "print(\"ğŸ¯ Agora todas as execuÃ§Ãµes serÃ£o monitoradas pelo LangSmith\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš€ Testando com Monitoramento Ativo\n\nAgora vamos executar nossa chain vÃ¡rias vezes para gerar dados no LangSmith!\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-17_img_03.png)\n\n**Dica!** Cada execuÃ§Ã£o serÃ¡ automaticamente logada no LangSmith!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Lista de textos para testar nossa aplicaÃ§Ã£o\n",
        "textos_teste = [\n",
        "    \"Adorei este produto! Superou minhas expectativas!\",\n",
        "    \"O atendimento foi pÃ©ssimo, nÃ£o recomendo.\",\n",
        "    \"O produto chegou no prazo esperado.\",\n",
        "    \"IncrÃ­vel! Melhor compra que jÃ¡ fiz na vida!\",\n",
        "    \"Tive problemas com a entrega, mas o produto Ã© bom.\",\n",
        "    \"Funcionou conforme descrito na embalagem.\",\n",
        "    \"Que decepÃ§Ã£o! Nada do que foi prometido.\",\n",
        "    \"Excelente qualidade, vale cada centavo!\"\n",
        "]\n",
        "\n",
        "print(f\"ğŸ“ Temos {len(textos_teste)} textos para analisar\")\n",
        "print(\"ğŸ”„ Cada execuÃ§Ã£o serÃ¡ trackeada pelo LangSmith!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Executando as anÃ¡lises (isso gerarÃ¡ traces no LangSmith)\n",
        "resultados = []\n",
        "\n",
        "for i, texto in enumerate(textos_teste):\n",
        "    print(f\"\\nğŸ” Analisando texto {i+1}/{len(textos_teste)}...\")\n",
        "    print(f\"ğŸ“„ Texto: {texto[:50]}...\")\n",
        "    \n",
        "    try:\n",
        "        # Esta execuÃ§Ã£o serÃ¡ automaticamente trackeada!\n",
        "        resultado = chain_analise_sentimento.invoke(texto)\n",
        "        resultados.append({\n",
        "            \"texto\": texto,\n",
        "            \"resultado\": resultado,\n",
        "            \"status\": \"sucesso\"\n",
        "        })\n",
        "        print(\"âœ… AnÃ¡lise concluÃ­da!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro na anÃ¡lise: {e}\")\n",
        "        resultados.append({\n",
        "            \"texto\": texto,\n",
        "            \"resultado\": None,\n",
        "            \"status\": \"erro\",\n",
        "            \"erro\": str(e)\n",
        "        })\n",
        "\n",
        "print(f\"\\nğŸ¯ Processamento concluÃ­do! {len(resultados)} anÃ¡lises realizadas\")\n",
        "print(\"ğŸ“Š Verifique seu dashboard do LangSmith para ver os traces!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š AnÃ¡lise Local dos Resultados\n\nEnquanto o LangSmith coleta os dados detalhados, vamos fazer uma anÃ¡lise local dos nossos resultados!\n\n### MÃ©tricas que o LangSmith coleta automaticamente:\n- **LatÃªncia**: Tempo de resposta\n- **Tokens**: Consumo de tokens de entrada e saÃ­da\n- **Custo**: Quanto cada execuÃ§Ã£o custou\n- **Erros**: Taxa de falha\n- **Traces**: Fluxo completo da execuÃ§Ã£o\n\n**Dica!** No dashboard vocÃª vÃª tudo isso em tempo real!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Analisando os resultados localmente\n",
        "sucessos = [r for r in resultados if r[\"status\"] == \"sucesso\"]\n",
        "erros = [r for r in resultados if r[\"status\"] == \"erro\"]\n",
        "\n",
        "print(f\"ğŸ“ˆ RelatÃ³rio de ExecuÃ§Ã£o:\")\n",
        "print(f\"âœ… Sucessos: {len(sucessos)} ({len(sucessos)/len(resultados)*100:.1f}%)\")\n",
        "print(f\"âŒ Erros: {len(erros)} ({len(erros)/len(resultados)*100:.1f}%)\")\n",
        "\n",
        "# Simulando mÃ©tricas de performance\n",
        "latencias_simuladas = np.random.normal(1.2, 0.3, len(sucessos))  # Segundos\n",
        "tokens_simulados = np.random.randint(50, 200, len(sucessos))     # Tokens\n",
        "\n",
        "print(f\"\\nâ±ï¸ Performance Simulada:\")\n",
        "print(f\"ğŸ“Š LatÃªncia mÃ©dia: {np.mean(latencias_simuladas):.2f}s\")\n",
        "print(f\"ğŸ¯ Tokens mÃ©dios: {np.mean(tokens_simulados):.0f} tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Criando visualizaÃ§Ãµes como as que vocÃª veria no LangSmith\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# GrÃ¡fico 1: Taxa de Sucesso\n",
        "labels = ['Sucessos', 'Erros']\n",
        "sizes = [len(sucessos), len(erros)]\n",
        "colors = ['#2ecc71', '#e74c3c']\n",
        "ax1.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "ax1.set_title('Taxa de Sucesso das ExecuÃ§Ãµes', fontsize=14, pad=20)\n",
        "\n",
        "# GrÃ¡fico 2: DistribuiÃ§Ã£o de LatÃªncia\n",
        "ax2.hist(latencias_simuladas, bins=10, color='#3498db', alpha=0.7, edgecolor='black')\n",
        "ax2.set_title('DistribuiÃ§Ã£o de LatÃªncia', fontsize=14, pad=20)\n",
        "ax2.set_xlabel('Tempo (segundos)')\n",
        "ax2.set_ylabel('FrequÃªncia')\n",
        "ax2.axvline(np.mean(latencias_simuladas), color='red', linestyle='--', label=f'MÃ©dia: {np.mean(latencias_simuladas):.2f}s')\n",
        "ax2.legend()\n",
        "\n",
        "# GrÃ¡fico 3: Consumo de Tokens\n",
        "ax3.bar(range(len(tokens_simulados)), tokens_simulados, color='#9b59b6', alpha=0.7)\n",
        "ax3.set_title('Consumo de Tokens por ExecuÃ§Ã£o', fontsize=14, pad=20)\n",
        "ax3.set_xlabel('ExecuÃ§Ã£o')\n",
        "ax3.set_ylabel('Tokens Utilizados')\n",
        "ax3.axhline(np.mean(tokens_simulados), color='red', linestyle='--', label=f'MÃ©dia: {np.mean(tokens_simulados):.0f}')\n",
        "ax3.legend()\n",
        "\n",
        "# GrÃ¡fico 4: Timeline de ExecuÃ§Ãµes\n",
        "horarios = [datetime.now() - timedelta(minutes=x*2) for x in range(len(sucessos))]\n",
        "ax4.plot(horarios, latencias_simuladas, 'o-', color='#e67e22', linewidth=2, markersize=6)\n",
        "ax4.set_title('Timeline de Performance', fontsize=14, pad=20)\n",
        "ax4.set_xlabel('Tempo')\n",
        "ax4.set_ylabel('LatÃªncia (s)')\n",
        "ax4.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ“Š Esses sÃ£o os tipos de grÃ¡ficos que vocÃª vÃª no LangSmith dashboard!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ” Tracing Detalhado: O Que Acontece Sob o CapÃ´\n\nO **Tracing** Ã© a funcionalidade mais poderosa do LangSmith. Ã‰ como ter raio-X da sua aplicaÃ§Ã£o!\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-17_img_04.png)\n\n### O que o Trace mostra:\n1. **Input**: O que entrou\n2. **Steps**: Cada passo da chain\n3. **Output**: O que saiu\n4. **Timing**: Quanto tempo cada parte demorou\n5. **Metadata**: InformaÃ§Ãµes extras (tokens, modelo usado, etc.)\n\n**Dica!** Ã‰ tipo o \"Inspect Element\" do navegador, mas para IA!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulando um trace detalhado (como vocÃª veria no LangSmith)\n",
        "exemplo_trace = {\n",
        "    \"run_id\": \"abc-123-def-456\",\n",
        "    \"name\": \"chain_analise_sentimento\",\n",
        "    \"start_time\": \"2024-01-15T10:30:00Z\",\n",
        "    \"end_time\": \"2024-01-15T10:30:02Z\",\n",
        "    \"duration_ms\": 2000,\n",
        "    \"inputs\": {\n",
        "        \"texto\": \"Adorei este produto! Superou minhas expectativas!\"\n",
        "    },\n",
        "    \"outputs\": {\n",
        "        \"content\": \"Sentimento: Positivo\\nConfianÃ§a: 95%\\nPalavras-chave: adorei, superou, expectativas\"\n",
        "    },\n",
        "    \"metadata\": {\n",
        "        \"model\": \"gemini-2.0-flash-exp\",\n",
        "        \"tokens_input\": 45,\n",
        "        \"tokens_output\": 23,\n",
        "        \"cost_usd\": 0.0012\n",
        "    },\n",
        "    \"children\": [\n",
        "        {\n",
        "            \"name\": \"PromptTemplate\",\n",
        "            \"duration_ms\": 5,\n",
        "            \"type\": \"prompt\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"ChatGoogleGenerativeAI\",\n",
        "            \"duration_ms\": 1800,\n",
        "            \"type\": \"llm\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"StrOutputParser\",\n",
        "            \"duration_ms\": 2,\n",
        "            \"type\": \"parser\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Exibindo o trace de forma organizada\n",
        "print(\"ğŸ” EXEMPLO DE TRACE DETALHADO:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"ğŸ“‹ Run ID: {exemplo_trace['run_id']}\")\n",
        "print(f\"â±ï¸  DuraÃ§Ã£o Total: {exemplo_trace['duration_ms']}ms\")\n",
        "print(f\"ğŸ’° Custo: ${exemplo_trace['metadata']['cost_usd']:.4f}\")\n",
        "print(f\"ğŸ¯ Tokens: {exemplo_trace['metadata']['tokens_input']} â†’ {exemplo_trace['metadata']['tokens_output']}\")\n",
        "\n",
        "print(\"\\nğŸ“ INPUT:\")\n",
        "print(f\"   {exemplo_trace['inputs']['texto']}\")\n",
        "\n",
        "print(\"\\nğŸ“¤ OUTPUT:\")\n",
        "print(f\"   {exemplo_trace['outputs']['content']}\")\n",
        "\n",
        "print(\"\\nğŸ”§ STEPS EXECUTADOS:\")\n",
        "for i, step in enumerate(exemplo_trace['children']):\n",
        "    print(f\"   {i+1}. {step['name']} ({step['duration_ms']}ms)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§ª Evaluation: Testando se sua IA EstÃ¡ Boa\n\nUma das funcionalidades mais **liiinda** do LangSmith Ã© a **Evaluation**!\n\nÃ‰ tipo ter um professor que corrige as respostas da sua IA automaticamente!\n\n### Tipos de Evaluation:\n1. **Manual**: VocÃª mesmo avalia\n2. **AutomÃ¡tica**: Outra IA avalia\n3. **MÃ©tricas**: BLEU, ROUGE, etc.\n4. **Custom**: Suas prÃ³prias regras\n\n**Dica!** Use evaluation para comparar diferentes versÃµes do seu prompt!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulando uma evaluation automÃ¡tica\n",
        "def avaliar_sentimento(texto_original, resposta_ia):\n",
        "    \"\"\"\n",
        "    FunÃ§Ã£o que simula como o LangSmith avaliaria nossa anÃ¡lise de sentimento\n",
        "    \"\"\"\n",
        "    # Palavras que indicam sentimento conhecido\n",
        "    palavras_positivas = ['adorei', 'excelente', 'incrÃ­vel', 'superou', 'melhor']\n",
        "    palavras_negativas = ['pÃ©ssimo', 'decepÃ§Ã£o', 'problemas', 'ruim']\n",
        "    \n",
        "    texto_lower = texto_original.lower()\n",
        "    resposta_lower = resposta_ia.lower()\n",
        "    \n",
        "    # Determinar sentimento esperado\n",
        "    if any(palavra in texto_lower for palavra in palavras_positivas):\n",
        "        sentimento_esperado = 'positivo'\n",
        "    elif any(palavra in texto_lower for palavra in palavras_negativas):\n",
        "        sentimento_esperado = 'negativo'\n",
        "    else:\n",
        "        sentimento_esperado = 'neutro'\n",
        "    \n",
        "    # Verificar se a IA acertou\n",
        "    acertou = sentimento_esperado in resposta_lower\n",
        "    \n",
        "    # Calcular score (simulado)\n",
        "    score = 1.0 if acertou else 0.0\n",
        "    \n",
        "    return {\n",
        "        'esperado': sentimento_esperado,\n",
        "        'acertou': acertou,\n",
        "        'score': score,\n",
        "        'confianca': np.random.uniform(0.7, 0.95) if acertou else np.random.uniform(0.3, 0.6)\n",
        "    }\n",
        "\n",
        "print(\"ğŸ§ª FunÃ§Ã£o de evaluation criada!\")\n",
        "print(\"ğŸ“Š Agora vamos avaliar nossos resultados...\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Avaliando nossos resultados\n",
        "avaliacoes = []\n",
        "\n",
        "print(\"ğŸ” AVALIAÃ‡ÃƒO DOS RESULTADOS:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for resultado in sucessos:\n",
        "    avaliacao = avaliar_sentimento(resultado['texto'], resultado['resultado'])\n",
        "    avaliacoes.append(avaliacao)\n",
        "    \n",
        "    status = \"âœ… CORRETO\" if avaliacao['acertou'] else \"âŒ INCORRETO\"\n",
        "    print(f\"{status} | Score: {avaliacao['score']:.1f} | ConfianÃ§a: {avaliacao['confianca']:.2f}\")\n",
        "    print(f\"   Texto: {resultado['texto'][:40]}...\")\n",
        "    print(f\"   Esperado: {avaliacao['esperado'].title()}\")\n",
        "    print()\n",
        "\n",
        "# Calculando mÃ©tricas finais\n",
        "accuracy = np.mean([a['score'] for a in avaliacoes])\n",
        "confianca_media = np.mean([a['confianca'] for a in avaliacoes])\n",
        "\n",
        "print(f\"ğŸ“Š MÃ‰TRICAS FINAIS:\")\n",
        "print(f\"ğŸ¯ Accuracy: {accuracy:.2%}\")\n",
        "print(f\"ğŸ’ª ConfianÃ§a MÃ©dia: {confianca_media:.2%}\")\n",
        "print(f\"ğŸ“ˆ Total Avaliado: {len(avaliacoes)} execuÃ§Ãµes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸš¨ Monitoring e Alertas\n\nO LangSmith pode te avisar quando algo vai mal! Ã‰ tipo ter um WhatsApp que te manda mensagem quando sua IA tÃ¡ com problema.\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-17_img_05.png)\n\n### Tipos de Alertas:\n- **Alta LatÃªncia**: Quando demora muito\n- **Taxa de Erro**: Quando falha muito\n- **Custo Elevado**: Quando gasta muito\n- **Uso AnÃ´malo**: Quando algo estranho acontece\n\n**Dica!** Configure alertas antes de colocar em produÃ§Ã£o!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulando um sistema de monitoramento\n",
        "class MonitorLangSmith:\n",
        "    def __init__(self):\n",
        "        self.limites = {\n",
        "            'latencia_max': 3.0,  # segundos\n",
        "            'erro_rate_max': 0.05,  # 5%\n",
        "            'custo_diario_max': 10.0,  # USD\n",
        "            'tokens_por_min_max': 1000\n",
        "        }\n",
        "        self.alertas = []\n",
        "    \n",
        "    def verificar_metricas(self, latencias, erros, custos, tokens):\n",
        "        # Verificar latÃªncia\n",
        "        latencia_media = np.mean(latencias)\n",
        "        if latencia_media > self.limites['latencia_max']:\n",
        "            self.alertas.append(f\"ğŸš¨ ALERTA: LatÃªncia alta ({latencia_media:.2f}s)\")\n",
        "        \n",
        "        # Verificar taxa de erro\n",
        "        erro_rate = len(erros) / (len(sucessos) + len(erros))\n",
        "        if erro_rate > self.limites['erro_rate_max']:\n",
        "            self.alertas.append(f\"ğŸš¨ ALERTA: Taxa de erro alta ({erro_rate:.2%})\")\n",
        "        \n",
        "        # Verificar custo\n",
        "        custo_total = sum(custos)\n",
        "        if custo_total > self.limites['custo_diario_max']:\n",
        "            self.alertas.append(f\"ğŸ’° ALERTA: Custo elevado (${custo_total:.2f})\")\n",
        "        \n",
        "        # Verificar tokens por minuto\n",
        "        tokens_por_min = sum(tokens) / 10  # Simulando 10 minutos\n",
        "        if tokens_por_min > self.limites['tokens_por_min_max']:\n",
        "            self.alertas.append(f\"ğŸ“Š ALERTA: Uso alto de tokens ({tokens_por_min:.0f}/min)\")\n",
        "    \n",
        "    def gerar_relatorio(self):\n",
        "        if self.alertas:\n",
        "            print(\"ğŸš¨ ALERTAS DETECTADOS:\")\n",
        "            for alerta in self.alertas:\n",
        "                print(f\"   {alerta}\")\n",
        "        else:\n",
        "            print(\"âœ… Tudo funcionando perfeitamente!\")\n",
        "\n",
        "# Testando o monitor\n",
        "monitor = MonitorLangSmith()\n",
        "\n",
        "# Dados simulados\n",
        "custos_simulados = np.random.uniform(0.001, 0.005, len(sucessos))\n",
        "\n",
        "monitor.verificar_metricas(\n",
        "    latencias_simuladas,\n",
        "    erros,\n",
        "    custos_simulados,\n",
        "    tokens_simulados\n",
        ")\n",
        "\n",
        "monitor.gerar_relatorio()\n",
        "\n",
        "print(f\"\\nğŸ“Š MÃ©tricas Atuais:\")\n",
        "print(f\"â±ï¸  LatÃªncia mÃ©dia: {np.mean(latencias_simuladas):.2f}s\")\n",
        "print(f\"âŒ Taxa de erro: {len(erros)/(len(sucessos)+len(erros)):.2%}\")\n",
        "print(f\"ğŸ’° Custo total: ${sum(custos_simulados):.4f}\")\n",
        "print(f\"ğŸ¯ Tokens/min: {sum(tokens_simulados)/10:.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”§ Debugging com LangSmith\n\nQuando algo dÃ¡ errado (e sempre dÃ¡ ğŸ˜…), o LangSmith Ã© seu melhor amigo!\n\n### Como debuggar:\n1. **Encontre o erro no trace**\n2. **Veja o input que causou**\n3. **Analise cada step**\n4. **Teste correÃ§Ãµes**\n5. **Compare resultados**\n\n**Dica!** Use os filtros do dashboard para encontrar erros rapidamente!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulando um processo de debugging\n",
        "def debug_execucao_falhada():\n",
        "    print(\"ğŸ› SIMULAÃ‡ÃƒO DE DEBUGGING\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Simulando um erro comum\n",
        "    erro_exemplo = {\n",
        "        \"run_id\": \"erro-123-abc\",\n",
        "        \"input\": \"Analyze this sentiment: [TEXTO MUITO LONGO COM 50000 CARACTERES...]\",\n",
        "        \"error\": \"TokenLimitExceededError: Input too long (50000 > 32000 tokens)\",\n",
        "        \"timestamp\": \"2024-01-15T15:30:00Z\",\n",
        "        \"step_failed\": \"ChatGoogleGenerativeAI\"\n",
        "    }\n",
        "    \n",
        "    print(f\"âŒ ERRO DETECTADO:\")\n",
        "    print(f\"   ID: {erro_exemplo['run_id']}\")\n",
        "    print(f\"   Erro: {erro_exemplo['error']}\")\n",
        "    print(f\"   Step que falhou: {erro_exemplo['step_failed']}\")\n",
        "    \n",
        "    print(f\"\\nğŸ” ANÃLISE DO PROBLEMA:\")\n",
        "    print(f\"   â¤ Input muito grande (>32k tokens)\")\n",
        "    print(f\"   â¤ Modelo tem limite de contexto\")\n",
        "    print(f\"   â¤ Precisa de text splitter\")\n",
        "    \n",
        "    print(f\"\\nğŸ’¡ SOLUÃ‡Ã•ES PROPOSTAS:\")\n",
        "    print(f\"   1. Implementar text splitter (MÃ³dulo 8)\")\n",
        "    print(f\"   2. Resumir texto antes de analisar\")\n",
        "    print(f\"   3. Usar modelo com contexto maior\")\n",
        "    print(f\"   4. Processar em chunks menores\")\n",
        "    \n",
        "    return erro_exemplo\n",
        "\n",
        "erro = debug_execucao_falhada()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ˆ Comparando VersÃµes e A/B Testing\n\nUma das funcionalidades mais **poderosas** do LangSmith Ã© comparar diferentes versÃµes!\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-17_img_06.png)\n\n### O que vocÃª pode comparar:\n- **Diferentes prompts**\n- **Modelos diferentes**\n- **VersÃµes da sua aplicaÃ§Ã£o**\n- **ParÃ¢metros (temperatura, etc.)**\n\n**Dica!** Sempre teste antes de fazer deploy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulando A/B Testing entre dois prompts\n",
        "prompt_v1 = \"\"\"\n",
        "Analise o sentimento do texto: {texto}\n",
        "Responda apenas: Positivo, Neutro ou Negativo\n",
        "\"\"\"\n",
        "\n",
        "prompt_v2 = \"\"\"\n",
        "VocÃª Ã© um especialista em anÃ¡lise de sentimentos.\n",
        "Analise cuidadosamente o texto abaixo e determine:\n",
        "1. Sentimento (Positivo/Neutro/Negativo)\n",
        "2. ConfianÃ§a (0-100%)\n",
        "3. Justificativa\n",
        "\n",
        "Texto: {texto}\n",
        "\"\"\"\n",
        "\n",
        "# Simulando mÃ©tricas para cada versÃ£o\n",
        "metricas_v1 = {\n",
        "    \"accuracy\": 0.75,\n",
        "    \"latencia_media\": 0.8,\n",
        "    \"tokens_medio\": 25,\n",
        "    \"custo_medio\": 0.0008,\n",
        "    \"satisfacao_usuario\": 3.2\n",
        "}\n",
        "\n",
        "metricas_v2 = {\n",
        "    \"accuracy\": 0.92,\n",
        "    \"latencia_media\": 1.4,\n",
        "    \"tokens_medio\": 65,\n",
        "    \"custo_medio\": 0.0021,\n",
        "    \"satisfacao_usuario\": 4.6\n",
        "}\n",
        "\n",
        "print(\"ğŸ†š COMPARAÃ‡ÃƒO A/B TESTING\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"ğŸ“Š Prompt V1 (Simples):\")\n",
        "for metrica, valor in metricas_v1.items():\n",
        "    print(f\"   {metrica}: {valor}\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Prompt V2 (Detalhado):\")\n",
        "for metrica, valor in metricas_v2.items():\n",
        "    print(f\"   {metrica}: {valor}\")\n",
        "\n",
        "print(f\"\\nğŸ† VENCEDOR: Prompt V2\")\n",
        "print(f\"   âœ… Maior accuracy (+17%)\")\n",
        "print(f\"   âœ… Melhor satisfaÃ§Ã£o (+44%)\")\n",
        "print(f\"   âŒ Maior latÃªncia (+75%)\")\n",
        "print(f\"   âŒ Maior custo (+162%)\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Visualizando a comparaÃ§Ã£o\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "metricas = ['accuracy', 'latencia_media', 'custo_medio', 'satisfacao_usuario']\n",
        "titulos = ['Accuracy', 'LatÃªncia MÃ©dia (s)', 'Custo MÃ©dio ($)', 'SatisfaÃ§Ã£o do UsuÃ¡rio']\n",
        "cores = ['#2ecc71', '#e74c3c', '#f39c12', '#9b59b6']\n",
        "\n",
        "for i, (metrica, titulo, cor) in enumerate(zip(metricas, titulos, cores)):\n",
        "    ax = axes[i//2, i%2]\n",
        "    \n",
        "    v1_valor = metricas_v1[metrica]\n",
        "    v2_valor = metricas_v2[metrica]\n",
        "    \n",
        "    ax.bar(['Prompt V1', 'Prompt V2'], [v1_valor, v2_valor], \n",
        "           color=[cor, cor], alpha=[0.6, 1.0], edgecolor='black')\n",
        "    \n",
        "    ax.set_title(titulo, fontsize=12, pad=15)\n",
        "    ax.set_ylabel('Valor')\n",
        "    \n",
        "    # Adicionar valores nas barras\n",
        "    for j, valor in enumerate([v1_valor, v2_valor]):\n",
        "        ax.text(j, valor + valor*0.05, f'{valor}', ha='center', fontweight='bold')\n",
        "\n",
        "plt.suptitle('ComparaÃ§Ã£o A/B Testing: Prompt V1 vs V2', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ“Š Esse tipo de comparaÃ§Ã£o Ã© automÃ¡tica no LangSmith!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ’° Controle de Custos e OtimizaÃ§Ã£o\n\nLangSmith te ajuda a nÃ£o quebrar o orÃ§amento! Ã‰ tipo ter um contador sempre de olho nos gastos.\n\n### MÃ©tricas de Custo:\n- **Custo por execuÃ§Ã£o**\n- **Custo por usuÃ¡rio**\n- **Custo por dia/mÃªs**\n- **ProjeÃ§Ãµes de gasto**\n- **OtimizaÃ§Ãµes sugeridas**\n\n**Dica!** Configure limites de gasto para nÃ£o ter surpresas!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulando anÃ¡lise de custos\n",
        "def analisar_custos():\n",
        "    # Simulando dados de uma semana\n",
        "    dias = ['Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'SÃ¡b', 'Dom']\n",
        "    execucoes_por_dia = [150, 200, 180, 220, 250, 100, 80]\n",
        "    custo_por_execucao = [0.0015, 0.0012, 0.0018, 0.0011, 0.0020, 0.0014, 0.0016]\n",
        "    \n",
        "    custos_diarios = [exec * custo for exec, custo in zip(execucoes_por_dia, custo_por_execucao)]\n",
        "    \n",
        "    # AnÃ¡lise\n",
        "    custo_total_semana = sum(custos_diarios)\n",
        "    custo_medio_dia = np.mean(custos_diarios)\n",
        "    projecao_mensal = custo_total_semana * 4.33  # 4.33 semanas por mÃªs\n",
        "    \n",
        "    print(\"ğŸ’° ANÃLISE DE CUSTOS - ÃšLTIMA SEMANA\")\n",
        "    print(\"=\" * 45)\n",
        "    \n",
        "    for dia, execucoes, custo_dia in zip(dias, execucoes_por_dia, custos_diarios):\n",
        "        print(f\"{dia}: {execucoes:3d} execuÃ§Ãµes = ${custo_dia:.4f}\")\n",
        "    \n",
        "    print(f\"\\nğŸ“Š RESUMO:\")\n",
        "    print(f\"   Total da semana: ${custo_total_semana:.4f}\")\n",
        "    print(f\"   MÃ©dia por dia: ${custo_medio_dia:.4f}\")\n",
        "    print(f\"   ProjeÃ§Ã£o mensal: ${projecao_mensal:.2f}\")\n",
        "    \n",
        "    # Alertas e sugestÃµes\n",
        "    if projecao_mensal > 50:\n",
        "        print(f\"\\nğŸš¨ ALERTA: ProjeÃ§Ã£o alta para o mÃªs!\")\n",
        "        print(f\"ğŸ’¡ SugestÃµes:\")\n",
        "        print(f\"   - Otimizar prompts (reduzir tokens)\")\n",
        "        print(f\"   - Usar cache para respostas repetidas\")\n",
        "        print(f\"   - Implementar rate limiting\")\n",
        "    else:\n",
        "        print(f\"\\nâœ… Custos sob controle!\")\n",
        "    \n",
        "    return dias, execucoes_por_dia, custos_diarios\n",
        "\n",
        "dias, execucoes, custos = analisar_custos()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# VisualizaÃ§Ã£o dos custos\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# GrÃ¡fico 1: Custos por dia\n",
        "bars1 = ax1.bar(dias, custos, color='#e74c3c', alpha=0.7, edgecolor='black')\n",
        "ax1.set_title('Custos DiÃ¡rios', fontsize=14, pad=15)\n",
        "ax1.set_ylabel('Custo ($)')\n",
        "ax1.set_xlabel('Dia da Semana')\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for bar, custo in zip(bars1, custos):\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + height*0.05,\n",
        "             f'${custo:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# GrÃ¡fico 2: ExecuÃ§Ãµes vs Custo\n",
        "ax2.scatter(execucoes, custos, c=range(len(dias)), s=100, alpha=0.7, \n",
        "           cmap='viridis', edgecolors='black')\n",
        "\n",
        "# Adicionar linha de tendÃªncia\n",
        "z = np.polyfit(execucoes, custos, 1)\n",
        "p = np.poly1d(z)\n",
        "ax2.plot(execucoes, p(execucoes), \"r--\", alpha=0.8, linewidth=2)\n",
        "\n",
        "ax2.set_title('ExecuÃ§Ãµes vs Custo', fontsize=14, pad=15)\n",
        "ax2.set_xlabel('NÃºmero de ExecuÃ§Ãµes')\n",
        "ax2.set_ylabel('Custo ($)')\n",
        "\n",
        "# Adicionar labels dos dias\n",
        "for i, (exec_count, custo, dia) in enumerate(zip(execucoes, custos, dias)):\n",
        "    ax2.annotate(dia, (exec_count, custo), xytext=(5, 5), \n",
        "                textcoords='offset points', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ“Š No LangSmith vocÃª tem esses grÃ¡ficos atualizados em tempo real!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ‹ï¸â€â™‚ï¸ ExercÃ­cio PrÃ¡tico: Implementando Monitoramento Completo\n\nBora colocar a mÃ£o na massa! Vamos criar um sistema de monitoramento completo para uma aplicaÃ§Ã£o RAG!\n\n**Desafio**: Implementar monitoramento para um sistema que responde perguntas sobre documentos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# EXERCÃCIO: Complete o cÃ³digo abaixo\n",
        "# Vamos simular uma aplicaÃ§Ã£o RAG com monitoramento\n",
        "\n",
        "class SistemaRAGMonitorado:\n",
        "    def __init__(self):\n",
        "        self.metricas = {\n",
        "            'total_queries': 0,\n",
        "            'sucessos': 0,\n",
        "            'erros': 0,\n",
        "            'tempo_total': 0,\n",
        "            'custo_total': 0,\n",
        "            'historico': []\n",
        "        }\n",
        "    \n",
        "    def processar_query(self, pergunta, documentos):\n",
        "        \"\"\"Simula processamento de uma query RAG\"\"\"\n",
        "        import time\n",
        "        import random\n",
        "        \n",
        "        inicio = time.time()\n",
        "        self.metricas['total_queries'] += 1\n",
        "        \n",
        "        try:\n",
        "            # Simula processamento RAG\n",
        "            time.sleep(random.uniform(0.1, 0.5))  # Simula tempo de processamento\n",
        "            \n",
        "            # TODO: Adicione aqui a lÃ³gica de processamento real\n",
        "            # Dica: Use os conceitos do MÃ³dulo 10 (RAG)\n",
        "            \n",
        "            resposta = f\"Baseado nos documentos, a resposta para '{pergunta[:30]}...' Ã©: [RESPOSTA SIMULADA]\"\n",
        "            \n",
        "            # MÃ©tricas de sucesso\n",
        "            tempo_execucao = time.time() - inicio\n",
        "            custo_estimado = random.uniform(0.002, 0.008)\n",
        "            \n",
        "            self.metricas['sucessos'] += 1\n",
        "            self.metricas['tempo_total'] += tempo_execucao\n",
        "            self.metricas['custo_total'] += custo_estimado\n",
        "            \n",
        "            # TODO: Adicione mais mÃ©tricas aqui\n",
        "            # - RelevÃ¢ncia da resposta\n",
        "            # - SatisfaÃ§Ã£o do usuÃ¡rio\n",
        "            # - Documentos utilizados\n",
        "            \n",
        "            self.metricas['historico'].append({\n",
        "                'pergunta': pergunta,\n",
        "                'resposta': resposta,\n",
        "                'tempo': tempo_execucao,\n",
        "                'custo': custo_estimado,\n",
        "                'status': 'sucesso',\n",
        "                'timestamp': datetime.now()\n",
        "            })\n",
        "            \n",
        "            return resposta\n",
        "            \n",
        "        except Exception as e:\n",
        "            # Tratamento de erro\n",
        "            self.metricas['erros'] += 1\n",
        "            \n",
        "            self.metricas['historico'].append({\n",
        "                'pergunta': pergunta,\n",
        "                'resposta': None,\n",
        "                'tempo': time.time() - inicio,\n",
        "                'custo': 0,\n",
        "                'status': 'erro',\n",
        "                'erro': str(e),\n",
        "                'timestamp': datetime.now()\n",
        "            })\n",
        "            \n",
        "            raise e\n",
        "    \n",
        "    def gerar_dashboard(self):\n",
        "        \"\"\"Gera um dashboard de mÃ©tricas\"\"\"\n",
        "        print(\"ğŸ“Š DASHBOARD DE MONITORAMENTO RAG\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        # TODO: Complete as mÃ©tricas\n",
        "        taxa_sucesso = self.metricas['sucessos'] / max(self.metricas['total_queries'], 1)\n",
        "        tempo_medio = self.metricas['tempo_total'] / max(self.metricas['sucessos'], 1)\n",
        "        custo_medio = self.metricas['custo_total'] / max(self.metricas['sucessos'], 1)\n",
        "        \n",
        "        print(f\"ğŸ“ˆ Total de Queries: {self.metricas['total_queries']}\")\n",
        "        print(f\"âœ… Taxa de Sucesso: {taxa_sucesso:.2%}\")\n",
        "        print(f\"â±ï¸  Tempo MÃ©dio: {tempo_medio:.2f}s\")\n",
        "        print(f\"ğŸ’° Custo MÃ©dio: ${custo_medio:.4f}\")\n",
        "        print(f\"ğŸ’¸ Custo Total: ${self.metricas['custo_total']:.4f}\")\n",
        "        \n",
        "        # TODO: Adicione mais mÃ©tricas aqui\n",
        "        \n",
        "        return {\n",
        "            'taxa_sucesso': taxa_sucesso,\n",
        "            'tempo_medio': tempo_medio,\n",
        "            'custo_medio': custo_medio\n",
        "        }\n",
        "\n",
        "# Testando o sistema\n",
        "sistema = SistemaRAGMonitorado()\n",
        "print(\"ğŸš€ Sistema RAG com monitoramento criado!\")\n",
        "print(\"ğŸ’¡ Agora complete as partes marcadas com TODO\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Testando o sistema com queries simuladas\n",
        "queries_teste = [\n",
        "    \"Qual Ã© a polÃ­tica de devoluÃ§Ã£o?\",\n",
        "    \"Como funciona o sistema de pagamento?\",\n",
        "    \"Quais sÃ£o os horÃ¡rios de funcionamento?\",\n",
        "    \"Como posso entrar em contato?\",\n",
        "    \"Qual Ã© o prazo de entrega?\"\n",
        "]\n",
        "\n",
        "documentos_simulados = [\n",
        "    \"Documento sobre polÃ­ticas da empresa\",\n",
        "    \"Manual do usuÃ¡rio\",\n",
        "    \"FAQ do sistema\"\n",
        "]\n",
        "\n",
        "print(\"ğŸ§ª TESTANDO SISTEMA RAG MONITORADO\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "for i, query in enumerate(queries_teste):\n",
        "    print(f\"\\nğŸ” Query {i+1}: {query}\")\n",
        "    try:\n",
        "        resposta = sistema.processar_query(query, documentos_simulados)\n",
        "        print(f\"âœ… Processada com sucesso!\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "metricas_finais = sistema.gerar_dashboard()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸŒŸ ResumÃ£o: O que Aprendemos sobre LangSmith\n\nLiiindo! Chegamos ao final do nosso curso completo! ğŸ‰\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-17_img_07.png)\n\n### ğŸ¯ O que o LangSmith faz por vocÃª:\n\n1. **ğŸ” Tracing Completo**: VÃª cada passo da sua aplicaÃ§Ã£o\n2. **ğŸ“Š MÃ©tricas Detalhadas**: Performance, custo, accuracy\n3. **ğŸš¨ Monitoramento**: Alertas quando algo vai mal\n4. **ğŸ§ª Evaluation**: Testa se sua IA estÃ¡ funcionando\n5. **ğŸ†š A/B Testing**: Compara diferentes versÃµes\n6. **ğŸ’° Controle de Custos**: NÃ£o quebra o orÃ§amento\n7. **ğŸ› Debugging**: Encontra e corrige problemas\n\n### ğŸ“š Jornada Completa do Curso:\n- **MÃ³dulos 1-6**: Fundamentos (Chat, Prompts, Chains)\n- **MÃ³dulos 7-10**: AvanÃ§ado (Memory, RAG, Vectors)\n- **MÃ³dulos 11-14**: AplicaÃ§Ãµes (Agents, Projetos, Deploy)\n- **MÃ³dulos 15-17**: EvoluÃ§Ã£o (v1.0, LangGraph, LangSmith)\n\n**Dica Final!** LangSmith Ã© essencial para produÃ§Ã£o. Use sempre!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# VisualizaÃ§Ã£o final: Jornada do curso\n",
        "modulos = [\n",
        "    'Intro', 'ChatModel', 'LCEL', 'Prompts', 'Parsers', \n",
        "    'Chains', 'Memory', 'Docs', 'Vectors', 'RAG', \n",
        "    'Agents', 'Proj1', 'Proj2', 'Deploy', 'v1.0', \n",
        "    'LangGraph', 'LangSmith'\n",
        "]\n",
        "\n",
        "complexidade = [1, 2, 3, 2, 2, 4, 5, 4, 6, 7, 8, 9, 9, 7, 6, 8, 6]\n",
        "utilidade = [8, 9, 7, 9, 6, 8, 7, 6, 8, 9, 8, 10, 10, 9, 7, 8, 9]\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10))\n",
        "\n",
        "# GrÃ¡fico 1: EvoluÃ§Ã£o da complexidade\n",
        "ax1.plot(range(len(modulos)), complexidade, 'o-', linewidth=3, markersize=8, \n",
        "         color='#e74c3c', label='Complexidade')\n",
        "ax1.fill_between(range(len(modulos)), complexidade, alpha=0.3, color='#e74c3c')\n",
        "ax1.set_title('EvoluÃ§Ã£o da Complexidade ao Longo do Curso', fontsize=16, pad=20)\n",
        "ax1.set_ylabel('NÃ­vel de Complexidade (1-10)')\n",
        "ax1.set_xticks(range(len(modulos)))\n",
        "ax1.set_xticklabels(modulos, rotation=45, ha='right')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend()\n",
        "\n",
        "# Destacar mÃ³dulos especiais\n",
        "especiais = [9, 10, 11, 15, 16]  # RAG, Projetos, LangGraph, LangSmith\n",
        "for idx in especiais:\n",
        "    ax1.annotate(f'ğŸŒŸ {modulos[idx]}', \n",
        "                xy=(idx, complexidade[idx]), \n",
        "                xytext=(10, 10), textcoords='offset points',\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),\n",
        "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
        "\n",
        "# GrÃ¡fico 2: Utilidade prÃ¡tica\n",
        "bars = ax2.bar(range(len(modulos)), utilidade, \n",
        "               color=['#2ecc71' if u >= 8 else '#f39c12' if u >= 6 else '#95a5a6' for u in utilidade],\n",
        "               alpha=0.8, edgecolor='black')\n",
        "\n",
        "ax2.set_title('Utilidade PrÃ¡tica de Cada MÃ³dulo', fontsize=16, pad=20)\n",
        "ax2.set_ylabel('Utilidade PrÃ¡tica (1-10)')\n",
        "ax2.set_xticks(range(len(modulos)))\n",
        "ax2.set_xticklabels(modulos, rotation=45, ha='right')\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for bar, util in zip(bars, utilidade):\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
        "             f'{util}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ“ PARABÃ‰NS! VocÃª completou todo o curso LangChain!\")\n",
        "print(\"ğŸš€ Agora vocÃª estÃ¡ pronto para criar aplicaÃ§Ãµes de IA incrÃ­veis!\")\n",
        "print(\"ğŸ“Š E o melhor: sabe como monitorar e manter elas funcionando!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ PrÃ³ximos Passos e Recursos\n\nTÃ¡, mas e agora? Como continuar evoluindo?\n\n### ğŸ”— Links Importantes:\n- **LangSmith**: [smith.langchain.com](https://smith.langchain.com)\n- **DocumentaÃ§Ã£o**: [docs.smith.langchain.com](https://docs.smith.langchain.com)\n- **LangChain**: [python.langchain.com](https://python.langchain.com)\n- **Community**: [discord.gg/langchain](https://discord.gg/langchain)\n\n### ğŸ› ï¸ Projetos para Praticar:\n1. **Chatbot com Monitoramento**: Use LangSmith desde o inÃ­cio\n2. **Sistema RAG Otimizado**: Compare diferentes estratÃ©gias\n3. **Agent Multi-Tool**: Monitore performance de cada tool\n4. **A/B Testing de Prompts**: Teste melhorias continuamente\n\n### ğŸ“š Continue Aprendendo:\n- **LangServe**: Para APIs em produÃ§Ã£o\n- **LangChain Templates**: Projetos prontos\n- **Fine-tuning**: Personalize modelos\n- **Multi-modal**: Texto + imagem + Ã¡udio\n\n**Dica Final!** A IA evolui rÃ¡pido. Continue estudando e praticando!\n\n---\n\n**Muito obrigado por acompanhar todo o curso!** ğŸ™\n\n**Pedro Nunes Guth** ğŸš€\n\n*\"A melhor forma de prever o futuro Ã© construÃ­-lo!\"*"
      ]
    }
  ]
}
