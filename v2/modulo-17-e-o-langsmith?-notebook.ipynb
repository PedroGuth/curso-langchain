{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîç LangSmith: O Sherlock Holmes das suas Aplica√ß√µes LangChain!\n\n**M√≥dulo 17 - Curso LangChain v0.3**\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-17_img_01.png)\n\nBora para o √∫ltimo m√≥dulo galera! T√°, j√° aprendemos a criar, agora vamos aprender a **MONITORAR** e **DEBUGGAR** nossas aplica√ß√µes!\n\n**Pedro Nunes Guth** üöÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§î T√°, mas o que √© o LangSmith?\n\nImagina que voc√™ tem um restaurante (sua aplica√ß√£o LangChain). Voc√™ sabe fazer a comida, mas como saber:\n- Quais pratos os clientes mais gostaram?\n- Onde a cozinha est√° demorada?\n- Qual gar√ßom est√° errando os pedidos?\n- Quanto est√° custando cada prato?\n\n**LangSmith √© seu sistema de monitoramento completo!**\n\n### O que o LangSmith faz:\n1. **Tracing**: Acompanha cada passo da sua chain\n2. **Logging**: Registra tudo que acontece\n3. **Evaluation**: Testa se sua IA est√° funcionando bem\n4. **Monitoring**: Alerta quando algo vai mal\n5. **Debugging**: Mostra onde est√° o problema\n\n**Dica!** √â tipo um Google Analytics para suas aplica√ß√µes de IA!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vamos instalar o que precisamos\n",
        "!pip install langsmith langchain-google-genai python-dotenv matplotlib seaborn -q\n",
        "\n",
        "print(\"üì¶ Pacotes instalados!\")\n",
        "print(\"üîë Agora voc√™ vai precisar de uma conta no LangSmith (smith.langchain.com)\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Imports necess√°rios\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "\n",
        "# Configurar estilo dos gr√°ficos\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üìä Bibliotecas carregadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Configurando o LangSmith\n\nPrimeiro, voc√™ precisa:\n1. Criar uma conta em [smith.langchain.com](https://smith.langchain.com)\n2. Pegar sua API Key\n3. Configurar as vari√°veis de ambiente\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-17_img_02.png)\n\n**Dica!** √â de gra√ßa para uso pessoal e pequenos projetos!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Carregando as vari√°veis de ambiente\n",
        "load_dotenv()\n",
        "\n",
        "# Configura√ß√µes do LangSmith\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"  # Habilita o tracing\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"meu-projeto-langchain\"  # Nome do projeto\n",
        "\n",
        "# Suas chaves (substitua pelos valores reais)\n",
        "# os.environ[\"LANGCHAIN_API_KEY\"] = \"sua_langsmith_api_key_aqui\"\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = \"sua_google_api_key_aqui\"\n",
        "\n",
        "print(\"üîß Configura√ß√µes do LangSmith definidas!\")\n",
        "print(f\"üìã Projeto: {os.environ.get('LANGCHAIN_PROJECT')}\")\n",
        "print(f\"üîç Tracing: {os.environ.get('LANGCHAIN_TRACING_V2')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Criando uma Aplica√ß√£o para Monitorar\n\nVamos criar uma aplica√ß√£o simples usando os conceitos que j√° aprendemos no curso:\n- **ChatModel** (M√≥dulo 2)\n- **PromptTemplate** (M√≥dulo 4)\n- **Chains** (M√≥dulo 6)\n- **RAG** (M√≥dulo 10)\n\n### Fluxo da Nossa Aplica√ß√£o:\n```mermaid\ngraph TD\n    A[Pergunta do Usu√°rio] --> B[Chain de An√°lise]\n    B --> C[Modelo Gemini]\n    C --> D[Resposta Processada]\n    D --> E[LangSmith Monitoring]\n    E --> F[Dashboard]\n```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "\n",
        "# Criando o modelo (lembrando do M√≥dulo 2)\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# Criando o prompt template (lembrando do M√≥dulo 4)\n",
        "prompt_template = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    Voc√™ √© um assistente especializado em an√°lise de sentimentos.\n",
        "    \n",
        "    Analise o texto abaixo e forne√ßa:\n",
        "    1. Sentimento (Positivo/Neutro/Negativo)\n",
        "    2. Confian√ßa (0-100%)\n",
        "    3. Palavras-chave que influenciaram sua decis√£o\n",
        "    \n",
        "    Texto: {texto}\n",
        "    \n",
        "    Resposta:\n",
        "    \"\"\",\n",
        "    input_variables=[\"texto\"]\n",
        ")\n",
        "\n",
        "print(\"ü§ñ Modelo e template criados!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Criando a chain (lembrando do M√≥dulo 6)\n",
        "chain_analise_sentimento = (\n",
        "    {\"texto\": RunnablePassthrough()}\n",
        "    | prompt_template\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"‚õìÔ∏è Chain criada!\")\n",
        "print(\"üéØ Agora todas as execu√ß√µes ser√£o monitoradas pelo LangSmith\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Testando com Monitoramento Ativo\n\nAgora vamos executar nossa chain v√°rias vezes para gerar dados no LangSmith!\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-17_img_03.png)\n\n**Dica!** Cada execu√ß√£o ser√° automaticamente logada no LangSmith!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Lista de textos para testar nossa aplica√ß√£o\n",
        "textos_teste = [\n",
        "    \"Adorei este produto! Superou minhas expectativas!\",\n",
        "    \"O atendimento foi p√©ssimo, n√£o recomendo.\",\n",
        "    \"O produto chegou no prazo esperado.\",\n",
        "    \"Incr√≠vel! Melhor compra que j√° fiz na vida!\",\n",
        "    \"Tive problemas com a entrega, mas o produto √© bom.\",\n",
        "    \"Funcionou conforme descrito na embalagem.\",\n",
        "    \"Que decep√ß√£o! Nada do que foi prometido.\",\n",
        "    \"Excelente qualidade, vale cada centavo!\"\n",
        "]\n",
        "\n",
        "print(f\"üìù Temos {len(textos_teste)} textos para analisar\")\n",
        "print(\"üîÑ Cada execu√ß√£o ser√° trackeada pelo LangSmith!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Executando as an√°lises (isso gerar√° traces no LangSmith)\n",
        "resultados = []\n",
        "\n",
        "for i, texto in enumerate(textos_teste):\n",
        "    print(f\"\\nüîç Analisando texto {i+1}/{len(textos_teste)}...\")\n",
        "    print(f\"üìÑ Texto: {texto[:50]}...\")\n",
        "    \n",
        "    try:\n",
        "        # Esta execu√ß√£o ser√° automaticamente trackeada!\n",
        "        resultado = chain_analise_sentimento.invoke(texto)\n",
        "        resultados.append({\n",
        "            \"texto\": texto,\n",
        "            \"resultado\": resultado,\n",
        "            \"status\": \"sucesso\"\n",
        "        })\n",
        "        print(\"‚úÖ An√°lise conclu√≠da!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro na an√°lise: {e}\")\n",
        "        resultados.append({\n",
        "            \"texto\": texto,\n",
        "            \"resultado\": None,\n",
        "            \"status\": \"erro\",\n",
        "            \"erro\": str(e)\n",
        "        })\n",
        "\n",
        "print(f\"\\nüéØ Processamento conclu√≠do! {len(resultados)} an√°lises realizadas\")\n",
        "print(\"üìä Verifique seu dashboard do LangSmith para ver os traces!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä An√°lise Local dos Resultados\n\nEnquanto o LangSmith coleta os dados detalhados, vamos fazer uma an√°lise local dos nossos resultados!\n\n### M√©tricas que o LangSmith coleta automaticamente:\n- **Lat√™ncia**: Tempo de resposta\n- **Tokens**: Consumo de tokens de entrada e sa√≠da\n- **Custo**: Quanto cada execu√ß√£o custou\n- **Erros**: Taxa de falha\n- **Traces**: Fluxo completo da execu√ß√£o\n\n**Dica!** No dashboard voc√™ v√™ tudo isso em tempo real!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Analisando os resultados localmente\n",
        "sucessos = [r for r in resultados if r[\"status\"] == \"sucesso\"]\n",
        "erros = [r for r in resultados if r[\"status\"] == \"erro\"]\n",
        "\n",
        "print(f\"üìà Relat√≥rio de Execu√ß√£o:\")\n",
        "print(f\"‚úÖ Sucessos: {len(sucessos)} ({len(sucessos)/len(resultados)*100:.1f}%)\")\n",
        "print(f\"‚ùå Erros: {len(erros)} ({len(erros)/len(resultados)*100:.1f}%)\")\n",
        "\n",
        "# Simulando m√©tricas de performance\n",
        "latencias_simuladas = np.random.normal(1.2, 0.3, len(sucessos))  # Segundos\n",
        "tokens_simulados = np.random.randint(50, 200, len(sucessos))     # Tokens\n",
        "\n",
        "print(f\"\\n‚è±Ô∏è Performance Simulada:\")\n",
        "print(f\"üìä Lat√™ncia m√©dia: {np.mean(latencias_simuladas):.2f}s\")\n",
        "print(f\"üéØ Tokens m√©dios: {np.mean(tokens_simulados):.0f} tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Criando visualiza√ß√µes como as que voc√™ veria no LangSmith\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Gr√°fico 1: Taxa de Sucesso\n",
        "labels = ['Sucessos', 'Erros']\n",
        "sizes = [len(sucessos), len(erros)]\n",
        "colors = ['#2ecc71', '#e74c3c']\n",
        "ax1.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "ax1.set_title('Taxa de Sucesso das Execu√ß√µes', fontsize=14, pad=20)\n",
        "\n",
        "# Gr√°fico 2: Distribui√ß√£o de Lat√™ncia\n",
        "ax2.hist(latencias_simuladas, bins=10, color='#3498db', alpha=0.7, edgecolor='black')\n",
        "ax2.set_title('Distribui√ß√£o de Lat√™ncia', fontsize=14, pad=20)\n",
        "ax2.set_xlabel('Tempo (segundos)')\n",
        "ax2.set_ylabel('Frequ√™ncia')\n",
        "ax2.axvline(np.mean(latencias_simuladas), color='red', linestyle='--', label=f'M√©dia: {np.mean(latencias_simuladas):.2f}s')\n",
        "ax2.legend()\n",
        "\n",
        "# Gr√°fico 3: Consumo de Tokens\n",
        "ax3.bar(range(len(tokens_simulados)), tokens_simulados, color='#9b59b6', alpha=0.7)\n",
        "ax3.set_title('Consumo de Tokens por Execu√ß√£o', fontsize=14, pad=20)\n",
        "ax3.set_xlabel('Execu√ß√£o')\n",
        "ax3.set_ylabel('Tokens Utilizados')\n",
        "ax3.axhline(np.mean(tokens_simulados), color='red', linestyle='--', label=f'M√©dia: {np.mean(tokens_simulados):.0f}')\n",
        "ax3.legend()\n",
        "\n",
        "# Gr√°fico 4: Timeline de Execu√ß√µes\n",
        "horarios = [datetime.now() - timedelta(minutes=x*2) for x in range(len(sucessos))]\n",
        "ax4.plot(horarios, latencias_simuladas, 'o-', color='#e67e22', linewidth=2, markersize=6)\n",
        "ax4.set_title('Timeline de Performance', fontsize=14, pad=20)\n",
        "ax4.set_xlabel('Tempo')\n",
        "ax4.set_ylabel('Lat√™ncia (s)')\n",
        "ax4.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Esses s√£o os tipos de gr√°ficos que voc√™ v√™ no LangSmith dashboard!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Tracing Detalhado: O Que Acontece Sob o Cap√¥\n\nO **Tracing** √© a funcionalidade mais poderosa do LangSmith. √â como ter raio-X da sua aplica√ß√£o!\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-17_img_04.png)\n\n### O que o Trace mostra:\n1. **Input**: O que entrou\n2. **Steps**: Cada passo da chain\n3. **Output**: O que saiu\n4. **Timing**: Quanto tempo cada parte demorou\n5. **Metadata**: Informa√ß√µes extras (tokens, modelo usado, etc.)\n\n**Dica!** √â tipo o \"Inspect Element\" do navegador, mas para IA!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulando um trace detalhado (como voc√™ veria no LangSmith)\n",
        "exemplo_trace = {\n",
        "    \"run_id\": \"abc-123-def-456\",\n",
        "    \"name\": \"chain_analise_sentimento\",\n",
        "    \"start_time\": \"2024-01-15T10:30:00Z\",\n",
        "    \"end_time\": \"2024-01-15T10:30:02Z\",\n",
        "    \"duration_ms\": 2000,\n",
        "    \"inputs\": {\n",
        "        \"texto\": \"Adorei este produto! Superou minhas expectativas!\"\n",
        "    },\n",
        "    \"outputs\": {\n",
        "        \"content\": \"Sentimento: Positivo\\nConfian√ßa: 95%\\nPalavras-chave: adorei, superou, expectativas\"\n",
        "    },\n",
        "    \"metadata\": {\n",
        "        \"model\": \"gemini-2.0-flash-exp\",\n",
        "        \"tokens_input\": 45,\n",
        "        \"tokens_output\": 23,\n",
        "        \"cost_usd\": 0.0012\n",
        "    },\n",
        "    \"children\": [\n",
        "        {\n",
        "            \"name\": \"PromptTemplate\",\n",
        "            \"duration_ms\": 5,\n",
        "            \"type\": \"prompt\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"ChatGoogleGenerativeAI\",\n",
        "            \"duration_ms\": 1800,\n",
        "            \"type\": \"llm\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"StrOutputParser\",\n",
        "            \"duration_ms\": 2,\n",
        "            \"type\": \"parser\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Exibindo o trace de forma organizada\n",
        "print(\"üîç EXEMPLO DE TRACE DETALHADO:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"üìã Run ID: {exemplo_trace['run_id']}\")\n",
        "print(f\"‚è±Ô∏è  Dura√ß√£o Total: {exemplo_trace['duration_ms']}ms\")\n",
        "print(f\"üí∞ Custo: ${exemplo_trace['metadata']['cost_usd']:.4f}\")\n",
        "print(f\"üéØ Tokens: {exemplo_trace['metadata']['tokens_input']} ‚Üí {exemplo_trace['metadata']['tokens_output']}\")\n",
        "\n",
        "print(\"\\nüìù INPUT:\")\n",
        "print(f\"   {exemplo_trace['inputs']['texto']}\")\n",
        "\n",
        "print(\"\\nüì§ OUTPUT:\")\n",
        "print(f\"   {exemplo_trace['outputs']['content']}\")\n",
        "\n",
        "print(\"\\nüîß STEPS EXECUTADOS:\")\n",
        "for i, step in enumerate(exemplo_trace['children']):\n",
        "    print(f\"   {i+1}. {step['name']} ({step['duration_ms']}ms)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Evaluation: Testando se sua IA Est√° Boa\n\nUma das funcionalidades mais **liiinda** do LangSmith √© a **Evaluation**!\n\n√â tipo ter um professor que corrige as respostas da sua IA automaticamente!\n\n### Tipos de Evaluation:\n1. **Manual**: Voc√™ mesmo avalia\n2. **Autom√°tica**: Outra IA avalia\n3. **M√©tricas**: BLEU, ROUGE, etc.\n4. **Custom**: Suas pr√≥prias regras\n\n**Dica!** Use evaluation para comparar diferentes vers√µes do seu prompt!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulando uma evaluation autom√°tica\n",
        "def avaliar_sentimento(texto_original, resposta_ia):\n",
        "    \"\"\"\n",
        "    Fun√ß√£o que simula como o LangSmith avaliaria nossa an√°lise de sentimento\n",
        "    \"\"\"\n",
        "    # Palavras que indicam sentimento conhecido\n",
        "    palavras_positivas = ['adorei', 'excelente', 'incr√≠vel', 'superou', 'melhor']\n",
        "    palavras_negativas = ['p√©ssimo', 'decep√ß√£o', 'problemas', 'ruim']\n",
        "    \n",
        "    texto_lower = texto_original.lower()\n",
        "    resposta_lower = resposta_ia.lower()\n",
        "    \n",
        "    # Determinar sentimento esperado\n",
        "    if any(palavra in texto_lower for palavra in palavras_positivas):\n",
        "        sentimento_esperado = 'positivo'\n",
        "    elif any(palavra in texto_lower for palavra in palavras_negativas):\n",
        "        sentimento_esperado = 'negativo'\n",
        "    else:\n",
        "        sentimento_esperado = 'neutro'\n",
        "    \n",
        "    # Verificar se a IA acertou\n",
        "    acertou = sentimento_esperado in resposta_lower\n",
        "    \n",
        "    # Calcular score (simulado)\n",
        "    score = 1.0 if acertou else 0.0\n",
        "    \n",
        "    return {\n",
        "        'esperado': sentimento_esperado,\n",
        "        'acertou': acertou,\n",
        "        'score': score,\n",
        "        'confianca': np.random.uniform(0.7, 0.95) if acertou else np.random.uniform(0.3, 0.6)\n",
        "    }\n",
        "\n",
        "print(\"üß™ Fun√ß√£o de evaluation criada!\")\n",
        "print(\"üìä Agora vamos avaliar nossos resultados...\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Avaliando nossos resultados\n",
        "avaliacoes = []\n",
        "\n",
        "print(\"üîç AVALIA√á√ÉO DOS RESULTADOS:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for resultado in sucessos:\n",
        "    avaliacao = avaliar_sentimento(resultado['texto'], resultado['resultado'])\n",
        "    avaliacoes.append(avaliacao)\n",
        "    \n",
        "    status = \"‚úÖ CORRETO\" if avaliacao['acertou'] else \"‚ùå INCORRETO\"\n",
        "    print(f\"{status} | Score: {avaliacao['score']:.1f} | Confian√ßa: {avaliacao['confianca']:.2f}\")\n",
        "    print(f\"   Texto: {resultado['texto'][:40]}...\")\n",
        "    print(f\"   Esperado: {avaliacao['esperado'].title()}\")\n",
        "    print()\n",
        "\n",
        "# Calculando m√©tricas finais\n",
        "accuracy = np.mean([a['score'] for a in avaliacoes])\n",
        "confianca_media = np.mean([a['confianca'] for a in avaliacoes])\n",
        "\n",
        "print(f\"üìä M√âTRICAS FINAIS:\")\n",
        "print(f\"üéØ Accuracy: {accuracy:.2%}\")\n",
        "print(f\"üí™ Confian√ßa M√©dia: {confianca_media:.2%}\")\n",
        "print(f\"üìà Total Avaliado: {len(avaliacoes)} execu√ß√µes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üö® Monitoring e Alertas\n\nO LangSmith pode te avisar quando algo vai mal! √â tipo ter um WhatsApp que te manda mensagem quando sua IA t√° com problema.\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-17_img_05.png)\n\n### Tipos de Alertas:\n- **Alta Lat√™ncia**: Quando demora muito\n- **Taxa de Erro**: Quando falha muito\n- **Custo Elevado**: Quando gasta muito\n- **Uso An√¥malo**: Quando algo estranho acontece\n\n**Dica!** Configure alertas antes de colocar em produ√ß√£o!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulando um sistema de monitoramento\n",
        "class MonitorLangSmith:\n",
        "    def __init__(self):\n",
        "        self.limites = {\n",
        "            'latencia_max': 3.0,  # segundos\n",
        "            'erro_rate_max': 0.05,  # 5%\n",
        "            'custo_diario_max': 10.0,  # USD\n",
        "            'tokens_por_min_max': 1000\n",
        "        }\n",
        "        self.alertas = []\n",
        "    \n",
        "    def verificar_metricas(self, latencias, erros, custos, tokens):\n",
        "        # Verificar lat√™ncia\n",
        "        latencia_media = np.mean(latencias)\n",
        "        if latencia_media > self.limites['latencia_max']:\n",
        "            self.alertas.append(f\"üö® ALERTA: Lat√™ncia alta ({latencia_media:.2f}s)\")\n",
        "        \n",
        "        # Verificar taxa de erro\n",
        "        erro_rate = len(erros) / (len(sucessos) + len(erros))\n",
        "        if erro_rate > self.limites['erro_rate_max']:\n",
        "            self.alertas.append(f\"üö® ALERTA: Taxa de erro alta ({erro_rate:.2%})\")\n",
        "        \n",
        "        # Verificar custo\n",
        "        custo_total = sum(custos)\n",
        "        if custo_total > self.limites['custo_diario_max']:\n",
        "            self.alertas.append(f\"üí∞ ALERTA: Custo elevado (${custo_total:.2f})\")\n",
        "        \n",
        "        # Verificar tokens por minuto\n",
        "        tokens_por_min = sum(tokens) / 10  # Simulando 10 minutos\n",
        "        if tokens_por_min > self.limites['tokens_por_min_max']:\n",
        "            self.alertas.append(f\"üìä ALERTA: Uso alto de tokens ({tokens_por_min:.0f}/min)\")\n",
        "    \n",
        "    def gerar_relatorio(self):\n",
        "        if self.alertas:\n",
        "            print(\"üö® ALERTAS DETECTADOS:\")\n",
        "            for alerta in self.alertas:\n",
        "                print(f\"   {alerta}\")\n",
        "        else:\n",
        "            print(\"‚úÖ Tudo funcionando perfeitamente!\")\n",
        "\n",
        "# Testando o monitor\n",
        "monitor = MonitorLangSmith()\n",
        "\n",
        "# Dados simulados\n",
        "custos_simulados = np.random.uniform(0.001, 0.005, len(sucessos))\n",
        "\n",
        "monitor.verificar_metricas(\n",
        "    latencias_simuladas,\n",
        "    erros,\n",
        "    custos_simulados,\n",
        "    tokens_simulados\n",
        ")\n",
        "\n",
        "monitor.gerar_relatorio()\n",
        "\n",
        "print(f\"\\nüìä M√©tricas Atuais:\")\n",
        "print(f\"‚è±Ô∏è  Lat√™ncia m√©dia: {np.mean(latencias_simuladas):.2f}s\")\n",
        "print(f\"‚ùå Taxa de erro: {len(erros)/(len(sucessos)+len(erros)):.2%}\")\n",
        "print(f\"üí∞ Custo total: ${sum(custos_simulados):.4f}\")\n",
        "print(f\"üéØ Tokens/min: {sum(tokens_simulados)/10:.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Debugging com LangSmith\n\nQuando algo d√° errado (e sempre d√° üòÖ), o LangSmith √© seu melhor amigo!\n\n### Como debuggar:\n1. **Encontre o erro no trace**\n2. **Veja o input que causou**\n3. **Analise cada step**\n4. **Teste corre√ß√µes**\n5. **Compare resultados**\n\n**Dica!** Use os filtros do dashboard para encontrar erros rapidamente!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulando um processo de debugging\n",
        "def debug_execucao_falhada():\n",
        "    print(\"üêõ SIMULA√á√ÉO DE DEBUGGING\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Simulando um erro comum\n",
        "    erro_exemplo = {\n",
        "        \"run_id\": \"erro-123-abc\",\n",
        "        \"input\": \"Analyze this sentiment: [TEXTO MUITO LONGO COM 50000 CARACTERES...]\",\n",
        "        \"error\": \"TokenLimitExceededError: Input too long (50000 > 32000 tokens)\",\n",
        "        \"timestamp\": \"2024-01-15T15:30:00Z\",\n",
        "        \"step_failed\": \"ChatGoogleGenerativeAI\"\n",
        "    }\n",
        "    \n",
        "    print(f\"‚ùå ERRO DETECTADO:\")\n",
        "    print(f\"   ID: {erro_exemplo['run_id']}\")\n",
        "    print(f\"   Erro: {erro_exemplo['error']}\")\n",
        "    print(f\"   Step que falhou: {erro_exemplo['step_failed']}\")\n",
        "    \n",
        "    print(f\"\\nüîç AN√ÅLISE DO PROBLEMA:\")\n",
        "    print(f\"   ‚û§ Input muito grande (>32k tokens)\")\n",
        "    print(f\"   ‚û§ Modelo tem limite de contexto\")\n",
        "    print(f\"   ‚û§ Precisa de text splitter\")\n",
        "    \n",
        "    print(f\"\\nüí° SOLU√á√ïES PROPOSTAS:\")\n",
        "    print(f\"   1. Implementar text splitter (M√≥dulo 8)\")\n",
        "    print(f\"   2. Resumir texto antes de analisar\")\n",
        "    print(f\"   3. Usar modelo com contexto maior\")\n",
        "    print(f\"   4. Processar em chunks menores\")\n",
        "    \n",
        "    return erro_exemplo\n",
        "\n",
        "erro = debug_execucao_falhada()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Comparando Vers√µes e A/B Testing\n\nUma das funcionalidades mais **poderosas** do LangSmith √© comparar diferentes vers√µes!\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-17_img_06.png)\n\n### O que voc√™ pode comparar:\n- **Diferentes prompts**\n- **Modelos diferentes**\n- **Vers√µes da sua aplica√ß√£o**\n- **Par√¢metros (temperatura, etc.)**\n\n**Dica!** Sempre teste antes de fazer deploy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulando A/B Testing entre dois prompts\n",
        "prompt_v1 = \"\"\"\n",
        "Analise o sentimento do texto: {texto}\n",
        "Responda apenas: Positivo, Neutro ou Negativo\n",
        "\"\"\"\n",
        "\n",
        "prompt_v2 = \"\"\"\n",
        "Voc√™ √© um especialista em an√°lise de sentimentos.\n",
        "Analise cuidadosamente o texto abaixo e determine:\n",
        "1. Sentimento (Positivo/Neutro/Negativo)\n",
        "2. Confian√ßa (0-100%)\n",
        "3. Justificativa\n",
        "\n",
        "Texto: {texto}\n",
        "\"\"\"\n",
        "\n",
        "# Simulando m√©tricas para cada vers√£o\n",
        "metricas_v1 = {\n",
        "    \"accuracy\": 0.75,\n",
        "    \"latencia_media\": 0.8,\n",
        "    \"tokens_medio\": 25,\n",
        "    \"custo_medio\": 0.0008,\n",
        "    \"satisfacao_usuario\": 3.2\n",
        "}\n",
        "\n",
        "metricas_v2 = {\n",
        "    \"accuracy\": 0.92,\n",
        "    \"latencia_media\": 1.4,\n",
        "    \"tokens_medio\": 65,\n",
        "    \"custo_medio\": 0.0021,\n",
        "    \"satisfacao_usuario\": 4.6\n",
        "}\n",
        "\n",
        "print(\"üÜö COMPARA√á√ÉO A/B TESTING\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"üìä Prompt V1 (Simples):\")\n",
        "for metrica, valor in metricas_v1.items():\n",
        "    print(f\"   {metrica}: {valor}\")\n",
        "\n",
        "print(f\"\\nüìä Prompt V2 (Detalhado):\")\n",
        "for metrica, valor in metricas_v2.items():\n",
        "    print(f\"   {metrica}: {valor}\")\n",
        "\n",
        "print(f\"\\nüèÜ VENCEDOR: Prompt V2\")\n",
        "print(f\"   ‚úÖ Maior accuracy (+17%)\")\n",
        "print(f\"   ‚úÖ Melhor satisfa√ß√£o (+44%)\")\n",
        "print(f\"   ‚ùå Maior lat√™ncia (+75%)\")\n",
        "print(f\"   ‚ùå Maior custo (+162%)\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Visualizando a compara√ß√£o\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "metricas = ['accuracy', 'latencia_media', 'custo_medio', 'satisfacao_usuario']\n",
        "titulos = ['Accuracy', 'Lat√™ncia M√©dia (s)', 'Custo M√©dio ($)', 'Satisfa√ß√£o do Usu√°rio']\n",
        "cores = ['#2ecc71', '#e74c3c', '#f39c12', '#9b59b6']\n",
        "\n",
        "for i, (metrica, titulo, cor) in enumerate(zip(metricas, titulos, cores)):\n",
        "    ax = axes[i//2, i%2]\n",
        "    \n",
        "    v1_valor = metricas_v1[metrica]\n",
        "    v2_valor = metricas_v2[metrica]\n",
        "    \n",
        "    ax.bar(['Prompt V1', 'Prompt V2'], [v1_valor, v2_valor], \n",
        "           color=[cor, cor], alpha=[0.6, 1.0], edgecolor='black')\n",
        "    \n",
        "    ax.set_title(titulo, fontsize=12, pad=15)\n",
        "    ax.set_ylabel('Valor')\n",
        "    \n",
        "    # Adicionar valores nas barras\n",
        "    for j, valor in enumerate([v1_valor, v2_valor]):\n",
        "        ax.text(j, valor + valor*0.05, f'{valor}', ha='center', fontweight='bold')\n",
        "\n",
        "plt.suptitle('Compara√ß√£o A/B Testing: Prompt V1 vs V2', fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Esse tipo de compara√ß√£o √© autom√°tica no LangSmith!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí∞ Controle de Custos e Otimiza√ß√£o\n\nLangSmith te ajuda a n√£o quebrar o or√ßamento! √â tipo ter um contador sempre de olho nos gastos.\n\n### M√©tricas de Custo:\n- **Custo por execu√ß√£o**\n- **Custo por usu√°rio**\n- **Custo por dia/m√™s**\n- **Proje√ß√µes de gasto**\n- **Otimiza√ß√µes sugeridas**\n\n**Dica!** Configure limites de gasto para n√£o ter surpresas!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulando an√°lise de custos\n",
        "def analisar_custos():\n",
        "    # Simulando dados de uma semana\n",
        "    dias = ['Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'S√°b', 'Dom']\n",
        "    execucoes_por_dia = [150, 200, 180, 220, 250, 100, 80]\n",
        "    custo_por_execucao = [0.0015, 0.0012, 0.0018, 0.0011, 0.0020, 0.0014, 0.0016]\n",
        "    \n",
        "    custos_diarios = [exec * custo for exec, custo in zip(execucoes_por_dia, custo_por_execucao)]\n",
        "    \n",
        "    # An√°lise\n",
        "    custo_total_semana = sum(custos_diarios)\n",
        "    custo_medio_dia = np.mean(custos_diarios)\n",
        "    projecao_mensal = custo_total_semana * 4.33  # 4.33 semanas por m√™s\n",
        "    \n",
        "    print(\"üí∞ AN√ÅLISE DE CUSTOS - √öLTIMA SEMANA\")\n",
        "    print(\"=\" * 45)\n",
        "    \n",
        "    for dia, execucoes, custo_dia in zip(dias, execucoes_por_dia, custos_diarios):\n",
        "        print(f\"{dia}: {execucoes:3d} execu√ß√µes = ${custo_dia:.4f}\")\n",
        "    \n",
        "    print(f\"\\nüìä RESUMO:\")\n",
        "    print(f\"   Total da semana: ${custo_total_semana:.4f}\")\n",
        "    print(f\"   M√©dia por dia: ${custo_medio_dia:.4f}\")\n",
        "    print(f\"   Proje√ß√£o mensal: ${projecao_mensal:.2f}\")\n",
        "    \n",
        "    # Alertas e sugest√µes\n",
        "    if projecao_mensal > 50:\n",
        "        print(f\"\\nüö® ALERTA: Proje√ß√£o alta para o m√™s!\")\n",
        "        print(f\"üí° Sugest√µes:\")\n",
        "        print(f\"   - Otimizar prompts (reduzir tokens)\")\n",
        "        print(f\"   - Usar cache para respostas repetidas\")\n",
        "        print(f\"   - Implementar rate limiting\")\n",
        "    else:\n",
        "        print(f\"\\n‚úÖ Custos sob controle!\")\n",
        "    \n",
        "    return dias, execucoes_por_dia, custos_diarios\n",
        "\n",
        "dias, execucoes, custos = analisar_custos()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Visualiza√ß√£o dos custos\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Gr√°fico 1: Custos por dia\n",
        "bars1 = ax1.bar(dias, custos, color='#e74c3c', alpha=0.7, edgecolor='black')\n",
        "ax1.set_title('Custos Di√°rios', fontsize=14, pad=15)\n",
        "ax1.set_ylabel('Custo ($)')\n",
        "ax1.set_xlabel('Dia da Semana')\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for bar, custo in zip(bars1, custos):\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + height*0.05,\n",
        "             f'${custo:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Gr√°fico 2: Execu√ß√µes vs Custo\n",
        "ax2.scatter(execucoes, custos, c=range(len(dias)), s=100, alpha=0.7, \n",
        "           cmap='viridis', edgecolors='black')\n",
        "\n",
        "# Adicionar linha de tend√™ncia\n",
        "z = np.polyfit(execucoes, custos, 1)\n",
        "p = np.poly1d(z)\n",
        "ax2.plot(execucoes, p(execucoes), \"r--\", alpha=0.8, linewidth=2)\n",
        "\n",
        "ax2.set_title('Execu√ß√µes vs Custo', fontsize=14, pad=15)\n",
        "ax2.set_xlabel('N√∫mero de Execu√ß√µes')\n",
        "ax2.set_ylabel('Custo ($)')\n",
        "\n",
        "# Adicionar labels dos dias\n",
        "for i, (exec_count, custo, dia) in enumerate(zip(execucoes, custos, dias)):\n",
        "    ax2.annotate(dia, (exec_count, custo), xytext=(5, 5), \n",
        "                textcoords='offset points', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä No LangSmith voc√™ tem esses gr√°ficos atualizados em tempo real!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèãÔ∏è‚Äç‚ôÇÔ∏è Exerc√≠cio Pr√°tico: Implementando Monitoramento Completo\n\nBora colocar a m√£o na massa! Vamos criar um sistema de monitoramento completo para uma aplica√ß√£o RAG!\n\n**Desafio**: Implementar monitoramento para um sistema que responde perguntas sobre documentos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# EXERC√çCIO: Complete o c√≥digo abaixo\n",
        "# Vamos simular uma aplica√ß√£o RAG com monitoramento\n",
        "\n",
        "class SistemaRAGMonitorado:\n",
        "    def __init__(self):\n",
        "        self.metricas = {\n",
        "            'total_queries': 0,\n",
        "            'sucessos': 0,\n",
        "            'erros': 0,\n",
        "            'tempo_total': 0,\n",
        "            'custo_total': 0,\n",
        "            'historico': []\n",
        "        }\n",
        "    \n",
        "    def processar_query(self, pergunta, documentos):\n",
        "        \"\"\"Simula processamento de uma query RAG\"\"\"\n",
        "        import time\n",
        "        import random\n",
        "        \n",
        "        inicio = time.time()\n",
        "        self.metricas['total_queries'] += 1\n",
        "        \n",
        "        try:\n",
        "            # Simula processamento RAG\n",
        "            time.sleep(random.uniform(0.1, 0.5))  # Simula tempo de processamento\n",
        "            \n",
        "            # TODO: Adicione aqui a l√≥gica de processamento real\n",
        "            # Dica: Use os conceitos do M√≥dulo 10 (RAG)\n",
        "            \n",
        "            resposta = f\"Baseado nos documentos, a resposta para '{pergunta[:30]}...' √©: [RESPOSTA SIMULADA]\"\n",
        "            \n",
        "            # M√©tricas de sucesso\n",
        "            tempo_execucao = time.time() - inicio\n",
        "            custo_estimado = random.uniform(0.002, 0.008)\n",
        "            \n",
        "            self.metricas['sucessos'] += 1\n",
        "            self.metricas['tempo_total'] += tempo_execucao\n",
        "            self.metricas['custo_total'] += custo_estimado\n",
        "            \n",
        "            # TODO: Adicione mais m√©tricas aqui\n",
        "            # - Relev√¢ncia da resposta\n",
        "            # - Satisfa√ß√£o do usu√°rio\n",
        "            # - Documentos utilizados\n",
        "            \n",
        "            self.metricas['historico'].append({\n",
        "                'pergunta': pergunta,\n",
        "                'resposta': resposta,\n",
        "                'tempo': tempo_execucao,\n",
        "                'custo': custo_estimado,\n",
        "                'status': 'sucesso',\n",
        "                'timestamp': datetime.now()\n",
        "            })\n",
        "            \n",
        "            return resposta\n",
        "            \n",
        "        except Exception as e:\n",
        "            # Tratamento de erro\n",
        "            self.metricas['erros'] += 1\n",
        "            \n",
        "            self.metricas['historico'].append({\n",
        "                'pergunta': pergunta,\n",
        "                'resposta': None,\n",
        "                'tempo': time.time() - inicio,\n",
        "                'custo': 0,\n",
        "                'status': 'erro',\n",
        "                'erro': str(e),\n",
        "                'timestamp': datetime.now()\n",
        "            })\n",
        "            \n",
        "            raise e\n",
        "    \n",
        "    def gerar_dashboard(self):\n",
        "        \"\"\"Gera um dashboard de m√©tricas\"\"\"\n",
        "        print(\"üìä DASHBOARD DE MONITORAMENTO RAG\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        # TODO: Complete as m√©tricas\n",
        "        taxa_sucesso = self.metricas['sucessos'] / max(self.metricas['total_queries'], 1)\n",
        "        tempo_medio = self.metricas['tempo_total'] / max(self.metricas['sucessos'], 1)\n",
        "        custo_medio = self.metricas['custo_total'] / max(self.metricas['sucessos'], 1)\n",
        "        \n",
        "        print(f\"üìà Total de Queries: {self.metricas['total_queries']}\")\n",
        "        print(f\"‚úÖ Taxa de Sucesso: {taxa_sucesso:.2%}\")\n",
        "        print(f\"‚è±Ô∏è  Tempo M√©dio: {tempo_medio:.2f}s\")\n",
        "        print(f\"üí∞ Custo M√©dio: ${custo_medio:.4f}\")\n",
        "        print(f\"üí∏ Custo Total: ${self.metricas['custo_total']:.4f}\")\n",
        "        \n",
        "        # TODO: Adicione mais m√©tricas aqui\n",
        "        \n",
        "        return {\n",
        "            'taxa_sucesso': taxa_sucesso,\n",
        "            'tempo_medio': tempo_medio,\n",
        "            'custo_medio': custo_medio\n",
        "        }\n",
        "\n",
        "# Testando o sistema\n",
        "sistema = SistemaRAGMonitorado()\n",
        "print(\"üöÄ Sistema RAG com monitoramento criado!\")\n",
        "print(\"üí° Agora complete as partes marcadas com TODO\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Testando o sistema com queries simuladas\n",
        "queries_teste = [\n",
        "    \"Qual √© a pol√≠tica de devolu√ß√£o?\",\n",
        "    \"Como funciona o sistema de pagamento?\",\n",
        "    \"Quais s√£o os hor√°rios de funcionamento?\",\n",
        "    \"Como posso entrar em contato?\",\n",
        "    \"Qual √© o prazo de entrega?\"\n",
        "]\n",
        "\n",
        "documentos_simulados = [\n",
        "    \"Documento sobre pol√≠ticas da empresa\",\n",
        "    \"Manual do usu√°rio\",\n",
        "    \"FAQ do sistema\"\n",
        "]\n",
        "\n",
        "print(\"üß™ TESTANDO SISTEMA RAG MONITORADO\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "for i, query in enumerate(queries_teste):\n",
        "    print(f\"\\nüîç Query {i+1}: {query}\")\n",
        "    try:\n",
        "        resposta = sistema.processar_query(query, documentos_simulados)\n",
        "        print(f\"‚úÖ Processada com sucesso!\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "metricas_finais = sistema.gerar_dashboard()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üåü Resum√£o: O que Aprendemos sobre LangSmith\n\nLiiindo! Chegamos ao final do nosso curso completo! üéâ\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-17_img_07.png)\n\n### üéØ O que o LangSmith faz por voc√™:\n\n1. **üîç Tracing Completo**: V√™ cada passo da sua aplica√ß√£o\n2. **üìä M√©tricas Detalhadas**: Performance, custo, accuracy\n3. **üö® Monitoramento**: Alertas quando algo vai mal\n4. **üß™ Evaluation**: Testa se sua IA est√° funcionando\n5. **üÜö A/B Testing**: Compara diferentes vers√µes\n6. **üí∞ Controle de Custos**: N√£o quebra o or√ßamento\n7. **üêõ Debugging**: Encontra e corrige problemas\n\n### üìö Jornada Completa do Curso:\n- **M√≥dulos 1-6**: Fundamentos (Chat, Prompts, Chains)\n- **M√≥dulos 7-10**: Avan√ßado (Memory, RAG, Vectors)\n- **M√≥dulos 11-14**: Aplica√ß√µes (Agents, Projetos, Deploy)\n- **M√≥dulos 15-17**: Evolu√ß√£o (v1.0, LangGraph, LangSmith)\n\n**Dica Final!** LangSmith √© essencial para produ√ß√£o. Use sempre!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Visualiza√ß√£o final: Jornada do curso\n",
        "modulos = [\n",
        "    'Intro', 'ChatModel', 'LCEL', 'Prompts', 'Parsers', \n",
        "    'Chains', 'Memory', 'Docs', 'Vectors', 'RAG', \n",
        "    'Agents', 'Proj1', 'Proj2', 'Deploy', 'v1.0', \n",
        "    'LangGraph', 'LangSmith'\n",
        "]\n",
        "\n",
        "complexidade = [1, 2, 3, 2, 2, 4, 5, 4, 6, 7, 8, 9, 9, 7, 6, 8, 6]\n",
        "utilidade = [8, 9, 7, 9, 6, 8, 7, 6, 8, 9, 8, 10, 10, 9, 7, 8, 9]\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10))\n",
        "\n",
        "# Gr√°fico 1: Evolu√ß√£o da complexidade\n",
        "ax1.plot(range(len(modulos)), complexidade, 'o-', linewidth=3, markersize=8, \n",
        "         color='#e74c3c', label='Complexidade')\n",
        "ax1.fill_between(range(len(modulos)), complexidade, alpha=0.3, color='#e74c3c')\n",
        "ax1.set_title('Evolu√ß√£o da Complexidade ao Longo do Curso', fontsize=16, pad=20)\n",
        "ax1.set_ylabel('N√≠vel de Complexidade (1-10)')\n",
        "ax1.set_xticks(range(len(modulos)))\n",
        "ax1.set_xticklabels(modulos, rotation=45, ha='right')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend()\n",
        "\n",
        "# Destacar m√≥dulos especiais\n",
        "especiais = [9, 10, 11, 15, 16]  # RAG, Projetos, LangGraph, LangSmith\n",
        "for idx in especiais:\n",
        "    ax1.annotate(f'üåü {modulos[idx]}', \n",
        "                xy=(idx, complexidade[idx]), \n",
        "                xytext=(10, 10), textcoords='offset points',\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),\n",
        "                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
        "\n",
        "# Gr√°fico 2: Utilidade pr√°tica\n",
        "bars = ax2.bar(range(len(modulos)), utilidade, \n",
        "               color=['#2ecc71' if u >= 8 else '#f39c12' if u >= 6 else '#95a5a6' for u in utilidade],\n",
        "               alpha=0.8, edgecolor='black')\n",
        "\n",
        "ax2.set_title('Utilidade Pr√°tica de Cada M√≥dulo', fontsize=16, pad=20)\n",
        "ax2.set_ylabel('Utilidade Pr√°tica (1-10)')\n",
        "ax2.set_xticks(range(len(modulos)))\n",
        "ax2.set_xticklabels(modulos, rotation=45, ha='right')\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for bar, util in zip(bars, utilidade):\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
        "             f'{util}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéì PARAB√âNS! Voc√™ completou todo o curso LangChain!\")\n",
        "print(\"üöÄ Agora voc√™ est√° pronto para criar aplica√ß√µes de IA incr√≠veis!\")\n",
        "print(\"üìä E o melhor: sabe como monitorar e manter elas funcionando!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Pr√≥ximos Passos e Recursos\n\nT√°, mas e agora? Como continuar evoluindo?\n\n### üîó Links Importantes:\n- **LangSmith**: [smith.langchain.com](https://smith.langchain.com)\n- **Documenta√ß√£o**: [docs.smith.langchain.com](https://docs.smith.langchain.com)\n- **LangChain**: [python.langchain.com](https://python.langchain.com)\n- **Community**: [discord.gg/langchain](https://discord.gg/langchain)\n\n### üõ†Ô∏è Projetos para Praticar:\n1. **Chatbot com Monitoramento**: Use LangSmith desde o in√≠cio\n2. **Sistema RAG Otimizado**: Compare diferentes estrat√©gias\n3. **Agent Multi-Tool**: Monitore performance de cada tool\n4. **A/B Testing de Prompts**: Teste melhorias continuamente\n\n### üìö Continue Aprendendo:\n- **LangServe**: Para APIs em produ√ß√£o\n- **LangChain Templates**: Projetos prontos\n- **Fine-tuning**: Personalize modelos\n- **Multi-modal**: Texto + imagem + √°udio\n\n**Dica Final!** A IA evolui r√°pido. Continue estudando e praticando!\n\n---\n\n**Muito obrigado por acompanhar todo o curso!** üôè\n\n**Pedro Nunes Guth** üöÄ\n\n*\"A melhor forma de prever o futuro √© constru√≠-lo!\"*"
      ]
    }
  ]
}
