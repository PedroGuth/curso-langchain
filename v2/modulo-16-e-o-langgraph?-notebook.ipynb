{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRyB7dQ-lcD9"
      },
      "source": [
        "# ğŸ•¸ï¸ LangGraph: Orquestrando Agentes como um Maestro Digital!\n",
        "\n",
        "## MÃ³dulo 16 - LangChain v0.3 Course\n",
        "### Por Pedro Nunes Guth\n",
        "\n",
        "---\n",
        "\n",
        "TÃ¡, chegamos aqui no mÃ³dulo 16 e vocÃª jÃ¡ viu **MUITA COISA**: ChatModels, Agents, Tools, RAG... Mas e se eu te disser que existe uma forma de orquestrar tudo isso como se vocÃª fosse o maestro de uma orquestra sinfÃ´nica? ğŸ¼\n",
        "\n",
        "Ã‰ aÃ­ que entra o **LangGraph**! Think of it como o \"WhatsApp em grupo\" dos seus agentes - cada um tem sua funÃ§Ã£o, mas todos trabalham juntos de forma coordenada.\n",
        "\n",
        "![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-16_img_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nOzHVkdlcEF"
      },
      "source": [
        "## ğŸ¤” TÃ¡, mas o que Ã© LangGraph?\n",
        "\n",
        "LangGraph Ã© uma extensÃ£o do LangChain que permite criar **workflows complexos** usando grafos (graphs). Imagine que vocÃª tem vÃ¡rios agentes especializados:\n",
        "\n",
        "- ğŸ” **Agente Pesquisador**: Busca informaÃ§Ãµes na web\n",
        "- ğŸ“Š **Agente Analista**: Processa dados e gera insights\n",
        "- âœï¸ **Agente Escritor**: Cria conteÃºdo baseado nas anÃ¡lises\n",
        "- ğŸ”§ **Agente Revisor**: Valida e corrige o resultado final\n",
        "\n",
        "Com LangGraph, vocÃª pode fazer esses agentes conversarem entre si, passarem informaÃ§Ãµes, tomarem decisÃµes e atÃ© **voltarem atrÃ¡s** quando necessÃ¡rio!\n",
        "\n",
        "### Por que nÃ£o usar sÃ³ Chains?\n",
        "\n",
        "Lembra das Chains que vimos lÃ¡ no mÃ³dulo 6? Elas sÃ£o **lineares** - como uma linha de produÃ§Ã£o. O LangGraph permite **fluxos condicionais** - como um GPS que recalcula a rota baseado no trÃ¢nsito!\n",
        "\n",
        "**Dica!** LangGraph Ã© perfeito quando vocÃª precisa de lÃ³gica condicional complexa entre seus agentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUPPVDThlcEH"
      },
      "outputs": [],
      "source": [
        "# Primeiro, vamos instalar tudo que precisamos\n",
        "!pip install langgraph langchain-google-genai python-dotenv --quiet\n",
        "\n",
        "# Imports bÃ¡sicos\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from typing import Dict, List, Any\n",
        "import json\n",
        "\n",
        "# LangGraph especÃ­fico\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Carregando variÃ¡veis de ambiente\n",
        "load_dotenv()\n",
        "\n",
        "print(\"Libs instaladas! Bora comeÃ§ar! ğŸš€\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InHb3xBOlcEK"
      },
      "source": [
        "## ğŸ§  Conceitos Fundamentais\n",
        "\n",
        "Antes de colocar a mÃ£o na massa, vamos entender os conceitos bÃ¡sicos:\n",
        "\n",
        "### 1. **Nodes (NÃ³s)**\n",
        "SÃ£o as \"estaÃ§Ãµes\" do seu fluxo. Cada node executa uma tarefa especÃ­fica.\n",
        "\n",
        "### 2. **Edges (Arestas)**\n",
        "SÃ£o as \"estradas\" que conectam os nodes. Podem ser:\n",
        "- **Fixas**: Sempre vai para o prÃ³ximo node\n",
        "- **Condicionais**: Decide para onde ir baseado no resultado\n",
        "\n",
        "### 3. **State (Estado)**\n",
        "Ã‰ o \"WhatsApp do grupo\" - todas as informaÃ§Ãµes compartilhadas entre os nodes.\n",
        "\n",
        "### Analogia Brasileira ğŸ‡§ğŸ‡·\n",
        "Pense no LangGraph como o **SUS (Sistema Ãšnico de SaÃºde)**:\n",
        "- VocÃª chega na **recepÃ§Ã£o** (node inicial)\n",
        "- Dependendo do seu caso, vai para **clÃ­nico geral** ou **especialista** (edges condicionais)\n",
        "- Cada mÃ©dico acessa seu **prontuÃ¡rio** (state compartilhado)\n",
        "- Pode precisar voltar para outros mÃ©dicos (loops no grafo)\n",
        "\n",
        "**Dica!** O state Ã© persistente - cada node pode ler e modificar as informaÃ§Ãµes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv9ZinqslcEK"
      },
      "outputs": [],
      "source": [
        "# Vamos criar nosso primeiro exemplo simples\n",
        "# Configurando o modelo que jÃ¡ conhecemos\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    google_api_key=\"Coloca-a-sua-chave-aqui!!!!\",\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "# Definindo nossa estrutura de estado\n",
        "# Ã‰ como um dicionÃ¡rio que todos os nodes podem acessar\n",
        "def create_initial_state(user_input: str) -> Dict[str, Any]:\n",
        "    return {\n",
        "        \"user_input\": user_input,\n",
        "        \"research_data\": \"\",\n",
        "        \"analysis\": \"\",\n",
        "        \"final_response\": \"\",\n",
        "        \"step_count\": 0\n",
        "    }\n",
        "\n",
        "print(\"Setup bÃ¡sico pronto! ğŸ¯\")\n",
        "print(\"Agora vamos criar nossos 'funcionÃ¡rios especializados'...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCmViBxwlcEL"
      },
      "source": [
        "## ğŸ” Criando Nossos Agentes Especializados\n",
        "\n",
        "Lembra dos Agents que vimos no mÃ³dulo 11? Agora vamos criar **funÃ§Ãµes especializadas** que funcionam como mini-agentes dentro do nosso grafo.\n",
        "\n",
        "Cada funÃ§Ã£o vai:\n",
        "1. Receber o **state atual**\n",
        "2. Fazer seu **trabalho especÃ­fico**\n",
        "3. Atualizar o **state** com os resultados\n",
        "4. Retornar o **state modificado**\n",
        "\n",
        "Ã‰ como um **revezamento** - cada corredor recebe o bastÃ£o, corre sua parte e passa adiante!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS7GKA-IlcEM"
      },
      "outputs": [],
      "source": [
        "# Node 1: Agente Pesquisador\n",
        "def research_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Este 'funcionÃ¡rio' Ã© especialista em pesquisa\n",
        "    Ele pega a pergunta do usuÃ¡rio e simula uma pesquisa\n",
        "    \"\"\"\n",
        "    print(\"ğŸ” Agente Pesquisador trabalhando...\")\n",
        "\n",
        "    user_question = state[\"user_input\"]\n",
        "\n",
        "    # Prompt para simular pesquisa\n",
        "    research_prompt = f\"\"\"\n",
        "    VocÃª Ã© um pesquisador expert. Sua tarefa Ã© simular uma pesquisa sobre: {user_question}\n",
        "\n",
        "    ForneÃ§a dados e informaÃ§Ãµes relevantes como se vocÃª tivesse pesquisado em fontes confiÃ¡veis.\n",
        "    Seja especÃ­fico e inclua nÃºmeros, estatÃ­sticas ou fatos quando possÃ­vel.\n",
        "\n",
        "    Formato: Lista com 3-5 pontos principais de pesquisa.\n",
        "    \"\"\"\n",
        "\n",
        "    # Fazendo a pesquisa com nossa LLM\n",
        "    research_result = llm.invoke(research_prompt)\n",
        "\n",
        "    # Atualizando o state\n",
        "    state[\"research_data\"] = research_result.content\n",
        "    state[\"step_count\"] += 1\n",
        "\n",
        "    print(f\"âœ… Pesquisa concluÃ­da! Step {state['step_count']}\")\n",
        "    return state\n",
        "\n",
        "# Node 2: Agente Analista\n",
        "def analysis_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Este 'funcionÃ¡rio' pega os dados da pesquisa e faz anÃ¡lise\n",
        "    \"\"\"\n",
        "    print(\"ğŸ“Š Agente Analista trabalhando...\")\n",
        "\n",
        "    research_data = state[\"research_data\"]\n",
        "    original_question = state[\"user_input\"]\n",
        "\n",
        "    analysis_prompt = f\"\"\"\n",
        "    VocÃª Ã© um analista expert. Baseado nestes dados de pesquisa:\n",
        "\n",
        "    {research_data}\n",
        "\n",
        "    FaÃ§a uma anÃ¡lise crÃ­tica e inteligente relacionada Ã  pergunta original: {original_question}\n",
        "\n",
        "    Inclua:\n",
        "    - Insights principais\n",
        "    - PadrÃµes identificados\n",
        "    - ConclusÃµes baseadas nos dados\n",
        "    \"\"\"\n",
        "\n",
        "    analysis_result = llm.invoke(analysis_prompt)\n",
        "\n",
        "    state[\"analysis\"] = analysis_result.content\n",
        "    state[\"step_count\"] += 1\n",
        "\n",
        "    print(f\"âœ… AnÃ¡lise concluÃ­da! Step {state['step_count']}\")\n",
        "    return state\n",
        "\n",
        "print(\"Agentes criados! ğŸ¤–\")\n",
        "print(\"PrÃ³ximo: vamos criar o agente que junta tudo...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZIYxLOplcEO"
      },
      "outputs": [],
      "source": [
        "# Node 3: Agente Sintetizador (junta tudo)\n",
        "def synthesis_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Este Ã© o 'chefe' que junta o trabalho de todos\n",
        "    \"\"\"\n",
        "    print(\"âœï¸ Agente Sintetizador trabalhando...\")\n",
        "\n",
        "    user_question = state[\"user_input\"]\n",
        "    research = state[\"research_data\"]\n",
        "    analysis = state[\"analysis\"]\n",
        "\n",
        "    synthesis_prompt = f\"\"\"\n",
        "    VocÃª Ã© um sintetizador expert. Sua missÃ£o Ã© criar uma resposta final completa e Ãºtil.\n",
        "\n",
        "    PERGUNTA ORIGINAL: {user_question}\n",
        "\n",
        "    DADOS DE PESQUISA:\n",
        "    {research}\n",
        "\n",
        "    ANÃLISE REALIZADA:\n",
        "    {analysis}\n",
        "\n",
        "    Crie uma resposta final que:\n",
        "    1. Responda diretamente Ã  pergunta\n",
        "    2. Use os dados pesquisados\n",
        "    3. Inclua os insights da anÃ¡lise\n",
        "    4. Seja clara e acionÃ¡vel\n",
        "\n",
        "    Tom: Profissional mas acessÃ­vel, como o Pedro Guth explicaria! ğŸš€\n",
        "    \"\"\"\n",
        "\n",
        "    final_result = llm.invoke(synthesis_prompt)\n",
        "\n",
        "    state[\"final_response\"] = final_result.content\n",
        "    state[\"step_count\"] += 1\n",
        "\n",
        "    print(f\"âœ… SÃ­ntese concluÃ­da! Step {state['step_count']}\")\n",
        "    print(\"ğŸ‰ Workflow completo!\")\n",
        "    return state\n",
        "\n",
        "# FunÃ§Ã£o para decidir qual caminho seguir (edge condicional)\n",
        "def decide_next_step(state: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Esta funÃ§Ã£o decide para onde ir baseado no estado atual\n",
        "    Ã‰ como um semÃ¡foro inteligente!\n",
        "    \"\"\"\n",
        "    step_count = state[\"step_count\"]\n",
        "\n",
        "    if step_count == 1:  # Acabou de pesquisar\n",
        "        return \"analysis\"\n",
        "    elif step_count == 2:  # Acabou de analisar\n",
        "        return \"synthesis\"\n",
        "    else:  # Acabou tudo\n",
        "        return END\n",
        "\n",
        "print(\"Todas as funÃ§Ãµes criadas! ğŸ› ï¸\")\n",
        "print(\"Agora vamos montar o grafo...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJUZ-aZMlcER"
      },
      "source": [
        "## ğŸ•¸ï¸ Montando o Grafo\n",
        "\n",
        "Agora vem a parte **MAIS LEGAL**! Vamos conectar nossos agentes como se fossem peÃ§as de Lego:\n",
        "\n",
        "```\n",
        "USUÃRIO â†’ PESQUISA â†’ ANÃLISE â†’ SÃNTESE â†’ RESPOSTA FINAL\n",
        "```\n",
        "\n",
        "O LangGraph vai cuidar de:\n",
        "- âœ… Executar cada node na ordem certa\n",
        "- âœ… Passar o state entre eles\n",
        "- âœ… Tomar decisÃµes baseado nas condiÃ§Ãµes\n",
        "- âœ… Gerenciar todo o fluxo automaticamente\n",
        "\n",
        "Ã‰ como ter um **assistente pessoal digital** coordenando uma equipe inteira!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XptDE9tPlcEU"
      },
      "outputs": [],
      "source": [
        "# Criando o grafo - Ã‰ aqui que a mÃ¡gica acontece! âœ¨\n",
        "workflow = StateGraph(dict)\n",
        "\n",
        "# Adicionando nossos 'funcionÃ¡rios' (nodes)\n",
        "workflow.add_node(\"research\", research_node)\n",
        "workflow.add_node(\"analysis\", analysis_node)\n",
        "workflow.add_node(\"synthesis\", synthesis_node)\n",
        "\n",
        "# Definindo o ponto de entrada (onde tudo comeÃ§a)\n",
        "workflow.set_entry_point(\"research\")\n",
        "\n",
        "# Conectando os nodes com edges condicionais\n",
        "workflow.add_conditional_edges(\n",
        "    \"research\",\n",
        "    decide_next_step,\n",
        "    {\n",
        "        \"analysis\": \"analysis\",\n",
        "        END: END\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"analysis\",\n",
        "    decide_next_step,\n",
        "    {\n",
        "        \"synthesis\": \"synthesis\",\n",
        "        END: END\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"synthesis\",\n",
        "    decide_next_step,\n",
        "    {\n",
        "        END: END\n",
        "    }\n",
        ")\n",
        "\n",
        "# Compilando o grafo (transformando em uma aplicaÃ§Ã£o executÃ¡vel)\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"ğŸ¯ Grafo montado e compilado!\")\n",
        "print(\"Agora temos um sistema completo de IA working together!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVb9AqrXlcEW"
      },
      "source": [
        "## ğŸš€ Executando Nosso Primeiro Workflow\n",
        "\n",
        "Chegou a hora da verdade! Vamos fazer nosso \"time de especialistas digitais\" trabalhar junto.\n",
        "\n",
        "Ã‰ como dar o play em uma sinfonia - cada instrumento (agente) vai tocar sua parte no momento certo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6yVUc3flcEW"
      },
      "outputs": [],
      "source": [
        "# Teste prÃ¡tico - Vamos fazer uma pergunta!\n",
        "user_question = \"Quais sÃ£o as principais tendÃªncias de IA para 2025?\"\n",
        "\n",
        "print(f\"ğŸ¤” Pergunta do usuÃ¡rio: {user_question}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸš€ INICIANDO WORKFLOW LANGGRAPH\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "# Criando o estado inicial\n",
        "initial_state = create_initial_state(user_question)\n",
        "\n",
        "# Executando o workflow completo!\n",
        "# O LangGraph vai cuidar de tudo automaticamente\n",
        "final_state = app.invoke(initial_state)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"âœ… WORKFLOW CONCLUÃDO!\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoHCLewalcEX"
      },
      "outputs": [],
      "source": [
        "# Vamos ver o que cada agente produziu!\n",
        "print(\"ğŸ“‹ RELATÃ“RIO COMPLETO DO WORKFLOW:\\n\")\n",
        "\n",
        "print(\"ğŸ” DADOS DA PESQUISA:\")\n",
        "print(\"-\" * 30)\n",
        "print(final_state[\"research_data\"][:300] + \"...\")\n",
        "\n",
        "print(\"\\nğŸ“Š ANÃLISE REALIZADA:\")\n",
        "print(\"-\" * 30)\n",
        "print(final_state[\"analysis\"][:300] + \"...\")\n",
        "\n",
        "print(\"\\nğŸ¯ RESPOSTA FINAL:\")\n",
        "print(\"-\" * 30)\n",
        "print(final_state[\"final_response\"])\n",
        "\n",
        "print(f\"\\nğŸ“ˆ Total de steps executados: {final_state['step_count']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YN0FkyHlcEX"
      },
      "source": [
        "## ğŸ“Š Visualizando o Fluxo\n",
        "\n",
        "Uma das coisas **MAIS LINDAS** do LangGraph Ã© que podemos visualizar nosso workflow! Ã‰ como ter um mapa do pensamento dos nossos agentes.\n",
        "\n",
        "Vamos criar um diagrama simples para entender o fluxo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLiOcHD0lcEX"
      },
      "outputs": [],
      "source": [
        "# Vamos criar uma visualizaÃ§Ã£o simples do nosso workflow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.patches import FancyBboxPatch\n",
        "import numpy as np\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Definindo posiÃ§Ãµes dos nodes\n",
        "positions = {\n",
        "    'START': (1, 4),\n",
        "    'RESEARCH': (3, 4),\n",
        "    'ANALYSIS': (5, 4),\n",
        "    'SYNTHESIS': (7, 4),\n",
        "    'END': (9, 4)\n",
        "}\n",
        "\n",
        "# Cores para cada tipo de node\n",
        "colors = {\n",
        "    'START': '#90EE90',      # Verde claro\n",
        "    'RESEARCH': '#87CEEB',   # Azul claro\n",
        "    'ANALYSIS': '#DDA0DD',   # Roxo claro\n",
        "    'SYNTHESIS': '#F0E68C',  # Amarelo claro\n",
        "    'END': '#FFB6C1'        # Rosa claro\n",
        "}\n",
        "\n",
        "# Desenhando os nodes\n",
        "for node, (x, y) in positions.items():\n",
        "    # Criando caixas arredondadas\n",
        "    bbox = FancyBboxPatch(\n",
        "        (x-0.4, y-0.3), 0.8, 0.6,\n",
        "        boxstyle=\"round,pad=0.1\",\n",
        "        facecolor=colors[node],\n",
        "        edgecolor='black',\n",
        "        linewidth=2\n",
        "    )\n",
        "    ax.add_patch(bbox)\n",
        "\n",
        "    # Adicionando texto\n",
        "    ax.text(x, y, node, ha='center', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Desenhando as setas (edges)\n",
        "arrows = [\n",
        "    ((1.4, 4), (2.6, 4)),   # START -> RESEARCH\n",
        "    ((3.4, 4), (4.6, 4)),   # RESEARCH -> ANALYSIS\n",
        "    ((5.4, 4), (6.6, 4)),   # ANALYSIS -> SYNTHESIS\n",
        "    ((7.4, 4), (8.6, 4))    # SYNTHESIS -> END\n",
        "]\n",
        "\n",
        "for (x1, y1), (x2, y2) in arrows:\n",
        "    ax.annotate('', xy=(x2, y2), xytext=(x1, y1),\n",
        "                arrowprops=dict(arrowstyle='->', lw=2, color='darkblue'))\n",
        "\n",
        "# Configurando o grÃ¡fico\n",
        "ax.set_xlim(0, 10)\n",
        "ax.set_ylim(3, 5)\n",
        "ax.set_aspect('equal')\n",
        "ax.axis('off')\n",
        "\n",
        "plt.title('ğŸ•¸ï¸ LangGraph Workflow - Fluxo dos Agentes', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ¨ Liiindo! Esse Ã© o mapa do nosso workflow!\")\n",
        "print(\"Cada caixa Ã© um agente especializado trabalhando em sequÃªncia.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNdvJFo6lcEY"
      },
      "source": [
        "## ğŸ”„ Workflows com Loops e CondiÃ§Ãµes\n",
        "\n",
        "Agora vamos para a parte **AVANÃ‡ADA**! E se nosso agente precisar **voltar** e refazer algo? Ou tomar decisÃµes diferentes baseado no conteÃºdo?\n",
        "\n",
        "Vamos criar um workflow que pode:\n",
        "- âœ… **Validar** se a resposta estÃ¡ boa\n",
        "- âœ… **Voltar** para melhorar se necessÃ¡rio\n",
        "- âœ… **Decidir** caminhos diferentes baseado no conteÃºdo\n",
        "\n",
        "Ã‰ como ter um **editor chato** que sempre pede para melhorar o texto! ğŸ˜…\n",
        "\n",
        "**Dica!** Isso Ã© o que diferencia LangGraph das Chains simples - a capacidade de ter loops e condiÃ§Ãµes complexas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-74X5CMlcEY"
      },
      "outputs": [],
      "source": [
        "# Vamos criar um workflow mais avanÃ§ado com validaÃ§Ã£o\n",
        "\n",
        "def content_generator_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Gera conteÃºdo inicial\"\"\"\n",
        "    print(\"âœï¸ Gerando conteÃºdo...\")\n",
        "\n",
        "    topic = state[\"topic\"]\n",
        "    attempt = state.get(\"attempt\", 1)\n",
        "\n",
        "    if attempt > 1:\n",
        "        feedback = state.get(\"feedback\", \"\")\n",
        "        prompt = f\"\"\"\n",
        "        Reescreva o conteÃºdo sobre: {topic}\n",
        "\n",
        "        Feedback para melhorar: {feedback}\n",
        "\n",
        "        Tentativa #{attempt} - FaÃ§a melhor desta vez!\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt = f\"\"\"\n",
        "        Escreva um conteÃºdo interessante sobre: {topic}\n",
        "\n",
        "        FaÃ§a algo informativo e engajante.\n",
        "        \"\"\"\n",
        "\n",
        "    result = llm.invoke(prompt)\n",
        "\n",
        "    state[\"content\"] = result.content\n",
        "    state[\"attempt\"] = attempt\n",
        "\n",
        "    return state\n",
        "\n",
        "def validator_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Valida se o conteÃºdo estÃ¡ bom\"\"\"\n",
        "    print(\"ğŸ” Validando conteÃºdo...\")\n",
        "\n",
        "    content = state[\"content\"]\n",
        "\n",
        "    validation_prompt = f\"\"\"\n",
        "    Analise este conteÃºdo e diga se estÃ¡ bom ou precisa melhorar:\n",
        "\n",
        "    {content}\n",
        "\n",
        "    CritÃ©rios:\n",
        "    - EstÃ¡ informativo?\n",
        "    - EstÃ¡ bem estruturado?\n",
        "    - Tem pelo menos 100 palavras?\n",
        "\n",
        "    Responda apenas:\n",
        "    \"APROVADO\" se estÃ¡ bom\n",
        "    \"REPROVAR: [motivo]\" se precisa melhorar\n",
        "    \"\"\"\n",
        "\n",
        "    validation = llm.invoke(validation_prompt)\n",
        "\n",
        "    state[\"validation_result\"] = validation.content\n",
        "\n",
        "    if \"REPROVAR\" in validation.content:\n",
        "        state[\"feedback\"] = validation.content.replace(\"REPROVAR:\", \"\").strip()\n",
        "        state[\"needs_improvement\"] = True\n",
        "    else:\n",
        "        state[\"needs_improvement\"] = False\n",
        "\n",
        "    return state\n",
        "\n",
        "def decide_improvement(state: Dict[str, Any]) -> str:\n",
        "    \"\"\"Decide se precisa melhorar ou se estÃ¡ pronto\"\"\"\n",
        "    max_attempts = 3\n",
        "    current_attempt = state.get(\"attempt\", 1)\n",
        "\n",
        "    if state.get(\"needs_improvement\", False) and current_attempt < max_attempts:\n",
        "        # Incrementa tentativa e volta para gerar conteÃºdo\n",
        "        state[\"attempt\"] = current_attempt + 1\n",
        "        return \"generate\"  # Volta para o gerador\n",
        "    else:\n",
        "        return END  # Termina (ou estÃ¡ aprovado, ou atingiu limite)\n",
        "\n",
        "print(\"ğŸ”„ Workflow avanÃ§ado com loops criado!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkKjNDJqlcEY"
      },
      "outputs": [],
      "source": [
        "# Montando o workflow avanÃ§ado\n",
        "advanced_workflow = StateGraph(dict)\n",
        "\n",
        "# Adicionando nodes\n",
        "advanced_workflow.add_node(\"generate\", content_generator_node)\n",
        "advanced_workflow.add_node(\"validate\", validator_node)\n",
        "\n",
        "# Entry point\n",
        "advanced_workflow.set_entry_point(\"generate\")\n",
        "\n",
        "# Connections\n",
        "# Gerador sempre vai para validador\n",
        "advanced_workflow.add_edge(\"generate\", \"validate\")\n",
        "\n",
        "# Validador decide se volta para gerador ou termina\n",
        "advanced_workflow.add_conditional_edges(\n",
        "    \"validate\",\n",
        "    decide_improvement,\n",
        "    {\n",
        "        \"generate\": \"generate\",  # Loop de volta!\n",
        "        END: END\n",
        "    }\n",
        ")\n",
        "\n",
        "# Compilando\n",
        "advanced_app = advanced_workflow.compile()\n",
        "\n",
        "print(\"ğŸ¯ Workflow avanÃ§ado compilado!\")\n",
        "print(\"Este pode fazer loops atÃ© ficar perfeito! ğŸ”„\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bllXKvVelcEZ"
      },
      "outputs": [],
      "source": [
        "# Testando o workflow avanÃ§ado\n",
        "topic = \"BenefÃ­cios da IA na educaÃ§Ã£o brasileira em menos de 99 palavras\"\n",
        "\n",
        "advanced_state = {\n",
        "    \"topic\": topic,\n",
        "    \"attempt\": 1,\n",
        "    \"content\": \"\",\n",
        "    \"validation_result\": \"\",\n",
        "    \"feedback\": \"\",\n",
        "    \"needs_improvement\": False\n",
        "}\n",
        "\n",
        "print(f\"ğŸ¯ TÃ³pico: {topic}\")\n",
        "print(\"\\nğŸš€ Executando workflow com validaÃ§Ã£o...\\n\")\n",
        "\n",
        "# Executando\n",
        "final_advanced_state = advanced_app.invoke(advanced_state)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸ“Š RESULTADO FINAL:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Tentativas: {final_advanced_state['attempt']}\")\n",
        "print(f\"ValidaÃ§Ã£o: {final_advanced_state['validation_result']}\")\n",
        "print(\"\\nConteÃºdo final:\")\n",
        "print(\"-\" * 30)\n",
        "print(final_advanced_state['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn83cobZlcEa"
      },
      "source": [
        "## ğŸ¯ Comparando com o que JÃ¡ Sabemos\n",
        "\n",
        "Vamos fazer uma **comparaÃ§Ã£o prÃ¡tica** entre as abordagens que jÃ¡ conhecemos:\n",
        "\n",
        "### ğŸ”— Chains (MÃ³dulo 6)\n",
        "- âœ… **Simples** e direto\n",
        "- âŒ **Linear** - nÃ£o pode voltar\n",
        "- âŒ **Sem condiÃ§Ãµes** complexas\n",
        "\n",
        "### ğŸ¤– Agents (MÃ³dulo 11)\n",
        "- âœ… **Inteligente** - usa tools\n",
        "- âœ… **FlexÃ­vel** - decide aÃ§Ãµes\n",
        "- âŒ **Um agente sÃ³** - nÃ£o coordena mÃºltiplos\n",
        "\n",
        "### ğŸ•¸ï¸ LangGraph (AGORA!)\n",
        "- âœ… **MÃºltiplos agentes** especializados\n",
        "- âœ… **Fluxos condicionais** complexos\n",
        "- âœ… **Loops** e validaÃ§Ãµes\n",
        "- âœ… **Estado compartilhado** entre todos\n",
        "- âœ… **OrquestraÃ§Ã£o** inteligente\n",
        "\n",
        "**Dica!** Use LangGraph quando precisar de workflows complexos com mÃºltiplos \"especialistas\" trabalhando juntos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyoii6dBlcEa"
      },
      "outputs": [],
      "source": [
        "# Vamos comparar na prÃ¡tica - mesma tarefa, abordagens diferentes\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "question = \"Como implementar IA no atendimento ao cliente?\"\n",
        "\n",
        "print(\"ğŸ¥Š COMPARAÃ‡ÃƒO PRÃTICA: Chain vs LangGraph\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Abordagem 1: Chain simples (que jÃ¡ conhecemos)\n",
        "print(\"\\nğŸ”— ABORDAGEM 1: CHAIN SIMPLES\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "simple_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"Responda esta pergunta de forma completa: {question}\"\n",
        ")\n",
        "\n",
        "simple_chain = simple_prompt | llm\n",
        "chain_result = simple_chain.invoke({\"question\": question})\n",
        "\n",
        "print(\"Resultado Chain:\")\n",
        "print(chain_result.content[:200] + \"...\")\n",
        "\n",
        "# Abordagem 2: LangGraph (nosso workflow)\n",
        "print(\"\\nğŸ•¸ï¸ ABORDAGEM 2: LANGGRAPH\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "graph_state = create_initial_state(question)\n",
        "graph_result = app.invoke(graph_state)\n",
        "\n",
        "print(\"Resultado LangGraph:\")\n",
        "print(graph_result[\"final_response\"][:200] + \"...\")\n",
        "\n",
        "print(\"\\nğŸ“Š DIFERENÃ‡AS:\")\n",
        "print(\"Chain: 1 etapa, resposta direta\")\n",
        "print(\"LangGraph: 3 etapas (pesquisa + anÃ¡lise + sÃ­ntese)\")\n",
        "print(\"\\nLangGraph Ã© mais rico e estruturado! ğŸš€\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mURTX2dnlcEa"
      },
      "source": [
        "## ğŸ› ï¸ Casos de Uso Reais\n",
        "\n",
        "Agora que vocÃª entendeu o conceito, vamos ver onde o LangGraph **brilha** na vida real:\n",
        "\n",
        "### 1. ğŸ¥ **DiagnÃ³stico MÃ©dico Assistido**\n",
        "- Agente coleta sintomas\n",
        "- Agente pesquisa condiÃ§Ãµes possÃ­veis\n",
        "- Agente analisa exames\n",
        "- Agente gera relatÃ³rio para mÃ©dico\n",
        "\n",
        "### 2. ğŸ“ˆ **AnÃ¡lise Financeira Completa**\n",
        "- Agente coleta dados do mercado\n",
        "- Agente analisa tendÃªncias\n",
        "- Agente calcula riscos\n",
        "- Agente gera recomendaÃ§Ãµes\n",
        "\n",
        "### 3. ğŸ“ **Tutor Educacional Personalizado**\n",
        "- Agente avalia nÃ­vel do aluno\n",
        "- Agente adapta conteÃºdo\n",
        "- Agente monitora progresso\n",
        "- Agente ajusta estratÃ©gia\n",
        "\n",
        "### 4. ğŸ¢ **Assistente Empresarial Completo**\n",
        "- Agente analisa documentos\n",
        "- Agente pesquisa regulamentaÃ§Ãµes\n",
        "- Agente gera relatÃ³rios\n",
        "- Agente sugere aÃ§Ãµes\n",
        "\n",
        "**Dica!** LangGraph Ã© perfeito para qualquer tarefa que normalmente precisaria de uma \"equipe\" de especialistas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQaM9xAelcEb"
      },
      "source": [
        "## ğŸ’¡ ExercÃ­cio PrÃ¡tico\n",
        "\n",
        "**DESAFIO**: Crie um workflow LangGraph para anÃ¡lise de currÃ­culo!\n",
        "\n",
        "Seu workflow deve ter:\n",
        "1. **Agente Extrator**: Extrai informaÃ§Ãµes principais do currÃ­culo\n",
        "2. **Agente Avaliador**: Avalia pontos fortes e fracos\n",
        "3. **Agente Conselheiro**: DÃ¡ sugestÃµes de melhoria\n",
        "\n",
        "**Entrada**: Texto de um currÃ­culo\n",
        "**SaÃ­da**: AnÃ¡lise completa com sugestÃµes\n",
        "\n",
        "Vamos fazer juntos! ğŸš€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQg6Uu1zlcEb"
      },
      "outputs": [],
      "source": [
        "# EXERCÃCIO: Complete o cÃ³digo abaixo!\n",
        "\n",
        "def extract_info_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"SEU CÃ“DIGO AQUI: Extrair informaÃ§Ãµes do currÃ­culo\"\"\"\n",
        "    print(\"ğŸ“‹ Extraindo informaÃ§Ãµes do currÃ­culo...\")\n",
        "\n",
        "    curriculum = state[\"curriculum_text\"]\n",
        "\n",
        "    # DICA: Crie um prompt para extrair:\n",
        "    # - ExperiÃªncias\n",
        "    # - Habilidades\n",
        "    # - FormaÃ§Ã£o\n",
        "    # - Contato\n",
        "\n",
        "    extract_prompt = f\"\"\"\n",
        "    Extraia as principais informaÃ§Ãµes deste currÃ­culo:\n",
        "\n",
        "    {curriculum}\n",
        "\n",
        "    Organize em:\n",
        "    - EXPERIÃŠNCIAS:\n",
        "    - HABILIDADES:\n",
        "    - FORMAÃ‡ÃƒO:\n",
        "    - CONTATO:\n",
        "    \"\"\"\n",
        "\n",
        "    result = llm.invoke(extract_prompt)\n",
        "    state[\"extracted_info\"] = result.content\n",
        "\n",
        "    return state\n",
        "\n",
        "def evaluate_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"SEU CÃ“DIGO AQUI: Avaliar pontos fortes e fracos\"\"\"\n",
        "    print(\"âš–ï¸ Avaliando currÃ­culo...\")\n",
        "\n",
        "    # COMPLETE AQUI!\n",
        "    extracted = state[\"extracted_info\"]\n",
        "\n",
        "    evaluate_prompt = f\"\"\"\n",
        "    Baseado nestas informaÃ§Ãµes extraÃ­das:\n",
        "\n",
        "    {extracted}\n",
        "\n",
        "    Avalie:\n",
        "    PONTOS FORTES:\n",
        "    PONTOS FRACOS:\n",
        "    NOTA GERAL (1-10):\n",
        "    \"\"\"\n",
        "\n",
        "    result = llm.invoke(evaluate_prompt)\n",
        "    state[\"evaluation\"] = result.content\n",
        "\n",
        "    return state\n",
        "\n",
        "def advice_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"SEU CÃ“DIGO AQUI: Dar conselhos de melhoria\"\"\"\n",
        "    print(\"ğŸ’¡ Gerando conselhos...\")\n",
        "\n",
        "    # COMPLETE AQUI!\n",
        "    evaluation = state[\"evaluation\"]\n",
        "\n",
        "    advice_prompt = f\"\"\"\n",
        "    Baseado nesta avaliaÃ§Ã£o:\n",
        "\n",
        "    {evaluation}\n",
        "\n",
        "    DÃª 5 conselhos prÃ¡ticos para melhorar o currÃ­culo:\n",
        "\n",
        "    1.\n",
        "    2.\n",
        "    3.\n",
        "    4.\n",
        "    5.\n",
        "    \"\"\"\n",
        "\n",
        "    result = llm.invoke(advice_prompt)\n",
        "    state[\"advice\"] = result.content\n",
        "\n",
        "    return state\n",
        "\n",
        "print(\"ğŸ“ ExercÃ­cio preparado! Complete as funÃ§Ãµes acima.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXYEjf2_lcEc"
      },
      "outputs": [],
      "source": [
        "# Montando o workflow do exercÃ­cio\n",
        "curriculum_workflow = StateGraph(dict)\n",
        "\n",
        "# Adicionando nodes\n",
        "curriculum_workflow.add_node(\"extract\", extract_info_node)\n",
        "curriculum_workflow.add_node(\"evaluate\", evaluate_node)\n",
        "curriculum_workflow.add_node(\"advice\", advice_node)\n",
        "\n",
        "# Entry point\n",
        "curriculum_workflow.set_entry_point(\"extract\")\n",
        "\n",
        "# Edges sequenciais\n",
        "curriculum_workflow.add_edge(\"extract\", \"evaluate\")\n",
        "curriculum_workflow.add_edge(\"evaluate\", \"advice\")\n",
        "curriculum_workflow.add_edge(\"advice\", END)\n",
        "\n",
        "# Compilando\n",
        "curriculum_app = curriculum_workflow.compile()\n",
        "\n",
        "print(\"âœ… Workflow de anÃ¡lise de currÃ­culo criado!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hIeXgG9lcEc"
      },
      "outputs": [],
      "source": [
        "# Testando com um currÃ­culo exemplo\n",
        "sample_curriculum = \"\"\"\n",
        "JoÃ£o Silva\n",
        "Desenvolvedor Python\n",
        "Email: joao@email.com\n",
        "Telefone: (11) 99999-9999\n",
        "\n",
        "EXPERIÃŠNCIA:\n",
        "- Desenvolvedor Jr na TechCorp (2022-2024)\n",
        "- EstagiÃ¡rio na StartupX (2021-2022)\n",
        "\n",
        "HABILIDADES:\n",
        "- Python, Django, Flask\n",
        "- HTML, CSS, JavaScript\n",
        "- Git, Docker\n",
        "\n",
        "FORMAÃ‡ÃƒO:\n",
        "- CiÃªncia da ComputaÃ§Ã£o - UNIFEI (2020-2024)\n",
        "\"\"\"\n",
        "\n",
        "# Estado inicial\n",
        "curriculum_state = {\n",
        "    \"curriculum_text\": sample_curriculum,\n",
        "    \"extracted_info\": \"\",\n",
        "    \"evaluation\": \"\",\n",
        "    \"advice\": \"\"\n",
        "}\n",
        "\n",
        "print(\"ğŸ¯ Analisando currÃ­culo do JoÃ£o...\\n\")\n",
        "\n",
        "# Executando\n",
        "final_analysis = curriculum_app.invoke(curriculum_state)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸ“Š ANÃLISE COMPLETA DE CURRÃCULO\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\nğŸ“‹ INFORMAÃ‡Ã•ES EXTRAÃDAS:\")\n",
        "print(final_analysis[\"extracted_info\"])\n",
        "\n",
        "print(\"\\nâš–ï¸ AVALIAÃ‡ÃƒO:\")\n",
        "print(final_analysis[\"evaluation\"])\n",
        "\n",
        "print(\"\\nğŸ’¡ CONSELHOS:\")\n",
        "print(final_analysis[\"advice\"])\n",
        "\n",
        "print(\"\\nğŸ‰ ParabÃ©ns! VocÃª criou um sistema completo de anÃ¡lise!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63128XMTlcEc"
      },
      "source": [
        "## ğŸš€ Indo AlÃ©m: Integrando com Tools\n",
        "\n",
        "Lembra das **Tools** que vimos no mÃ³dulo 11? Podemos integrar elas com LangGraph!\n",
        "\n",
        "Imagine um agente que:\n",
        "1. **Pesquisa** na web (usando tool de busca)\n",
        "2. **Calcula** valores (usando tool de matemÃ¡tica)\n",
        "3. **Envia** emails (usando tool de email)\n",
        "4. **Salva** em banco de dados (usando tool de BD)\n",
        "\n",
        "Ã‰ como ter **super poderes** em cada node do grafo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGG-DoNelcEd"
      },
      "outputs": [],
      "source": [
        "# Exemplo rÃ¡pido: LangGraph + Tools\n",
        "from langchain.tools import Tool\n",
        "\n",
        "# Criando uma tool simples (lembra do mÃ³dulo 11?)\n",
        "def calculate_roi(investment: str) -> str:\n",
        "    \"\"\"Calcula ROI bÃ¡sico\"\"\"\n",
        "    try:\n",
        "        # Parsing simples - na vida real seria mais robusto\n",
        "        parts = investment.split(\",\")\n",
        "        initial = float(parts[0])\n",
        "        final = float(parts[1])\n",
        "        roi = ((final - initial) / initial) * 100\n",
        "        return f\"ROI: {roi:.2f}%\"\n",
        "    except:\n",
        "        return \"Erro no cÃ¡lculo. Use formato: valor_inicial,valor_final\"\n",
        "\n",
        "# Criando a tool\n",
        "roi_tool = Tool(\n",
        "    name=\"calculate_roi\",\n",
        "    description=\"Calcula ROI. Input: 'valor_inicial,valor_final'\",\n",
        "    func=calculate_roi\n",
        ")\n",
        "\n",
        "def investment_analyzer_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Node que usa tools para anÃ¡lise de investimento\"\"\"\n",
        "    print(\"ğŸ’° Analisando investimento com tools...\")\n",
        "\n",
        "    # Simulando uso de tool\n",
        "    investment_data = \"1000,1200\"  # R$ 1000 virou R$ 1200\n",
        "    roi_result = roi_tool.func(investment_data)\n",
        "\n",
        "    state[\"roi_calculation\"] = roi_result\n",
        "\n",
        "    # Agora usa LLM para interpretar\n",
        "    interpretation_prompt = f\"\"\"\n",
        "    Baseado neste cÃ¡lculo de ROI: {roi_result}\n",
        "\n",
        "    DÃª uma interpretaÃ§Ã£o:\n",
        "    - Ã‰ um bom retorno?\n",
        "    - Qual o risco?\n",
        "    - RecomendaÃ§Ãµes?\n",
        "    \"\"\"\n",
        "\n",
        "    analysis = llm.invoke(interpretation_prompt)\n",
        "    state[\"investment_analysis\"] = analysis.content\n",
        "\n",
        "    return state\n",
        "\n",
        "# Testando\n",
        "investment_state = {\"roi_calculation\": \"\", \"investment_analysis\": \"\"}\n",
        "result = investment_analyzer_node(investment_state)\n",
        "\n",
        "print(\"\\nğŸ“Š RESULTADO:\")\n",
        "print(f\"CÃ¡lculo: {result['roi_calculation']}\")\n",
        "print(f\"AnÃ¡lise: {result['investment_analysis'][:150]}...\")\n",
        "\n",
        "print(\"\\nğŸ¯ ISSO Ã© o poder do LangGraph + Tools!\")\n",
        "print(\"Cada node pode usar ferramentas externas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myISDJXPlcEd"
      },
      "source": [
        "## ğŸ“ˆ Performance e OtimizaÃ§Ã£o\n",
        "\n",
        "Quando vocÃª comeÃ§a a usar LangGraph em **produÃ§Ã£o**, algumas dicas importantes:\n",
        "\n",
        "### ğŸš€ **Dicas de Performance**\n",
        "\n",
        "1. **ParalelizaÃ§Ã£o**: Alguns nodes podem rodar em paralelo\n",
        "2. **Cache**: Evite recalcular coisas iguais\n",
        "3. **Timeouts**: Defina limites para evitar travamentos\n",
        "4. **Logging**: Monitore cada step do workflow\n",
        "\n",
        "### ğŸ’¡ **Boas PrÃ¡ticas**\n",
        "\n",
        "- âœ… **Nodes pequenos** e focados\n",
        "- âœ… **Estado mÃ­nimo** - sÃ³ o necessÃ¡rio\n",
        "- âœ… **Tratamento de erros** em cada node\n",
        "- âœ… **DocumentaÃ§Ã£o** clara do fluxo\n",
        "\n",
        "**Dica!** Em produÃ§Ã£o, sempre monitore o tempo de execuÃ§Ã£o de cada node!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01HQ04wolcEd"
      },
      "outputs": [],
      "source": [
        "# Exemplo de monitoramento simples\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "def monitored_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Node com monitoramento bÃ¡sico\"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"â° [{datetime.now().strftime('%H:%M:%S')}] Iniciando node...\")\n",
        "\n",
        "    try:\n",
        "        # Simulando processamento\n",
        "        time.sleep(1)  # Simula 1 segundo de trabalho\n",
        "\n",
        "        state[\"result\"] = \"Processamento concluÃ­do com sucesso!\"\n",
        "        state[\"status\"] = \"success\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro: {str(e)}\")\n",
        "        state[\"result\"] = f\"Erro: {str(e)}\"\n",
        "        state[\"status\"] = \"error\"\n",
        "\n",
        "    finally:\n",
        "        end_time = time.time()\n",
        "        execution_time = end_time - start_time\n",
        "\n",
        "        print(f\"â±ï¸ Node executado em {execution_time:.2f}s\")\n",
        "        state[\"execution_time\"] = execution_time\n",
        "\n",
        "    return state\n",
        "\n",
        "# Testando monitoramento\n",
        "test_state = {}\n",
        "monitored_result = monitored_node(test_state)\n",
        "\n",
        "print(\"\\nğŸ“Š Estado final:\")\n",
        "for key, value in monitored_result.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "print(\"\\nğŸ¯ Em produÃ§Ã£o, vocÃª salvaria esses logs em um sistema de monitoramento!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Dkd0YXlcEd"
      },
      "source": [
        "## ğŸ­ Casos de Uso AvanÃ§ados\n",
        "\n",
        "Para finalizar, vamos ver alguns casos **SUPER AVANÃ‡ADOS** onde LangGraph realmente brilha:\n",
        "\n",
        "### 1. **Sistema de AprovaÃ§Ã£o Multi-NÃ­vel**\n",
        "```\n",
        "SOLICITAÃ‡ÃƒO â†’ SUPERVISOR â†’ GERENTE â†’ DIRETOR â†’ APROVADO/NEGADO\n",
        "     â†‘______________|_______________|____________â†‘\n",
        "          (pode voltar para qualquer nÃ­vel)\n",
        "```\n",
        "\n",
        "### 2. **Chatbot com Contexto Complexo**\n",
        "```\n",
        "USUÃRIO â†’ CLASSIFICADOR â†’ ESPECIALISTA_A â†’ VALIDADOR â†’ RESPOSTA\n",
        "              â†“              â†‘              â†‘\n",
        "         ESPECIALISTA_B â†’ COMBINADOR ------â†‘\n",
        "```\n",
        "\n",
        "### 3. **Pipeline de ML Completo**\n",
        "```\n",
        "DADOS â†’ LIMPEZA â†’ FEATURE_ENG â†’ TREINO â†’ VALIDAÃ‡ÃƒO â†’ DEPLOY\n",
        "   â†‘        â†“          â†‘           â†“        â†“         â†‘\n",
        "   â””â”€â”€â”€â”€FEEDBACKâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "```\n",
        "\n",
        "**Dica!** LangGraph permite modelar qualquer processo complexo que vocÃª imaginar!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICcxZfyKlcEe"
      },
      "source": [
        "## ğŸ¯ Resumo: O que Aprendemos\n",
        "\n",
        "**ParabÃ©ns!** ğŸ‰ VocÃª dominou o LangGraph! Aqui estÃ¡ o que cobrimos:\n",
        "\n",
        "### âœ… **Conceitos Fundamentais**\n",
        "- Nodes, Edges e State\n",
        "- DiferenÃ§as entre Chains, Agents e LangGraph\n",
        "- Fluxos condicionais e loops\n",
        "\n",
        "### âœ… **ImplementaÃ§Ã£o PrÃ¡tica**\n",
        "- Criamos workflows completos\n",
        "- Integramos mÃºltiplos agentes especializados\n",
        "- Implementamos validaÃ§Ã£o e melhoria iterativa\n",
        "\n",
        "### âœ… **Casos de Uso Reais**\n",
        "- AnÃ¡lise de conteÃºdo com validaÃ§Ã£o\n",
        "- AnÃ¡lise de currÃ­culo multi-etapas\n",
        "- IntegraÃ§Ã£o com Tools externas\n",
        "\n",
        "### âœ… **Boas PrÃ¡ticas**\n",
        "- Monitoramento e logging\n",
        "- Tratamento de erros\n",
        "- OtimizaÃ§Ã£o de performance\n",
        "\n",
        "### ğŸš€ **PrÃ³ximos Passos**\n",
        "No **mÃ³dulo 17**, vamos ver o **LangSmith** - a ferramenta para monitorar, debuggar e otimizar tudo que construÃ­mos!\n",
        "\n",
        "**Dica Final!** LangGraph Ã© perfeito para substituir sistemas complexos que normalmente precisariam de mÃºltiplas pessoas ou ferramentas separadas. Ã‰ IA trabalhando em equipe! ğŸ¤"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6CZbWqTlcEe"
      },
      "source": [
        "## ğŸ† Desafio Final\n",
        "\n",
        "**MISSÃƒO ESPECIAL**: Crie um LangGraph que simula uma **consultoria empresarial completa**!\n",
        "\n",
        "### Requisitos:\n",
        "1. **Agente DiagnÃ³stico**: Analisa problemas da empresa\n",
        "2. **Agente Pesquisador**: Busca soluÃ§Ãµes similares no mercado\n",
        "3. **Agente Estrategista**: PropÃµe estratÃ©gias\n",
        "4. **Agente Validador**: Valida viabilidade das propostas\n",
        "5. **Agente Apresentador**: Cria apresentaÃ§Ã£o final\n",
        "\n",
        "### Diferenciais:\n",
        "- âœ… Loops de validaÃ§Ã£o\n",
        "- âœ… DecisÃµes condicionais baseadas no tipo de empresa\n",
        "- âœ… IntegraÃ§Ã£o com tools (se possÃ­vel)\n",
        "- âœ… Monitoramento de cada etapa\n",
        "\n",
        "**Prazo**: PrÃ³xima aula! ğŸ˜„\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”¥ **VocÃª chegou atÃ© aqui = VOCÃŠ Ã‰ TOP!**\n",
        "\n",
        "LangGraph Ã© uma das ferramentas mais avanÃ§adas do ecossistema LangChain. Dominando ela, vocÃª pode criar sistemas de IA **extremamente sofisticados**.\n",
        "\n",
        "**Nos vemos no mÃ³dulo 17** para descobrir como monitorar e otimizar tudo isso com **LangSmith**! ğŸš€\n",
        "\n",
        "![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-16_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mtSKjOlBt1D7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}