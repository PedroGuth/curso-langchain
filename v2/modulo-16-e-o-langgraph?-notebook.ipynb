{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRyB7dQ-lcD9"
      },
      "source": [
        "# üï∏Ô∏è LangGraph: Orquestrando Agentes como um Maestro Digital!\n",
        "\n",
        "## M√≥dulo 16 - LangChain v0.3 Course\n",
        "### Por Pedro Nunes Guth\n",
        "\n",
        "---\n",
        "\n",
        "T√°, chegamos aqui no m√≥dulo 16 e voc√™ j√° viu **MUITA COISA**: ChatModels, Agents, Tools, RAG... Mas e se eu te disser que existe uma forma de orquestrar tudo isso como se voc√™ fosse o maestro de uma orquestra sinf√¥nica? üéº\n",
        "\n",
        "√â a√≠ que entra o **LangGraph**! Think of it como o \"WhatsApp em grupo\" dos seus agentes - cada um tem sua fun√ß√£o, mas todos trabalham juntos de forma coordenada.\n",
        "\n",
        "![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-16_img_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nOzHVkdlcEF"
      },
      "source": [
        "## ü§î T√°, mas o que √© LangGraph?\n",
        "\n",
        "LangGraph √© uma extens√£o do LangChain que permite criar **workflows complexos** usando grafos (graphs). Imagine que voc√™ tem v√°rios agentes especializados:\n",
        "\n",
        "- üîç **Agente Pesquisador**: Busca informa√ß√µes na web\n",
        "- üìä **Agente Analista**: Processa dados e gera insights\n",
        "- ‚úçÔ∏è **Agente Escritor**: Cria conte√∫do baseado nas an√°lises\n",
        "- üîß **Agente Revisor**: Valida e corrige o resultado final\n",
        "\n",
        "Com LangGraph, voc√™ pode fazer esses agentes conversarem entre si, passarem informa√ß√µes, tomarem decis√µes e at√© **voltarem atr√°s** quando necess√°rio!\n",
        "\n",
        "### Por que n√£o usar s√≥ Chains?\n",
        "\n",
        "Lembra das Chains que vimos l√° no m√≥dulo 6? Elas s√£o **lineares** - como uma linha de produ√ß√£o. O LangGraph permite **fluxos condicionais** - como um GPS que recalcula a rota baseado no tr√¢nsito!\n",
        "\n",
        "**Dica!** LangGraph √© perfeito quando voc√™ precisa de l√≥gica condicional complexa entre seus agentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUPPVDThlcEH"
      },
      "outputs": [],
      "source": [
        "# Primeiro, vamos instalar tudo que precisamos\n",
        "!pip install langgraph langchain-google-genai python-dotenv --quiet\n",
        "\n",
        "# Imports b√°sicos\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from typing import Dict, List, Any\n",
        "import json\n",
        "\n",
        "# LangGraph espec√≠fico\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Carregando vari√°veis de ambiente\n",
        "load_dotenv()\n",
        "\n",
        "print(\"Libs instaladas! Bora come√ßar! üöÄ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InHb3xBOlcEK"
      },
      "source": [
        "## üß† Conceitos Fundamentais\n",
        "\n",
        "Antes de colocar a m√£o na massa, vamos entender os conceitos b√°sicos:\n",
        "\n",
        "### 1. **Nodes (N√≥s)**\n",
        "S√£o as \"esta√ß√µes\" do seu fluxo. Cada node executa uma tarefa espec√≠fica.\n",
        "\n",
        "### 2. **Edges (Arestas)**\n",
        "S√£o as \"estradas\" que conectam os nodes. Podem ser:\n",
        "- **Fixas**: Sempre vai para o pr√≥ximo node\n",
        "- **Condicionais**: Decide para onde ir baseado no resultado\n",
        "\n",
        "### 3. **State (Estado)**\n",
        "√â o \"WhatsApp do grupo\" - todas as informa√ß√µes compartilhadas entre os nodes.\n",
        "\n",
        "### Analogia Brasileira üáßüá∑\n",
        "Pense no LangGraph como o **SUS (Sistema √önico de Sa√∫de)**:\n",
        "- Voc√™ chega na **recep√ß√£o** (node inicial)\n",
        "- Dependendo do seu caso, vai para **cl√≠nico geral** ou **especialista** (edges condicionais)\n",
        "- Cada m√©dico acessa seu **prontu√°rio** (state compartilhado)\n",
        "- Pode precisar voltar para outros m√©dicos (loops no grafo)\n",
        "\n",
        "**Dica!** O state √© persistente - cada node pode ler e modificar as informa√ß√µes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv9ZinqslcEK"
      },
      "outputs": [],
      "source": [
        "# Vamos criar nosso primeiro exemplo simples\n",
        "# Configurando o modelo que j√° conhecemos\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    google_api_key=\"Coloca-a-sua-chave-aqui!!!!\",\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "# Definindo nossa estrutura de estado\n",
        "# √â como um dicion√°rio que todos os nodes podem acessar\n",
        "def create_initial_state(user_input: str) -> Dict[str, Any]:\n",
        "    return {\n",
        "        \"user_input\": user_input,\n",
        "        \"research_data\": \"\",\n",
        "        \"analysis\": \"\",\n",
        "        \"final_response\": \"\",\n",
        "        \"step_count\": 0\n",
        "    }\n",
        "\n",
        "print(\"Setup b√°sico pronto! üéØ\")\n",
        "print(\"Agora vamos criar nossos 'funcion√°rios especializados'...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCmViBxwlcEL"
      },
      "source": [
        "## üîç Criando Nossos Agentes Especializados\n",
        "\n",
        "Lembra dos Agents que vimos no m√≥dulo 11? Agora vamos criar **fun√ß√µes especializadas** que funcionam como mini-agentes dentro do nosso grafo.\n",
        "\n",
        "Cada fun√ß√£o vai:\n",
        "1. Receber o **state atual**\n",
        "2. Fazer seu **trabalho espec√≠fico**\n",
        "3. Atualizar o **state** com os resultados\n",
        "4. Retornar o **state modificado**\n",
        "\n",
        "√â como um **revezamento** - cada corredor recebe o bast√£o, corre sua parte e passa adiante!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS7GKA-IlcEM"
      },
      "outputs": [],
      "source": [
        "# Node 1: Agente Pesquisador\n",
        "def research_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Este 'funcion√°rio' √© especialista em pesquisa\n",
        "    Ele pega a pergunta do usu√°rio e simula uma pesquisa\n",
        "    \"\"\"\n",
        "    print(\"üîç Agente Pesquisador trabalhando...\")\n",
        "\n",
        "    user_question = state[\"user_input\"]\n",
        "\n",
        "    # Prompt para simular pesquisa\n",
        "    research_prompt = f\"\"\"\n",
        "    Voc√™ √© um pesquisador expert. Sua tarefa √© simular uma pesquisa sobre: {user_question}\n",
        "\n",
        "    Forne√ßa dados e informa√ß√µes relevantes como se voc√™ tivesse pesquisado em fontes confi√°veis.\n",
        "    Seja espec√≠fico e inclua n√∫meros, estat√≠sticas ou fatos quando poss√≠vel.\n",
        "\n",
        "    Formato: Lista com 3-5 pontos principais de pesquisa.\n",
        "    \"\"\"\n",
        "\n",
        "    # Fazendo a pesquisa com nossa LLM\n",
        "    research_result = llm.invoke(research_prompt)\n",
        "\n",
        "    # Atualizando o state\n",
        "    state[\"research_data\"] = research_result.content\n",
        "    state[\"step_count\"] += 1\n",
        "\n",
        "    print(f\"‚úÖ Pesquisa conclu√≠da! Step {state['step_count']}\")\n",
        "    return state\n",
        "\n",
        "# Node 2: Agente Analista\n",
        "def analysis_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Este 'funcion√°rio' pega os dados da pesquisa e faz an√°lise\n",
        "    \"\"\"\n",
        "    print(\"üìä Agente Analista trabalhando...\")\n",
        "\n",
        "    research_data = state[\"research_data\"]\n",
        "    original_question = state[\"user_input\"]\n",
        "\n",
        "    analysis_prompt = f\"\"\"\n",
        "    Voc√™ √© um analista expert. Baseado nestes dados de pesquisa:\n",
        "\n",
        "    {research_data}\n",
        "\n",
        "    Fa√ßa uma an√°lise cr√≠tica e inteligente relacionada √† pergunta original: {original_question}\n",
        "\n",
        "    Inclua:\n",
        "    - Insights principais\n",
        "    - Padr√µes identificados\n",
        "    - Conclus√µes baseadas nos dados\n",
        "    \"\"\"\n",
        "\n",
        "    analysis_result = llm.invoke(analysis_prompt)\n",
        "\n",
        "    state[\"analysis\"] = analysis_result.content\n",
        "    state[\"step_count\"] += 1\n",
        "\n",
        "    print(f\"‚úÖ An√°lise conclu√≠da! Step {state['step_count']}\")\n",
        "    return state\n",
        "\n",
        "print(\"Agentes criados! ü§ñ\")\n",
        "print(\"Pr√≥ximo: vamos criar o agente que junta tudo...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZIYxLOplcEO"
      },
      "outputs": [],
      "source": [
        "# Node 3: Agente Sintetizador (junta tudo)\n",
        "def synthesis_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Este √© o 'chefe' que junta o trabalho de todos\n",
        "    \"\"\"\n",
        "    print(\"‚úçÔ∏è Agente Sintetizador trabalhando...\")\n",
        "\n",
        "    user_question = state[\"user_input\"]\n",
        "    research = state[\"research_data\"]\n",
        "    analysis = state[\"analysis\"]\n",
        "\n",
        "    synthesis_prompt = f\"\"\"\n",
        "    Voc√™ √© um sintetizador expert. Sua miss√£o √© criar uma resposta final completa e √∫til.\n",
        "\n",
        "    PERGUNTA ORIGINAL: {user_question}\n",
        "\n",
        "    DADOS DE PESQUISA:\n",
        "    {research}\n",
        "\n",
        "    AN√ÅLISE REALIZADA:\n",
        "    {analysis}\n",
        "\n",
        "    Crie uma resposta final que:\n",
        "    1. Responda diretamente √† pergunta\n",
        "    2. Use os dados pesquisados\n",
        "    3. Inclua os insights da an√°lise\n",
        "    4. Seja clara e acion√°vel\n",
        "\n",
        "    Tom: Profissional mas acess√≠vel, como o Pedro Guth explicaria! üöÄ\n",
        "    \"\"\"\n",
        "\n",
        "    final_result = llm.invoke(synthesis_prompt)\n",
        "\n",
        "    state[\"final_response\"] = final_result.content\n",
        "    state[\"step_count\"] += 1\n",
        "\n",
        "    print(f\"‚úÖ S√≠ntese conclu√≠da! Step {state['step_count']}\")\n",
        "    print(\"üéâ Workflow completo!\")\n",
        "    return state\n",
        "\n",
        "# Fun√ß√£o para decidir qual caminho seguir (edge condicional)\n",
        "def decide_next_step(state: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Esta fun√ß√£o decide para onde ir baseado no estado atual\n",
        "    √â como um sem√°foro inteligente!\n",
        "    \"\"\"\n",
        "    step_count = state[\"step_count\"]\n",
        "\n",
        "    if step_count == 1:  # Acabou de pesquisar\n",
        "        return \"analysis\"\n",
        "    elif step_count == 2:  # Acabou de analisar\n",
        "        return \"synthesis\"\n",
        "    else:  # Acabou tudo\n",
        "        return END\n",
        "\n",
        "print(\"Todas as fun√ß√µes criadas! üõ†Ô∏è\")\n",
        "print(\"Agora vamos montar o grafo...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJUZ-aZMlcER"
      },
      "source": [
        "## üï∏Ô∏è Montando o Grafo\n",
        "\n",
        "Agora vem a parte **MAIS LEGAL**! Vamos conectar nossos agentes como se fossem pe√ßas de Lego:\n",
        "\n",
        "```\n",
        "USU√ÅRIO ‚Üí PESQUISA ‚Üí AN√ÅLISE ‚Üí S√çNTESE ‚Üí RESPOSTA FINAL\n",
        "```\n",
        "\n",
        "O LangGraph vai cuidar de:\n",
        "- ‚úÖ Executar cada node na ordem certa\n",
        "- ‚úÖ Passar o state entre eles\n",
        "- ‚úÖ Tomar decis√µes baseado nas condi√ß√µes\n",
        "- ‚úÖ Gerenciar todo o fluxo automaticamente\n",
        "\n",
        "√â como ter um **assistente pessoal digital** coordenando uma equipe inteira!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XptDE9tPlcEU"
      },
      "outputs": [],
      "source": [
        "# Criando o grafo - √â aqui que a m√°gica acontece! ‚ú®\n",
        "workflow = StateGraph(dict)\n",
        "\n",
        "# Adicionando nossos 'funcion√°rios' (nodes)\n",
        "workflow.add_node(\"research\", research_node)\n",
        "workflow.add_node(\"analysis\", analysis_node)\n",
        "workflow.add_node(\"synthesis\", synthesis_node)\n",
        "\n",
        "# Definindo o ponto de entrada (onde tudo come√ßa)\n",
        "workflow.set_entry_point(\"research\")\n",
        "\n",
        "# Conectando os nodes com edges condicionais\n",
        "workflow.add_conditional_edges(\n",
        "    \"research\",\n",
        "    decide_next_step,\n",
        "    {\n",
        "        \"analysis\": \"analysis\",\n",
        "        END: END\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"analysis\",\n",
        "    decide_next_step,\n",
        "    {\n",
        "        \"synthesis\": \"synthesis\",\n",
        "        END: END\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"synthesis\",\n",
        "    decide_next_step,\n",
        "    {\n",
        "        END: END\n",
        "    }\n",
        ")\n",
        "\n",
        "# Compilando o grafo (transformando em uma aplica√ß√£o execut√°vel)\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"üéØ Grafo montado e compilado!\")\n",
        "print(\"Agora temos um sistema completo de IA working together!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVb9AqrXlcEW"
      },
      "source": [
        "## üöÄ Executando Nosso Primeiro Workflow\n",
        "\n",
        "Chegou a hora da verdade! Vamos fazer nosso \"time de especialistas digitais\" trabalhar junto.\n",
        "\n",
        "√â como dar o play em uma sinfonia - cada instrumento (agente) vai tocar sua parte no momento certo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6yVUc3flcEW"
      },
      "outputs": [],
      "source": [
        "# Teste pr√°tico - Vamos fazer uma pergunta!\n",
        "user_question = \"Quais s√£o as principais tend√™ncias de IA para 2025?\"\n",
        "\n",
        "print(f\"ü§î Pergunta do usu√°rio: {user_question}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üöÄ INICIANDO WORKFLOW LANGGRAPH\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "# Criando o estado inicial\n",
        "initial_state = create_initial_state(user_question)\n",
        "\n",
        "# Executando o workflow completo!\n",
        "# O LangGraph vai cuidar de tudo automaticamente\n",
        "final_state = app.invoke(initial_state)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"‚úÖ WORKFLOW CONCLU√çDO!\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoHCLewalcEX"
      },
      "outputs": [],
      "source": [
        "# Vamos ver o que cada agente produziu!\n",
        "print(\"üìã RELAT√ìRIO COMPLETO DO WORKFLOW:\\n\")\n",
        "\n",
        "print(\"üîç DADOS DA PESQUISA:\")\n",
        "print(\"-\" * 30)\n",
        "print(final_state[\"research_data\"][:300] + \"...\")\n",
        "\n",
        "print(\"\\nüìä AN√ÅLISE REALIZADA:\")\n",
        "print(\"-\" * 30)\n",
        "print(final_state[\"analysis\"][:300] + \"...\")\n",
        "\n",
        "print(\"\\nüéØ RESPOSTA FINAL:\")\n",
        "print(\"-\" * 30)\n",
        "print(final_state[\"final_response\"])\n",
        "\n",
        "print(f\"\\nüìà Total de steps executados: {final_state['step_count']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YN0FkyHlcEX"
      },
      "source": [
        "## üìä Visualizando o Fluxo\n",
        "\n",
        "Uma das coisas **MAIS LINDAS** do LangGraph √© que podemos visualizar nosso workflow! √â como ter um mapa do pensamento dos nossos agentes.\n",
        "\n",
        "Vamos criar um diagrama simples para entender o fluxo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLiOcHD0lcEX"
      },
      "outputs": [],
      "source": [
        "# Vamos criar uma visualiza√ß√£o simples do nosso workflow\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.patches import FancyBboxPatch\n",
        "import numpy as np\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Definindo posi√ß√µes dos nodes\n",
        "positions = {\n",
        "    'START': (1, 4),\n",
        "    'RESEARCH': (3, 4),\n",
        "    'ANALYSIS': (5, 4),\n",
        "    'SYNTHESIS': (7, 4),\n",
        "    'END': (9, 4)\n",
        "}\n",
        "\n",
        "# Cores para cada tipo de node\n",
        "colors = {\n",
        "    'START': '#90EE90',      # Verde claro\n",
        "    'RESEARCH': '#87CEEB',   # Azul claro\n",
        "    'ANALYSIS': '#DDA0DD',   # Roxo claro\n",
        "    'SYNTHESIS': '#F0E68C',  # Amarelo claro\n",
        "    'END': '#FFB6C1'        # Rosa claro\n",
        "}\n",
        "\n",
        "# Desenhando os nodes\n",
        "for node, (x, y) in positions.items():\n",
        "    # Criando caixas arredondadas\n",
        "    bbox = FancyBboxPatch(\n",
        "        (x-0.4, y-0.3), 0.8, 0.6,\n",
        "        boxstyle=\"round,pad=0.1\",\n",
        "        facecolor=colors[node],\n",
        "        edgecolor='black',\n",
        "        linewidth=2\n",
        "    )\n",
        "    ax.add_patch(bbox)\n",
        "\n",
        "    # Adicionando texto\n",
        "    ax.text(x, y, node, ha='center', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Desenhando as setas (edges)\n",
        "arrows = [\n",
        "    ((1.4, 4), (2.6, 4)),   # START -> RESEARCH\n",
        "    ((3.4, 4), (4.6, 4)),   # RESEARCH -> ANALYSIS\n",
        "    ((5.4, 4), (6.6, 4)),   # ANALYSIS -> SYNTHESIS\n",
        "    ((7.4, 4), (8.6, 4))    # SYNTHESIS -> END\n",
        "]\n",
        "\n",
        "for (x1, y1), (x2, y2) in arrows:\n",
        "    ax.annotate('', xy=(x2, y2), xytext=(x1, y1),\n",
        "                arrowprops=dict(arrowstyle='->', lw=2, color='darkblue'))\n",
        "\n",
        "# Configurando o gr√°fico\n",
        "ax.set_xlim(0, 10)\n",
        "ax.set_ylim(3, 5)\n",
        "ax.set_aspect('equal')\n",
        "ax.axis('off')\n",
        "\n",
        "plt.title('üï∏Ô∏è LangGraph Workflow - Fluxo dos Agentes', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üé® Liiindo! Esse √© o mapa do nosso workflow!\")\n",
        "print(\"Cada caixa √© um agente especializado trabalhando em sequ√™ncia.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNdvJFo6lcEY"
      },
      "source": [
        "## üîÑ Workflows com Loops e Condi√ß√µes\n",
        "\n",
        "Agora vamos para a parte **AVAN√áADA**! E se nosso agente precisar **voltar** e refazer algo? Ou tomar decis√µes diferentes baseado no conte√∫do?\n",
        "\n",
        "Vamos criar um workflow que pode:\n",
        "- ‚úÖ **Validar** se a resposta est√° boa\n",
        "- ‚úÖ **Voltar** para melhorar se necess√°rio\n",
        "- ‚úÖ **Decidir** caminhos diferentes baseado no conte√∫do\n",
        "\n",
        "√â como ter um **editor chato** que sempre pede para melhorar o texto! üòÖ\n",
        "\n",
        "**Dica!** Isso √© o que diferencia LangGraph das Chains simples - a capacidade de ter loops e condi√ß√µes complexas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-74X5CMlcEY"
      },
      "outputs": [],
      "source": [
        "# Vamos criar um workflow mais avan√ßado com valida√ß√£o\n",
        "\n",
        "def content_generator_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Gera conte√∫do inicial\"\"\"\n",
        "    print(\"‚úçÔ∏è Gerando conte√∫do...\")\n",
        "\n",
        "    topic = state[\"topic\"]\n",
        "    attempt = state.get(\"attempt\", 1)\n",
        "\n",
        "    if attempt > 1:\n",
        "        feedback = state.get(\"feedback\", \"\")\n",
        "        prompt = f\"\"\"\n",
        "        Reescreva o conte√∫do sobre: {topic}\n",
        "\n",
        "        Feedback para melhorar: {feedback}\n",
        "\n",
        "        Tentativa #{attempt} - Fa√ßa melhor desta vez!\n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt = f\"\"\"\n",
        "        Escreva um conte√∫do interessante sobre: {topic}\n",
        "\n",
        "        Fa√ßa algo informativo e engajante.\n",
        "        \"\"\"\n",
        "\n",
        "    result = llm.invoke(prompt)\n",
        "\n",
        "    state[\"content\"] = result.content\n",
        "    state[\"attempt\"] = attempt\n",
        "\n",
        "    return state\n",
        "\n",
        "def validator_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Valida se o conte√∫do est√° bom\"\"\"\n",
        "    print(\"üîç Validando conte√∫do...\")\n",
        "\n",
        "    content = state[\"content\"]\n",
        "\n",
        "    validation_prompt = f\"\"\"\n",
        "    Analise este conte√∫do e diga se est√° bom ou precisa melhorar:\n",
        "\n",
        "    {content}\n",
        "\n",
        "    Crit√©rios:\n",
        "    - Est√° informativo?\n",
        "    - Est√° bem estruturado?\n",
        "    - Tem pelo menos 100 palavras?\n",
        "\n",
        "    Responda apenas:\n",
        "    \"APROVADO\" se est√° bom\n",
        "    \"REPROVAR: [motivo]\" se precisa melhorar\n",
        "    \"\"\"\n",
        "\n",
        "    validation = llm.invoke(validation_prompt)\n",
        "\n",
        "    state[\"validation_result\"] = validation.content\n",
        "\n",
        "    if \"REPROVAR\" in validation.content:\n",
        "        state[\"feedback\"] = validation.content.replace(\"REPROVAR:\", \"\").strip()\n",
        "        state[\"needs_improvement\"] = True\n",
        "    else:\n",
        "        state[\"needs_improvement\"] = False\n",
        "\n",
        "    return state\n",
        "\n",
        "def decide_improvement(state: Dict[str, Any]) -> str:\n",
        "    \"\"\"Decide se precisa melhorar ou se est√° pronto\"\"\"\n",
        "    max_attempts = 3\n",
        "    current_attempt = state.get(\"attempt\", 1)\n",
        "\n",
        "    if state.get(\"needs_improvement\", False) and current_attempt < max_attempts:\n",
        "        # Incrementa tentativa e volta para gerar conte√∫do\n",
        "        state[\"attempt\"] = current_attempt + 1\n",
        "        return \"generate\"  # Volta para o gerador\n",
        "    else:\n",
        "        return END  # Termina (ou est√° aprovado, ou atingiu limite)\n",
        "\n",
        "print(\"üîÑ Workflow avan√ßado com loops criado!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkKjNDJqlcEY"
      },
      "outputs": [],
      "source": [
        "# Montando o workflow avan√ßado\n",
        "advanced_workflow = StateGraph(dict)\n",
        "\n",
        "# Adicionando nodes\n",
        "advanced_workflow.add_node(\"generate\", content_generator_node)\n",
        "advanced_workflow.add_node(\"validate\", validator_node)\n",
        "\n",
        "# Entry point\n",
        "advanced_workflow.set_entry_point(\"generate\")\n",
        "\n",
        "# Connections\n",
        "# Gerador sempre vai para validador\n",
        "advanced_workflow.add_edge(\"generate\", \"validate\")\n",
        "\n",
        "# Validador decide se volta para gerador ou termina\n",
        "advanced_workflow.add_conditional_edges(\n",
        "    \"validate\",\n",
        "    decide_improvement,\n",
        "    {\n",
        "        \"generate\": \"generate\",  # Loop de volta!\n",
        "        END: END\n",
        "    }\n",
        ")\n",
        "\n",
        "# Compilando\n",
        "advanced_app = advanced_workflow.compile()\n",
        "\n",
        "print(\"üéØ Workflow avan√ßado compilado!\")\n",
        "print(\"Este pode fazer loops at√© ficar perfeito! üîÑ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bllXKvVelcEZ"
      },
      "outputs": [],
      "source": [
        "# Testando o workflow avan√ßado\n",
        "topic = \"Benef√≠cios da IA na educa√ß√£o brasileira em menos de 99 palavras\"\n",
        "\n",
        "advanced_state = {\n",
        "    \"topic\": topic,\n",
        "    \"attempt\": 1,\n",
        "    \"content\": \"\",\n",
        "    \"validation_result\": \"\",\n",
        "    \"feedback\": \"\",\n",
        "    \"needs_improvement\": False\n",
        "}\n",
        "\n",
        "print(f\"üéØ T√≥pico: {topic}\")\n",
        "print(\"\\nüöÄ Executando workflow com valida√ß√£o...\\n\")\n",
        "\n",
        "# Executando\n",
        "final_advanced_state = advanced_app.invoke(advanced_state)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üìä RESULTADO FINAL:\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Tentativas: {final_advanced_state['attempt']}\")\n",
        "print(f\"Valida√ß√£o: {final_advanced_state['validation_result']}\")\n",
        "print(\"\\nConte√∫do final:\")\n",
        "print(\"-\" * 30)\n",
        "print(final_advanced_state['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn83cobZlcEa"
      },
      "source": [
        "## üéØ Comparando com o que J√° Sabemos\n",
        "\n",
        "Vamos fazer uma **compara√ß√£o pr√°tica** entre as abordagens que j√° conhecemos:\n",
        "\n",
        "### üîó Chains (M√≥dulo 6)\n",
        "- ‚úÖ **Simples** e direto\n",
        "- ‚ùå **Linear** - n√£o pode voltar\n",
        "- ‚ùå **Sem condi√ß√µes** complexas\n",
        "\n",
        "### ü§ñ Agents (M√≥dulo 11)\n",
        "- ‚úÖ **Inteligente** - usa tools\n",
        "- ‚úÖ **Flex√≠vel** - decide a√ß√µes\n",
        "- ‚ùå **Um agente s√≥** - n√£o coordena m√∫ltiplos\n",
        "\n",
        "### üï∏Ô∏è LangGraph (AGORA!)\n",
        "- ‚úÖ **M√∫ltiplos agentes** especializados\n",
        "- ‚úÖ **Fluxos condicionais** complexos\n",
        "- ‚úÖ **Loops** e valida√ß√µes\n",
        "- ‚úÖ **Estado compartilhado** entre todos\n",
        "- ‚úÖ **Orquestra√ß√£o** inteligente\n",
        "\n",
        "**Dica!** Use LangGraph quando precisar de workflows complexos com m√∫ltiplos \"especialistas\" trabalhando juntos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyoii6dBlcEa"
      },
      "outputs": [],
      "source": [
        "# Vamos comparar na pr√°tica - mesma tarefa, abordagens diferentes\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "question = \"Como implementar IA no atendimento ao cliente?\"\n",
        "\n",
        "print(\"ü•ä COMPARA√á√ÉO PR√ÅTICA: Chain vs LangGraph\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Abordagem 1: Chain simples (que j√° conhecemos)\n",
        "print(\"\\nüîó ABORDAGEM 1: CHAIN SIMPLES\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "simple_prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"Responda esta pergunta de forma completa: {question}\"\n",
        ")\n",
        "\n",
        "simple_chain = simple_prompt | llm\n",
        "chain_result = simple_chain.invoke({\"question\": question})\n",
        "\n",
        "print(\"Resultado Chain:\")\n",
        "print(chain_result.content[:200] + \"...\")\n",
        "\n",
        "# Abordagem 2: LangGraph (nosso workflow)\n",
        "print(\"\\nüï∏Ô∏è ABORDAGEM 2: LANGGRAPH\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "graph_state = create_initial_state(question)\n",
        "graph_result = app.invoke(graph_state)\n",
        "\n",
        "print(\"Resultado LangGraph:\")\n",
        "print(graph_result[\"final_response\"][:200] + \"...\")\n",
        "\n",
        "print(\"\\nüìä DIFEREN√áAS:\")\n",
        "print(\"Chain: 1 etapa, resposta direta\")\n",
        "print(\"LangGraph: 3 etapas (pesquisa + an√°lise + s√≠ntese)\")\n",
        "print(\"\\nLangGraph √© mais rico e estruturado! üöÄ\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mURTX2dnlcEa"
      },
      "source": [
        "## üõ†Ô∏è Casos de Uso Reais\n",
        "\n",
        "Agora que voc√™ entendeu o conceito, vamos ver onde o LangGraph **brilha** na vida real:\n",
        "\n",
        "### 1. üè• **Diagn√≥stico M√©dico Assistido**\n",
        "- Agente coleta sintomas\n",
        "- Agente pesquisa condi√ß√µes poss√≠veis\n",
        "- Agente analisa exames\n",
        "- Agente gera relat√≥rio para m√©dico\n",
        "\n",
        "### 2. üìà **An√°lise Financeira Completa**\n",
        "- Agente coleta dados do mercado\n",
        "- Agente analisa tend√™ncias\n",
        "- Agente calcula riscos\n",
        "- Agente gera recomenda√ß√µes\n",
        "\n",
        "### 3. üéì **Tutor Educacional Personalizado**\n",
        "- Agente avalia n√≠vel do aluno\n",
        "- Agente adapta conte√∫do\n",
        "- Agente monitora progresso\n",
        "- Agente ajusta estrat√©gia\n",
        "\n",
        "### 4. üè¢ **Assistente Empresarial Completo**\n",
        "- Agente analisa documentos\n",
        "- Agente pesquisa regulamenta√ß√µes\n",
        "- Agente gera relat√≥rios\n",
        "- Agente sugere a√ß√µes\n",
        "\n",
        "**Dica!** LangGraph √© perfeito para qualquer tarefa que normalmente precisaria de uma \"equipe\" de especialistas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQaM9xAelcEb"
      },
      "source": [
        "## üí° Exerc√≠cio Pr√°tico\n",
        "\n",
        "**DESAFIO**: Crie um workflow LangGraph para an√°lise de curr√≠culo!\n",
        "\n",
        "Seu workflow deve ter:\n",
        "1. **Agente Extrator**: Extrai informa√ß√µes principais do curr√≠culo\n",
        "2. **Agente Avaliador**: Avalia pontos fortes e fracos\n",
        "3. **Agente Conselheiro**: D√° sugest√µes de melhoria\n",
        "\n",
        "**Entrada**: Texto de um curr√≠culo\n",
        "**Sa√≠da**: An√°lise completa com sugest√µes\n",
        "\n",
        "Vamos fazer juntos! üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQg6Uu1zlcEb"
      },
      "outputs": [],
      "source": [
        "# EXERC√çCIO: Complete o c√≥digo abaixo!\n",
        "\n",
        "def extract_info_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"SEU C√ìDIGO AQUI: Extrair informa√ß√µes do curr√≠culo\"\"\"\n",
        "    print(\"üìã Extraindo informa√ß√µes do curr√≠culo...\")\n",
        "\n",
        "    curriculum = state[\"curriculum_text\"]\n",
        "\n",
        "    # DICA: Crie um prompt para extrair:\n",
        "    # - Experi√™ncias\n",
        "    # - Habilidades\n",
        "    # - Forma√ß√£o\n",
        "    # - Contato\n",
        "\n",
        "    extract_prompt = f\"\"\"\n",
        "    Extraia as principais informa√ß√µes deste curr√≠culo:\n",
        "\n",
        "    {curriculum}\n",
        "\n",
        "    Organize em:\n",
        "    - EXPERI√äNCIAS:\n",
        "    - HABILIDADES:\n",
        "    - FORMA√á√ÉO:\n",
        "    - CONTATO:\n",
        "    \"\"\"\n",
        "\n",
        "    result = llm.invoke(extract_prompt)\n",
        "    state[\"extracted_info\"] = result.content\n",
        "\n",
        "    return state\n",
        "\n",
        "def evaluate_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"SEU C√ìDIGO AQUI: Avaliar pontos fortes e fracos\"\"\"\n",
        "    print(\"‚öñÔ∏è Avaliando curr√≠culo...\")\n",
        "\n",
        "    # COMPLETE AQUI!\n",
        "    extracted = state[\"extracted_info\"]\n",
        "\n",
        "    evaluate_prompt = f\"\"\"\n",
        "    Baseado nestas informa√ß√µes extra√≠das:\n",
        "\n",
        "    {extracted}\n",
        "\n",
        "    Avalie:\n",
        "    PONTOS FORTES:\n",
        "    PONTOS FRACOS:\n",
        "    NOTA GERAL (1-10):\n",
        "    \"\"\"\n",
        "\n",
        "    result = llm.invoke(evaluate_prompt)\n",
        "    state[\"evaluation\"] = result.content\n",
        "\n",
        "    return state\n",
        "\n",
        "def advice_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"SEU C√ìDIGO AQUI: Dar conselhos de melhoria\"\"\"\n",
        "    print(\"üí° Gerando conselhos...\")\n",
        "\n",
        "    # COMPLETE AQUI!\n",
        "    evaluation = state[\"evaluation\"]\n",
        "\n",
        "    advice_prompt = f\"\"\"\n",
        "    Baseado nesta avalia√ß√£o:\n",
        "\n",
        "    {evaluation}\n",
        "\n",
        "    D√™ 5 conselhos pr√°ticos para melhorar o curr√≠culo:\n",
        "\n",
        "    1.\n",
        "    2.\n",
        "    3.\n",
        "    4.\n",
        "    5.\n",
        "    \"\"\"\n",
        "\n",
        "    result = llm.invoke(advice_prompt)\n",
        "    state[\"advice\"] = result.content\n",
        "\n",
        "    return state\n",
        "\n",
        "print(\"üìù Exerc√≠cio preparado! Complete as fun√ß√µes acima.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXYEjf2_lcEc"
      },
      "outputs": [],
      "source": [
        "# Montando o workflow do exerc√≠cio\n",
        "curriculum_workflow = StateGraph(dict)\n",
        "\n",
        "# Adicionando nodes\n",
        "curriculum_workflow.add_node(\"extract\", extract_info_node)\n",
        "curriculum_workflow.add_node(\"evaluate\", evaluate_node)\n",
        "curriculum_workflow.add_node(\"advice\", advice_node)\n",
        "\n",
        "# Entry point\n",
        "curriculum_workflow.set_entry_point(\"extract\")\n",
        "\n",
        "# Edges sequenciais\n",
        "curriculum_workflow.add_edge(\"extract\", \"evaluate\")\n",
        "curriculum_workflow.add_edge(\"evaluate\", \"advice\")\n",
        "curriculum_workflow.add_edge(\"advice\", END)\n",
        "\n",
        "# Compilando\n",
        "curriculum_app = curriculum_workflow.compile()\n",
        "\n",
        "print(\"‚úÖ Workflow de an√°lise de curr√≠culo criado!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hIeXgG9lcEc"
      },
      "outputs": [],
      "source": [
        "# Testando com um curr√≠culo exemplo\n",
        "sample_curriculum = \"\"\"\n",
        "Jo√£o Silva\n",
        "Desenvolvedor Python\n",
        "Email: joao@email.com\n",
        "Telefone: (11) 99999-9999\n",
        "\n",
        "EXPERI√äNCIA:\n",
        "- Desenvolvedor Jr na TechCorp (2022-2024)\n",
        "- Estagi√°rio na StartupX (2021-2022)\n",
        "\n",
        "HABILIDADES:\n",
        "- Python, Django, Flask\n",
        "- HTML, CSS, JavaScript\n",
        "- Git, Docker\n",
        "\n",
        "FORMA√á√ÉO:\n",
        "- Ci√™ncia da Computa√ß√£o - UNIFEI (2020-2024)\n",
        "\"\"\"\n",
        "\n",
        "# Estado inicial\n",
        "curriculum_state = {\n",
        "    \"curriculum_text\": sample_curriculum,\n",
        "    \"extracted_info\": \"\",\n",
        "    \"evaluation\": \"\",\n",
        "    \"advice\": \"\"\n",
        "}\n",
        "\n",
        "print(\"üéØ Analisando curr√≠culo do Jo√£o...\\n\")\n",
        "\n",
        "# Executando\n",
        "final_analysis = curriculum_app.invoke(curriculum_state)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üìä AN√ÅLISE COMPLETA DE CURR√çCULO\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\nüìã INFORMA√á√ïES EXTRA√çDAS:\")\n",
        "print(final_analysis[\"extracted_info\"])\n",
        "\n",
        "print(\"\\n‚öñÔ∏è AVALIA√á√ÉO:\")\n",
        "print(final_analysis[\"evaluation\"])\n",
        "\n",
        "print(\"\\nüí° CONSELHOS:\")\n",
        "print(final_analysis[\"advice\"])\n",
        "\n",
        "print(\"\\nüéâ Parab√©ns! Voc√™ criou um sistema completo de an√°lise!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63128XMTlcEc"
      },
      "source": [
        "## üöÄ Indo Al√©m: Integrando com Tools\n",
        "\n",
        "Lembra das **Tools** que vimos no m√≥dulo 11? Podemos integrar elas com LangGraph!\n",
        "\n",
        "Imagine um agente que:\n",
        "1. **Pesquisa** na web (usando tool de busca)\n",
        "2. **Calcula** valores (usando tool de matem√°tica)\n",
        "3. **Envia** emails (usando tool de email)\n",
        "4. **Salva** em banco de dados (usando tool de BD)\n",
        "\n",
        "√â como ter **super poderes** em cada node do grafo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGG-DoNelcEd"
      },
      "outputs": [],
      "source": [
        "# Exemplo r√°pido: LangGraph + Tools\n",
        "from langchain.tools import Tool\n",
        "\n",
        "# Criando uma tool simples (lembra do m√≥dulo 11?)\n",
        "def calculate_roi(investment: str) -> str:\n",
        "    \"\"\"Calcula ROI b√°sico\"\"\"\n",
        "    try:\n",
        "        # Parsing simples - na vida real seria mais robusto\n",
        "        parts = investment.split(\",\")\n",
        "        initial = float(parts[0])\n",
        "        final = float(parts[1])\n",
        "        roi = ((final - initial) / initial) * 100\n",
        "        return f\"ROI: {roi:.2f}%\"\n",
        "    except:\n",
        "        return \"Erro no c√°lculo. Use formato: valor_inicial,valor_final\"\n",
        "\n",
        "# Criando a tool\n",
        "roi_tool = Tool(\n",
        "    name=\"calculate_roi\",\n",
        "    description=\"Calcula ROI. Input: 'valor_inicial,valor_final'\",\n",
        "    func=calculate_roi\n",
        ")\n",
        "\n",
        "def investment_analyzer_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Node que usa tools para an√°lise de investimento\"\"\"\n",
        "    print(\"üí∞ Analisando investimento com tools...\")\n",
        "\n",
        "    # Simulando uso de tool\n",
        "    investment_data = \"1000,1200\"  # R$ 1000 virou R$ 1200\n",
        "    roi_result = roi_tool.func(investment_data)\n",
        "\n",
        "    state[\"roi_calculation\"] = roi_result\n",
        "\n",
        "    # Agora usa LLM para interpretar\n",
        "    interpretation_prompt = f\"\"\"\n",
        "    Baseado neste c√°lculo de ROI: {roi_result}\n",
        "\n",
        "    D√™ uma interpreta√ß√£o:\n",
        "    - √â um bom retorno?\n",
        "    - Qual o risco?\n",
        "    - Recomenda√ß√µes?\n",
        "    \"\"\"\n",
        "\n",
        "    analysis = llm.invoke(interpretation_prompt)\n",
        "    state[\"investment_analysis\"] = analysis.content\n",
        "\n",
        "    return state\n",
        "\n",
        "# Testando\n",
        "investment_state = {\"roi_calculation\": \"\", \"investment_analysis\": \"\"}\n",
        "result = investment_analyzer_node(investment_state)\n",
        "\n",
        "print(\"\\nüìä RESULTADO:\")\n",
        "print(f\"C√°lculo: {result['roi_calculation']}\")\n",
        "print(f\"An√°lise: {result['investment_analysis'][:150]}...\")\n",
        "\n",
        "print(\"\\nüéØ ISSO √© o poder do LangGraph + Tools!\")\n",
        "print(\"Cada node pode usar ferramentas externas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myISDJXPlcEd"
      },
      "source": [
        "## üìà Performance e Otimiza√ß√£o\n",
        "\n",
        "Quando voc√™ come√ßa a usar LangGraph em **produ√ß√£o**, algumas dicas importantes:\n",
        "\n",
        "### üöÄ **Dicas de Performance**\n",
        "\n",
        "1. **Paraleliza√ß√£o**: Alguns nodes podem rodar em paralelo\n",
        "2. **Cache**: Evite recalcular coisas iguais\n",
        "3. **Timeouts**: Defina limites para evitar travamentos\n",
        "4. **Logging**: Monitore cada step do workflow\n",
        "\n",
        "### üí° **Boas Pr√°ticas**\n",
        "\n",
        "- ‚úÖ **Nodes pequenos** e focados\n",
        "- ‚úÖ **Estado m√≠nimo** - s√≥ o necess√°rio\n",
        "- ‚úÖ **Tratamento de erros** em cada node\n",
        "- ‚úÖ **Documenta√ß√£o** clara do fluxo\n",
        "\n",
        "**Dica!** Em produ√ß√£o, sempre monitore o tempo de execu√ß√£o de cada node!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01HQ04wolcEd"
      },
      "outputs": [],
      "source": [
        "# Exemplo de monitoramento simples\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "def monitored_node(state: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Node com monitoramento b√°sico\"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"‚è∞ [{datetime.now().strftime('%H:%M:%S')}] Iniciando node...\")\n",
        "\n",
        "    try:\n",
        "        # Simulando processamento\n",
        "        time.sleep(1)  # Simula 1 segundo de trabalho\n",
        "\n",
        "        state[\"result\"] = \"Processamento conclu√≠do com sucesso!\"\n",
        "        state[\"status\"] = \"success\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro: {str(e)}\")\n",
        "        state[\"result\"] = f\"Erro: {str(e)}\"\n",
        "        state[\"status\"] = \"error\"\n",
        "\n",
        "    finally:\n",
        "        end_time = time.time()\n",
        "        execution_time = end_time - start_time\n",
        "\n",
        "        print(f\"‚è±Ô∏è Node executado em {execution_time:.2f}s\")\n",
        "        state[\"execution_time\"] = execution_time\n",
        "\n",
        "    return state\n",
        "\n",
        "# Testando monitoramento\n",
        "test_state = {}\n",
        "monitored_result = monitored_node(test_state)\n",
        "\n",
        "print(\"\\nüìä Estado final:\")\n",
        "for key, value in monitored_result.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "print(\"\\nüéØ Em produ√ß√£o, voc√™ salvaria esses logs em um sistema de monitoramento!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Dkd0YXlcEd"
      },
      "source": [
        "## üé≠ Casos de Uso Avan√ßados\n",
        "\n",
        "Para finalizar, vamos ver alguns casos **SUPER AVAN√áADOS** onde LangGraph realmente brilha:\n",
        "\n",
        "### 1. **Sistema de Aprova√ß√£o Multi-N√≠vel**\n",
        "```\n",
        "SOLICITA√á√ÉO ‚Üí SUPERVISOR ‚Üí GERENTE ‚Üí DIRETOR ‚Üí APROVADO/NEGADO\n",
        "     ‚Üë______________|_______________|____________‚Üë\n",
        "          (pode voltar para qualquer n√≠vel)\n",
        "```\n",
        "\n",
        "### 2. **Chatbot com Contexto Complexo**\n",
        "```\n",
        "USU√ÅRIO ‚Üí CLASSIFICADOR ‚Üí ESPECIALISTA_A ‚Üí VALIDADOR ‚Üí RESPOSTA\n",
        "              ‚Üì              ‚Üë              ‚Üë\n",
        "         ESPECIALISTA_B ‚Üí COMBINADOR ------‚Üë\n",
        "```\n",
        "\n",
        "### 3. **Pipeline de ML Completo**\n",
        "```\n",
        "DADOS ‚Üí LIMPEZA ‚Üí FEATURE_ENG ‚Üí TREINO ‚Üí VALIDA√á√ÉO ‚Üí DEPLOY\n",
        "   ‚Üë        ‚Üì          ‚Üë           ‚Üì        ‚Üì         ‚Üë\n",
        "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄFEEDBACK‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "**Dica!** LangGraph permite modelar qualquer processo complexo que voc√™ imaginar!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICcxZfyKlcEe"
      },
      "source": [
        "## üéØ Resumo: O que Aprendemos\n",
        "\n",
        "**Parab√©ns!** üéâ Voc√™ dominou o LangGraph! Aqui est√° o que cobrimos:\n",
        "\n",
        "### ‚úÖ **Conceitos Fundamentais**\n",
        "- Nodes, Edges e State\n",
        "- Diferen√ßas entre Chains, Agents e LangGraph\n",
        "- Fluxos condicionais e loops\n",
        "\n",
        "### ‚úÖ **Implementa√ß√£o Pr√°tica**\n",
        "- Criamos workflows completos\n",
        "- Integramos m√∫ltiplos agentes especializados\n",
        "- Implementamos valida√ß√£o e melhoria iterativa\n",
        "\n",
        "### ‚úÖ **Casos de Uso Reais**\n",
        "- An√°lise de conte√∫do com valida√ß√£o\n",
        "- An√°lise de curr√≠culo multi-etapas\n",
        "- Integra√ß√£o com Tools externas\n",
        "\n",
        "### ‚úÖ **Boas Pr√°ticas**\n",
        "- Monitoramento e logging\n",
        "- Tratamento de erros\n",
        "- Otimiza√ß√£o de performance\n",
        "\n",
        "### üöÄ **Pr√≥ximos Passos**\n",
        "No **m√≥dulo 17**, vamos ver o **LangSmith** - a ferramenta para monitorar, debuggar e otimizar tudo que constru√≠mos!\n",
        "\n",
        "**Dica Final!** LangGraph √© perfeito para substituir sistemas complexos que normalmente precisariam de m√∫ltiplas pessoas ou ferramentas separadas. √â IA trabalhando em equipe! ü§ù"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6CZbWqTlcEe"
      },
      "source": [
        "## üèÜ Desafio Final\n",
        "\n",
        "**MISS√ÉO ESPECIAL**: Crie um LangGraph que simula uma **consultoria empresarial completa**!\n",
        "\n",
        "### Requisitos:\n",
        "1. **Agente Diagn√≥stico**: Analisa problemas da empresa\n",
        "2. **Agente Pesquisador**: Busca solu√ß√µes similares no mercado\n",
        "3. **Agente Estrategista**: Prop√µe estrat√©gias\n",
        "4. **Agente Validador**: Valida viabilidade das propostas\n",
        "5. **Agente Apresentador**: Cria apresenta√ß√£o final\n",
        "\n",
        "### Diferenciais:\n",
        "- ‚úÖ Loops de valida√ß√£o\n",
        "- ‚úÖ Decis√µes condicionais baseadas no tipo de empresa\n",
        "- ‚úÖ Integra√ß√£o com tools (se poss√≠vel)\n",
        "- ‚úÖ Monitoramento de cada etapa\n",
        "\n",
        "**Prazo**: Pr√≥xima aula! üòÑ\n",
        "\n",
        "---\n",
        "\n",
        "### üî• **Voc√™ chegou at√© aqui = VOC√ä √â TOP!**\n",
        "\n",
        "LangGraph √© uma das ferramentas mais avan√ßadas do ecossistema LangChain. Dominando ela, voc√™ pode criar sistemas de IA **extremamente sofisticados**.\n",
        "\n",
        "**Nos vemos no m√≥dulo 17** para descobrir como monitorar e otimizar tudo isso com **LangSmith**! üöÄ\n",
        "\n",
        "![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-16_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mtSKjOlBt1D7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}