{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† Memory Systems - A Mem√≥ria que Faltava na sua IA!\n",
        "\n",
        "**M√≥dulo 7 de 17 - LangChain v0.3**\n",
        "\n",
        "Eai pessoal! Tudo certo? üöÄ\n",
        "\n",
        "At√© agora a gente viu Chains, Prompts, OutputParsers... mas cara, tem um problem√£o! Toda vez que voc√™ faz uma pergunta pro seu modelo, ele esquece completamente da conversa anterior. √â como se voc√™ tivesse um amigo com amn√©sia total!\n",
        "\n",
        "**T√°, mas o que √© Memory System mesmo?**\n",
        "\n",
        "√â literalmente dar mem√≥ria pro seu chatbot! Imagina que voc√™ t√° conversando com algu√©m e a pessoa esquece seu nome a cada 2 minutos... chato n√©? √â exatamente isso que acontece sem Memory Systems.\n",
        "\n",
        "Bora resolver isso! üî•"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ O que vamos aprender hoje?\n",
        "\n",
        "1. **Por que precisamos de mem√≥ria?** (spoiler: LLMs s√£o meio \"esquecidos\")\n",
        "2. **Tipos de Memory no LangChain**\n",
        "3. **ConversationBufferMemory** - A mais simples\n",
        "4. **ConversationSummaryMemory** - Quando a conversa fica longa\n",
        "5. **ConversationBufferWindowMemory** - Mem√≥ria com \"janela\"\n",
        "6. **Implementando na pr√°tica**\n",
        "7. **Preparando pro RAG** (m√≥dulo 10)\n",
        "\n",
        "**Dica!** Mem√≥ria vai ser FUNDAMENTAL quando a gente chegar no RAG e nos Agents!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup inicial - Bora instalar o que precisamos!\n",
        "!pip install langchain langchain-google-genai python-dotenv matplotlib -q\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Carregando vari√°veis de ambiente\n",
        "load_dotenv()\n",
        "\n",
        "print(\"‚úÖ Tudo instalado! Bora pro pr√≥ximo passo!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurando o modelo que vamos usar (nosso querido Gemini!)\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.schema import HumanMessage, AIMessage\n",
        "\n",
        "# Usando o Gemini 2.0 Flash (como vimos no m√≥dulo 2)\n",
        "model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    google_api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(\"ü§ñ Modelo configurado! Vamos testar sem mem√≥ria primeiro...\")\n",
        "\n",
        "# Teste simples sem mem√≥ria\n",
        "response1 = model.invoke(\"Oi! Meu nome √© Jo√£o\")\n",
        "print(f\"Resposta 1: {response1.content}\")\n",
        "\n",
        "response2 = model.invoke(\"Qual √© o meu nome?\")\n",
        "print(f\"\\nResposta 2: {response2.content}\")\n",
        "\n",
        "print(\"\\nüòÖ Viu s√≥? Ele esqueceu seu nome! √â por isso que precisamos de mem√≥ria!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß© Entendendo o Problema\n",
        "\n",
        "**T√°, mas por que isso acontece?**\n",
        "\n",
        "Os LLMs (Large Language Models) s√£o **stateless** - isso significa que eles n√£o guardam nada entre as conversas. √â como se voc√™ ligasse pro atendimento e a cada pergunta te transferissem pra uma pessoa diferente que n√£o sabe de nada!\n",
        "\n",
        "### Como funciona sem mem√≥ria:\n",
        "\n",
        "```\n",
        "Voc√™: \"Oi, meu nome √© Jo√£o\"\n",
        "IA: \"Ol√° Jo√£o! Como posso ajudar?\"\n",
        "\n",
        "Voc√™: \"Qual meu nome?\"\n",
        "IA: \"Desculpe, n√£o sei seu nome\" ü§¶‚Äç‚ôÇÔ∏è\n",
        "```\n",
        "\n",
        "### Como funciona COM mem√≥ria:\n",
        "\n",
        "```\n",
        "Voc√™: \"Oi, meu nome √© Jo√£o\"\n",
        "IA: \"Ol√° Jo√£o! Como posso ajudar?\"\n",
        "[MEM√ìRIA SALVA: Usuario se chama Jo√£o]\n",
        "\n",
        "Voc√™: \"Qual meu nome?\"\n",
        "IA: \"Seu nome √© Jo√£o!\" ‚úÖ\n",
        "```\n",
        "\n",
        "**Dica!** A mem√≥ria no LangChain funciona como um \"caderninho\" que vai anotando toda a conversa!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìö Tipos de Memory no LangChain\n",
        "\n",
        "O LangChain tem v√°rios tipos de mem√≥ria, cada um pra uma situa√ß√£o:\n",
        "\n",
        "### 1. **ConversationBufferMemory** üìù\n",
        "- Guarda TODA a conversa\n",
        "- Simples e direta\n",
        "- Problema: Pode ficar muito longa\n",
        "\n",
        "### 2. **ConversationSummaryMemory** üóûÔ∏è\n",
        "- Resume conversas longas\n",
        "- Economiza tokens\n",
        "- Ideal pra conversas extensas\n",
        "\n",
        "### 3. **ConversationBufferWindowMemory** ü™ü\n",
        "- Mant√©m apenas as √∫ltimas N mensagens\n",
        "- Tipo \"mem√≥ria de peixinho\"\n",
        "- Boa pra conversas focadas\n",
        "\n",
        "### 4. **ConversationSummaryBufferMemory** üéØ\n",
        "- Combina resumo + buffer\n",
        "- A mais sofisticada\n",
        "\n",
        "**Analogia:** √â como escolher entre um caderno completo, um resumo do caderno, ou s√≥ as √∫ltimas p√°ginas!\n",
        "\n",
        "**Dica!** Vamos come√ßar pela mais simples e ir evoluindo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importando as mem√≥rias que vamos usar\n",
        "from langchain.memory import (\n",
        "    ConversationBufferMemory,\n",
        "    ConversationSummaryMemory,\n",
        "    ConversationBufferWindowMemory\n",
        ")\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "print(\"üì¶ Imports feitos! Agora vamos ver cada tipo na pr√°tica...\")\n",
        "\n",
        "# Visualizando os tipos de mem√≥ria\n",
        "memory_types = ['Buffer\\n(Completa)', 'Summary\\n(Resumida)', 'Window\\n(Janela)']\n",
        "memory_sizes = [100, 30, 50]  # Tamanho relativo da mem√≥ria\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(memory_types, memory_sizes, color=colors, alpha=0.8)\n",
        "plt.title('Tipos de Memory Systems - Compara√ß√£o de Tamanho', fontsize=16, fontweight='bold')\n",
        "plt.ylabel('Tamanho da Mem√≥ria (relativo)', fontsize=12)\n",
        "plt.xlabel('Tipos de Mem√≥ria', fontsize=12)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bar, size in zip(bars, memory_sizes):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
        "             f'{size}%', ha='center', fontweight='bold')\n",
        "\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Cada tipo tem seu uso espec√≠fico! Vamos testar cada um...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ ConversationBufferMemory - A B√°sica\n",
        "\n",
        "**T√°, mas como funciona a Buffer Memory?**\n",
        "\n",
        "√â bem simples! Ela salva literalmente TUDO que foi falado. Imagina um gravador que nunca para de gravar.\n",
        "\n",
        "### Estrutura da Buffer Memory:\n",
        "\n",
        "$$\\text{Memory} = \\{\\text{Human}_1, \\text{AI}_1, \\text{Human}_2, \\text{AI}_2, ..., \\text{Human}_n, \\text{AI}_n\\}$$\n",
        "\n",
        "Onde cada par (Human, AI) √© uma intera√ß√£o completa.\n",
        "\n",
        "**Vantagens:**\n",
        "- ‚úÖ Contexto completo\n",
        "- ‚úÖ F√°cil de implementar\n",
        "- ‚úÖ Nada se perde\n",
        "\n",
        "**Desvantagens:**\n",
        "- ‚ùå Pode ficar muito longa\n",
        "- ‚ùå Cara em tokens\n",
        "- ‚ùå Pode passar do limite do modelo\n",
        "\n",
        "**Dica!** Use quando voc√™ tem conversas curtas ou quando o contexto completo √© crucial!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando nossa primeira mem√≥ria - ConversationBufferMemory\n",
        "buffer_memory = ConversationBufferMemory()\n",
        "\n",
        "# Criando uma chain com mem√≥ria (lembra das chains do m√≥dulo 6?)\n",
        "conversation_chain = ConversationChain(\n",
        "    llm=model,\n",
        "    memory=buffer_memory,\n",
        "    verbose=True  # Pra ver o que t√° rolando por baixo dos panos\n",
        ")\n",
        "\n",
        "print(\"üéâ Chain com mem√≥ria criada! Bora testar...\")\n",
        "\n",
        "# Teste 1 - Apresenta√ß√£o\n",
        "response1 = conversation_chain.predict(input=\"Oi! Meu nome √© Pedro e eu sou instrutor de IA\")\n",
        "print(f\"\\nü§ñ Resposta 1: {response1}\")\n",
        "\n",
        "# Teste 2 - Pergunta sobre a informa√ß√£o anterior\n",
        "response2 = conversation_chain.predict(input=\"Qual √© meu nome e minha profiss√£o?\")\n",
        "print(f\"\\nü§ñ Resposta 2: {response2}\")\n",
        "\n",
        "print(\"\\nüéØ Liiindo! Agora ele lembra! Vamos ver o que tem na mem√≥ria...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Investigando o que tem dentro da mem√≥ria\n",
        "print(\"üîç O que tem na mem√≥ria Buffer:\")\n",
        "print(\"=\" * 50)\n",
        "print(buffer_memory.buffer)\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Vamos ver as vari√°veis da mem√≥ria tamb√©m\n",
        "print(\"\\nüìù Vari√°veis da mem√≥ria:\")\n",
        "memory_variables = buffer_memory.load_memory_variables({})\n",
        "print(memory_variables)\n",
        "\n",
        "# Adicionando mais uma intera√ß√£o pra ver como cresce\n",
        "response3 = conversation_chain.predict(input=\"Quais s√£o suas linguagens de programa√ß√£o favoritas?\")\n",
        "print(f\"\\nü§ñ Resposta 3: {response3}\")\n",
        "\n",
        "print(\"\\nüìà Vamos ver como a mem√≥ria cresceu:\")\n",
        "print(\"=\" * 50)\n",
        "print(buffer_memory.buffer)\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üóûÔ∏è ConversationSummaryMemory - A Inteligente\n",
        "\n",
        "**E quando a conversa fica muito longa?**\n",
        "\n",
        "A√≠ que entra a Summary Memory! Ao inv√©s de guardar tudo palavra por palavra, ela vai fazendo um resumo da conversa. √â como ter uma secret√°ria que vai anotando s√≥ o importante!\n",
        "\n",
        "### Como funciona:\n",
        "\n",
        "1. **Conversa acontece** üí¨\n",
        "2. **IA resume o que foi dito** üìÑ \n",
        "3. **Pr√≥xima pergunta usa o resumo** üîÑ\n",
        "\n",
        "### F√≥rmula da Summary Memory:\n",
        "\n",
        "$$\\text{Summary}_{n+1} = \\text{Summarize}(\\text{Summary}_n + \\text{New Interaction})$$\n",
        "\n",
        "**Vantagens:**\n",
        "- ‚úÖ Economiza tokens\n",
        "- ‚úÖ N√£o estoura limite do modelo\n",
        "- ‚úÖ Mant√©m informa√ß√µes importantes\n",
        "\n",
        "**Desvantagens:**\n",
        "- ‚ùå Pode perder detalhes\n",
        "- ‚ùå Gasta tokens pra fazer resumo\n",
        "- ‚ùå Resumo pode n√£o ser perfeito\n",
        "\n",
        "**Dica!** Ideal pra conversas longas onde voc√™ precisa do contexto geral, mas n√£o de cada palavra!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando Summary Memory\n",
        "summary_memory = ConversationSummaryMemory(\n",
        "    llm=model,  # Precisa do modelo pra fazer os resumos\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "# Chain com summary memory\n",
        "summary_chain = ConversationChain(\n",
        "    llm=model,\n",
        "    memory=summary_memory,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"üìÑ Summary Memory criada! Vamos simular uma conversa longa...\")\n",
        "\n",
        "# Simulando v√°rias intera√ß√µes\n",
        "interactions = [\n",
        "    \"Oi! Sou Maria, tenho 30 anos e trabalho como desenvolvedora Python em S√£o Paulo\",\n",
        "    \"Estou aprendendo IA e machine learning h√° 6 meses\",\n",
        "    \"Meu projeto atual √© um sistema de recomenda√ß√£o para e-commerce\",\n",
        "    \"Uso principalmente scikit-learn e tensorflow no meu trabalho\",\n",
        "    \"Qual √© meu nome, idade e em que cidade trabalho?\"\n",
        "]\n",
        "\n",
        "responses = []\n",
        "for i, interaction in enumerate(interactions):\n",
        "    response = summary_chain.predict(input=interaction)\n",
        "    responses.append(response)\n",
        "    print(f\"\\nüîÑ Intera√ß√£o {i+1}:\")\n",
        "    print(f\"Voc√™: {interaction}\")\n",
        "    print(f\"IA: {response[:100]}...\")\n",
        "\n",
        "print(\"\\nüéØ Vamos ver o resumo que foi criado!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Investigando o resumo criado\n",
        "print(\"üìã Resumo da conversa:\")\n",
        "print(\"=\" * 60)\n",
        "summary_variables = summary_memory.load_memory_variables({})\n",
        "print(summary_variables['history'])\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Comparando tamanhos - Buffer vs Summary\n",
        "buffer_size = len(buffer_memory.buffer) if hasattr(buffer_memory, 'buffer') else 0\n",
        "summary_size = len(str(summary_variables['history']))\n",
        "\n",
        "print(f\"\\nüìä Compara√ß√£o de tamanhos:\")\n",
        "print(f\"Buffer Memory: {buffer_size} caracteres\")\n",
        "print(f\"Summary Memory: {summary_size} caracteres\")\n",
        "\n",
        "if summary_size < buffer_size:\n",
        "    reduction = ((buffer_size - summary_size) / buffer_size) * 100\n",
        "    print(f\"\\nüéâ Summary Memory √© {reduction:.1f}% menor!\")\n",
        "\n",
        "print(\"\\nüí° Viu a diferen√ßa? O resumo mant√©m o essencial mas economiza espa√ßo!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü™ü ConversationBufferWindowMemory - A Focada\n",
        "\n",
        "**E se eu quiser s√≥ as √∫ltimas conversas?**\n",
        "\n",
        "Perfeito! √â exatamente pra isso que serve a Window Memory. Ela funciona como uma \"janela deslizante\" - mant√©m apenas as √∫ltimas N intera√ß√µes.\n",
        "\n",
        "### Analogia da Janela:\n",
        "Imagina que voc√™ t√° olhando pela janela de um trem em movimento. Voc√™ s√≥ v√™ a paisagem que t√° passando agora, n√£o o que j√° passou l√° atr√°s!\n",
        "\n",
        "### Funcionamento:\n",
        "\n",
        "```\n",
        "Window Size = 3\n",
        "\n",
        "Mensagem 1, 2, 3 ‚Üí [1, 2, 3]\n",
        "Mensagem 4 ‚Üí [2, 3, 4] (remove a 1)\n",
        "Mensagem 5 ‚Üí [3, 4, 5] (remove a 2)\n",
        "```\n",
        "\n",
        "**Vantagens:**\n",
        "- ‚úÖ Tamanho fixo e previs√≠vel\n",
        "- ‚úÖ Foco no contexto recente\n",
        "- ‚úÖ N√£o estoura limites\n",
        "\n",
        "**Desvantagens:**\n",
        "- ‚ùå Perde informa√ß√µes antigas\n",
        "- ‚ùå Pode quebrar contexto longo\n",
        "\n",
        "**Dica!** Ideal pra conversas onde s√≥ o contexto recente importa (tipo um chatbot de suporte)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando Window Memory com janela de 3 intera√ß√µes\n",
        "window_memory = ConversationBufferWindowMemory(\n",
        "    k=3,  # Mant√©m apenas as 3 √∫ltimas intera√ß√µes\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "# Chain com window memory\n",
        "window_chain = ConversationChain(\n",
        "    llm=model,\n",
        "    memory=window_memory,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"ü™ü Window Memory criada (janela = 3)! Vamos testar...\")\n",
        "\n",
        "# Simulando 6 intera√ß√µes pra ver a janela deslizar\n",
        "test_messages = [\n",
        "    \"Msg 1: Oi, sou Carlos\",\n",
        "    \"Msg 2: Trabalho com dados\", \n",
        "    \"Msg 3: Moro no Rio de Janeiro\",\n",
        "    \"Msg 4: Tenho 25 anos\",\n",
        "    \"Msg 5: Gosto de futebol\",\n",
        "    \"Msg 6: Qual meu nome? (deve lembrar)\",\n",
        "    \"Msg 7: Onde eu trabalho? (deve esquecer - muito antiga!)\"\n",
        "]\n",
        "\n",
        "for i, msg in enumerate(test_messages):\n",
        "    response = window_chain.predict(input=msg)\n",
        "    \n",
        "    print(f\"\\n--- Intera√ß√£o {i+1} ---\")\n",
        "    print(f\"Entrada: {msg}\")\n",
        "    print(f\"Resposta: {response[:80]}...\")\n",
        "    \n",
        "    # Mostrando o que tem na janela atual\n",
        "    current_window = window_memory.load_memory_variables({})\n",
        "    window_size = len(str(current_window['history']))\n",
        "    print(f\"Tamanho da janela: {window_size} chars\")\n",
        "    \n",
        "    if i >= 2:  # Ap√≥s 3 mensagens, mostrar que a janela desliza\n",
        "        print(\"ü™ü Janela deslizando - informa√ß√µes antigas sendo removidas!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando como a Window Memory funciona\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Simulando o deslizamento da janela\n",
        "messages = list(range(1, 8))  # Mensagens 1 a 7\n",
        "window_size = 3\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Criando visualiza√ß√£o do deslizamento\n",
        "for i, msg_num in enumerate(messages):\n",
        "    # Calculando quais mensagens est√£o na janela\n",
        "    if msg_num <= window_size:\n",
        "        window_start = 1\n",
        "        window_end = msg_num\n",
        "    else:\n",
        "        window_start = msg_num - window_size + 1\n",
        "        window_end = msg_num\n",
        "    \n",
        "    # Plotando todas as mensagens\n",
        "    y_pos = len(messages) - i - 1\n",
        "    \n",
        "    # Mensagens fora da janela (cinza)\n",
        "    for m in range(1, window_start):\n",
        "        ax.add_patch(plt.Rectangle((m-0.4, y_pos-0.4), 0.8, 0.8, \n",
        "                                  facecolor='lightgray', alpha=0.5))\n",
        "    \n",
        "    # Mensagens na janela (colorido)\n",
        "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
        "    for j, m in enumerate(range(window_start, window_end + 1)):\n",
        "        color = colors[j % len(colors)]\n",
        "        ax.add_patch(plt.Rectangle((m-0.4, y_pos-0.4), 0.8, 0.8, \n",
        "                                  facecolor=color, alpha=0.7))\n",
        "    \n",
        "    # Mensagens futuras (vazio)\n",
        "    for m in range(window_end + 1, 8):\n",
        "        ax.add_patch(plt.Rectangle((m-0.4, y_pos-0.4), 0.8, 0.8, \n",
        "                                  facecolor='white', edgecolor='gray', alpha=0.3))\n",
        "\n",
        "# Configurando o plot\n",
        "ax.set_xlim(0, 8)\n",
        "ax.set_ylim(-1, len(messages))\n",
        "ax.set_xlabel('Mensagens', fontsize=12)\n",
        "ax.set_ylabel('Momento da Conversa', fontsize=12)\n",
        "ax.set_title('Window Memory - Como a Janela Desliza (Window Size = 3)', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Labels\n",
        "ax.set_xticks(range(1, 8))\n",
        "ax.set_xticklabels([f'Msg {i}' for i in range(1, 8)])\n",
        "ax.set_yticks(range(len(messages)))\n",
        "ax.set_yticklabels([f'Ap√≥s Msg {i+1}' for i in range(len(messages))][::-1])\n",
        "\n",
        "# Legenda\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [\n",
        "    Patch(facecolor='#FF6B6B', alpha=0.7, label='Na Janela (lembrada)'),\n",
        "    Patch(facecolor='lightgray', alpha=0.5, label='Fora da Janela (esquecida)'),\n",
        "    Patch(facecolor='white', edgecolor='gray', alpha=0.3, label='Ainda n√£o enviada')\n",
        "]\n",
        "ax.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Assim funciona a Window Memory! Vai deslizando e esquecendo o passado...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öñÔ∏è Comparando os Tr√™s Tipos\n",
        "\n",
        "**T√°, mas qual usar quando?**\n",
        "\n",
        "Cada tipo de mem√≥ria tem seu lugar! Vamos fazer um comparativo pr√°tico:\n",
        "\n",
        "| Tipo | Quando Usar | Pr√≥s | Contras |\n",
        "|------|-------------|------|----------|\n",
        "| **Buffer** | Conversas curtas, contexto completo necess√°rio | Nada se perde | Pode ficar muito grande |\n",
        "| **Summary** | Conversas longas, contexto geral importante | Economiza tokens | Pode perder detalhes |\n",
        "| **Window** | Contexto recente √© o que importa | Tamanho previs√≠vel | Esquece o passado |\n",
        "\n",
        "### F√≥rmula de Escolha:\n",
        "\n",
        "$$\\text{Memory Type} = \\begin{cases} \n",
        "\\text{Buffer} & \\text{se } \\text{conversa} < 10 \\text{ intera√ß√µes} \\\\\n",
        "\\text{Summary} & \\text{se } \\text{contexto hist√≥rico importante} \\\\\n",
        "\\text{Window} & \\text{se } \\text{s√≥ contexto recente importa}\n",
        "\\end{cases}$$\n",
        "\n",
        "**Dica!** Na d√∫vida, comece com Buffer pra conversas simples e Window pra chatbots!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos fazer um teste comparativo lado a lado!\n",
        "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "# Criando tr√™s chains diferentes\n",
        "buffer_mem = ConversationBufferMemory()\n",
        "window_mem = ConversationBufferWindowMemory(k=2)  # Janela pequena pra ver diferen√ßa\n",
        "\n",
        "buffer_chain = ConversationChain(llm=model, memory=buffer_mem, verbose=False)\n",
        "window_chain = ConversationChain(llm=model, memory=window_mem, verbose=False)\n",
        "\n",
        "# Teste com sequ√™ncia de mensagens\n",
        "test_sequence = [\n",
        "    \"Meu nome √© Ana\",\n",
        "    \"Tenho 28 anos\", \n",
        "    \"Moro em Bras√≠lia\",\n",
        "    \"Trabalho como engenheira\",\n",
        "    \"Qual meu nome e idade?\"\n",
        "]\n",
        "\n",
        "print(\"ü•ä BATTLE ROYALE - Buffer vs Window!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "buffer_responses = []\n",
        "window_responses = []\n",
        "\n",
        "for i, msg in enumerate(test_sequence):\n",
        "    print(f\"\\nüì© Mensagem {i+1}: {msg}\")\n",
        "    \n",
        "    # Testando Buffer\n",
        "    buffer_response = buffer_chain.predict(input=msg)\n",
        "    buffer_responses.append(buffer_response)\n",
        "    \n",
        "    # Testando Window  \n",
        "    window_response = window_chain.predict(input=msg)\n",
        "    window_responses.append(window_response)\n",
        "    \n",
        "    print(f\"\\nüß† Buffer: {buffer_response[:100]}...\")\n",
        "    print(f\"ü™ü Window: {window_response[:100]}...\")\n",
        "    \n",
        "    # Mostrando tamanho da mem√≥ria\n",
        "    buffer_size = len(buffer_mem.buffer)\n",
        "    window_vars = window_mem.load_memory_variables({})\n",
        "    window_size = len(str(window_vars['history']))\n",
        "    \n",
        "    print(f\"üìä Tamanhos - Buffer: {buffer_size}, Window: {window_size}\")\n",
        "\n",
        "print(\"\\nüèÜ Resultado: Ambos t√™m seus m√©ritos! Depende do caso de uso.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Memory Systems Customizadas\n",
        "\n",
        "**E se eu quiser criar minha pr√≥pria mem√≥ria?**\n",
        "\n",
        "Claro que d√°! O LangChain √© super flex√≠vel. Voc√™ pode:\n",
        "\n",
        "1. **Customizar prompts das mem√≥rias**\n",
        "2. **Combinar diferentes tipos**\n",
        "3. **Adicionar filtros e regras**\n",
        "4. **Integrar com bancos de dados**\n",
        "\n",
        "### Exemplo Pr√°tico: Mem√≥ria com Filtro de Import√¢ncia\n",
        "\n",
        "Vamos criar uma mem√≥ria que s√≥ guarda informa√ß√µes \"importantes\"!\n",
        "\n",
        "**Dica!** Isso vai ser √∫til quando chegarmos no m√≥dulo de RAG - voc√™ vai querer filtrar o que vale a pena lembrar!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando uma mem√≥ria customizada com filtro de import√¢ncia\n",
        "from langchain.schema import BaseMessage\n",
        "from langchain.memory.chat_message_histories import ChatMessageHistory\n",
        "\n",
        "# Palavras-chave que consideramos \"importantes\"\n",
        "important_keywords = [\n",
        "    'nome', 'idade', 'trabalho', 'profiss√£o', 'empresa', 'projeto', \n",
        "    'problema', 'erro', 'help', 'ajuda', 'importante', 'urgente'\n",
        "]\n",
        "\n",
        "def is_important_message(message_text):\n",
        "    \"\"\"Verifica se uma mensagem cont√©m informa√ß√µes importantes\"\"\"\n",
        "    message_lower = message_text.lower()\n",
        "    return any(keyword in message_lower for keyword in important_keywords)\n",
        "\n",
        "# Mem√≥ria customizada que filtra por import√¢ncia\n",
        "class FilteredMemory(ConversationBufferMemory):\n",
        "    def save_context(self, inputs, outputs):\n",
        "        \"\"\"Salva apenas contextos importantes\"\"\"\n",
        "        input_text = inputs.get('input', '')\n",
        "        output_text = outputs.get('response', '')\n",
        "        \n",
        "        # Verifica se √© importante\n",
        "        if is_important_message(input_text) or is_important_message(output_text):\n",
        "            print(f\"üéØ Mensagem importante detectada! Salvando...\")\n",
        "            super().save_context(inputs, outputs)\n",
        "        else:\n",
        "            print(f\"üòê Mensagem comum, n√£o salvando...\")\n",
        "\n",
        "# Testando nossa mem√≥ria customizada\n",
        "filtered_memory = FilteredMemory()\n",
        "filtered_chain = ConversationChain(llm=model, memory=filtered_memory, verbose=False)\n",
        "\n",
        "print(\"üéõÔ∏è Mem√≥ria customizada criada! Vamos testar o filtro...\")\n",
        "\n",
        "test_messages = [\n",
        "    \"Oi, como voc√™ est√°?\",  # Comum\n",
        "    \"Meu nome √© Roberto\",   # Importante (nome)\n",
        "    \"Que dia bonito hoje\",  # Comum  \n",
        "    \"Trabalho na Google\",   # Importante (trabalho)\n",
        "    \"Gosto de caf√©\",        # Comum\n",
        "    \"Preciso de ajuda com Python\"  # Importante (ajuda)\n",
        "]\n",
        "\n",
        "for i, msg in enumerate(test_messages):\n",
        "    print(f\"\\n--- Teste {i+1} ---\")\n",
        "    print(f\"Mensagem: {msg}\")\n",
        "    response = filtered_chain.predict(input=msg)\n",
        "\n",
        "print(f\"\\nüìã Mem√≥ria final (s√≥ o importante):\")\n",
        "print(filtered_memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Integrando Memory com Chains Avan√ßadas\n",
        "\n",
        "**Lembra das Chains do m√≥dulo 6?** Agora vamos turbinar elas com mem√≥ria!\n",
        "\n",
        "Podemos combinar:\n",
        "- ‚úÖ **PromptTemplate** (m√≥dulo 4) + Memory\n",
        "- ‚úÖ **OutputParser** (m√≥dulo 5) + Memory  \n",
        "- ‚úÖ **Chains customizadas** (m√≥dulo 6) + Memory\n",
        "\n",
        "Isso vai ser a base pro RAG que vamos ver no m√≥dulo 10!\n",
        "\n",
        "**Dica!** Memory + Chains √© a combina√ß√£o perfeita pra criar chatbots inteligentes!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combinando Memory com PromptTemplate e OutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.schema import OutputParserException\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "# Modelo pra estruturar as respostas (do m√≥dulo 5)\n",
        "class UserInfo(BaseModel):\n",
        "    name: str = Field(description=\"Nome do usu√°rio\")\n",
        "    interests: List[str] = Field(description=\"Lista de interesses mencionados\")\n",
        "    questions: List[str] = Field(description=\"Perguntas feitas pelo usu√°rio\")\n",
        "    \n",
        "# Parser estruturado\n",
        "parser = PydanticOutputParser(pydantic_object=UserInfo)\n",
        "\n",
        "# Prompt customizado que usa mem√≥ria\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"Voc√™ √© um assistente que coleta informa√ß√µes sobre usu√°rios.\n",
        "    \n",
        "Hist√≥rico da conversa:\n",
        "{history}\n",
        "\n",
        "Pergunta atual: {input}\n",
        "\n",
        "Com base no hist√≥rico e pergunta atual, extraia:\n",
        "1. Nome do usu√°rio (se mencionado)\n",
        "2. Interesses mencionados\n",
        "3. Perguntas feitas\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "Se alguma informa√ß√£o n√£o foi mencionada, use valores padr√£o apropriados.\"\"\",\n",
        "    input_variables=[\"history\", \"input\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "# Mem√≥ria pra nossa chain avan√ßada\n",
        "advanced_memory = ConversationBufferMemory(memory_key=\"history\")\n",
        "\n",
        "# Chain avan√ßada (do m√≥dulo 6 + mem√≥ria)\n",
        "advanced_chain = ConversationChain(\n",
        "    llm=model,\n",
        "    prompt=prompt,\n",
        "    memory=advanced_memory,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"üöÄ Chain avan√ßada com mem√≥ria criada! Testando...\")\n",
        "\n",
        "# Testando a chain avan√ßada\n",
        "test_inputs = [\n",
        "    \"Oi! Sou Lucas e adoro programa√ß√£o\",\n",
        "    \"Tamb√©m gosto muito de machine learning\", \n",
        "    \"Como posso aprender mais sobre IA?\"\n",
        "]\n",
        "\n",
        "for i, user_input in enumerate(test_inputs):\n",
        "    print(f\"\\nüîÑ Teste {i+1}: {user_input}\")\n",
        "    try:\n",
        "        response = advanced_chain.predict(input=user_input)\n",
        "        print(f\"Raw response: {response[:200]}...\")\n",
        "        \n",
        "        # Tentando parsear a resposta\n",
        "        # parsed_info = parser.parse(response)\n",
        "        # print(f\"‚úÖ Info estruturada: {parsed_info}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro no parsing: {e}\")\n",
        "        print(f\"Resposta bruta: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Exerc√≠cio Pr√°tico - Sistema de Atendimento\n",
        "\n",
        "**Bora colocar a m√£o na massa!** üî•\n",
        "\n",
        "Vamos criar um sistema de atendimento ao cliente que:\n",
        "1. Lembra do hist√≥rico da conversa\n",
        "2. Identifica o tipo de problema\n",
        "3. Oferece solu√ß√µes personalizadas\n",
        "4. Usa diferentes tipos de mem√≥ria\n",
        "\n",
        "**Seu desafio:**\n",
        "- Escolha o tipo de mem√≥ria mais adequado\n",
        "- Crie prompts eficazes\n",
        "- Teste com casos reais\n",
        "\n",
        "**Dica!** Pense em como isso vai ajudar quando criarmos RAG com documentos de help!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO: Sistema de Atendimento com Memory\n",
        "# Sua miss√£o: completar este sistema!\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferWindowMemory  # Voc√™ pode mudar!\n",
        "\n",
        "# 1. Escolha o tipo de mem√≥ria (complete aqui)\n",
        "# TODO: Experimente diferentes tipos e veja qual funciona melhor\n",
        "customer_memory = ConversationBufferWindowMemory(\n",
        "    k=5,  # Ajuste este n√∫mero!\n",
        "    memory_key=\"chat_history\"\n",
        ")\n",
        "\n",
        "# 2. Crie um prompt para atendimento (complete aqui)\n",
        "customer_service_prompt = PromptTemplate(\n",
        "    template=\"\"\"Voc√™ √© um atendente virtual experiente e emp√°tico.\n",
        "\n",
        "Hist√≥rico da conversa:\n",
        "{chat_history}\n",
        "\n",
        "Cliente: {input}\n",
        "\n",
        "Instru√ß√µes:\n",
        "- Seja sempre educado e prestativo\n",
        "- Use informa√ß√µes do hist√≥rico para personalizar respostas\n",
        "- Identifique o tipo de problema (t√©cnico, comercial, d√∫vida)\n",
        "- Ofere√ßa solu√ß√µes pr√°ticas\n",
        "- Se n√£o souber algo, seja honesto\n",
        "\n",
        "Resposta:\"\"\",\n",
        "    input_variables=[\"chat_history\", \"input\"]\n",
        ")\n",
        "\n",
        "# 3. Crie a chain de atendimento\n",
        "customer_service_chain = ConversationChain(\n",
        "    llm=model,\n",
        "    prompt=customer_service_prompt,\n",
        "    memory=customer_memory,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(\"üéß Sistema de Atendimento Online! Como posso ajudar?\")\n",
        "\n",
        "# 4. Simule uma conversa de atendimento\n",
        "customer_conversation = [\n",
        "    \"Oi, estou com problema no meu pedido\",\n",
        "    \"Meu nome √© Sandra Silva, CPF 123.456.789-00\", \n",
        "    \"Comprei um notebook mas n√£o chegou ainda\",\n",
        "    \"O pedido foi feito h√° 15 dias, n√∫mero #12345\",\n",
        "    \"Preciso do notebook urgente para trabalhar\",\n",
        "    \"Voc√™s podem me dar uma previs√£o?\"\n",
        "]\n",
        "\n",
        "for i, message in enumerate(customer_conversation):\n",
        "    print(f\"\\nüë§ Cliente: {message}\")\n",
        "    response = customer_service_chain.predict(input=message)\n",
        "    print(f\"üéß Atendente: {response}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(\"\\n‚úÖ Conversa√ß√£o finalizada!\")\n",
        "\n",
        "# DESAFIO EXTRA: Modifique o c√≥digo acima para:\n",
        "# - Usar ConversationSummaryMemory \n",
        "# - Adicionar categoriza√ß√£o autom√°tica de problemas\n",
        "# - Incluir um sistema de escala√ß√£o para problemas complexos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîó Preparando para o RAG (M√≥dulo 10)\n",
        "\n",
        "**T√°, mas como Memory se conecta com RAG?**\n",
        "\n",
        "√ìtima pergunta! No RAG (Retrieval-Augmented Generation) que vamos ver no m√≥dulo 10, a mem√≥ria √© FUNDAMENTAL:\n",
        "\n",
        "### RAG + Memory = üöÄ\n",
        "\n",
        "1. **Contexto de Consultas** ‚Üí Mem√≥ria lembra o que o usu√°rio j√° perguntou\n",
        "2. **Refinamento de Busca** ‚Üí Usa hist√≥rico pra melhorar retrieval\n",
        "3. **Conversas Longas** ‚Üí Mant√©m contexto em documentos grandes\n",
        "4. **Personaliza√ß√£o** ‚Üí Adapta respostas baseado no hist√≥rico\n",
        "\n",
        "### Pipeline RAG + Memory:\n",
        "\n",
        "```\n",
        "Pergunta + Hist√≥rico ‚Üí Busca Documentos ‚Üí Gera Resposta ‚Üí Atualiza Mem√≥ria\n",
        "```\n",
        "\n",
        "**Pr√≥ximos m√≥dulos:**\n",
        "- **M√≥dulo 8:** Document Loading (pra alimentar o RAG)\n",
        "- **M√≥dulo 9:** Vector Stores (pra buscar documentos)\n",
        "- **M√≥dulo 10:** RAG completo com mem√≥ria!\n",
        "\n",
        "**Dica!** A mem√≥ria que voc√™ aprendeu hoje vai ser a base pra criar chatbots que conversam sobre documentos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview: Como vai ser RAG + Memory (s√≥ um gostinho!)\n",
        "# Vamos simular como seria sem implementar RAG completo ainda\n",
        "\n",
        "# Simulando uma \"base de conhecimento\" simples\n",
        "knowledge_base = {\n",
        "    \"python\": \"Python √© uma linguagem de programa√ß√£o vers√°til e f√°cil de aprender.\",\n",
        "    \"machine learning\": \"ML √© um subcampo da IA que permite sistemas aprenderem automaticamente.\", \n",
        "    \"langchain\": \"LangChain √© um framework para desenvolver aplica√ß√µes com LLMs.\"\n",
        "}\n",
        "\n",
        "def simple_retrieval(query):\n",
        "    \"\"\"Simula√ß√£o simples de retrieval\"\"\"\n",
        "    query_lower = query.lower()\n",
        "    for topic, info in knowledge_base.items():\n",
        "        if topic in query_lower:\n",
        "            return info\n",
        "    return \"Informa√ß√£o n√£o encontrada na base de conhecimento.\"\n",
        "\n",
        "# Prompt que combina retrieved info + memory\n",
        "rag_prompt = PromptTemplate(\n",
        "    template=\"\"\"Voc√™ √© um assistente especializado em tecnologia.\n",
        "\n",
        "Hist√≥rico da conversa:\n",
        "{history}\n",
        "\n",
        "Informa√ß√£o relevante encontrada:\n",
        "{retrieved_info}\n",
        "\n",
        "Pergunta do usu√°rio: {input}\n",
        "\n",
        "Use o hist√≥rico da conversa e a informa√ß√£o encontrada para dar uma resposta completa e contextualizada.\n",
        "Se j√° falamos sobre o assunto antes, referencie isso na resposta.\n",
        "\n",
        "Resposta:\"\"\",\n",
        "    input_variables=[\"history\", \"retrieved_info\", \"input\"]\n",
        ")\n",
        "\n",
        "# Memory pro RAG\n",
        "rag_memory = ConversationBufferMemory(memory_key=\"history\")\n",
        "\n",
        "# Chain simulando RAG + Memory\n",
        "rag_chain = ConversationChain(\n",
        "    llm=model,\n",
        "    prompt=rag_prompt, \n",
        "    memory=rag_memory\n",
        ")\n",
        "\n",
        "print(\"üîÆ Preview: RAG + Memory em a√ß√£o!\")\n",
        "\n",
        "# Simulando consultas com retrieval + memory\n",
        "rag_queries = [\n",
        "    \"O que √© Python?\",\n",
        "    \"E machine learning?\", \n",
        "    \"Qual a diferen√ßa entre Python e ML que voc√™ mencionou?\"\n",
        "]\n",
        "\n",
        "for query in rag_queries:\n",
        "    # Simular retrieval\n",
        "    retrieved = simple_retrieval(query)\n",
        "    \n",
        "    print(f\"\\nüîç Pergunta: {query}\")\n",
        "    print(f\"üìÑ Retrieved: {retrieved}\")\n",
        "    \n",
        "    # Usar a chain com info recuperada\n",
        "    response = rag_chain.predict(\n",
        "        input=query,\n",
        "        retrieved_info=retrieved\n",
        "    )\n",
        "    print(f\"ü§ñ Resposta: {response}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "print(\"\\nüöÄ Isso √© s√≥ um preview! No m√≥dulo 10 vamos fazer RAG completo com vector stores!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exerc√≠cio Final - Desafio Completo\n",
        "\n",
        "**Hora do desafio final!** üèÜ\n",
        "\n",
        "Crie um **Personal Assistant** que:\n",
        "\n",
        "1. **Lembra informa√ß√µes pessoais** (nome, prefer√™ncias, etc.)\n",
        "2. **Adapta respostas baseado no hist√≥rico**\n",
        "3. **Usa diferentes tipos de mem√≥ria conforme necess√°rio**\n",
        "4. **Integra com prompts customizados**\n",
        "\n",
        "**Requisitos:**\n",
        "- [ ] Use pelo menos 2 tipos de mem√≥ria diferentes\n",
        "- [ ] Crie prompts personalizados \n",
        "- [ ] Implemente filtros de import√¢ncia\n",
        "- [ ] Teste com conversas longas\n",
        "\n",
        "**Dica!** Este exerc√≠cio vai preparar voc√™ pra criar assistentes mais complexos nos pr√≥ximos m√≥dulos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DESAFIO FINAL: Personal Assistant com Memory Systems\n",
        "# Complete este c√≥digo criando um assistente pessoal completo!\n",
        "\n",
        "print(\"ü§ñ DESAFIO: Personal Assistant com Memory Systems\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Sua miss√£o: Completar este assistente pessoal inteligente!\\n\")\n",
        "\n",
        "# TODO 1: Escolha e configure diferentes tipos de mem√≥ria\n",
        "# Dica: Use Buffer para info pessoal e Window para conversas casuais\n",
        "\n",
        "personal_info_memory = None  # Configure aqui!\n",
        "conversation_memory = None   # Configure aqui!\n",
        "\n",
        "# TODO 2: Crie prompts customizados\n",
        "# Dica: Um prompt pra capturar info pessoal, outro pra conversa geral\n",
        "\n",
        "personal_prompt = None  # Configure aqui!\n",
        "general_prompt = None   # Configure aqui!\n",
        "\n",
        "# TODO 3: Implemente l√≥gica de decis√£o\n",
        "# Quando usar cada tipo de mem√≥ria/prompt?\n",
        "\n",
        "def choose_memory_type(user_input):\n",
        "    \"\"\"Decide qual tipo de mem√≥ria usar baseado na entrada\"\"\"\n",
        "    # TODO: Implementar l√≥gica aqui\n",
        "    pass\n",
        "\n",
        "# TODO 4: Crie o assistente completo\n",
        "class PersonalAssistant:\n",
        "    def __init__(self):\n",
        "        # TODO: Inicializar chains, mem√≥rias, etc.\n",
        "        pass\n",
        "    \n",
        "    def process_message(self, message):\n",
        "        \"\"\"Processa mensagem escolhendo mem√≥ria e prompt adequados\"\"\"\n",
        "        # TODO: Implementar l√≥gica completa\n",
        "        pass\n",
        "\n",
        "# TODO 5: Teste seu assistente\n",
        "test_conversation = [\n",
        "    \"Oi! Meu nome √© Alex\",\n",
        "    \"Trabalho como designer\", \n",
        "    \"Gosto muito de caf√© pela manh√£\",\n",
        "    \"Como est√° o tempo hoje?\",\n",
        "    \"Voc√™ lembra qual √© minha profiss√£o?\",\n",
        "    \"E o que eu gosto de beber de manh√£?\"\n",
        "]\n",
        "\n",
        "print(\"üß™ Testando seu assistente...\")\n",
        "print(\"Implemente o c√≥digo acima e descomente os testes!\\n\")\n",
        "\n",
        "# assistant = PersonalAssistant()\n",
        "# for msg in test_conversation:\n",
        "#     print(f\"Voc√™: {msg}\")\n",
        "#     response = assistant.process_message(msg)\n",
        "#     print(f\"Assistant: {response}\\n\")\n",
        "\n",
        "print(\"üí° Dicas para implementar:\")\n",
        "print(\"- Use ConversationBufferMemory para info pessoal\")\n",
        "print(\"- Use ConversationBufferWindowMemory para conversas casuais\")\n",
        "print(\"- Crie prompts que referenciam o tipo de informa√ß√£o\")\n",
        "print(\"- Implemente keywords para decidir qual chain usar\")\n",
        "print(\"\\nüöÄ Boa sorte! Este exerc√≠cio vai te preparar para os pr√≥ximos m√≥dulos!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Resumo do M√≥dulo - O que Aprendemos\n",
        "\n",
        "**Liiindo! Chegamos ao final!** üöÄ\n",
        "\n",
        "### ‚úÖ O que voc√™ domina agora:\n",
        "\n",
        "1. **Por que precisamos de mem√≥ria** ‚Üí LLMs s√£o stateless\n",
        "2. **ConversationBufferMemory** ‚Üí Guarda tudo, boa pra conversas curtas\n",
        "3. **ConversationSummaryMemory** ‚Üí Resume conversas, economiza tokens\n",
        "4. **ConversationBufferWindowMemory** ‚Üí Janela deslizante, foco no recente\n",
        "5. **Memory customizada** ‚Üí Filtros e regras personalizadas\n",
        "6. **Integra√ß√£o com Chains** ‚Üí Combinando com prompts e parsers\n",
        "7. **Preview do RAG** ‚Üí Como mem√≥ria vai ser crucial\n",
        "\n",
        "### üîó Conectando com outros m√≥dulos:\n",
        "\n",
        "- **M√≥dulos 1-6** ‚Üí Base s√≥lida pra usar memory\n",
        "- **M√≥dulo 8-10** ‚Üí Document Loading, Vector Stores e RAG\n",
        "- **M√≥dulo 11** ‚Üí Agents v√£o usar memory pra ser mais inteligentes\n",
        "\n",
        "### üéØ Pr√≥ximos passos:\n",
        "\n",
        "No **m√≥dulo 8** vamos aprender **Document Loading** - como carregar e processar documentos pra alimentar nossos sistemas de IA. A mem√≥ria que voc√™ aprendeu hoje vai ser fundamental pra criar conversas sobre documentos!\n",
        "\n",
        "**Dica!** Pratique criando diferentes tipos de chatbots com memory. Vai te ajudar muito nos pr√≥ximos m√≥dulos!\n",
        "\n",
        "**Bora pro pr√≥ximo m√≥dulo?** üî•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualiza√ß√£o final - Resumo dos tipos de Memory\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Dados para compara√ß√£o final\n",
        "memory_types = ['Buffer', 'Summary', 'Window']\n",
        "metrics = ['Completude', 'Efici√™ncia', 'Simplicidade']\n",
        "\n",
        "# Scores de 0 a 5 para cada m√©trica\n",
        "scores = {\n",
        "    'Buffer': [5, 2, 5],    # Completa, pouco eficiente, muito simples\n",
        "    'Summary': [3, 5, 3],   # Moderada, muito eficiente, moderada\n",
        "    'Window': [3, 4, 4]     # Moderada, eficiente, simples\n",
        "}\n",
        "\n",
        "# Criando gr√°fico radar\n",
        "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
        "\n",
        "# √Çngulos para cada m√©trica\n",
        "angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()\n",
        "angles += angles[:1]  # Fechar o c√≠rculo\n",
        "\n",
        "# Cores para cada tipo\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
        "\n",
        "# Plotar cada tipo de mem√≥ria\n",
        "for i, (memory_type, color) in enumerate(zip(memory_types, colors)):\n",
        "    values = scores[memory_type] + scores[memory_type][:1]  # Fechar o c√≠rculo\n",
        "    ax.plot(angles, values, 'o-', linewidth=2, label=memory_type, color=color)\n",
        "    ax.fill(angles, values, alpha=0.25, color=color)\n",
        "\n",
        "# Configurar gr√°fico\n",
        "ax.set_xticks(angles[:-1])\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.set_ylim(0, 5)\n",
        "ax.set_yticks([1, 2, 3, 4, 5])\n",
        "ax.set_title('Compara√ß√£o dos Tipos de Memory Systems\\n(Maior = Melhor)', \n",
        "             size=16, fontweight='bold', pad=20)\n",
        "ax.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
        "ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Resumo Visual Completo!\")\n",
        "print(\"\\nüéì Voc√™ agora domina Memory Systems no LangChain!\")\n",
        "print(\"\\nüöÄ Pr√≥ximo m√≥dulo: Document Loading e Splitters\")\n",
        "print(\"   Vamos aprender a carregar e processar documentos!\")\n",
        "print(\"\\nüí™ Continue praticando e nos vemos no pr√≥ximo m√≥dulo!\")"
      ]
    }
  ]
}