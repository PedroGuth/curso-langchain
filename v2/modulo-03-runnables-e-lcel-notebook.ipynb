{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bh09YHRaqdl"
      },
      "source": [
        "# üîó Runnables e LCEL: O Poder da Orquestra√ß√£o no LangChain!\n",
        "\n",
        "**M√≥dulo 3 - LangChain v0.3 com Pedro Guth**\n",
        "\n",
        "Ea√≠ pessoal! Tudo certo? Hoje vamos mergulhar no cora√ß√£o do LangChain: os **Runnables** e a **LCEL (LangChain Expression Language)**!\n",
        "\n",
        "Lembra do m√≥dulo anterior onde mexemos com ChatModels? Agora vamos ver como conectar essas pe√ßas como se fosse um LEGO super inteligente!\n",
        "\n",
        "![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-03_img_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVZnSxllaqdm"
      },
      "source": [
        "## ü§î T√°, mas o que s√£o Runnables?\n",
        "\n",
        "Imagina que voc√™ tem uma f√°brica de brigadeiros. Voc√™ tem:\n",
        "- A esta√ß√£o que mistura o chocolate üç´\n",
        "- A esta√ß√£o que enrola as bolinhas ü•Ñ\n",
        "- A esta√ß√£o que p√µe o granulado ‚ú®\n",
        "\n",
        "Cada esta√ß√£o √© um **Runnable** - uma unidade que recebe algo, processa e passa adiante!\n",
        "\n",
        "No LangChain, **TUDO** √© um Runnable:\n",
        "- ChatModels (que j√° vimos!)\n",
        "- PromptTemplates (que vamos ver no pr√≥ximo m√≥dulo!)\n",
        "- OutputParsers\n",
        "- Chains\n",
        "- E por a√≠ vai...\n",
        "\n",
        "**Dica!** Runnable √© a interface padr√£o que permite conectar qualquer componente do LangChain de forma consistente!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihv5jSDiaqdm"
      },
      "outputs": [],
      "source": [
        "# Primeiro, vamos instalar e importar o que precisamos\n",
        "!pip install langchain langchain-google-genai python-dotenv\n",
        "\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Carrega as vari√°veis de ambiente\n",
        "load_dotenv()\n",
        "\n",
        "print(\"üì¶ Bibliotecas importadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmipBjdXaqdm"
      },
      "outputs": [],
      "source": [
        "# Configurando nossa API key do Google (lembra do m√≥dulo 2?)\n",
        "# Substitua por sua chave ou configure no .env\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"sua_chave_aqui\"\n",
        "\n",
        "# Criando nosso ChatModel (j√° conhecemos esse cara!)\n",
        "modelo = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(\"ü§ñ Modelo configurado e pronto para usar!\")\n",
        "print(f\"Tipo do modelo: {type(modelo)}\")\n",
        "print(f\"√â um Runnable? {hasattr(modelo, 'invoke')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozEWpSuEaqdn"
      },
      "source": [
        "## üèÉ‚Äç‚ôÇÔ∏è Os M√©todos Fundamentais dos Runnables\n",
        "\n",
        "Todo Runnable tem 4 m√©todos principais:\n",
        "\n",
        "| M√©todo | O que faz | Quando usar |\n",
        "|--------|-----------|-------------|\n",
        "| `invoke()` | Executa uma vez | Quando voc√™ quer uma resposta simples |\n",
        "| `batch()` | Executa em lote | Quando tem v√°rias perguntas de uma vez |\n",
        "| `stream()` | Executa com streaming | Quando quer ver a resposta chegando aos poucos |\n",
        "| `ainvoke()` | Executa de forma ass√≠ncrona | Para aplica√ß√µes mais avan√ßadas |\n",
        "\n",
        "√â como ter 4 formas diferentes de pedir um Uber! üöó"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9xW0wSVaqdn"
      },
      "outputs": [],
      "source": [
        "# Testando o m√©todo invoke() - o mais b√°sico\n",
        "resposta = modelo.invoke(\"Explique o que √© intelig√™ncia artificial em uma frase\")\n",
        "print(\"üéØ M√©todo invoke():\")\n",
        "print(resposta.content)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Testando o m√©todo batch() - v√°rias perguntas de uma vez\n",
        "perguntas = [\n",
        "    \"O que √© Python?\",\n",
        "    \"O que √© JavaScript?\",\n",
        "    \"O que √© LangChain?\"\n",
        "]\n",
        "\n",
        "respostas = modelo.batch(perguntas)\n",
        "print(\"üì¶ M√©todo batch():\")\n",
        "for i, resposta in enumerate(respostas):\n",
        "    print(f\"{i+1}. {resposta.content[:100]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3263qyxOaqdn"
      },
      "outputs": [],
      "source": [
        "# Testando o m√©todo stream() - vendo a resposta chegar aos poucos\n",
        "print(\"üåä M√©todo stream():\")\n",
        "pergunta = \"Conte uma hist√≥ria curta sobre um rob√¥ que aprende a fazer caf√©\"\n",
        "\n",
        "for chunk in modelo.stream(pergunta):\n",
        "    print(chunk.content, end=\"\", flush=True)\n",
        "\n",
        "print(\"\\n\\n‚ú® Liiindo! A resposta chegou aos poucos!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV6pH83laqdn"
      },
      "source": [
        "## ‚ö° LCEL - LangChain Expression Language\n",
        "\n",
        "Agora vem a parte mais massa! A **LCEL** √© como se fosse a \"linguagem\" para conectar Runnables.\n",
        "\n",
        "√â tipo aqueles conectores de mangueira de jardim - voc√™ vai encaixando um no outro at√© formar o sistema perfeito! üå±\n",
        "\n",
        "A sintaxe b√°sica √© usar o operador `|` (pipe):\n",
        "\n",
        "```python\n",
        "chain = componente1 | componente2 | componente3\n",
        "```\n",
        "\n",
        "**Dica!** O pipe (`|`) √© como uma seta que diz \"pega o resultado daqui e manda pra l√°\"!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3X9_vFTaqdn"
      },
      "source": [
        "[![](https://mermaid.ink/img/eyJjb2RlIjoiZ3JhcGggTFJcbiAgICBBW0lucHV0XSAtLT4gQltSdW5uYWJsZSAxXVxuICAgIEIgLS0-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)](https://mermaid.d.foundation/#/edit/eyJjb2RlIjoiZ3JhcGggTFJcbiAgICBBW0lucHV0XSAtLT4gQltSdW5uYWJsZSAxXVxuICAgIEIgLS0-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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0eEuBi9aqdn"
      },
      "outputs": [],
      "source": [
        "# Vamos criar nossa primeira chain simples!\n",
        "# Lembra: ChatModel retorna um objeto AIMessage, mas queremos s√≥ o texto\n",
        "\n",
        "# Criando um parser para extrair s√≥ o texto\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# Nossa primeira chain! üéâ\n",
        "chain_simples = modelo | parser\n",
        "\n",
        "print(\"üîó Chain criada!\")\n",
        "print(f\"Tipo da chain: {type(chain_simples)}\")\n",
        "\n",
        "# Testando nossa chain\n",
        "resultado = chain_simples.invoke(\"Me conte uma piada sobre programadores\")\n",
        "print(\"\\nüòÑ Resultado da chain:\")\n",
        "print(resultado)\n",
        "print(f\"\\nTipo do resultado: {type(resultado)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB4PNR_Haqdn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iCfSZeZaqdn"
      },
      "outputs": [],
      "source": [
        "# Vamos criar fun√ß√µes customizadas como Runnables!\n",
        "# Isso √© √∫til para adicionar l√≥gica personalizada\n",
        "\n",
        "def adicionar_emoji(texto):\n",
        "    \"\"\"Adiciona emojis aleat√≥rios ao texto\"\"\"\n",
        "    emojis = [\"üöÄ\", \"‚≠ê\", \"üéØ\", \"üí°\", \"üî•\", \"‚ú®\"]\n",
        "    import random\n",
        "    emoji_escolhido = random.choice(emojis)\n",
        "    return f\"{emoji_escolhido} {texto} {emoji_escolhido}\"\n",
        "\n",
        "def deixar_maiusculo(texto):\n",
        "    \"\"\"Transforma o texto em mai√∫sculo\"\"\"\n",
        "    return texto.upper()\n",
        "\n",
        "# Transformando fun√ß√µes em Runnables\n",
        "runnable_emoji = RunnableLambda(adicionar_emoji)\n",
        "runnable_maiusculo = RunnableLambda(deixar_maiusculo)\n",
        "\n",
        "print(\"üõ†Ô∏è Runnables customizados criados!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkDFtQtWaqdn"
      },
      "outputs": [],
      "source": [
        "# Agora vamos criar uma chain mais complexa!\n",
        "# modelo -> parser -> emoji -> mai√∫sculo\n",
        "\n",
        "chain_complexa = modelo | parser | runnable_emoji | runnable_maiusculo\n",
        "\n",
        "resultado = chain_complexa.invoke(\"Diga algo motivacional sobre aprender IA\")\n",
        "\n",
        "print(\"üé™ Chain complexa em a√ß√£o:\")\n",
        "print(resultado)\n",
        "\n",
        "print(\"\\nüîç Vamos ver o que aconteceu em cada etapa:\")\n",
        "# Executando passo a passo para entender\n",
        "etapa1 = modelo.invoke(\"Diga algo motivacional sobre aprender IA\")\n",
        "print(f\"1. Modelo: {etapa1.content[:50]}...\")\n",
        "\n",
        "etapa2 = parser.invoke(etapa1)\n",
        "print(f\"2. Parser: {etapa2[:50]}...\")\n",
        "\n",
        "etapa3 = runnable_emoji.invoke(etapa2)\n",
        "print(f\"3. Emoji: {etapa3[:50]}...\")\n",
        "\n",
        "etapa4 = runnable_maiusculo.invoke(etapa3)\n",
        "print(f\"4. Mai√∫sculo: {etapa4[:50]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uzWEY1Eaqdn"
      },
      "source": [
        "## üîÄ RunnablePassthrough - O Cara que N√£o Muda Nada\n",
        "\n",
        "√Äs vezes voc√™ quer que um valor passe pela chain sem ser modificado. √â como ter um \"atalho\" na nossa f√°brica de brigadeiros.\n",
        "\n",
        "O `RunnablePassthrough` √© perfeito para isso! Ele recebe algo e passa adiante sem modificar.\n",
        "\n",
        "**Dica!** Muito √∫til quando voc√™ quer manter o input original em chains mais complexas!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uM2fhRmaqdn"
      },
      "outputs": [],
      "source": [
        "# Testando o RunnablePassthrough\n",
        "passthrough = RunnablePassthrough()\n",
        "\n",
        "# Criando uma chain que preserva o input original\n",
        "texto_original = \"Esta mensagem vai passar inalterada\"\n",
        "resultado = passthrough.invoke(texto_original)\n",
        "\n",
        "print(\"üîÑ RunnablePassthrough em a√ß√£o:\")\n",
        "print(f\"Input: {texto_original}\")\n",
        "print(f\"Output: {resultado}\")\n",
        "print(f\"S√£o iguais? {texto_original == resultado}\")\n",
        "\n",
        "# Exemplo pr√°tico: chain que retorna tanto o original quanto processado\n",
        "def processar_texto(texto):\n",
        "    return f\"Processado: {texto.upper()}\"\n",
        "\n",
        "runnable_processar = RunnableLambda(processar_texto)\n",
        "\n",
        "# Chain que mostra antes e depois\n",
        "texto_teste = \"ol√° mundo\"\n",
        "original = passthrough.invoke(texto_teste)\n",
        "processado = runnable_processar.invoke(texto_teste)\n",
        "\n",
        "print(f\"\\nüìä Compara√ß√£o:\")\n",
        "print(f\"Original: {original}\")\n",
        "print(f\"Processado: {processado}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ppCSi8Caqdn"
      },
      "source": [
        "## üé≠ Chains Paralelas - Fazendo V√°rias Coisas ao Mesmo Tempo\n",
        "\n",
        "E se voc√™ quiser fazer v√°rias opera√ß√µes em paralelo? √â como ter v√°rias linhas de produ√ß√£o na f√°brica!\n",
        "\n",
        "No LangChain, usamos dicion√°rios para criar execu√ß√£o paralela:\n",
        "\n",
        "```python\n",
        "chain_paralela = {\n",
        "    \"operacao1\": runnable1,\n",
        "    \"operacao2\": runnable2\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzpUopvRaqdn"
      },
      "outputs": [],
      "source": [
        "# Criando fun√ß√µes para processar texto de formas diferentes\n",
        "def contar_palavras(texto):\n",
        "    \"\"\"Conta as palavras no texto\"\"\"\n",
        "    palavras = len(texto.split())\n",
        "    return f\"Tem {palavras} palavras\"\n",
        "\n",
        "def contar_caracteres(texto):\n",
        "    \"\"\"Conta os caracteres no texto\"\"\"\n",
        "    chars = len(texto)\n",
        "    return f\"Tem {chars} caracteres\"\n",
        "\n",
        "def primeira_palavra(texto):\n",
        "    \"\"\"Pega a primeira palavra\"\"\"\n",
        "    primeira = texto.split()[0] if texto.split() else \"Nenhuma\"\n",
        "    return f\"Primeira palavra: {primeira}\"\n",
        "\n",
        "# Transformando em Runnables\n",
        "runnable_palavras = RunnableLambda(contar_palavras)\n",
        "runnable_chars = RunnableLambda(contar_caracteres)\n",
        "runnable_primeira = RunnableLambda(primeira_palavra)\n",
        "\n",
        "print(\"‚ö° Runnables para an√°lise de texto criados!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yyyp9HrYaqdo"
      },
      "outputs": [],
      "source": [
        "# Criando uma chain paralela!\n",
        "# Primeiro, vamos fazer o modelo gerar um texto\n",
        "# Depois, vamos analisar esse texto de 3 formas diferentes\n",
        "\n",
        "chain_paralela = modelo | parser | {\n",
        "    \"palavras\": runnable_palavras,\n",
        "    \"caracteres\": runnable_chars,\n",
        "    \"primeira\": runnable_primeira,\n",
        "    \"original\": RunnablePassthrough()\n",
        "}\n",
        "\n",
        "resultado = chain_paralela.invoke(\"Escreva uma frase sobre o futuro da tecnologia\")\n",
        "\n",
        "print(\"üîÄ Chain paralela em a√ß√£o:\")\n",
        "print(f\"Original: {resultado['original']}\")\n",
        "print(f\"An√°lise - {resultado['palavras']}\")\n",
        "print(f\"An√°lise - {resultado['caracteres']}\")\n",
        "print(f\"An√°lise - {resultado['primeira']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUSiDadnaqdo"
      },
      "source": [
        "[![](https://mermaid.ink/img/eyJjb2RlIjoiZ3JhcGggVERcbiAgICBBW0lucHV0XSAtLT4gQltNb2RlbG9dXG4gICAgQiAtLT4gQ1tQYXJzZXJdXG4gICAgQyAtLT4gRFtFeGVjdcOnw6NvIFBhcmFsZWxhXVxuICAgIEQgLS0-IEVbQ29udGFyIFBhbGF2cmFzXVxuICAgIEQgLS0-IEZbQ29udGFyIENhcmFjdGVyZXNdXG4gICAgRCAtLT4gR1tQcmltZWlyYSBQYWxhdnJhXVxuICAgIEQgLS0-IEhbT3JpZ2luYWxdXG4gICAgRSAtLT4gSVtPdXRwdXQgRGljdF1cbiAgICBGIC0tPiBJXG4gICAgRyAtLT4gSVxuICAgIEggLS0-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)](https://mermaid.d.foundation/#/edit/eyJjb2RlIjoiZ3JhcGggVERcbiAgICBBW0lucHV0XSAtLT4gQltNb2RlbG9dXG4gICAgQiAtLT4gQ1tQYXJzZXJdXG4gICAgQyAtLT4gRFtFeGVjdcOnw6NvIFBhcmFsZWxhXVxuICAgIEQgLS0-IEVbQ29udGFyIFBhbGF2cmFzXVxuICAgIEQgLS0-IEZbQ29udGFyIENhcmFjdGVyZXNdXG4gICAgRCAtLT4gR1tQcmltZWlyYSBQYWxhdnJhXVxuICAgIEQgLS0-IEhbT3JpZ2luYWxdXG4gICAgRSAtLT4gSVtPdXRwdXQgRGljdF1cbiAgICBGIC0tPiBJXG4gICAgRyAtLT4gSVxuICAgIEggLS0-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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKdLdUoMaqdo"
      },
      "source": [
        "## üìä Visualizando o Fluxo das Chains\n",
        "\n",
        "Bora criar um gr√°fico para entender melhor como os dados fluem pelas chains!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMGbXXBmaqdo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Simulando tempos de execu√ß√£o de diferentes chains\n",
        "chains = ['Simples\\n(Modelo + Parser)', 'Complexa\\n(4 etapas)', 'Paralela\\n(4 opera√ß√µes)']\n",
        "tempos = [1.2, 2.1, 1.8]  # Tempos simulados em segundos\n",
        "cores = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "barras = ax.bar(chains, tempos, color=cores, alpha=0.8, edgecolor='white', linewidth=2)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for i, (barra, tempo) in enumerate(zip(barras, tempos)):\n",
        "    ax.text(barra.get_x() + barra.get_width()/2, barra.get_height() + 0.05,\n",
        "            f'{tempo}s', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
        "\n",
        "ax.set_title('‚ö° Compara√ß√£o de Desempenho das Chains', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.set_ylabel('Tempo de Execu√ß√£o (segundos)', fontsize=12)\n",
        "ax.set_ylim(0, max(tempos) * 1.3)\n",
        "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "# Adicionando anota√ß√µes\n",
        "ax.annotate('Mais r√°pida!', xy=(0, tempos[0]), xytext=(0.5, tempos[0] + 0.5),\n",
        "            arrowprops=dict(arrowstyle='->', color='green', lw=2),\n",
        "            fontsize=10, ha='center', color='green', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìà Gr√°fico criado! Como voc√™ pode ver, chains paralelas s√£o eficientes!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srNbou6vaqdo"
      },
      "source": [
        "## üéØ Exemplo Pr√°tico: Sistema de An√°lise de Sentimentos\n",
        "\n",
        "Vamos criar um sistema real que usa tudo que aprendemos! Vamos analisar o sentimento de textos de forma completa.\n",
        "\n",
        "![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-03_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Len7XHipaqdo"
      },
      "outputs": [],
      "source": [
        "# Vamos criar um sistema completo de an√°lise de sentimentos!\n",
        "\n",
        "def criar_prompt_sentimento(texto):\n",
        "    \"\"\"Cria um prompt espec√≠fico para an√°lise de sentimentos\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Analise o sentimento do seguinte texto e retorne apenas uma das op√ß√µes:\n",
        "    - POSITIVO\n",
        "    - NEGATIVO\n",
        "    - NEUTRO\n",
        "\n",
        "    Texto: {texto}\n",
        "\n",
        "    Sentimento:\n",
        "    \"\"\"\n",
        "    return prompt\n",
        "\n",
        "def extrair_sentimento(resposta):\n",
        "    \"\"\"Extrai o sentimento da resposta do modelo\"\"\"\n",
        "    resposta = resposta.upper().strip()\n",
        "    if \"POSITIVO\" in resposta:\n",
        "        return \"POSITIVO üòä\"\n",
        "    elif \"NEGATIVO\" in resposta:\n",
        "        return \"NEGATIVO üò¢\"\n",
        "    elif \"NEUTRO\" in resposta:\n",
        "        return \"NEUTRO üòê\"\n",
        "    else:\n",
        "        return \"INDEFINIDO ü§î\"\n",
        "\n",
        "def contar_sentimentos_palavras(texto):\n",
        "    \"\"\"Conta palavras que indicam sentimentos\"\"\"\n",
        "    palavras_positivas = ['bom', '√≥timo', 'excelente', 'feliz', 'alegre', 'amor', 'sucesso']\n",
        "    palavras_negativas = ['ruim', 'p√©ssimo', 'triste', 'raiva', '√≥dio', 'fracasso', 'problema']\n",
        "\n",
        "    texto_lower = texto.lower()\n",
        "    pos = sum(1 for palavra in palavras_positivas if palavra in texto_lower)\n",
        "    neg = sum(1 for palavra in palavras_negativas if palavra in texto_lower)\n",
        "\n",
        "    return f\"Palavras positivas: {pos}, Negativas: {neg}\"\n",
        "\n",
        "# Transformando em Runnables\n",
        "runnable_prompt = RunnableLambda(criar_prompt_sentimento)\n",
        "runnable_extrair = RunnableLambda(extrair_sentimento)\n",
        "runnable_contar = RunnableLambda(contar_sentimentos_palavras)\n",
        "\n",
        "print(\"üé≠ Sistema de an√°lise de sentimentos criado!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9Zx9ZVtaqdo"
      },
      "outputs": [],
      "source": [
        "# Montando nossa chain completa de an√°lise de sentimentos\n",
        "chain_sentimentos = {\n",
        "    \"analise_ia\": runnable_prompt | modelo | parser | runnable_extrair,\n",
        "    \"analise_palavras\": runnable_contar,\n",
        "    \"texto_original\": RunnablePassthrough(),\n",
        "    \"tamanho\": RunnableLambda(lambda x: f\"Caracteres: {len(x)}\")\n",
        "}\n",
        "\n",
        "# Testando com diferentes textos\n",
        "textos_teste = [\n",
        "    \"Estou muito feliz com meu progresso em IA! Est√° sendo uma jornada incr√≠vel!\",\n",
        "    \"Esse c√≥digo n√£o funciona e estou muito frustrado com esses erros.\",\n",
        "    \"Hoje √© segunda-feira e tenho uma reuni√£o √†s 14h.\"\n",
        "]\n",
        "\n",
        "print(\"üîç Analisando diferentes textos:\\n\")\n",
        "\n",
        "for i, texto in enumerate(textos_teste, 1):\n",
        "    print(f\"üìÑ Texto {i}: {texto[:50]}...\")\n",
        "    resultado = chain_sentimentos.invoke(texto)\n",
        "\n",
        "    print(f\"   ü§ñ IA diz: {resultado['analise_ia']}\")\n",
        "    print(f\"   üìä Contagem: {resultado['analise_palavras']}\")\n",
        "    print(f\"   üìè {resultado['tamanho']}\")\n",
        "    print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc0mCQtzaqdo"
      },
      "source": [
        "## üöÄ Streaming com Chains - Vendo em Tempo Real\n",
        "\n",
        "Uma das coisas mais legais das chains √© que voc√™ pode fazer streaming! √â como ver a m√°gica acontecer em tempo real.\n",
        "\n",
        "**Dica!** Streaming √© especialmente √∫til para aplica√ß√µes web onde voc√™ quer mostrar a resposta chegando aos poucos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG4YjYsvaqdo"
      },
      "outputs": [],
      "source": [
        "# Vamos criar uma chain simples para streaming\n",
        "chain_streaming = modelo | parser\n",
        "\n",
        "print(\"üåä Demonstra√ß√£o de streaming:\")\n",
        "print(\"Pergunta: 'Explique como funciona o machine learning'\")\n",
        "print(\"Resposta chegando aos poucos...\\n\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Fazendo streaming da resposta\n",
        "for chunk in chain_streaming.stream(\"Explique como funciona o machine learning em termos simples\"):\n",
        "    print(chunk, end=\"\", flush=True)\n",
        "\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"\\n‚ú® Streaming finalizado! Legal n√©?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niv_Zn2Naqdo"
      },
      "source": [
        "## üéÆ Exerc√≠cio Pr√°tico 1: Sua Primeira Chain!\n",
        "\n",
        "Agora √© sua vez! Vamos criar uma chain que:\n",
        "1. Recebe um t√≥pico\n",
        "2. Pede para o modelo criar uma pergunta sobre esse t√≥pico\n",
        "3. Conta quantas palavras tem a pergunta\n",
        "4. Adiciona emojis relacionados ao t√≥pico\n",
        "\n",
        "**Desafio:** Complete o c√≥digo abaixo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72P1X-q6aqdo"
      },
      "outputs": [],
      "source": [
        "# üéØ EXERC√çCIO 1: Complete a chain abaixo\n",
        "\n",
        "def criar_pergunta(topico):\n",
        "    \"\"\"Cria um prompt para gerar uma pergunta sobre o t√≥pico\"\"\"\n",
        "    # TODO: Complete esta fun√ß√£o\n",
        "    # Dica: retorne um prompt pedindo uma pergunta interessante sobre o t√≥pico\n",
        "    pass\n",
        "\n",
        "def adicionar_emoji_topico(texto):\n",
        "    \"\"\"Adiciona emojis baseados no conte√∫do\"\"\"\n",
        "    # TODO: Complete esta fun√ß√£o\n",
        "    # Dica: use if/elif para diferentes t√≥picos (tecnologia, comida, esporte, etc.)\n",
        "    pass\n",
        "\n",
        "def contar_info(texto):\n",
        "    \"\"\"Conta palavras e caracteres\"\"\"\n",
        "    # TODO: Complete esta fun√ß√£o\n",
        "    # Dica: retorne algo como \"X palavras, Y caracteres\"\n",
        "    pass\n",
        "\n",
        "# Transforme suas fun√ß√µes em Runnables\n",
        "# TODO: Crie os RunnableLambda\n",
        "\n",
        "# Crie a chain completa\n",
        "# TODO: Monte a chain usando o operador |\n",
        "\n",
        "# Teste com um t√≥pico\n",
        "# resultado = sua_chain.invoke(\"intelig√™ncia artificial\")\n",
        "# print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk6P0r2uaqdo"
      },
      "source": [
        "## üí° Solu√ß√£o do Exerc√≠cio 1\n",
        "\n",
        "Aqui est√° uma poss√≠vel solu√ß√£o para o exerc√≠cio anterior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlng0Sz_aqdo"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ SOLU√á√ÉO DO EXERC√çCIO 1\n",
        "\n",
        "def criar_pergunta(topico):\n",
        "    \"\"\"Cria um prompt para gerar uma pergunta sobre o t√≥pico\"\"\"\n",
        "    return f\"Crie uma pergunta interessante e educativa sobre: {topico}\"\n",
        "\n",
        "def adicionar_emoji_topico(texto):\n",
        "    \"\"\"Adiciona emojis baseados no conte√∫do\"\"\"\n",
        "    texto_lower = texto.lower()\n",
        "\n",
        "    if any(palavra in texto_lower for palavra in ['tecnologia', 'ia', 'computador', 'software']):\n",
        "        return f\"üíª {texto} ü§ñ\"\n",
        "    elif any(palavra in texto_lower for palavra in ['comida', 'receita', 'cozinha']):\n",
        "        return f\"üç≥ {texto} üçΩÔ∏è\"\n",
        "    elif any(palavra in texto_lower for palavra in ['esporte', 'futebol', 'basquete']):\n",
        "        return f\"‚öΩ {texto} üèÜ\"\n",
        "    else:\n",
        "        return f\"üìö {texto} üéì\"\n",
        "\n",
        "def contar_info(texto):\n",
        "    \"\"\"Conta palavras e caracteres\"\"\"\n",
        "    palavras = len(texto.split())\n",
        "    caracteres = len(texto)\n",
        "    return f\"{texto} | [Info: {palavras} palavras, {caracteres} caracteres]\"\n",
        "\n",
        "# Criando os Runnables\n",
        "runnable_pergunta = RunnableLambda(criar_pergunta)\n",
        "runnable_emoji_topico = RunnableLambda(adicionar_emoji_topico)\n",
        "runnable_info = RunnableLambda(contar_info)\n",
        "\n",
        "# Chain completa\n",
        "chain_exercicio = runnable_pergunta | modelo | parser | runnable_emoji_topico | runnable_info\n",
        "\n",
        "# Testando\n",
        "resultado = chain_exercicio.invoke(\"intelig√™ncia artificial\")\n",
        "print(\"üéØ Resultado do exerc√≠cio:\")\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "je4b71f-aqdo"
      },
      "source": [
        "## üé≤ Exerc√≠cio Pr√°tico 2: Chain Paralela Avan√ßada\n",
        "\n",
        "Agora vamos criar algo mais desafiador! Uma chain que processa um texto de m√∫ltiplas formas simultaneamente.\n",
        "\n",
        "**Objetivo:** Criar uma chain que analise um texto e retorne:\n",
        "- Resumo em uma frase\n",
        "- Tradu√ß√£o para ingl√™s  \n",
        "- An√°lise de sentimento\n",
        "- Estat√≠sticas b√°sicas\n",
        "\n",
        "![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-03_img_04.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-O96V9xaqdo"
      },
      "outputs": [],
      "source": [
        "# üéØ EXERC√çCIO 2: Chain Paralela Avan√ßada\n",
        "\n",
        "# Fun√ß√µes auxiliares j√° prontas\n",
        "def criar_prompt_resumo(texto):\n",
        "    return f\"Resuma este texto em uma frase: {texto}\"\n",
        "\n",
        "def criar_prompt_traducao(texto):\n",
        "    return f\"Traduza este texto para o ingl√™s: {texto}\"\n",
        "\n",
        "def criar_prompt_sentimento_simples(texto):\n",
        "    return f\"Qual o sentimento deste texto? Responda apenas: POSITIVO, NEGATIVO ou NEUTRO. Texto: {texto}\"\n",
        "\n",
        "def estatisticas_texto(texto):\n",
        "    palavras = len(texto.split())\n",
        "    frases = texto.count('.') + texto.count('!') + texto.count('?')\n",
        "    chars = len(texto)\n",
        "    return f\"Estat√≠sticas: {palavras} palavras, {frases} frases, {chars} caracteres\"\n",
        "\n",
        "# TODO: Crie os Runnables necess√°rios\n",
        "# TODO: Monte a chain paralela usando dicion√°rio\n",
        "# TODO: Teste com um texto interessante\n",
        "\n",
        "# Dica: Lembre-se que para chains que usam o modelo, voc√™ precisa:\n",
        "# prompt_function | modelo | parser\n",
        "\n",
        "texto_teste = \"\"\"\n",
        "A intelig√™ncia artificial est√° revolucionando a forma como trabalhamos e vivemos.\n",
        "Com o LangChain, conseguimos criar aplica√ß√µes incr√≠veis que antes pareciam imposs√≠veis.\n",
        "√â uma √©poca fant√°stica para ser um desenvolvedor!\n",
        "\"\"\"\n",
        "\n",
        "print(\"üìù Texto para an√°lise:\")\n",
        "print(texto_teste)\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# TODO: Execute sua chain aqui\n",
        "# resultado = sua_chain_paralela.invoke(texto_teste)\n",
        "# print(resultado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlWY9jWUaqdp"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ SOLU√á√ÉO DO EXERC√çCIO 2\n",
        "\n",
        "# Criando os Runnables\n",
        "runnable_prompt_resumo = RunnableLambda(criar_prompt_resumo)\n",
        "runnable_prompt_traducao = RunnableLambda(criar_prompt_traducao)\n",
        "runnable_prompt_sentimento = RunnableLambda(criar_prompt_sentimento_simples)\n",
        "runnable_estatisticas = RunnableLambda(estatisticas_texto)\n",
        "\n",
        "# Chain paralela completa\n",
        "chain_analise_completa = {\n",
        "    \"resumo\": runnable_prompt_resumo | modelo | parser,\n",
        "    \"traducao\": runnable_prompt_traducao | modelo | parser,\n",
        "    \"sentimento\": runnable_prompt_sentimento | modelo | parser,\n",
        "    \"estatisticas\": runnable_estatisticas,\n",
        "    \"original\": RunnablePassthrough()\n",
        "}\n",
        "\n",
        "# Executando a an√°lise\n",
        "resultado = chain_analise_completa.invoke(texto_teste)\n",
        "\n",
        "print(\"üîç AN√ÅLISE COMPLETA DO TEXTO:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"üìä {resultado['estatisticas']}\")\n",
        "print(f\"üìù Resumo: {resultado['resumo']}\")\n",
        "print(f\"üåç Tradu√ß√£o: {resultado['traducao']}\")\n",
        "print(f\"üé≠ Sentimento: {resultado['sentimento']}\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nüéâ Liiindo! Conseguimos analisar o texto de 4 formas diferentes simultaneamente!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkaX9_qHaqdp"
      },
      "source": [
        "## üìà Visualizando a Performance das Chains\n",
        "\n",
        "Vamos criar um gr√°fico para comparar a efici√™ncia das diferentes abordagens que aprendemos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSP61U2Eaqdp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# Simulando tempos de execu√ß√£o para diferentes tipos de chains\n",
        "tipos_chain = ['Sequencial\\nSimples', 'Sequencial\\nComplexa', 'Paralela\\n4 opera√ß√µes', 'Streaming\\nTempo Real']\n",
        "tempos_medio = [0.8, 2.5, 1.2, 0.9]\n",
        "complexidade = [1, 4, 4, 2]  # N√∫mero de opera√ß√µes\n",
        "\n",
        "# Criando subplot com dois gr√°ficos\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Gr√°fico 1: Tempo de Execu√ß√£o\n",
        "cores1 = ['#FF6B6B', '#FF8E53', '#FF6B9D', '#4ECDC4']\n",
        "barras1 = ax1.bar(tipos_chain, tempos_medio, color=cores1, alpha=0.8, edgecolor='white', linewidth=2)\n",
        "\n",
        "for barra, tempo in zip(barras1, tempos_medio):\n",
        "    ax1.text(barra.get_x() + barra.get_width()/2, barra.get_height() + 0.05,\n",
        "             f'{tempo}s', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "ax1.set_title('‚ö° Tempo de Execu√ß√£o por Tipo de Chain', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Tempo (segundos)')\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Gr√°fico 2: Complexidade vs Efici√™ncia\n",
        "scatter = ax2.scatter(complexidade, tempos_medio, c=cores1, s=200, alpha=0.7, edgecolors='white', linewidth=2)\n",
        "\n",
        "for i, tipo in enumerate(tipos_chain):\n",
        "    ax2.annotate(tipo.replace('\\n', ' '), (complexidade[i], tempos_medio[i]),\n",
        "                xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
        "\n",
        "ax2.set_title('üéØ Complexidade vs Tempo de Execu√ß√£o', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('N√∫mero de Opera√ß√µes')\n",
        "ax2.set_ylabel('Tempo (segundos)')\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Observa√ß√µes importantes:\")\n",
        "print(\"‚Ä¢ Chains paralelas s√£o mais eficientes que sequenciais complexas\")\n",
        "print(\"‚Ä¢ Streaming oferece boa experi√™ncia do usu√°rio\")\n",
        "print(\"‚Ä¢ Complexidade nem sempre significa maior tempo de execu√ß√£o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c680h0rqaqdp"
      },
      "source": [
        "## üîÆ Conectando com os Pr√≥ximos M√≥dulos\n",
        "\n",
        "Agora que voc√™ domina Runnables e LCEL, vamos ver como eles se conectam com o resto do curso:\n",
        "\n",
        "### üìã M√≥dulo 4 - Prompt Templates\n",
        "- Os PromptTemplates s√£o Runnables!\n",
        "- Voc√™ vai usar LCEL para conectar templates com modelos\n",
        "- Exemplo: `template | modelo | parser`\n",
        "\n",
        "### üéØ M√≥dulo 5 - OutputParsers\n",
        "- OutputParsers tamb√©m s√£o Runnables!\n",
        "- Voc√™ vai criar chains do tipo: `modelo | custom_parser`\n",
        "\n",
        "### ‚õìÔ∏è M√≥dulo 6 - Chains\n",
        "- Chains mais complexas usando tudo que aprendemos aqui\n",
        "- Composi√ß√£o de m√∫ltiplos Runnables\n",
        "\n",
        "**Dica!** Tudo no LangChain √© um Runnable - esse √© o segredo para criar aplica√ß√µes poderosas!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w97r9g08aqdp"
      },
      "source": [
        "## üéì Resumo do M√≥dulo - O que Aprendemos?\n",
        "\n",
        "Bora recapitular tudo que vimos neste m√≥dulo:\n",
        "\n",
        "### ‚úÖ Conceitos Fundamentais\n",
        "- **Runnables**: A interface padr√£o de tudo no LangChain\n",
        "- **LCEL**: A linguagem para conectar componentes\n",
        "- **Operador Pipe (`|`)**: Para conectar Runnables\n",
        "\n",
        "### ‚úÖ M√©todos dos Runnables\n",
        "- `invoke()`: Execu√ß√£o simples\n",
        "- `batch()`: Execu√ß√£o em lote\n",
        "- `stream()`: Execu√ß√£o com streaming\n",
        "- `ainvoke()`: Execu√ß√£o ass√≠ncrona\n",
        "\n",
        "### ‚úÖ Tipos de Chains\n",
        "- **Sequenciais**: Uma opera√ß√£o ap√≥s a outra\n",
        "- **Paralelas**: M√∫ltiplas opera√ß√µes simult√¢neas\n",
        "- **Complexas**: Combina√ß√£o de ambas\n",
        "\n",
        "### ‚úÖ Componentes Especiais\n",
        "- `RunnableLambda`: Para fun√ß√µes customizadas\n",
        "- `RunnablePassthrough`: Para manter dados inalterados\n",
        "- `StrOutputParser`: Para extrair texto simples\n",
        "\n",
        "### üöÄ Pr√≥ximos Passos\n",
        "No pr√≥ximo m√≥dulo vamos aprender sobre **Prompt Templates** - como criar prompts din√¢micos e reutiliz√°veis que se conectam perfeitamente com as chains que criamos hoje!\n",
        "\n",
        "**Bora continuar essa jornada incr√≠vel! üéâ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKCLTB1Kaqdp"
      },
      "source": [
        "![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-03_img_05.png)"
      ]
    }
  ]
}