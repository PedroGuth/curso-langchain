{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîó Runnables e LCEL: O Poder da Orquestra√ß√£o no LangChain! \n\n**M√≥dulo 3 - LangChain v0.3 com Pedro Guth**\n\nEa√≠ pessoal! Tudo certo? Hoje vamos mergulhar no cora√ß√£o do LangChain: os **Runnables** e a **LCEL (LangChain Expression Language)**!\n\nLembra do m√≥dulo anterior onde mexemos com ChatModels? Agora vamos ver como conectar essas pe√ßas como se fosse um LEGO super inteligente!\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-03_img_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§î T√°, mas o que s√£o Runnables?\n\nImagina que voc√™ tem uma f√°brica de brigadeiros. Voc√™ tem:\n- A esta√ß√£o que mistura o chocolate üç´\n- A esta√ß√£o que enrola as bolinhas ü•Ñ\n- A esta√ß√£o que p√µe o granulado ‚ú®\n\nCada esta√ß√£o √© um **Runnable** - uma unidade que recebe algo, processa e passa adiante!\n\nNo LangChain, **TUDO** √© um Runnable:\n- ChatModels (que j√° vimos!)\n- PromptTemplates (que vamos ver no pr√≥ximo m√≥dulo!)\n- OutputParsers\n- Chains\n- E por a√≠ vai...\n\n**Dica!** Runnable √© a interface padr√£o que permite conectar qualquer componente do LangChain de forma consistente!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Primeiro, vamos instalar e importar o que precisamos\n",
        "!pip install langchain langchain-google-genai python-dotenv\n\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from dotenv import load_dotenv\n\n",
        "# Carrega as vari√°veis de ambiente\n",
        "load_dotenv()\n\n",
        "print(\"üì¶ Bibliotecas importadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurando nossa API key do Google (lembra do m√≥dulo 2?)\n",
        "# Substitua por sua chave ou configure no .env\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"sua_chave_aqui\"\n\n",
        "# Criando nosso ChatModel (j√° conhecemos esse cara!)\n",
        "modelo = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0.7\n",
        ")\n\n",
        "print(\"ü§ñ Modelo configurado e pronto para usar!\")\n",
        "print(f\"Tipo do modelo: {type(modelo)}\")\n",
        "print(f\"√â um Runnable? {hasattr(modelo, 'invoke')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèÉ‚Äç‚ôÇÔ∏è Os M√©todos Fundamentais dos Runnables\n\nTodo Runnable tem 4 m√©todos principais:\n\n| M√©todo | O que faz | Quando usar |\n|--------|-----------|-------------|\n| `invoke()` | Executa uma vez | Quando voc√™ quer uma resposta simples |\n| `batch()` | Executa em lote | Quando tem v√°rias perguntas de uma vez |\n| `stream()` | Executa com streaming | Quando quer ver a resposta chegando aos poucos |\n| `ainvoke()` | Executa de forma ass√≠ncrona | Para aplica√ß√µes mais avan√ßadas |\n\n√â como ter 4 formas diferentes de pedir um Uber! üöó"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando o m√©todo invoke() - o mais b√°sico\n",
        "resposta = modelo.invoke(\"Explique o que √© intelig√™ncia artificial em uma frase\")\n",
        "print(\"üéØ M√©todo invoke():\")\n",
        "print(resposta.content)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n\n",
        "# Testando o m√©todo batch() - v√°rias perguntas de uma vez\n",
        "perguntas = [\n",
        "    \"O que √© Python?\",\n",
        "    \"O que √© JavaScript?\",\n",
        "    \"O que √© LangChain?\"\n",
        "]\n\n",
        "respostas = modelo.batch(perguntas)\n",
        "print(\"üì¶ M√©todo batch():\")\n",
        "for i, resposta in enumerate(respostas):\n",
        "    print(f\"{i+1}. {resposta.content[:100]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando o m√©todo stream() - vendo a resposta chegar aos poucos\n",
        "print(\"üåä M√©todo stream():\")\n",
        "pergunta = \"Conte uma hist√≥ria curta sobre um rob√¥ que aprende a fazer caf√©\"\n\n",
        "for chunk in modelo.stream(pergunta):\n",
        "    print(chunk.content, end=\"\", flush=True)\n",
        "\n",
        "print(\"\\n\\n‚ú® Liiindo! A resposta chegou aos poucos!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° LCEL - LangChain Expression Language\n\nAgora vem a parte mais massa! A **LCEL** √© como se fosse a \"linguagem\" para conectar Runnables.\n\n√â tipo aqueles conectores de mangueira de jardim - voc√™ vai encaixando um no outro at√© formar o sistema perfeito! üå±\n\nA sintaxe b√°sica √© usar o operador `|` (pipe):\n\n```python\nchain = componente1 | componente2 | componente3\n```\n\n**Dica!** O pipe (`|`) √© como uma seta que diz \"pega o resultado daqui e manda pra l√°\"!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\ngraph LR\n    A[Input] --> B[Runnable 1]\n    B --> C[Runnable 2]\n    C --> D[Runnable 3]\n    D --> E[Output]\n    \n    style A fill:#e1f5fe\n    style E fill:#c8e6c9\n    style B fill:#fff3e0\n    style C fill:#fff3e0\n    style D fill:#fff3e0\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar nossa primeira chain simples!\n",
        "# Lembra: ChatModel retorna um objeto AIMessage, mas queremos s√≥ o texto\n",
        "\n",
        "# Criando um parser para extrair s√≥ o texto\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# Nossa primeira chain! üéâ\n",
        "chain_simples = modelo | parser\n",
        "\n",
        "print(\"üîó Chain criada!\")\n",
        "print(f\"Tipo da chain: {type(chain_simples)}\")\n",
        "\n",
        "# Testando nossa chain\n",
        "resultado = chain_simples.invoke(\"Me conte uma piada sobre programadores\")\n",
        "print(\"\\nüòÑ Resultado da chain:\")\n",
        "print(resultado)\n",
        "print(f\"\\nTipo do resultado: {type(resultado)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar fun√ß√µes customizadas como Runnables!\n",
        "# Isso √© √∫til para adicionar l√≥gica personalizada\n\n",
        "def adicionar_emoji(texto):\n",
        "    \"\"\"Adiciona emojis aleat√≥rios ao texto\"\"\"\n",
        "    emojis = [\"üöÄ\", \"‚≠ê\", \"üéØ\", \"üí°\", \"üî•\", \"‚ú®\"]\n",
        "    import random\n",
        "    emoji_escolhido = random.choice(emojis)\n",
        "    return f\"{emoji_escolhido} {texto} {emoji_escolhido}\"\n\n",
        "def deixar_maiusculo(texto):\n",
        "    \"\"\"Transforma o texto em mai√∫sculo\"\"\"\n",
        "    return texto.upper()\n\n",
        "# Transformando fun√ß√µes em Runnables\n",
        "runnable_emoji = RunnableLambda(adicionar_emoji)\n",
        "runnable_maiusculo = RunnableLambda(deixar_maiusculo)\n\n",
        "print(\"üõ†Ô∏è Runnables customizados criados!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agora vamos criar uma chain mais complexa!\n",
        "# modelo -> parser -> emoji -> mai√∫sculo\n\n",
        "chain_complexa = modelo | parser | runnable_emoji | runnable_maiusculo\n\n",
        "resultado = chain_complexa.invoke(\"Diga algo motivacional sobre aprender IA\")\n",
        "\n",
        "print(\"üé™ Chain complexa em a√ß√£o:\")\n",
        "print(resultado)\n",
        "\n",
        "print(\"\\nüîç Vamos ver o que aconteceu em cada etapa:\")\n",
        "# Executando passo a passo para entender\n",
        "etapa1 = modelo.invoke(\"Diga algo motivacional sobre aprender IA\")\n",
        "print(f\"1. Modelo: {etapa1.content[:50]}...\")\n",
        "\n",
        "etapa2 = parser.invoke(etapa1)\n",
        "print(f\"2. Parser: {etapa2[:50]}...\")\n",
        "\n",
        "etapa3 = runnable_emoji.invoke(etapa2)\n",
        "print(f\"3. Emoji: {etapa3[:50]}...\")\n",
        "\n",
        "etapa4 = runnable_maiusculo.invoke(etapa3)\n",
        "print(f\"4. Mai√∫sculo: {etapa4[:50]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÄ RunnablePassthrough - O Cara que N√£o Muda Nada\n\n√Äs vezes voc√™ quer que um valor passe pela chain sem ser modificado. √â como ter um \"atalho\" na nossa f√°brica de brigadeiros.\n\nO `RunnablePassthrough` √© perfeito para isso! Ele recebe algo e passa adiante sem modificar.\n\n**Dica!** Muito √∫til quando voc√™ quer manter o input original em chains mais complexas!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando o RunnablePassthrough\n",
        "passthrough = RunnablePassthrough()\n\n",
        "# Criando uma chain que preserva o input original\n",
        "texto_original = \"Esta mensagem vai passar inalterada\"\n",
        "resultado = passthrough.invoke(texto_original)\n",
        "\n",
        "print(\"üîÑ RunnablePassthrough em a√ß√£o:\")\n",
        "print(f\"Input: {texto_original}\")\n",
        "print(f\"Output: {resultado}\")\n",
        "print(f\"S√£o iguais? {texto_original == resultado}\")\n\n",
        "# Exemplo pr√°tico: chain que retorna tanto o original quanto processado\n",
        "def processar_texto(texto):\n",
        "    return f\"Processado: {texto.upper()}\"\n",
        "\n",
        "runnable_processar = RunnableLambda(processar_texto)\n\n",
        "# Chain que mostra antes e depois\n",
        "texto_teste = \"ol√° mundo\"\n",
        "original = passthrough.invoke(texto_teste)\n",
        "processado = runnable_processar.invoke(texto_teste)\n\n",
        "print(f\"\\nüìä Compara√ß√£o:\")\n",
        "print(f\"Original: {original}\")\n",
        "print(f\"Processado: {processado}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé≠ Chains Paralelas - Fazendo V√°rias Coisas ao Mesmo Tempo\n\nE se voc√™ quiser fazer v√°rias opera√ß√µes em paralelo? √â como ter v√°rias linhas de produ√ß√£o na f√°brica!\n\nNo LangChain, usamos dicion√°rios para criar execu√ß√£o paralela:\n\n```python\nchain_paralela = {\n    \"operacao1\": runnable1,\n    \"operacao2\": runnable2\n}\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando fun√ß√µes para processar texto de formas diferentes\n",
        "def contar_palavras(texto):\n",
        "    \"\"\"Conta as palavras no texto\"\"\"\n",
        "    palavras = len(texto.split())\n",
        "    return f\"Tem {palavras} palavras\"\n",
        "\n",
        "def contar_caracteres(texto):\n",
        "    \"\"\"Conta os caracteres no texto\"\"\"\n",
        "    chars = len(texto)\n",
        "    return f\"Tem {chars} caracteres\"\n",
        "\n",
        "def primeira_palavra(texto):\n",
        "    \"\"\"Pega a primeira palavra\"\"\"\n",
        "    primeira = texto.split()[0] if texto.split() else \"Nenhuma\"\n",
        "    return f\"Primeira palavra: {primeira}\"\n\n",
        "# Transformando em Runnables\n",
        "runnable_palavras = RunnableLambda(contar_palavras)\n",
        "runnable_chars = RunnableLambda(contar_caracteres)\n",
        "runnable_primeira = RunnableLambda(primeira_palavra)\n\n",
        "print(\"‚ö° Runnables para an√°lise de texto criados!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando uma chain paralela!\n",
        "# Primeiro, vamos fazer o modelo gerar um texto\n",
        "# Depois, vamos analisar esse texto de 3 formas diferentes\n\n",
        "chain_paralela = modelo | parser | {\n",
        "    \"palavras\": runnable_palavras,\n",
        "    \"caracteres\": runnable_chars,\n",
        "    \"primeira\": runnable_primeira,\n",
        "    \"original\": RunnablePassthrough()\n",
        "}\n\n",
        "resultado = chain_paralela.invoke(\"Escreva uma frase sobre o futuro da tecnologia\")\n",
        "\n",
        "print(\"üîÄ Chain paralela em a√ß√£o:\")\n",
        "print(f\"Original: {resultado['original']}\")\n",
        "print(f\"An√°lise - {resultado['palavras']}\")\n",
        "print(f\"An√°lise - {resultado['caracteres']}\")\n",
        "print(f\"An√°lise - {resultado['primeira']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\ngraph TD\n    A[Input] --> B[Modelo]\n    B --> C[Parser]\n    C --> D[Execu√ß√£o Paralela]\n    D --> E[Contar Palavras]\n    D --> F[Contar Caracteres]\n    D --> G[Primeira Palavra]\n    D --> H[Original]\n    E --> I[Output Dict]\n    F --> I\n    G --> I\n    H --> I\n    \n    style A fill:#e1f5fe\n    style I fill:#c8e6c9\n    style D fill:#fff3e0\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Visualizando o Fluxo das Chains\n\nBora criar um gr√°fico para entender melhor como os dados fluem pelas chains!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Simulando tempos de execu√ß√£o de diferentes chains\n",
        "chains = ['Simples\\n(Modelo + Parser)', 'Complexa\\n(4 etapas)', 'Paralela\\n(4 opera√ß√µes)']\n",
        "tempos = [1.2, 2.1, 1.8]  # Tempos simulados em segundos\n",
        "cores = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "barras = ax.bar(chains, tempos, color=cores, alpha=0.8, edgecolor='white', linewidth=2)\n\n",
        "# Adicionando valores nas barras\n",
        "for i, (barra, tempo) in enumerate(zip(barras, tempos)):\n",
        "    ax.text(barra.get_x() + barra.get_width()/2, barra.get_height() + 0.05, \n",
        "            f'{tempo}s', ha='center', va='bottom', fontweight='bold', fontsize=12)\n\n",
        "ax.set_title('‚ö° Compara√ß√£o de Desempenho das Chains', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.set_ylabel('Tempo de Execu√ß√£o (segundos)', fontsize=12)\n",
        "ax.set_ylim(0, max(tempos) * 1.3)\n",
        "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "# Adicionando anota√ß√µes\n",
        "ax.annotate('Mais r√°pida!', xy=(0, tempos[0]), xytext=(0.5, tempos[0] + 0.5),\n",
        "            arrowprops=dict(arrowstyle='->', color='green', lw=2),\n",
        "            fontsize=10, ha='center', color='green', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìà Gr√°fico criado! Como voc√™ pode ver, chains paralelas s√£o eficientes!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exemplo Pr√°tico: Sistema de An√°lise de Sentimentos\n\nVamos criar um sistema real que usa tudo que aprendemos! Vamos analisar o sentimento de textos de forma completa.\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-03_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar um sistema completo de an√°lise de sentimentos!\n",
        "\n",
        "def criar_prompt_sentimento(texto):\n",
        "    \"\"\"Cria um prompt espec√≠fico para an√°lise de sentimentos\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Analise o sentimento do seguinte texto e retorne apenas uma das op√ß√µes:\n",
        "    - POSITIVO\n",
        "    - NEGATIVO  \n",
        "    - NEUTRO\n",
        "    \n",
        "    Texto: {texto}\n",
        "    \n",
        "    Sentimento:\n",
        "    \"\"\"\n",
        "    return prompt\n",
        "\n",
        "def extrair_sentimento(resposta):\n",
        "    \"\"\"Extrai o sentimento da resposta do modelo\"\"\"\n",
        "    resposta = resposta.upper().strip()\n",
        "    if \"POSITIVO\" in resposta:\n",
        "        return \"POSITIVO üòä\"\n",
        "    elif \"NEGATIVO\" in resposta:\n",
        "        return \"NEGATIVO üò¢\"\n",
        "    elif \"NEUTRO\" in resposta:\n",
        "        return \"NEUTRO üòê\"\n",
        "    else:\n",
        "        return \"INDEFINIDO ü§î\"\n",
        "\n",
        "def contar_sentimentos_palavras(texto):\n",
        "    \"\"\"Conta palavras que indicam sentimentos\"\"\"\n",
        "    palavras_positivas = ['bom', '√≥timo', 'excelente', 'feliz', 'alegre', 'amor', 'sucesso']\n",
        "    palavras_negativas = ['ruim', 'p√©ssimo', 'triste', 'raiva', '√≥dio', 'fracasso', 'problema']\n",
        "    \n",
        "    texto_lower = texto.lower()\n",
        "    pos = sum(1 for palavra in palavras_positivas if palavra in texto_lower)\n",
        "    neg = sum(1 for palavra in palavras_negativas if palavra in texto_lower)\n",
        "    \n",
        "    return f\"Palavras positivas: {pos}, Negativas: {neg}\"\n\n",
        "# Transformando em Runnables\n",
        "runnable_prompt = RunnableLambda(criar_prompt_sentimento)\n",
        "runnable_extrair = RunnableLambda(extrair_sentimento)\n",
        "runnable_contar = RunnableLambda(contar_sentimentos_palavras)\n\n",
        "print(\"üé≠ Sistema de an√°lise de sentimentos criado!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Montando nossa chain completa de an√°lise de sentimentos\n",
        "chain_sentimentos = {\n",
        "    \"analise_ia\": runnable_prompt | modelo | parser | runnable_extrair,\n",
        "    \"analise_palavras\": runnable_contar,\n",
        "    \"texto_original\": RunnablePassthrough(),\n",
        "    \"tamanho\": RunnableLambda(lambda x: f\"Caracteres: {len(x)}\")\n",
        "}\n\n",
        "# Testando com diferentes textos\n",
        "textos_teste = [\n",
        "    \"Estou muito feliz com meu progresso em IA! Est√° sendo uma jornada incr√≠vel!\",\n",
        "    \"Esse c√≥digo n√£o funciona e estou muito frustrado com esses erros.\",\n",
        "    \"Hoje √© segunda-feira e tenho uma reuni√£o √†s 14h.\"\n",
        "]\n\n",
        "print(\"üîç Analisando diferentes textos:\\n\")\n",
        "\n",
        "for i, texto in enumerate(textos_teste, 1):\n",
        "    print(f\"üìÑ Texto {i}: {texto[:50]}...\")\n",
        "    resultado = chain_sentimentos.invoke(texto)\n",
        "    \n",
        "    print(f\"   ü§ñ IA diz: {resultado['analise_ia']}\")\n",
        "    print(f\"   üìä Contagem: {resultado['analise_palavras']}\")\n",
        "    print(f\"   üìè {resultado['tamanho']}\")\n",
        "    print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Streaming com Chains - Vendo em Tempo Real\n\nUma das coisas mais legais das chains √© que voc√™ pode fazer streaming! √â como ver a m√°gica acontecer em tempo real.\n\n**Dica!** Streaming √© especialmente √∫til para aplica√ß√µes web onde voc√™ quer mostrar a resposta chegando aos poucos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar uma chain simples para streaming\n",
        "chain_streaming = modelo | parser\n\n",
        "print(\"üåä Demonstra√ß√£o de streaming:\")\n",
        "print(\"Pergunta: 'Explique como funciona o machine learning'\")\n",
        "print(\"Resposta chegando aos poucos...\\n\")\n",
        "print(\"-\" * 50)\n\n",
        "# Fazendo streaming da resposta\n",
        "for chunk in chain_streaming.stream(\"Explique como funciona o machine learning em termos simples\"):\n",
        "    print(chunk, end=\"\", flush=True)\n",
        "\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"\\n‚ú® Streaming finalizado! Legal n√©?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéÆ Exerc√≠cio Pr√°tico 1: Sua Primeira Chain!\n\nAgora √© sua vez! Vamos criar uma chain que:\n1. Recebe um t√≥pico\n2. Pede para o modelo criar uma pergunta sobre esse t√≥pico\n3. Conta quantas palavras tem a pergunta\n4. Adiciona emojis relacionados ao t√≥pico\n\n**Desafio:** Complete o c√≥digo abaixo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ EXERC√çCIO 1: Complete a chain abaixo\n",
        "\n",
        "def criar_pergunta(topico):\n",
        "    \"\"\"Cria um prompt para gerar uma pergunta sobre o t√≥pico\"\"\"\n",
        "    # TODO: Complete esta fun√ß√£o\n",
        "    # Dica: retorne um prompt pedindo uma pergunta interessante sobre o t√≥pico\n",
        "    pass\n",
        "\n",
        "def adicionar_emoji_topico(texto):\n",
        "    \"\"\"Adiciona emojis baseados no conte√∫do\"\"\"\n",
        "    # TODO: Complete esta fun√ß√£o\n",
        "    # Dica: use if/elif para diferentes t√≥picos (tecnologia, comida, esporte, etc.)\n",
        "    pass\n",
        "\n",
        "def contar_info(texto):\n",
        "    \"\"\"Conta palavras e caracteres\"\"\"\n",
        "    # TODO: Complete esta fun√ß√£o\n",
        "    # Dica: retorne algo como \"X palavras, Y caracteres\"\n",
        "    pass\n",
        "\n",
        "# Transforme suas fun√ß√µes em Runnables\n",
        "# TODO: Crie os RunnableLambda\n",
        "\n",
        "# Crie a chain completa\n",
        "# TODO: Monte a chain usando o operador |\n",
        "\n",
        "# Teste com um t√≥pico\n",
        "# resultado = sua_chain.invoke(\"intelig√™ncia artificial\")\n",
        "# print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí° Solu√ß√£o do Exerc√≠cio 1\n\nAqui est√° uma poss√≠vel solu√ß√£o para o exerc√≠cio anterior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚úÖ SOLU√á√ÉO DO EXERC√çCIO 1\n\n",
        "def criar_pergunta(topico):\n",
        "    \"\"\"Cria um prompt para gerar uma pergunta sobre o t√≥pico\"\"\"\n",
        "    return f\"Crie uma pergunta interessante e educativa sobre: {topico}\"\n",
        "\n",
        "def adicionar_emoji_topico(texto):\n",
        "    \"\"\"Adiciona emojis baseados no conte√∫do\"\"\"\n",
        "    texto_lower = texto.lower()\n",
        "    \n",
        "    if any(palavra in texto_lower for palavra in ['tecnologia', 'ia', 'computador', 'software']):\n",
        "        return f\"üíª {texto} ü§ñ\"\n",
        "    elif any(palavra in texto_lower for palavra in ['comida', 'receita', 'cozinha']):\n",
        "        return f\"üç≥ {texto} üçΩÔ∏è\"\n",
        "    elif any(palavra in texto_lower for palavra in ['esporte', 'futebol', 'basquete']):\n",
        "        return f\"‚öΩ {texto} üèÜ\"\n",
        "    else:\n",
        "        return f\"üìö {texto} üéì\"\n",
        "\n",
        "def contar_info(texto):\n",
        "    \"\"\"Conta palavras e caracteres\"\"\"\n",
        "    palavras = len(texto.split())\n",
        "    caracteres = len(texto)\n",
        "    return f\"{texto} | [Info: {palavras} palavras, {caracteres} caracteres]\"\n",
        "\n",
        "# Criando os Runnables\n",
        "runnable_pergunta = RunnableLambda(criar_pergunta)\n",
        "runnable_emoji_topico = RunnableLambda(adicionar_emoji_topico)\n",
        "runnable_info = RunnableLambda(contar_info)\n",
        "\n",
        "# Chain completa\n",
        "chain_exercicio = runnable_pergunta | modelo | parser | runnable_emoji_topico | runnable_info\n",
        "\n",
        "# Testando\n",
        "resultado = chain_exercicio.invoke(\"intelig√™ncia artificial\")\n",
        "print(\"üéØ Resultado do exerc√≠cio:\")\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé≤ Exerc√≠cio Pr√°tico 2: Chain Paralela Avan√ßada\n\nAgora vamos criar algo mais desafiador! Uma chain que processa um texto de m√∫ltiplas formas simultaneamente.\n\n**Objetivo:** Criar uma chain que analise um texto e retorne:\n- Resumo em uma frase\n- Tradu√ß√£o para ingl√™s  \n- An√°lise de sentimento\n- Estat√≠sticas b√°sicas\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-03_img_04.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ EXERC√çCIO 2: Chain Paralela Avan√ßada\n",
        "\n",
        "# Fun√ß√µes auxiliares j√° prontas\n",
        "def criar_prompt_resumo(texto):\n",
        "    return f\"Resuma este texto em uma frase: {texto}\"\n",
        "\n",
        "def criar_prompt_traducao(texto):\n",
        "    return f\"Traduza este texto para o ingl√™s: {texto}\"\n",
        "\n",
        "def criar_prompt_sentimento_simples(texto):\n",
        "    return f\"Qual o sentimento deste texto? Responda apenas: POSITIVO, NEGATIVO ou NEUTRO. Texto: {texto}\"\n",
        "\n",
        "def estatisticas_texto(texto):\n",
        "    palavras = len(texto.split())\n",
        "    frases = texto.count('.') + texto.count('!') + texto.count('?')\n",
        "    chars = len(texto)\n",
        "    return f\"Estat√≠sticas: {palavras} palavras, {frases} frases, {chars} caracteres\"\n",
        "\n",
        "# TODO: Crie os Runnables necess√°rios\n",
        "# TODO: Monte a chain paralela usando dicion√°rio\n",
        "# TODO: Teste com um texto interessante\n",
        "\n",
        "# Dica: Lembre-se que para chains que usam o modelo, voc√™ precisa:\n",
        "# prompt_function | modelo | parser\n",
        "\n",
        "texto_teste = \"\"\"\n",
        "A intelig√™ncia artificial est√° revolucionando a forma como trabalhamos e vivemos. \n",
        "Com o LangChain, conseguimos criar aplica√ß√µes incr√≠veis que antes pareciam imposs√≠veis. \n",
        "√â uma √©poca fant√°stica para ser um desenvolvedor!\n",
        "\"\"\"\n\n",
        "print(\"üìù Texto para an√°lise:\")\n",
        "print(texto_teste)\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# TODO: Execute sua chain aqui\n",
        "# resultado = sua_chain_paralela.invoke(texto_teste)\n",
        "# print(resultado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚úÖ SOLU√á√ÉO DO EXERC√çCIO 2\n\n",
        "# Criando os Runnables\n",
        "runnable_prompt_resumo = RunnableLambda(criar_prompt_resumo)\n",
        "runnable_prompt_traducao = RunnableLambda(criar_prompt_traducao)\n",
        "runnable_prompt_sentimento = RunnableLambda(criar_prompt_sentimento_simples)\n",
        "runnable_estatisticas = RunnableLambda(estatisticas_texto)\n",
        "\n",
        "# Chain paralela completa\n",
        "chain_analise_completa = {\n",
        "    \"resumo\": runnable_prompt_resumo | modelo | parser,\n",
        "    \"traducao\": runnable_prompt_traducao | modelo | parser,\n",
        "    \"sentimento\": runnable_prompt_sentimento | modelo | parser,\n",
        "    \"estatisticas\": runnable_estatisticas,\n",
        "    \"original\": RunnablePassthrough()\n",
        "}\n",
        "\n",
        "# Executando a an√°lise\n",
        "resultado = chain_analise_completa.invoke(texto_teste)\n",
        "\n",
        "print(\"üîç AN√ÅLISE COMPLETA DO TEXTO:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"üìä {resultado['estatisticas']}\")\n",
        "print(f\"üìù Resumo: {resultado['resumo']}\")\n",
        "print(f\"üåç Tradu√ß√£o: {resultado['traducao']}\")\n",
        "print(f\"üé≠ Sentimento: {resultado['sentimento']}\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nüéâ Liiindo! Conseguimos analisar o texto de 4 formas diferentes simultaneamente!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Visualizando a Performance das Chains\n\nVamos criar um gr√°fico para comparar a efici√™ncia das diferentes abordagens que aprendemos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n\n",
        "# Simulando tempos de execu√ß√£o para diferentes tipos de chains\n",
        "tipos_chain = ['Sequencial\\nSimples', 'Sequencial\\nComplexa', 'Paralela\\n4 opera√ß√µes', 'Streaming\\nTempo Real']\n",
        "tempos_medio = [0.8, 2.5, 1.2, 0.9]\n",
        "complexidade = [1, 4, 4, 2]  # N√∫mero de opera√ß√µes\n",
        "\n",
        "# Criando subplot com dois gr√°ficos\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Gr√°fico 1: Tempo de Execu√ß√£o\n",
        "cores1 = ['#FF6B6B', '#FF8E53', '#FF6B9D', '#4ECDC4']\n",
        "barras1 = ax1.bar(tipos_chain, tempos_medio, color=cores1, alpha=0.8, edgecolor='white', linewidth=2)\n",
        "\n",
        "for barra, tempo in zip(barras1, tempos_medio):\n",
        "    ax1.text(barra.get_x() + barra.get_width()/2, barra.get_height() + 0.05, \n",
        "             f'{tempo}s', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "ax1.set_title('‚ö° Tempo de Execu√ß√£o por Tipo de Chain', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Tempo (segundos)')\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Gr√°fico 2: Complexidade vs Efici√™ncia\n",
        "scatter = ax2.scatter(complexidade, tempos_medio, c=cores1, s=200, alpha=0.7, edgecolors='white', linewidth=2)\n",
        "\n",
        "for i, tipo in enumerate(tipos_chain):\n",
        "    ax2.annotate(tipo.replace('\\n', ' '), (complexidade[i], tempos_medio[i]), \n",
        "                xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
        "\n",
        "ax2.set_title('üéØ Complexidade vs Tempo de Execu√ß√£o', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('N√∫mero de Opera√ß√µes')\n",
        "ax2.set_ylabel('Tempo (segundos)')\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Observa√ß√µes importantes:\")\n",
        "print(\"‚Ä¢ Chains paralelas s√£o mais eficientes que sequenciais complexas\")\n",
        "print(\"‚Ä¢ Streaming oferece boa experi√™ncia do usu√°rio\")\n",
        "print(\"‚Ä¢ Complexidade nem sempre significa maior tempo de execu√ß√£o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÆ Conectando com os Pr√≥ximos M√≥dulos\n\nAgora que voc√™ domina Runnables e LCEL, vamos ver como eles se conectam com o resto do curso:\n\n### üìã M√≥dulo 4 - Prompt Templates\n- Os PromptTemplates s√£o Runnables!\n- Voc√™ vai usar LCEL para conectar templates com modelos\n- Exemplo: `template | modelo | parser`\n\n### üéØ M√≥dulo 5 - OutputParsers\n- OutputParsers tamb√©m s√£o Runnables!\n- Voc√™ vai criar chains do tipo: `modelo | custom_parser`\n\n### ‚õìÔ∏è M√≥dulo 6 - Chains\n- Chains mais complexas usando tudo que aprendemos aqui\n- Composi√ß√£o de m√∫ltiplos Runnables\n\n**Dica!** Tudo no LangChain √© um Runnable - esse √© o segredo para criar aplica√ß√µes poderosas!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéì Resumo do M√≥dulo - O que Aprendemos?\n\nBora recapitular tudo que vimos neste m√≥dulo:\n\n### ‚úÖ Conceitos Fundamentais\n- **Runnables**: A interface padr√£o de tudo no LangChain\n- **LCEL**: A linguagem para conectar componentes\n- **Operador Pipe (`|`)**: Para conectar Runnables\n\n### ‚úÖ M√©todos dos Runnables\n- `invoke()`: Execu√ß√£o simples\n- `batch()`: Execu√ß√£o em lote\n- `stream()`: Execu√ß√£o com streaming\n- `ainvoke()`: Execu√ß√£o ass√≠ncrona\n\n### ‚úÖ Tipos de Chains\n- **Sequenciais**: Uma opera√ß√£o ap√≥s a outra\n- **Paralelas**: M√∫ltiplas opera√ß√µes simult√¢neas\n- **Complexas**: Combina√ß√£o de ambas\n\n### ‚úÖ Componentes Especiais\n- `RunnableLambda`: Para fun√ß√µes customizadas\n- `RunnablePassthrough`: Para manter dados inalterados\n- `StrOutputParser`: Para extrair texto simples\n\n### üöÄ Pr√≥ximos Passos\nNo pr√≥ximo m√≥dulo vamos aprender sobre **Prompt Templates** - como criar prompts din√¢micos e reutiliz√°veis que se conectam perfeitamente com as chains que criamos hoje!\n\n**Bora continuar essa jornada incr√≠vel! üéâ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-03_img_05.png)"
      ]
    }
  ]
}