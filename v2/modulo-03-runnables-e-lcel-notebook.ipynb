{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🔗 Runnables e LCEL: O Poder da Orquestração no LangChain! \n\n**Módulo 3 - LangChain v0.3 com Pedro Guth**\n\nEaí pessoal! Tudo certo? Hoje vamos mergulhar no coração do LangChain: os **Runnables** e a **LCEL (LangChain Expression Language)**!\n\nLembra do módulo anterior onde mexemos com ChatModels? Agora vamos ver como conectar essas peças como se fosse um LEGO super inteligente!\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-03_img_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🤔 Tá, mas o que são Runnables?\n\nImagina que você tem uma fábrica de brigadeiros. Você tem:\n- A estação que mistura o chocolate 🍫\n- A estação que enrola as bolinhas 🥄\n- A estação que põe o granulado ✨\n\nCada estação é um **Runnable** - uma unidade que recebe algo, processa e passa adiante!\n\nNo LangChain, **TUDO** é um Runnable:\n- ChatModels (que já vimos!)\n- PromptTemplates (que vamos ver no próximo módulo!)\n- OutputParsers\n- Chains\n- E por aí vai...\n\n**Dica!** Runnable é a interface padrão que permite conectar qualquer componente do LangChain de forma consistente!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Primeiro, vamos instalar e importar o que precisamos\n",
        "!pip install langchain langchain-google-genai python-dotenv\n\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from dotenv import load_dotenv\n\n",
        "# Carrega as variáveis de ambiente\n",
        "load_dotenv()\n\n",
        "print(\"📦 Bibliotecas importadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configurando nossa API key do Google (lembra do módulo 2?)\n",
        "# Substitua por sua chave ou configure no .env\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"sua_chave_aqui\"\n\n",
        "# Criando nosso ChatModel (já conhecemos esse cara!)\n",
        "modelo = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0.7\n",
        ")\n\n",
        "print(\"🤖 Modelo configurado e pronto para usar!\")\n",
        "print(f\"Tipo do modelo: {type(modelo)}\")\n",
        "print(f\"É um Runnable? {hasattr(modelo, 'invoke')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🏃‍♂️ Os Métodos Fundamentais dos Runnables\n\nTodo Runnable tem 4 métodos principais:\n\n| Método | O que faz | Quando usar |\n|--------|-----------|-------------|\n| `invoke()` | Executa uma vez | Quando você quer uma resposta simples |\n| `batch()` | Executa em lote | Quando tem várias perguntas de uma vez |\n| `stream()` | Executa com streaming | Quando quer ver a resposta chegando aos poucos |\n| `ainvoke()` | Executa de forma assíncrona | Para aplicações mais avançadas |\n\nÉ como ter 4 formas diferentes de pedir um Uber! 🚗"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando o método invoke() - o mais básico\n",
        "resposta = modelo.invoke(\"Explique o que é inteligência artificial em uma frase\")\n",
        "print(\"🎯 Método invoke():\")\n",
        "print(resposta.content)\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n\n",
        "# Testando o método batch() - várias perguntas de uma vez\n",
        "perguntas = [\n",
        "    \"O que é Python?\",\n",
        "    \"O que é JavaScript?\",\n",
        "    \"O que é LangChain?\"\n",
        "]\n\n",
        "respostas = modelo.batch(perguntas)\n",
        "print(\"📦 Método batch():\")\n",
        "for i, resposta in enumerate(respostas):\n",
        "    print(f\"{i+1}. {resposta.content[:100]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando o método stream() - vendo a resposta chegar aos poucos\n",
        "print(\"🌊 Método stream():\")\n",
        "pergunta = \"Conte uma história curta sobre um robô que aprende a fazer café\"\n\n",
        "for chunk in modelo.stream(pergunta):\n",
        "    print(chunk.content, end=\"\", flush=True)\n",
        "\n",
        "print(\"\\n\\n✨ Liiindo! A resposta chegou aos poucos!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ⚡ LCEL - LangChain Expression Language\n\nAgora vem a parte mais massa! A **LCEL** é como se fosse a \"linguagem\" para conectar Runnables.\n\nÉ tipo aqueles conectores de mangueira de jardim - você vai encaixando um no outro até formar o sistema perfeito! 🌱\n\nA sintaxe básica é usar o operador `|` (pipe):\n\n```python\nchain = componente1 | componente2 | componente3\n```\n\n**Dica!** O pipe (`|`) é como uma seta que diz \"pega o resultado daqui e manda pra lá\"!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\ngraph LR\n    A[Input] --> B[Runnable 1]\n    B --> C[Runnable 2]\n    C --> D[Runnable 3]\n    D --> E[Output]\n    \n    style A fill:#e1f5fe\n    style E fill:#c8e6c9\n    style B fill:#fff3e0\n    style C fill:#fff3e0\n    style D fill:#fff3e0\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar nossa primeira chain simples!\n",
        "# Lembra: ChatModel retorna um objeto AIMessage, mas queremos só o texto\n",
        "\n",
        "# Criando um parser para extrair só o texto\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# Nossa primeira chain! 🎉\n",
        "chain_simples = modelo | parser\n",
        "\n",
        "print(\"🔗 Chain criada!\")\n",
        "print(f\"Tipo da chain: {type(chain_simples)}\")\n",
        "\n",
        "# Testando nossa chain\n",
        "resultado = chain_simples.invoke(\"Me conte uma piada sobre programadores\")\n",
        "print(\"\\n😄 Resultado da chain:\")\n",
        "print(resultado)\n",
        "print(f\"\\nTipo do resultado: {type(resultado)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar funções customizadas como Runnables!\n",
        "# Isso é útil para adicionar lógica personalizada\n\n",
        "def adicionar_emoji(texto):\n",
        "    \"\"\"Adiciona emojis aleatórios ao texto\"\"\"\n",
        "    emojis = [\"🚀\", \"⭐\", \"🎯\", \"💡\", \"🔥\", \"✨\"]\n",
        "    import random\n",
        "    emoji_escolhido = random.choice(emojis)\n",
        "    return f\"{emoji_escolhido} {texto} {emoji_escolhido}\"\n\n",
        "def deixar_maiusculo(texto):\n",
        "    \"\"\"Transforma o texto em maiúsculo\"\"\"\n",
        "    return texto.upper()\n\n",
        "# Transformando funções em Runnables\n",
        "runnable_emoji = RunnableLambda(adicionar_emoji)\n",
        "runnable_maiusculo = RunnableLambda(deixar_maiusculo)\n\n",
        "print(\"🛠️ Runnables customizados criados!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agora vamos criar uma chain mais complexa!\n",
        "# modelo -> parser -> emoji -> maiúsculo\n\n",
        "chain_complexa = modelo | parser | runnable_emoji | runnable_maiusculo\n\n",
        "resultado = chain_complexa.invoke(\"Diga algo motivacional sobre aprender IA\")\n",
        "\n",
        "print(\"🎪 Chain complexa em ação:\")\n",
        "print(resultado)\n",
        "\n",
        "print(\"\\n🔍 Vamos ver o que aconteceu em cada etapa:\")\n",
        "# Executando passo a passo para entender\n",
        "etapa1 = modelo.invoke(\"Diga algo motivacional sobre aprender IA\")\n",
        "print(f\"1. Modelo: {etapa1.content[:50]}...\")\n",
        "\n",
        "etapa2 = parser.invoke(etapa1)\n",
        "print(f\"2. Parser: {etapa2[:50]}...\")\n",
        "\n",
        "etapa3 = runnable_emoji.invoke(etapa2)\n",
        "print(f\"3. Emoji: {etapa3[:50]}...\")\n",
        "\n",
        "etapa4 = runnable_maiusculo.invoke(etapa3)\n",
        "print(f\"4. Maiúsculo: {etapa4[:50]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔀 RunnablePassthrough - O Cara que Não Muda Nada\n\nÀs vezes você quer que um valor passe pela chain sem ser modificado. É como ter um \"atalho\" na nossa fábrica de brigadeiros.\n\nO `RunnablePassthrough` é perfeito para isso! Ele recebe algo e passa adiante sem modificar.\n\n**Dica!** Muito útil quando você quer manter o input original em chains mais complexas!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando o RunnablePassthrough\n",
        "passthrough = RunnablePassthrough()\n\n",
        "# Criando uma chain que preserva o input original\n",
        "texto_original = \"Esta mensagem vai passar inalterada\"\n",
        "resultado = passthrough.invoke(texto_original)\n",
        "\n",
        "print(\"🔄 RunnablePassthrough em ação:\")\n",
        "print(f\"Input: {texto_original}\")\n",
        "print(f\"Output: {resultado}\")\n",
        "print(f\"São iguais? {texto_original == resultado}\")\n\n",
        "# Exemplo prático: chain que retorna tanto o original quanto processado\n",
        "def processar_texto(texto):\n",
        "    return f\"Processado: {texto.upper()}\"\n",
        "\n",
        "runnable_processar = RunnableLambda(processar_texto)\n\n",
        "# Chain que mostra antes e depois\n",
        "texto_teste = \"olá mundo\"\n",
        "original = passthrough.invoke(texto_teste)\n",
        "processado = runnable_processar.invoke(texto_teste)\n\n",
        "print(f\"\\n📊 Comparação:\")\n",
        "print(f\"Original: {original}\")\n",
        "print(f\"Processado: {processado}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎭 Chains Paralelas - Fazendo Várias Coisas ao Mesmo Tempo\n\nE se você quiser fazer várias operações em paralelo? É como ter várias linhas de produção na fábrica!\n\nNo LangChain, usamos dicionários para criar execução paralela:\n\n```python\nchain_paralela = {\n    \"operacao1\": runnable1,\n    \"operacao2\": runnable2\n}\n```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando funções para processar texto de formas diferentes\n",
        "def contar_palavras(texto):\n",
        "    \"\"\"Conta as palavras no texto\"\"\"\n",
        "    palavras = len(texto.split())\n",
        "    return f\"Tem {palavras} palavras\"\n",
        "\n",
        "def contar_caracteres(texto):\n",
        "    \"\"\"Conta os caracteres no texto\"\"\"\n",
        "    chars = len(texto)\n",
        "    return f\"Tem {chars} caracteres\"\n",
        "\n",
        "def primeira_palavra(texto):\n",
        "    \"\"\"Pega a primeira palavra\"\"\"\n",
        "    primeira = texto.split()[0] if texto.split() else \"Nenhuma\"\n",
        "    return f\"Primeira palavra: {primeira}\"\n\n",
        "# Transformando em Runnables\n",
        "runnable_palavras = RunnableLambda(contar_palavras)\n",
        "runnable_chars = RunnableLambda(contar_caracteres)\n",
        "runnable_primeira = RunnableLambda(primeira_palavra)\n\n",
        "print(\"⚡ Runnables para análise de texto criados!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando uma chain paralela!\n",
        "# Primeiro, vamos fazer o modelo gerar um texto\n",
        "# Depois, vamos analisar esse texto de 3 formas diferentes\n\n",
        "chain_paralela = modelo | parser | {\n",
        "    \"palavras\": runnable_palavras,\n",
        "    \"caracteres\": runnable_chars,\n",
        "    \"primeira\": runnable_primeira,\n",
        "    \"original\": RunnablePassthrough()\n",
        "}\n\n",
        "resultado = chain_paralela.invoke(\"Escreva uma frase sobre o futuro da tecnologia\")\n",
        "\n",
        "print(\"🔀 Chain paralela em ação:\")\n",
        "print(f\"Original: {resultado['original']}\")\n",
        "print(f\"Análise - {resultado['palavras']}\")\n",
        "print(f\"Análise - {resultado['caracteres']}\")\n",
        "print(f\"Análise - {resultado['primeira']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```mermaid\ngraph TD\n    A[Input] --> B[Modelo]\n    B --> C[Parser]\n    C --> D[Execução Paralela]\n    D --> E[Contar Palavras]\n    D --> F[Contar Caracteres]\n    D --> G[Primeira Palavra]\n    D --> H[Original]\n    E --> I[Output Dict]\n    F --> I\n    G --> I\n    H --> I\n    \n    style A fill:#e1f5fe\n    style I fill:#c8e6c9\n    style D fill:#fff3e0\n```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Visualizando o Fluxo das Chains\n\nBora criar um gráfico para entender melhor como os dados fluem pelas chains!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Simulando tempos de execução de diferentes chains\n",
        "chains = ['Simples\\n(Modelo + Parser)', 'Complexa\\n(4 etapas)', 'Paralela\\n(4 operações)']\n",
        "tempos = [1.2, 2.1, 1.8]  # Tempos simulados em segundos\n",
        "cores = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "barras = ax.bar(chains, tempos, color=cores, alpha=0.8, edgecolor='white', linewidth=2)\n\n",
        "# Adicionando valores nas barras\n",
        "for i, (barra, tempo) in enumerate(zip(barras, tempos)):\n",
        "    ax.text(barra.get_x() + barra.get_width()/2, barra.get_height() + 0.05, \n",
        "            f'{tempo}s', ha='center', va='bottom', fontweight='bold', fontsize=12)\n\n",
        "ax.set_title('⚡ Comparação de Desempenho das Chains', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.set_ylabel('Tempo de Execução (segundos)', fontsize=12)\n",
        "ax.set_ylim(0, max(tempos) * 1.3)\n",
        "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "\n",
        "# Adicionando anotações\n",
        "ax.annotate('Mais rápida!', xy=(0, tempos[0]), xytext=(0.5, tempos[0] + 0.5),\n",
        "            arrowprops=dict(arrowstyle='->', color='green', lw=2),\n",
        "            fontsize=10, ha='center', color='green', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"📈 Gráfico criado! Como você pode ver, chains paralelas são eficientes!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Exemplo Prático: Sistema de Análise de Sentimentos\n\nVamos criar um sistema real que usa tudo que aprendemos! Vamos analisar o sentimento de textos de forma completa.\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-03_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar um sistema completo de análise de sentimentos!\n",
        "\n",
        "def criar_prompt_sentimento(texto):\n",
        "    \"\"\"Cria um prompt específico para análise de sentimentos\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Analise o sentimento do seguinte texto e retorne apenas uma das opções:\n",
        "    - POSITIVO\n",
        "    - NEGATIVO  \n",
        "    - NEUTRO\n",
        "    \n",
        "    Texto: {texto}\n",
        "    \n",
        "    Sentimento:\n",
        "    \"\"\"\n",
        "    return prompt\n",
        "\n",
        "def extrair_sentimento(resposta):\n",
        "    \"\"\"Extrai o sentimento da resposta do modelo\"\"\"\n",
        "    resposta = resposta.upper().strip()\n",
        "    if \"POSITIVO\" in resposta:\n",
        "        return \"POSITIVO 😊\"\n",
        "    elif \"NEGATIVO\" in resposta:\n",
        "        return \"NEGATIVO 😢\"\n",
        "    elif \"NEUTRO\" in resposta:\n",
        "        return \"NEUTRO 😐\"\n",
        "    else:\n",
        "        return \"INDEFINIDO 🤔\"\n",
        "\n",
        "def contar_sentimentos_palavras(texto):\n",
        "    \"\"\"Conta palavras que indicam sentimentos\"\"\"\n",
        "    palavras_positivas = ['bom', 'ótimo', 'excelente', 'feliz', 'alegre', 'amor', 'sucesso']\n",
        "    palavras_negativas = ['ruim', 'péssimo', 'triste', 'raiva', 'ódio', 'fracasso', 'problema']\n",
        "    \n",
        "    texto_lower = texto.lower()\n",
        "    pos = sum(1 for palavra in palavras_positivas if palavra in texto_lower)\n",
        "    neg = sum(1 for palavra in palavras_negativas if palavra in texto_lower)\n",
        "    \n",
        "    return f\"Palavras positivas: {pos}, Negativas: {neg}\"\n\n",
        "# Transformando em Runnables\n",
        "runnable_prompt = RunnableLambda(criar_prompt_sentimento)\n",
        "runnable_extrair = RunnableLambda(extrair_sentimento)\n",
        "runnable_contar = RunnableLambda(contar_sentimentos_palavras)\n\n",
        "print(\"🎭 Sistema de análise de sentimentos criado!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Montando nossa chain completa de análise de sentimentos\n",
        "chain_sentimentos = {\n",
        "    \"analise_ia\": runnable_prompt | modelo | parser | runnable_extrair,\n",
        "    \"analise_palavras\": runnable_contar,\n",
        "    \"texto_original\": RunnablePassthrough(),\n",
        "    \"tamanho\": RunnableLambda(lambda x: f\"Caracteres: {len(x)}\")\n",
        "}\n\n",
        "# Testando com diferentes textos\n",
        "textos_teste = [\n",
        "    \"Estou muito feliz com meu progresso em IA! Está sendo uma jornada incrível!\",\n",
        "    \"Esse código não funciona e estou muito frustrado com esses erros.\",\n",
        "    \"Hoje é segunda-feira e tenho uma reunião às 14h.\"\n",
        "]\n\n",
        "print(\"🔍 Analisando diferentes textos:\\n\")\n",
        "\n",
        "for i, texto in enumerate(textos_teste, 1):\n",
        "    print(f\"📄 Texto {i}: {texto[:50]}...\")\n",
        "    resultado = chain_sentimentos.invoke(texto)\n",
        "    \n",
        "    print(f\"   🤖 IA diz: {resultado['analise_ia']}\")\n",
        "    print(f\"   📊 Contagem: {resultado['analise_palavras']}\")\n",
        "    print(f\"   📏 {resultado['tamanho']}\")\n",
        "    print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 Streaming com Chains - Vendo em Tempo Real\n\nUma das coisas mais legais das chains é que você pode fazer streaming! É como ver a mágica acontecer em tempo real.\n\n**Dica!** Streaming é especialmente útil para aplicações web onde você quer mostrar a resposta chegando aos poucos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar uma chain simples para streaming\n",
        "chain_streaming = modelo | parser\n\n",
        "print(\"🌊 Demonstração de streaming:\")\n",
        "print(\"Pergunta: 'Explique como funciona o machine learning'\")\n",
        "print(\"Resposta chegando aos poucos...\\n\")\n",
        "print(\"-\" * 50)\n\n",
        "# Fazendo streaming da resposta\n",
        "for chunk in chain_streaming.stream(\"Explique como funciona o machine learning em termos simples\"):\n",
        "    print(chunk, end=\"\", flush=True)\n",
        "\n",
        "print(\"\\n\" + \"-\" * 50)\n",
        "print(\"\\n✨ Streaming finalizado! Legal né?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎮 Exercício Prático 1: Sua Primeira Chain!\n\nAgora é sua vez! Vamos criar uma chain que:\n1. Recebe um tópico\n2. Pede para o modelo criar uma pergunta sobre esse tópico\n3. Conta quantas palavras tem a pergunta\n4. Adiciona emojis relacionados ao tópico\n\n**Desafio:** Complete o código abaixo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 EXERCÍCIO 1: Complete a chain abaixo\n",
        "\n",
        "def criar_pergunta(topico):\n",
        "    \"\"\"Cria um prompt para gerar uma pergunta sobre o tópico\"\"\"\n",
        "    # TODO: Complete esta função\n",
        "    # Dica: retorne um prompt pedindo uma pergunta interessante sobre o tópico\n",
        "    pass\n",
        "\n",
        "def adicionar_emoji_topico(texto):\n",
        "    \"\"\"Adiciona emojis baseados no conteúdo\"\"\"\n",
        "    # TODO: Complete esta função\n",
        "    # Dica: use if/elif para diferentes tópicos (tecnologia, comida, esporte, etc.)\n",
        "    pass\n",
        "\n",
        "def contar_info(texto):\n",
        "    \"\"\"Conta palavras e caracteres\"\"\"\n",
        "    # TODO: Complete esta função\n",
        "    # Dica: retorne algo como \"X palavras, Y caracteres\"\n",
        "    pass\n",
        "\n",
        "# Transforme suas funções em Runnables\n",
        "# TODO: Crie os RunnableLambda\n",
        "\n",
        "# Crie a chain completa\n",
        "# TODO: Monte a chain usando o operador |\n",
        "\n",
        "# Teste com um tópico\n",
        "# resultado = sua_chain.invoke(\"inteligência artificial\")\n",
        "# print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 💡 Solução do Exercício 1\n\nAqui está uma possível solução para o exercício anterior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✅ SOLUÇÃO DO EXERCÍCIO 1\n\n",
        "def criar_pergunta(topico):\n",
        "    \"\"\"Cria um prompt para gerar uma pergunta sobre o tópico\"\"\"\n",
        "    return f\"Crie uma pergunta interessante e educativa sobre: {topico}\"\n",
        "\n",
        "def adicionar_emoji_topico(texto):\n",
        "    \"\"\"Adiciona emojis baseados no conteúdo\"\"\"\n",
        "    texto_lower = texto.lower()\n",
        "    \n",
        "    if any(palavra in texto_lower for palavra in ['tecnologia', 'ia', 'computador', 'software']):\n",
        "        return f\"💻 {texto} 🤖\"\n",
        "    elif any(palavra in texto_lower for palavra in ['comida', 'receita', 'cozinha']):\n",
        "        return f\"🍳 {texto} 🍽️\"\n",
        "    elif any(palavra in texto_lower for palavra in ['esporte', 'futebol', 'basquete']):\n",
        "        return f\"⚽ {texto} 🏆\"\n",
        "    else:\n",
        "        return f\"📚 {texto} 🎓\"\n",
        "\n",
        "def contar_info(texto):\n",
        "    \"\"\"Conta palavras e caracteres\"\"\"\n",
        "    palavras = len(texto.split())\n",
        "    caracteres = len(texto)\n",
        "    return f\"{texto} | [Info: {palavras} palavras, {caracteres} caracteres]\"\n",
        "\n",
        "# Criando os Runnables\n",
        "runnable_pergunta = RunnableLambda(criar_pergunta)\n",
        "runnable_emoji_topico = RunnableLambda(adicionar_emoji_topico)\n",
        "runnable_info = RunnableLambda(contar_info)\n",
        "\n",
        "# Chain completa\n",
        "chain_exercicio = runnable_pergunta | modelo | parser | runnable_emoji_topico | runnable_info\n",
        "\n",
        "# Testando\n",
        "resultado = chain_exercicio.invoke(\"inteligência artificial\")\n",
        "print(\"🎯 Resultado do exercício:\")\n",
        "print(resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎲 Exercício Prático 2: Chain Paralela Avançada\n\nAgora vamos criar algo mais desafiador! Uma chain que processa um texto de múltiplas formas simultaneamente.\n\n**Objetivo:** Criar uma chain que analise um texto e retorne:\n- Resumo em uma frase\n- Tradução para inglês  \n- Análise de sentimento\n- Estatísticas básicas\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-03_img_04.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 EXERCÍCIO 2: Chain Paralela Avançada\n",
        "\n",
        "# Funções auxiliares já prontas\n",
        "def criar_prompt_resumo(texto):\n",
        "    return f\"Resuma este texto em uma frase: {texto}\"\n",
        "\n",
        "def criar_prompt_traducao(texto):\n",
        "    return f\"Traduza este texto para o inglês: {texto}\"\n",
        "\n",
        "def criar_prompt_sentimento_simples(texto):\n",
        "    return f\"Qual o sentimento deste texto? Responda apenas: POSITIVO, NEGATIVO ou NEUTRO. Texto: {texto}\"\n",
        "\n",
        "def estatisticas_texto(texto):\n",
        "    palavras = len(texto.split())\n",
        "    frases = texto.count('.') + texto.count('!') + texto.count('?')\n",
        "    chars = len(texto)\n",
        "    return f\"Estatísticas: {palavras} palavras, {frases} frases, {chars} caracteres\"\n",
        "\n",
        "# TODO: Crie os Runnables necessários\n",
        "# TODO: Monte a chain paralela usando dicionário\n",
        "# TODO: Teste com um texto interessante\n",
        "\n",
        "# Dica: Lembre-se que para chains que usam o modelo, você precisa:\n",
        "# prompt_function | modelo | parser\n",
        "\n",
        "texto_teste = \"\"\"\n",
        "A inteligência artificial está revolucionando a forma como trabalhamos e vivemos. \n",
        "Com o LangChain, conseguimos criar aplicações incríveis que antes pareciam impossíveis. \n",
        "É uma época fantástica para ser um desenvolvedor!\n",
        "\"\"\"\n\n",
        "print(\"📝 Texto para análise:\")\n",
        "print(texto_teste)\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# TODO: Execute sua chain aqui\n",
        "# resultado = sua_chain_paralela.invoke(texto_teste)\n",
        "# print(resultado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ✅ SOLUÇÃO DO EXERCÍCIO 2\n\n",
        "# Criando os Runnables\n",
        "runnable_prompt_resumo = RunnableLambda(criar_prompt_resumo)\n",
        "runnable_prompt_traducao = RunnableLambda(criar_prompt_traducao)\n",
        "runnable_prompt_sentimento = RunnableLambda(criar_prompt_sentimento_simples)\n",
        "runnable_estatisticas = RunnableLambda(estatisticas_texto)\n",
        "\n",
        "# Chain paralela completa\n",
        "chain_analise_completa = {\n",
        "    \"resumo\": runnable_prompt_resumo | modelo | parser,\n",
        "    \"traducao\": runnable_prompt_traducao | modelo | parser,\n",
        "    \"sentimento\": runnable_prompt_sentimento | modelo | parser,\n",
        "    \"estatisticas\": runnable_estatisticas,\n",
        "    \"original\": RunnablePassthrough()\n",
        "}\n",
        "\n",
        "# Executando a análise\n",
        "resultado = chain_analise_completa.invoke(texto_teste)\n",
        "\n",
        "print(\"🔍 ANÁLISE COMPLETA DO TEXTO:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"📊 {resultado['estatisticas']}\")\n",
        "print(f\"📝 Resumo: {resultado['resumo']}\")\n",
        "print(f\"🌍 Tradução: {resultado['traducao']}\")\n",
        "print(f\"🎭 Sentimento: {resultado['sentimento']}\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\n🎉 Liiindo! Conseguimos analisar o texto de 4 formas diferentes simultaneamente!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📈 Visualizando a Performance das Chains\n\nVamos criar um gráfico para comparar a eficiência das diferentes abordagens que aprendemos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import numpy as np\n\n",
        "# Simulando tempos de execução para diferentes tipos de chains\n",
        "tipos_chain = ['Sequencial\\nSimples', 'Sequencial\\nComplexa', 'Paralela\\n4 operações', 'Streaming\\nTempo Real']\n",
        "tempos_medio = [0.8, 2.5, 1.2, 0.9]\n",
        "complexidade = [1, 4, 4, 2]  # Número de operações\n",
        "\n",
        "# Criando subplot com dois gráficos\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Gráfico 1: Tempo de Execução\n",
        "cores1 = ['#FF6B6B', '#FF8E53', '#FF6B9D', '#4ECDC4']\n",
        "barras1 = ax1.bar(tipos_chain, tempos_medio, color=cores1, alpha=0.8, edgecolor='white', linewidth=2)\n",
        "\n",
        "for barra, tempo in zip(barras1, tempos_medio):\n",
        "    ax1.text(barra.get_x() + barra.get_width()/2, barra.get_height() + 0.05, \n",
        "             f'{tempo}s', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "ax1.set_title('⚡ Tempo de Execução por Tipo de Chain', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Tempo (segundos)')\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Gráfico 2: Complexidade vs Eficiência\n",
        "scatter = ax2.scatter(complexidade, tempos_medio, c=cores1, s=200, alpha=0.7, edgecolors='white', linewidth=2)\n",
        "\n",
        "for i, tipo in enumerate(tipos_chain):\n",
        "    ax2.annotate(tipo.replace('\\n', ' '), (complexidade[i], tempos_medio[i]), \n",
        "                xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
        "\n",
        "ax2.set_title('🎯 Complexidade vs Tempo de Execução', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Número de Operações')\n",
        "ax2.set_ylabel('Tempo (segundos)')\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"📊 Observações importantes:\")\n",
        "print(\"• Chains paralelas são mais eficientes que sequenciais complexas\")\n",
        "print(\"• Streaming oferece boa experiência do usuário\")\n",
        "print(\"• Complexidade nem sempre significa maior tempo de execução\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔮 Conectando com os Próximos Módulos\n\nAgora que você domina Runnables e LCEL, vamos ver como eles se conectam com o resto do curso:\n\n### 📋 Módulo 4 - Prompt Templates\n- Os PromptTemplates são Runnables!\n- Você vai usar LCEL para conectar templates com modelos\n- Exemplo: `template | modelo | parser`\n\n### 🎯 Módulo 5 - OutputParsers\n- OutputParsers também são Runnables!\n- Você vai criar chains do tipo: `modelo | custom_parser`\n\n### ⛓️ Módulo 6 - Chains\n- Chains mais complexas usando tudo que aprendemos aqui\n- Composição de múltiplos Runnables\n\n**Dica!** Tudo no LangChain é um Runnable - esse é o segredo para criar aplicações poderosas!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎓 Resumo do Módulo - O que Aprendemos?\n\nBora recapitular tudo que vimos neste módulo:\n\n### ✅ Conceitos Fundamentais\n- **Runnables**: A interface padrão de tudo no LangChain\n- **LCEL**: A linguagem para conectar componentes\n- **Operador Pipe (`|`)**: Para conectar Runnables\n\n### ✅ Métodos dos Runnables\n- `invoke()`: Execução simples\n- `batch()`: Execução em lote\n- `stream()`: Execução com streaming\n- `ainvoke()`: Execução assíncrona\n\n### ✅ Tipos de Chains\n- **Sequenciais**: Uma operação após a outra\n- **Paralelas**: Múltiplas operações simultâneas\n- **Complexas**: Combinação de ambas\n\n### ✅ Componentes Especiais\n- `RunnableLambda`: Para funções customizadas\n- `RunnablePassthrough`: Para manter dados inalterados\n- `StrOutputParser`: Para extrair texto simples\n\n### 🚀 Próximos Passos\nNo próximo módulo vamos aprender sobre **Prompt Templates** - como criar prompts dinâmicos e reutilizáveis que se conectam perfeitamente com as chains que criamos hoje!\n\n**Bora continuar essa jornada incrível! 🎉**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-03_img_05.png)"
      ]
    }
  ]
}