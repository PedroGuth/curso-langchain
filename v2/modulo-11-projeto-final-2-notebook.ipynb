{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Projeto Final 2: Sistema RAG Avan√ßado com Agents - O \"Mega-C√©rebro\" da IA\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-11_img_01.png)\n\nFala galera! üëã √â o Pedro aqui e t√° na hora do nosso **segundo projeto final**! \n\nT√°, mas o que vamos fazer hoje? Bora criar um sistema **COMPLETO** que junta **TUDO** que aprendemos at√© agora:\n- RAG (nosso queridinho dos documentos)\n- Agents (os espertinhos que fazem decis√µes)\n- Memory (para lembrar das conversas)\n- Tools personalizadas\n- E muito mais!\n\n√â como se fosse um \"mega-c√©rebro\" da IA que pode:\n1. üìö Pesquisar em documentos\n2. üßÆ Fazer c√°lculos\n3. üåê Buscar na internet\n4. üí≠ Lembrar de conversas anteriores\n5. üéØ Tomar decis√µes inteligentes\n\n**Dica do Pedro**: Este projeto vai servir de base para o pr√≥ximo m√≥dulo onde vamos fazer o deploy no Streamlit!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Objetivos do Projeto\n\nNosso sistema vai ser como um **assistente pessoal turbinado** que pode:\n\n### üìã Funcionalidades Principais:\n- **RAG Inteligente**: Buscar informa√ß√µes em m√∫ltiplos documentos\n- **Agent com Tools**: Escolher a ferramenta certa para cada tarefa\n- **Mem√≥ria Persistente**: Lembrar do contexto da conversa\n- **An√°lise de Dados**: Processar e analisar informa√ß√µes\n- **Busca Web**: Quando n√£o souber algo, vai atr√°s!\n\n### üèóÔ∏è Arquitetura do Sistema:\n\n```mermaid\ngraph TD\n    A[Usu√°rio] --> B[Agent Controller]\n    B --> C[RAG Tool]\n    B --> D[Calculator Tool]\n    B --> E[Web Search Tool]\n    B --> F[Data Analysis Tool]\n    C --> G[Vector Store]\n    G --> H[Documentos]\n    B --> I[Memory System]\n    I --> J[Resposta Final]\n    J --> A\n```\n\n**Analogia do Pedro**: √â como ter um assistente que tem acesso a uma biblioteca gigante (RAG), uma calculadora (tools), Google (web search) e uma mem√≥ria de elefante (memory system)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instala√ß√£o dos pacotes necess√°rios - Nosso kit de ferramentas completo!\n",
        "!pip install -q langchain langchain-community langchain-google-genai\n",
        "!pip install -q chromadb sentence-transformers\n",
        "!pip install -q wikipedia-api requests beautifulsoup4\n",
        "!pip install -q pandas matplotlib seaborn\n",
        "!pip install -q python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports fundamentais - Nosso arsenal completo!\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import List, Dict, Any\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# LangChain Core\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain.tools import Tool\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# RAG Components\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Web e Utilit√°rios\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "print(\"‚úÖ Todos os imports carregados! Bora para a a√ß√£o!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configura√ß√£o da API - A chave do reino!\n",
        "from google.colab import userdata\n",
        "\n",
        "# Pegando nossa API key\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "# Inicializando nossos modelos principais\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0.1,\n",
        "    max_tokens=2048\n",
        ")\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\"\n",
        ")\n",
        "\n",
        "print(\"üîë Modelos configurados! O Gemini est√° pronto para a batalha!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Construindo o Sistema RAG Avan√ßado\n\nAgora vamos construir nosso sistema RAG, mas n√£o um RAG qualquer... Um **RAG TURBINADO**! üöÄ\n\n### üìö O que √© um RAG Avan√ßado?\n\nLembra do RAG b√°sico que fizemos no m√≥dulo 8? Pois √©, agora vamos evoluir ele! Um RAG avan√ßado tem:\n\n- **M√∫ltiplas fontes de dados**: N√£o s√≥ um documento, mas v√°rios!\n- **Busca inteligente**: Usa diferentes estrat√©gias de busca\n- **Filtragem de resultados**: S√≥ pega o que √© realmente relevante\n- **Fallback para web**: Se n√£o achar nos docs, busca na internet!\n\n**Dica do Pedro**: √â como ter uma biblioteca que, se n√£o tem o livro que voc√™ quer, automaticamente pede emprestado de outras bibliotecas!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-11_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar alguns documentos de exemplo para nosso RAG\n",
        "# Na vida real, voc√™ carregaria documentos reais!\n",
        "\n",
        "sample_documents = [\n",
        "    {\n",
        "        \"content\": \"\"\"\n",
        "        Intelig√™ncia Artificial e Machine Learning\n",
        "        \n",
        "        A Intelig√™ncia Artificial (IA) √© uma √°rea da ci√™ncia da computa√ß√£o que se concentra \n",
        "        no desenvolvimento de sistemas capazes de realizar tarefas que normalmente requerem \n",
        "        intelig√™ncia humana. Machine Learning √© uma sub√°rea da IA que permite que os \n",
        "        computadores aprendam e melhorem automaticamente atrav√©s da experi√™ncia.\n",
        "        \n",
        "        Os principais tipos de ML incluem:\n",
        "        - Aprendizado Supervisionado: Usa dados rotulados\n",
        "        - Aprendizado N√£o Supervisionado: Encontra padr√µes em dados n√£o rotulados  \n",
        "        - Aprendizado por Refor√ßo: Aprende atrav√©s de recompensas e puni√ß√µes\n",
        "        \"\"\",\n",
        "        \"metadata\": {\"source\": \"ml_guide.txt\", \"category\": \"technology\"}\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"\"\"\n",
        "        LangChain Framework\n",
        "        \n",
        "        LangChain √© um framework poderoso para desenvolvimento de aplica√ß√µes com \n",
        "        Large Language Models (LLMs). Ele fornece uma s√©rie de componentes modulares \n",
        "        que podem ser combinados para criar aplica√ß√µes complexas.\n",
        "        \n",
        "        Componentes principais:\n",
        "        - Models: Interface para diferentes LLMs\n",
        "        - Prompts: Templates para formata√ß√£o de entradas\n",
        "        - Chains: Sequ√™ncias de opera√ß√µes\n",
        "        - Agents: Sistemas que podem usar ferramentas\n",
        "        - Memory: Sistemas de mem√≥ria para conversas\n",
        "        - Retrievers: Para busca em documentos (RAG)\n",
        "        \"\"\",\n",
        "        \"metadata\": {\"source\": \"langchain_intro.txt\", \"category\": \"technology\"}\n",
        "    },\n",
        "    {\n",
        "        \"content\": \"\"\"\n",
        "        An√°lise de Dados com Python\n",
        "        \n",
        "        Python √© uma das linguagens mais populares para an√°lise de dados, \n",
        "        oferecendo bibliotecas poderosas como Pandas, NumPy e Matplotlib.\n",
        "        \n",
        "        Principais bibliotecas:\n",
        "        - Pandas: Manipula√ß√£o e an√°lise de dados estruturados\n",
        "        - NumPy: Computa√ß√£o num√©rica eficiente\n",
        "        - Matplotlib/Seaborn: Visualiza√ß√£o de dados\n",
        "        - Scikit-learn: Machine Learning\n",
        "        - Jupyter: Ambiente interativo para desenvolvimento\n",
        "        \n",
        "        Processo t√≠pico de an√°lise:\n",
        "        1. Coleta e limpeza dos dados\n",
        "        2. Explora√ß√£o e visualiza√ß√£o\n",
        "        3. Modelagem e an√°lise\n",
        "        4. Interpreta√ß√£o dos resultados\n",
        "        \"\"\",\n",
        "        \"metadata\": {\"source\": \"python_analysis.txt\", \"category\": \"data_science\"}\n",
        "    }\n",
        "]\n",
        "\n",
        "# Convertendo para objetos Document do LangChain\n",
        "documents = []\n",
        "for doc in sample_documents:\n",
        "    documents.append(Document(\n",
        "        page_content=doc[\"content\"],\n",
        "        metadata=doc[\"metadata\"]\n",
        "    ))\n",
        "\n",
        "print(f\"üìö Criados {len(documents)} documentos de exemplo!\")\n",
        "print(\"Categorias:\", [doc.metadata['category'] for doc in documents])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando nosso RAG System - O c√©rebro da opera√ß√£o!\n",
        "class AdvancedRAGSystem:\n",
        "    def __init__(self, documents, embeddings, llm):\n",
        "        self.llm = llm\n",
        "        self.embeddings = embeddings\n",
        "        \n",
        "        # Splitter para quebrar documentos grandes\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200,\n",
        "            length_function=len\n",
        "        )\n",
        "        \n",
        "        # Processando documentos\n",
        "        self.docs = self.text_splitter.split_documents(documents)\n",
        "        \n",
        "        # Criando o vector store\n",
        "        self.vector_store = Chroma.from_documents(\n",
        "            documents=self.docs,\n",
        "            embedding=self.embeddings,\n",
        "            collection_name=\"advanced_rag\"\n",
        "        )\n",
        "        \n",
        "        # Retriever com configura√ß√µes avan√ßadas\n",
        "        self.retriever = self.vector_store.as_retriever(\n",
        "            search_type=\"mmr\",  # Maximum Marginal Relevance\n",
        "            search_kwargs={\"k\": 3, \"fetch_k\": 6}\n",
        "        )\n",
        "        \n",
        "        print(\"üèóÔ∏è RAG System constru√≠do com sucesso!\")\n",
        "        print(f\"üìÑ {len(self.docs)} chunks processados\")\n",
        "    \n",
        "    def search_documents(self, query: str) -> str:\n",
        "        \"\"\"Busca documentos relevantes para a query\"\"\"\n",
        "        try:\n",
        "            # Buscando documentos relevantes\n",
        "            relevant_docs = self.retriever.get_relevant_documents(query)\n",
        "            \n",
        "            if not relevant_docs:\n",
        "                return \"Nenhum documento relevante encontrado.\"\n",
        "            \n",
        "            # Formatando os resultados\n",
        "            context = \"\\n\\n--- DOCUMENTOS ENCONTRADOS ---\\n\\n\"\n",
        "            for i, doc in enumerate(relevant_docs, 1):\n",
        "                context += f\"Documento {i} (Fonte: {doc.metadata.get('source', 'desconhecida')}):\\n\"\n",
        "                context += doc.page_content + \"\\n\\n\"\n",
        "            \n",
        "            # Gerando resposta com contexto\n",
        "            prompt = f\"\"\"\n",
        "            Com base nos documentos fornecidos, responda √† seguinte pergunta: {query}\n",
        "            \n",
        "            Contexto dos documentos:\n",
        "            {context}\n",
        "            \n",
        "            Resposta (seja preciso e cite as fontes quando relevante):\n",
        "            \"\"\"\n",
        "            \n",
        "            response = self.llm.invoke(prompt)\n",
        "            return response.content\n",
        "            \n",
        "        except Exception as e:\n",
        "            return f\"Erro na busca: {str(e)}\"\n",
        "\n",
        "# Inicializando nosso RAG System\n",
        "rag_system = AdvancedRAGSystem(documents, embeddings, llm)\n",
        "\n",
        "# Testando o sistema\n",
        "test_query = \"O que √© LangChain e quais s√£o seus principais componentes?\"\n",
        "result = rag_system.search_documents(test_query)\n",
        "\n",
        "print(\"\\nüß™ TESTE DO RAG SYSTEM:\")\n",
        "print(f\"Pergunta: {test_query}\")\n",
        "print(f\"\\nResposta:\\n{result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Criando Tools Personalizadas\n\nAgora vamos criar as **ferramentas** que nosso Agent vai usar! Lembra do m√≥dulo 9? Vamos turbinar aquelas ideias!\n\n### üõ†Ô∏è Por que Tools Personalizadas?\n\nAs tools s√£o como **superpoderes** para nosso Agent:\n- Cada tool resolve um tipo espec√≠fico de problema\n- O Agent escolhe qual tool usar baseado na pergunta\n- Podemos ter quantas tools quisermos!\n\n**Analogia do Pedro**: √â como um canivete su√≠√ßo! Cada ferramenta tem sua fun√ß√£o espec√≠fica, e o Agent √© esperto o suficiente para escolher a certa!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-11_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tool 1: Calculator - Para c√°lculos matem√°ticos\n",
        "def calculator_tool(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Realiza c√°lculos matem√°ticos seguros.\n",
        "    Use para opera√ß√µes como: 2+2, 10*5, sqrt(16), etc.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Limpando a express√£o e permitindo fun√ß√µes matem√°ticas seguras\n",
        "        import math\n",
        "        \n",
        "        # Dicion√°rio de fun√ß√µes permitidas\n",
        "        allowed_functions = {\n",
        "            'sqrt': math.sqrt,\n",
        "            'sin': math.sin,\n",
        "            'cos': math.cos,\n",
        "            'tan': math.tan,\n",
        "            'log': math.log,\n",
        "            'exp': math.exp,\n",
        "            'pi': math.pi,\n",
        "            'e': math.e\n",
        "        }\n",
        "        \n",
        "        # Avaliando a express√£o de forma segura\n",
        "        result = eval(expression, {\"__builtins__\": {}}, allowed_functions)\n",
        "        return f\"Resultado: {result}\"\n",
        "        \n",
        "    except Exception as e:\n",
        "        return f\"Erro no c√°lculo: {str(e)}. Use express√µes matem√°ticas v√°lidas como: 2+2, sqrt(16), etc.\"\n",
        "\n",
        "# Tool 2: Web Search - Para buscar na internet\n",
        "def web_search_tool(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Busca informa√ß√µes na internet quando n√£o h√° dados suficientes nos documentos.\n",
        "    Use para informa√ß√µes atuais, not√≠cias, ou dados n√£o dispon√≠veis localmente.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Simulando uma busca web (na vida real, use APIs como Google Custom Search)\n",
        "        # Por quest√µes de simplicidade, vamos simular alguns resultados\n",
        "        \n",
        "        simulated_results = {\n",
        "            \"clima\": \"O clima hoje est√° ensolarado com temperatura de 25¬∞C.\",\n",
        "            \"not√≠cias\": \"√öltimas not√≠cias: Avan√ßos em IA continuam crescendo exponencialmente.\",\n",
        "            \"bitcoin\": \"Bitcoin est√° cotado em aproximadamente $43,000 USD hoje.\",\n",
        "            \"python\": \"Python continua sendo uma das linguagens mais populares para ci√™ncia de dados.\"\n",
        "        }\n",
        "        \n",
        "        # Busca por palavras-chave\n",
        "        query_lower = query.lower()\n",
        "        for key, result in simulated_results.items():\n",
        "            if key in query_lower:\n",
        "                return f\"Resultado da busca web: {result}\"\n",
        "        \n",
        "        return f\"Busca web para '{query}': Informa√ß√µes n√£o encontradas na simula√ß√£o. Na implementa√ß√£o real, seria usado uma API de busca.\"\n",
        "        \n",
        "    except Exception as e:\n",
        "        return f\"Erro na busca web: {str(e)}\"\n",
        "\n",
        "# Tool 3: Data Analysis - Para an√°lise de dados\n",
        "def data_analysis_tool(data_request: str) -> str:\n",
        "    \"\"\"\n",
        "    Realiza an√°lise de dados simples e gera visualiza√ß√µes.\n",
        "    Use para requests como: 'criar gr√°fico', 'analisar dados', 'estat√≠sticas'.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Criando dados de exemplo para demonstra√ß√£o\n",
        "        np.random.seed(42)\n",
        "        data = {\n",
        "            'vendas': np.random.normal(1000, 200, 30),\n",
        "            'lucro': np.random.normal(150, 50, 30),\n",
        "            'clientes': np.random.randint(50, 200, 30)\n",
        "        }\n",
        "        \n",
        "        df = pd.DataFrame(data)\n",
        "        \n",
        "        # An√°lise b√°sica\n",
        "        stats = df.describe()\n",
        "        \n",
        "        analysis = f\"\"\"\n",
        "        AN√ÅLISE DE DADOS GERADOS:\n",
        "        \n",
        "        Estat√≠sticas Descritivas:\n",
        "        - Vendas m√©dias: R$ {df['vendas'].mean():.2f}\n",
        "        - Lucro m√©dio: R$ {df['lucro'].mean():.2f}\n",
        "        - Clientes m√©dios: {df['clientes'].mean():.0f}\n",
        "        \n",
        "        Correla√ß√µes:\n",
        "        - Vendas vs Lucro: {df['vendas'].corr(df['lucro']):.3f}\n",
        "        - Vendas vs Clientes: {df['vendas'].corr(df['clientes']):.3f}\n",
        "        \n",
        "        Insights: Os dados mostram uma correla√ß√£o moderada entre vendas e lucro.\n",
        "        \"\"\"\n",
        "        \n",
        "        return analysis\n",
        "        \n",
        "    except Exception as e:\n",
        "        return f\"Erro na an√°lise: {str(e)}\"\n",
        "\n",
        "print(\"üîß Tools criadas com sucesso!\")\n",
        "print(\"‚úÖ Calculator Tool - Para c√°lculos\")\n",
        "print(\"‚úÖ Web Search Tool - Para busca na internet\")\n",
        "print(\"‚úÖ Data Analysis Tool - Para an√°lise de dados\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando as Tools do LangChain\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"RAG_Search\",\n",
        "        func=rag_system.search_documents,\n",
        "        description=\"Busca informa√ß√µes em documentos sobre IA, LangChain, Python e an√°lise de dados. Use quando a pergunta for sobre estes t√≥picos.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Calculator\",\n",
        "        func=calculator_tool,\n",
        "        description=\"Realiza c√°lculos matem√°ticos. Use para opera√ß√µes como soma, subtra√ß√£o, multiplica√ß√£o, divis√£o, raiz quadrada, etc. Exemplo: '2+2' ou 'sqrt(16)'\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Web_Search\",\n",
        "        func=web_search_tool,\n",
        "        description=\"Busca informa√ß√µes na internet quando n√£o h√° dados suficientes nos documentos locais. Use para informa√ß√µes atuais ou espec√≠ficas.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Data_Analysis\",\n",
        "        func=data_analysis_tool,\n",
        "        description=\"Realiza an√°lise de dados e gera estat√≠sticas. Use quando precisar analisar dados ou gerar insights.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"üõ†Ô∏è LangChain Tools configuradas!\")\n",
        "for tool in tools:\n",
        "    print(f\"- {tool.name}: {tool.description[:50]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Sistema de Mem√≥ria Avan√ßado\n\nAgora vamos implementar um sistema de mem√≥ria mais sofisticado! Lembra do m√≥dulo 5? Vamos evoluir aqueles conceitos!\n\n### üêò Por que Mem√≥ria √© Crucial?\n\nA mem√≥ria permite que nosso Agent:\n- **Mantenha contexto** entre perguntas\n- **Aprenda** com intera√ß√µes anteriores\n- **Seja mais natural** nas conversas\n- **Evite repeti√ß√µes** desnecess√°rias\n\n### üìä Tipos de Mem√≥ria que vamos usar:\n\n$$ \\text{Mem√≥ria Total} = \\text{Conversa} + \\text{Contexto} + \\text{Prefer√™ncias} $$\n\n**Dica do Pedro**: √â como a diferen√ßa entre falar com algu√©m que te conhece h√° anos versus um estranho. A mem√≥ria faz toda a diferen√ßa!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-11_img_04.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sistema de Mem√≥ria Avan√ßado\n",
        "class AdvancedMemorySystem:\n",
        "    def __init__(self, window_size=10):\n",
        "        # Mem√≥ria principal para conversas\n",
        "        self.conversation_memory = ConversationBufferWindowMemory(\n",
        "            k=window_size,\n",
        "            memory_key=\"chat_history\",\n",
        "            return_messages=True\n",
        "        )\n",
        "        \n",
        "        # Mem√≥ria de longo prazo para prefer√™ncias do usu√°rio\n",
        "        self.user_preferences = {}\n",
        "        \n",
        "        # Cache de consultas frequentes\n",
        "        self.query_cache = {}\n",
        "        \n",
        "        # Estat√≠sticas de uso\n",
        "        self.usage_stats = {\n",
        "            'total_queries': 0,\n",
        "            'tool_usage': {},\n",
        "            'common_topics': {}\n",
        "        }\n",
        "        \n",
        "        print(\"üß† Sistema de Mem√≥ria Avan√ßado inicializado!\")\n",
        "    \n",
        "    def add_user_preference(self, key: str, value: str):\n",
        "        \"\"\"Adiciona uma prefer√™ncia do usu√°rio\"\"\"\n",
        "        self.user_preferences[key] = value\n",
        "        print(f\"‚úÖ Prefer√™ncia salva: {key} = {value}\")\n",
        "    \n",
        "    def get_user_context(self) -> str:\n",
        "        \"\"\"Retorna o contexto do usu√°rio para personaliza√ß√£o\"\"\"\n",
        "        if not self.user_preferences:\n",
        "            return \"Novo usu√°rio, sem prefer√™ncias salvas.\"\n",
        "        \n",
        "        context = \"Prefer√™ncias do usu√°rio: \"\n",
        "        for key, value in self.user_preferences.items():\n",
        "            context += f\"{key}: {value}; \"\n",
        "        \n",
        "        return context\n",
        "    \n",
        "    def update_stats(self, query: str, tool_used: str = None):\n",
        "        \"\"\"Atualiza estat√≠sticas de uso\"\"\"\n",
        "        self.usage_stats['total_queries'] += 1\n",
        "        \n",
        "        if tool_used:\n",
        "            if tool_used not in self.usage_stats['tool_usage']:\n",
        "                self.usage_stats['tool_usage'][tool_used] = 0\n",
        "            self.usage_stats['tool_usage'][tool_used] += 1\n",
        "        \n",
        "        # An√°lise simples de t√≥picos\n",
        "        query_lower = query.lower()\n",
        "        topics = ['ia', 'python', 'dados', 'c√°lculo', 'langchain']\n",
        "        \n",
        "        for topic in topics:\n",
        "            if topic in query_lower:\n",
        "                if topic not in self.usage_stats['common_topics']:\n",
        "                    self.usage_stats['common_topics'][topic] = 0\n",
        "                self.usage_stats['common_topics'][topic] += 1\n",
        "    \n",
        "    def get_stats_summary(self) -> str:\n",
        "        \"\"\"Retorna um resumo das estat√≠sticas\"\"\"\n",
        "        stats = self.usage_stats\n",
        "        \n",
        "        summary = f\"\"\"\n",
        "        üìä ESTAT√çSTICAS DE USO:\n",
        "        \n",
        "        Total de consultas: {stats['total_queries']}\n",
        "        \n",
        "        Tools mais usadas:\n",
        "        {dict(sorted(stats['tool_usage'].items(), key=lambda x: x[1], reverse=True))}\n",
        "        \n",
        "        T√≥picos mais consultados:\n",
        "        {dict(sorted(stats['common_topics'].items(), key=lambda x: x[1], reverse=True))}\n",
        "        \n",
        "        Prefer√™ncias do usu√°rio: {len(self.user_preferences)} salvas\n",
        "        \"\"\"\n",
        "        \n",
        "        return summary\n",
        "\n",
        "# Inicializando o sistema de mem√≥ria\n",
        "memory_system = AdvancedMemorySystem(window_size=15)\n",
        "\n",
        "# Testando com algumas prefer√™ncias\n",
        "memory_system.add_user_preference(\"linguagem_preferida\", \"Python\")\n",
        "memory_system.add_user_preference(\"nivel_tecnico\", \"Avan√ßado\")\n",
        "memory_system.add_user_preference(\"area_interesse\", \"IA e Machine Learning\")\n",
        "\n",
        "print(\"\\nüìã Contexto do usu√°rio:\")\n",
        "print(memory_system.get_user_context())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ Criando o Agent Master - O C√©rebro Central\n\nAgora chegou a hora do **show**! Vamos criar nosso Agent principal que vai orquestrar tudo!\n\n### üéØ O que √© um Agent Master?\n\n√â como um **maestro de orquestra** que:\n- üéº **Coordena** todas as tools\n- üß† **Decide** qual ferramenta usar\n- üí≠ **Mant√©m** o contexto da conversa\n- üéØ **Entrega** respostas precisas\n\n### üîÑ Fluxo de Decis√£o do Agent:\n\n```mermaid\ngraph TD\n    A[Pergunta do Usu√°rio] --> B[Agent Analisa]\n    B --> C{Tipo de Pergunta?}\n    C -->|Conhecimento| D[RAG Search]\n    C -->|C√°lculo| E[Calculator]\n    C -->|Web Info| F[Web Search]\n    C -->|Dados| G[Data Analysis]\n    D --> H[Resposta Final]\n    E --> H\n    F --> H\n    G --> H\n    H --> I[Atualiza Mem√≥ria]\n```\n\n**Dica do Pedro**: O Agent usa ReAct (Reasoning + Acting), que significa que ele pensa antes de agir!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando o Prompt Template para nosso Agent\n",
        "agent_prompt = PromptTemplate(\n",
        "    input_variables=[\"tools\", \"tool_names\", \"input\", \"agent_scratchpad\", \"chat_history\", \"user_context\"],\n",
        "    template=\"\"\"\n",
        "Voc√™ √© um assistente IA avan√ßado com acesso a m√∫ltiplas ferramentas especializadas.\n",
        "\n",
        "CONTEXTO DO USU√ÅRIO: {user_context}\n",
        "\n",
        "HIST√ìRICO DA CONVERSA:\n",
        "{chat_history}\n",
        "\n",
        "FERRAMENTAS DISPON√çVEIS:\n",
        "{tools}\n",
        "\n",
        "Use o seguinte formato para responder:\n",
        "\n",
        "Question: a pergunta que voc√™ deve responder\n",
        "Thought: voc√™ deve sempre pensar sobre o que fazer\n",
        "Action: a a√ß√£o a tomar, deve ser uma de [{tool_names}]\n",
        "Action Input: a entrada para a a√ß√£o\n",
        "Observation: o resultado da a√ß√£o\n",
        "... (esse Thought/Action/Action Input/Observation pode repetir N vezes)\n",
        "Thought: Eu sei a resposta final\n",
        "Final Answer: a resposta final para a pergunta original\n",
        "\n",
        "REGRAS IMPORTANTES:\n",
        "1. Use RAG_Search para perguntas sobre IA, LangChain, Python, an√°lise de dados\n",
        "2. Use Calculator para opera√ß√µes matem√°ticas\n",
        "3. Use Web_Search para informa√ß√µes atuais ou n√£o dispon√≠veis localmente\n",
        "4. Use Data_Analysis para an√°lise de dados e estat√≠sticas\n",
        "5. Seja sempre preciso e cite fontes quando relevante\n",
        "6. Mantenha o contexto da conversa anterior\n",
        "7. Responda em portugu√™s de forma clara e did√°tica\n",
        "\n",
        "Question: {input}\n",
        "Thought:{agent_scratchpad}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "print(\"üìù Prompt do Agent configurado!\")\n",
        "print(\"üéØ O Agent agora sabe exatamente como usar cada ferramenta!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando o Agent Master - O c√©rebro da opera√ß√£o!\n",
        "class AgentMaster:\n",
        "    def __init__(self, llm, tools, memory_system, agent_prompt):\n",
        "        self.llm = llm\n",
        "        self.tools = tools\n",
        "        self.memory_system = memory_system\n",
        "        \n",
        "        # Criando o agent ReAct\n",
        "        self.agent = create_react_agent(\n",
        "            llm=self.llm,\n",
        "            tools=self.tools,\n",
        "            prompt=agent_prompt\n",
        "        )\n",
        "        \n",
        "        # Executor do agent com mem√≥ria\n",
        "        self.agent_executor = AgentExecutor(\n",
        "            agent=self.agent,\n",
        "            tools=self.tools,\n",
        "            memory=self.memory_system.conversation_memory,\n",
        "            verbose=True,\n",
        "            handle_parsing_errors=True,\n",
        "            max_iterations=3,\n",
        "            max_execution_time=60\n",
        "        )\n",
        "        \n",
        "        print(\"ü§ñ Agent Master criado com sucesso!\")\n",
        "        print(\"üß† ReAct Agent configurado com mem√≥ria\")\n",
        "        print(f\"üõ†Ô∏è {len(self.tools)} ferramentas dispon√≠veis\")\n",
        "    \n",
        "    def chat(self, message: str) -> str:\n",
        "        \"\"\"Interface principal para conversar com o agent\"\"\"\n",
        "        try:\n",
        "            # Preparando o contexto do usu√°rio\n",
        "            user_context = self.memory_system.get_user_context()\n",
        "            \n",
        "            # Executando o agent\n",
        "            response = self.agent_executor.invoke({\n",
        "                \"input\": message,\n",
        "                \"user_context\": user_context\n",
        "            })\n",
        "            \n",
        "            # Atualizando estat√≠sticas\n",
        "            self.memory_system.update_stats(message)\n",
        "            \n",
        "            return response[\"output\"]\n",
        "            \n",
        "        except Exception as e:\n",
        "            error_msg = f\"Ops! Ocorreu um erro: {str(e)}\"\n",
        "            print(f\"‚ùå {error_msg}\")\n",
        "            return error_msg\n",
        "    \n",
        "    def get_system_status(self) -> str:\n",
        "        \"\"\"Retorna o status do sistema\"\"\"\n",
        "        status = f\"\"\"\n",
        "        ü§ñ STATUS DO AGENT MASTER:\n",
        "        \n",
        "        ‚úÖ Agent ReAct: Ativo\n",
        "        ‚úÖ Ferramentas: {len(self.tools)} dispon√≠veis\n",
        "        ‚úÖ Mem√≥ria: Ativa (janela de {self.memory_system.conversation_memory.k} mensagens)\n",
        "        ‚úÖ LLM: {type(self.llm).__name__}\n",
        "        \n",
        "        {self.memory_system.get_stats_summary()}\n",
        "        \"\"\"\n",
        "        return status\n",
        "\n",
        "# Inicializando nosso Agent Master\n",
        "agent_master = AgentMaster(\n",
        "    llm=llm,\n",
        "    tools=tools,\n",
        "    memory_system=memory_system,\n",
        "    agent_prompt=agent_prompt\n",
        ")\n",
        "\n",
        "print(\"\\nüéâ SISTEMA COMPLETO INICIALIZADO!\")\n",
        "print(agent_master.get_system_status())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Testando Nosso Sistema Completo\n\nAgora √© a hora da verdade! Vamos testar nosso **mega-sistema** com diferentes tipos de perguntas!\n\n### üéØ Cen√°rios de Teste:\n1. **RAG**: Perguntas sobre nossos documentos\n2. **C√°lculos**: Opera√ß√µes matem√°ticas\n3. **Busca Web**: Informa√ß√µes externas  \n4. **An√°lise**: Processamento de dados\n5. **Mem√≥ria**: Continuidade da conversa\n\n**Dica do Pedro**: Observe como o Agent **pensa** antes de agir! Isso √© o ReAct em a√ß√£o!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-11_img_05.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Teste 1: RAG - Pergunta sobre nossos documentos\n",
        "print(\"üß™ TESTE 1: RAG SEARCH\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "question1 = \"Quais s√£o os principais tipos de Machine Learning?\"\n",
        "print(f\"Pergunta: {question1}\")\n",
        "print(\"\\nResposta:\")\n",
        "\n",
        "response1 = agent_master.chat(question1)\n",
        "print(response1)\n",
        "print(\"\\n\" + \"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Teste 2: Calculator - Opera√ß√£o matem√°tica\n",
        "print(\"üß™ TESTE 2: CALCULATOR\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "question2 = \"Quanto √© a raiz quadrada de 144 multiplicada por 5?\"\n",
        "print(f\"Pergunta: {question2}\")\n",
        "print(\"\\nResposta:\")\n",
        "\n",
        "response2 = agent_master.chat(question2)\n",
        "print(response2)\n",
        "print(\"\\n\" + \"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Teste 3: An√°lise de Dados\n",
        "print(\"üß™ TESTE 3: DATA ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "question3 = \"Pode fazer uma an√°lise de dados para mim?\"\n",
        "print(f\"Pergunta: {question3}\")\n",
        "print(\"\\nResposta:\")\n",
        "\n",
        "response3 = agent_master.chat(question3)\n",
        "print(response3)\n",
        "print(\"\\n\" + \"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Teste 4: Teste de Mem√≥ria - Pergunta que referencia conversa anterior\n",
        "print(\"üß™ TESTE 4: MEM√ìRIA\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "question4 = \"Baseado no que conversamos sobre Machine Learning, qual tipo seria melhor para classifica√ß√£o de imagens?\"\n",
        "print(f\"Pergunta: {question4}\")\n",
        "print(\"\\nResposta:\")\n",
        "\n",
        "response4 = agent_master.chat(question4)\n",
        "print(response4)\n",
        "print(\"\\n\" + \"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Teste 5: Web Search\n",
        "print(\"üß™ TESTE 5: WEB SEARCH\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "question5 = \"Qual √© o pre√ßo atual do Bitcoin?\"\n",
        "print(f\"Pergunta: {question5}\")\n",
        "print(\"\\nResposta:\")\n",
        "\n",
        "response5 = agent_master.chat(question5)\n",
        "print(response5)\n",
        "print(\"\\n\" + \"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizando o status final do sistema\n",
        "print(\"üìä STATUS FINAL DO SISTEMA\")\n",
        "print(agent_master.get_system_status())\n",
        "\n",
        "# Criando um gr√°fico das estat√≠sticas de uso\n",
        "stats = memory_system.usage_stats\n",
        "\n",
        "if stats['tool_usage']:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    # Gr√°fico 1: Uso das Tools\n",
        "    plt.subplot(1, 2, 1)\n",
        "    tools_names = list(stats['tool_usage'].keys())\n",
        "    tools_counts = list(stats['tool_usage'].values())\n",
        "    \n",
        "    plt.bar(tools_names, tools_counts, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
        "    plt.title('Uso das Ferramentas', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Ferramentas')\n",
        "    plt.ylabel('N√∫mero de Usos')\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    # Gr√°fico 2: T√≥picos mais consultados\n",
        "    plt.subplot(1, 2, 2)\n",
        "    if stats['common_topics']:\n",
        "        topics = list(stats['common_topics'].keys())\n",
        "        counts = list(stats['common_topics'].values())\n",
        "        \n",
        "        plt.pie(counts, labels=topics, autopct='%1.1f%%', startangle=90,\n",
        "               colors=['#FFB6C1', '#87CEEB', '#DDA0DD', '#98FB98', '#F0E68C'])\n",
        "        plt.title('T√≥picos Mais Consultados', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"üìà Gr√°ficos de uso gerados!\")\nelse:\n    print(\"üìä Ainda n√£o h√° dados suficientes para gr√°ficos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exerc√≠cio Pr√°tico: Teste o Sistema!\n\nAgora √© a sua vez de testar nosso sistema! üí™\n\n### üìù Desafio:\nFa√ßa pelo menos **3 perguntas diferentes** que testem diferentes funcionalidades:\n\n1. **Uma pergunta sobre nossos documentos** (para testar RAG)\n2. **Um c√°lculo matem√°tico complexo** (para testar Calculator)\n3. **Uma pergunta que combine m√∫ltiplas tools**\n\n### üéÅ Exemplos de perguntas interessantes:\n- \"O que √© LangChain e qual seria o resultado de sqrt(25) * 10?\"\n- \"Baseado nos documentos, explique IA e depois fa√ßa uma an√°lise de dados\"\n- \"Compare Python com outras linguagens e calcule 2^8\"\n\n**Dica do Pedro**: Observe como o Agent **raciocina** e escolhe as ferramentas certas!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ SEU TESTE AQUI!\n",
        "# Substitua a pergunta abaixo pela sua pr√≥pria pergunta\n",
        "\n",
        "# Teste 1 - Sua pergunta sobre documentos\n",
        "sua_pergunta_1 = \"[SUBSTITUA AQUI] - Ex: Explique o que s√£o Chains no LangChain\"\n",
        "\n",
        "# Descomente e teste:\n",
        "# print(\"üéØ SEU TESTE 1:\")\n",
        "# print(f\"Pergunta: {sua_pergunta_1}\")\n",
        "# resposta1 = agent_master.chat(sua_pergunta_1)\n",
        "# print(f\"Resposta: {resposta1}\")\n",
        "\n",
        "print(\"‚úèÔ∏è Modifique as perguntas acima e teste o sistema!\")\n",
        "print(\"üí° Dica: Tente perguntas que combinem diferentes ferramentas!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ TESTE COMBINADO - Exemplo de pergunta complexa\n",
        "pergunta_complexa = \"Explique o que √© LangChain, calcule quantos componentes principais ele tem multiplicado por 3, e depois fa√ßa uma an√°lise dos dados que voc√™ possui.\"\n",
        "\n",
        "print(\"üéØ TESTE COMPLEXO - M√∫ltiplas Tools:\")\n",
        "print(f\"Pergunta: {pergunta_complexa}\")\n",
        "print(\"\\nProcessando... (pode demorar um pouco)\")\n",
        "\n",
        "resposta_complexa = agent_master.chat(pergunta_complexa)\n",
        "print(f\"\\nResposta Completa:\")\n",
        "print(resposta_complexa)\n",
        "\n",
        "print(\"\\nüéâ Liiindo! Viu como o Agent conseguiu usar m√∫ltiplas ferramentas?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Melhorias e Otimiza√ß√µes\n\nNosso sistema est√° funcionando, mas sempre podemos melhorar! Vamos ver algumas **otimiza√ß√µes avan√ßadas**:\n\n### üîß Poss√≠veis Melhorias:\n\n1. **Cache Inteligente**: Salvar respostas frequentes\n2. **An√°lise de Sentimento**: Entender o humor do usu√°rio\n3. **Auto-avalia√ß√£o**: O Agent se auto-criticar\n4. **Streaming**: Respostas em tempo real\n5. **Multi-modal**: Processar imagens e √°udio\n\n### üìà M√©tricas de Performance:\n\n$$ \\text{Efici√™ncia} = \\frac{\\text{Respostas Corretas}}{\\text{Total de Tentativas}} \\times \\frac{1}{\\text{Tempo M√©dio}} $$\n\n**Dica do Pedro**: Em produ√ß√£o, sempre monitore performance e precis√£o!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sistema de Cache Simples\n",
        "class CacheSystem:\n",
        "    def __init__(self, max_size=100):\n",
        "        self.cache = {}\n",
        "        self.max_size = max_size\n",
        "        self.access_count = {}\n",
        "    \n",
        "    def get(self, key: str):\n",
        "        \"\"\"Busca no cache\"\"\"\n",
        "        if key in self.cache:\n",
        "            self.access_count[key] = self.access_count.get(key, 0) + 1\n",
        "            return self.cache[key]\n",
        "        return None\n",
        "    \n",
        "    def set(self, key: str, value: str):\n",
        "        \"\"\"Salva no cache\"\"\"\n",
        "        if len(self.cache) >= self.max_size:\n",
        "            # Remove o menos usado\n",
        "            least_used = min(self.access_count, key=self.access_count.get)\n",
        "            del self.cache[least_used]\n",
        "            del self.access_count[least_used]\n",
        "        \n",
        "        self.cache[key] = value\n",
        "        self.access_count[key] = 1\n",
        "    \n",
        "    def get_stats(self):\n",
        "        \"\"\"Estat√≠sticas do cache\"\"\"\n",
        "        return {\n",
        "            'size': len(self.cache),\n",
        "            'max_size': self.max_size,\n",
        "            'hit_rate': sum(self.access_count.values()),\n",
        "            'most_accessed': max(self.access_count, key=self.access_count.get) if self.access_count else None\n",
        "        }\n",
        "\n",
        "# Sistema de M√©tricas\n",
        "class PerformanceMonitor:\n",
        "    def __init__(self):\n",
        "        self.response_times = []\n",
        "        self.success_count = 0\n",
        "        self.error_count = 0\n",
        "        \n",
        "    def log_response(self, response_time: float, success: bool):\n",
        "        \"\"\"Registra uma resposta\"\"\"\n",
        "        self.response_times.append(response_time)\n",
        "        if success:\n",
        "            self.success_count += 1\n",
        "        else:\n",
        "            self.error_count += 1\n",
        "    \n",
        "    def get_metrics(self):\n",
        "        \"\"\"Calcula m√©tricas de performance\"\"\"\n",
        "        if not self.response_times:\n",
        "            return \"Nenhuma m√©trica dispon√≠vel ainda.\"\n",
        "        \n",
        "        avg_time = np.mean(self.response_times)\n",
        "        success_rate = self.success_count / (self.success_count + self.error_count) * 100\n",
        "        \n",
        "        return f\"\"\"\n",
        "        üìä M√âTRICAS DE PERFORMANCE:\n",
        "        \n",
        "        ‚è±Ô∏è Tempo m√©dio de resposta: {avg_time:.2f}s\n",
        "        ‚úÖ Taxa de sucesso: {success_rate:.1f}%\n",
        "        üìà Total de consultas: {len(self.response_times)}\n",
        "        ‚ùå Erros: {self.error_count}\n",
        "        \"\"\"\n",
        "\n",
        "# Inicializando sistemas de otimiza√ß√£o\n",
        "cache_system = CacheSystem()\n",
        "performance_monitor = PerformanceMonitor()\n",
        "\n",
        "print(\"üîß Sistemas de otimiza√ß√£o inicializados!\")\n",
        "print(\"‚úÖ Cache System: Ativo\")\n",
        "print(\"‚úÖ Performance Monitor: Ativo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Visualiza√ß√£o Final - Dashboard do Sistema\n\nVamos criar um **dashboard visual** para monitorar nosso sistema!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-11_img_06.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dashboard Visual do Sistema\n",
        "def create_system_dashboard():\n",
        "    \"\"\"Cria um dashboard completo do sistema\"\"\"\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('ü§ñ Dashboard do Agent Master System', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # Gr√°fico 1: Uso das Tools\n",
        "    ax1 = axes[0, 0]\n",
        "    if memory_system.usage_stats['tool_usage']:\n",
        "        tools = list(memory_system.usage_stats['tool_usage'].keys())\n",
        "        counts = list(memory_system.usage_stats['tool_usage'].values())\n",
        "        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
        "        \n",
        "        bars = ax1.bar(tools, counts, color=colors[:len(tools)])\n",
        "        ax1.set_title('Uso das Ferramentas', fontweight='bold')\n",
        "        ax1.set_ylabel('N√∫mero de Usos')\n",
        "        \n",
        "        # Adicionando valores nas barras\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{int(height)}', ha='center', va='bottom')\n",
        "    else:\n",
        "        ax1.text(0.5, 0.5, 'Nenhum dado\\ndispon√≠vel', ha='center', va='center',\n",
        "                transform=ax1.transAxes, fontsize=12)\n",
        "        ax1.set_title('Uso das Ferramentas', fontweight='bold')\n",
        "    \n",
        "    # Gr√°fico 2: Simula√ß√£o de Performance ao longo do tempo\n",
        "    ax2 = axes[0, 1]\n",
        "    time_points = np.arange(1, 11)\n",
        "    performance = np.random.normal(0.85, 0.1, 10)\n",
        "    performance = np.clip(performance, 0.6, 1.0)  # Mant√©m entre 60% e 100%\n",
        "    \n",
        "    ax2.plot(time_points, performance, marker='o', linewidth=2, color='#45B7D1')\n",
        "    ax2.fill_between(time_points, performance, alpha=0.3, color='#45B7D1')\n",
        "    ax2.set_title('Performance ao Longo do Tempo', fontweight='bold')\n",
        "    ax2.set_xlabel('Intera√ß√µes')\n",
        "    ax2.set_ylabel('Taxa de Sucesso')\n",
        "    ax2.set_ylim(0.5, 1.0)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Gr√°fico 3: Distribui√ß√£o de T√≥picos\n",
        "    ax3 = axes[1, 0]\n",
        "    if memory_system.usage_stats['common_topics']:\n",
        "        topics = list(memory_system.usage_stats['common_topics'].keys())\n",
        "        topic_counts = list(memory_system.usage_stats['common_topics'].values())\n",
        "        colors = ['#FFB6C1', '#87CEEB', '#DDA0DD', '#98FB98', '#F0E68C']\n",
        "        \n",
        "        wedges, texts, autotexts = ax3.pie(topic_counts, labels=topics, autopct='%1.1f%%',\n",
        "                                          colors=colors[:len(topics)], startangle=90)\n",
        "        ax3.set_title('Distribui√ß√£o de T√≥picos', fontweight='bold')\n",
        "    else:\n",
        "        ax3.text(0.5, 0.5, 'Nenhum t√≥pico\\nidentificado', ha='center', va='center',\n",
        "                transform=ax3.transAxes, fontsize=12)\n",
        "        ax3.set_title('Distribui√ß√£o de T√≥picos', fontweight='bold')\n",
        "    \n",
        "    # Gr√°fico 4: M√©tricas do Sistema\n",
        "    ax4 = axes[1, 1]\n",
        "    metrics_names = ['Precis√£o', 'Velocidade', 'Mem√≥ria', 'Satisfa√ß√£o']\n",
        "    metrics_values = [0.89, 0.75, 0.92, 0.87]  # Valores simulados\n",
        "    \n",
        "    y_pos = np.arange(len(metrics_names))\n",
        "    bars = ax4.barh(y_pos, metrics_values, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
        "    \n",
        "    ax4.set_yticks(y_pos)\n",
        "    ax4.set_yticklabels(metrics_names)\n",
        "    ax4.set_xlabel('Score (0-1)')\n",
        "    ax4.set_title('M√©tricas do Sistema', fontweight='bold')\n",
        "    ax4.set_xlim(0, 1)\n",
        "    \n",
        "    # Adicionando valores nas barras\n",
        "    for i, bar in enumerate(bars):\n",
        "        width = bar.get_width()\n",
        "        ax4.text(width + 0.01, bar.get_y() + bar.get_height()/2.,\n",
        "                f'{metrics_values[i]:.2f}', ha='left', va='center')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Gerando o dashboard\n",
        "print(\"üìä Gerando Dashboard do Sistema...\")\n",
        "create_system_dashboard()\n",
        "print(\"‚úÖ Dashboard criado com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéì Resumo e Pr√≥ximos Passos\n\n**Parab√©ns!** üéâ Voc√™ acabou de construir um sistema de IA **COMPLETO** e **AVAN√áADO**!\n\n### üèÜ O que Conseguimos:\n\n‚úÖ **RAG Avan√ßado**: Sistema de busca inteligente em documentos  \n‚úÖ **Agent ReAct**: IA que pensa antes de agir  \n‚úÖ **Multiple Tools**: Calculadora, busca web, an√°lise de dados  \n‚úÖ **Mem√≥ria Persistente**: Contexto entre conversas  \n‚úÖ **Sistema de Cache**: Otimiza√ß√£o de performance  \n‚úÖ **Dashboard Completo**: Monitoramento visual  \n\n### üîó Conex√£o com o Curso:\n\nEste projeto integrou **TODOS** os m√≥dulos anteriores:\n- **M√≥dulos 1-2**: Fundamentos e Models ‚úÖ\n- **M√≥dulos 3-4**: Prompts e Chains ‚úÖ  \n- **M√≥dulo 5**: Memory Systems ‚úÖ\n- **M√≥dulos 6-8**: RAG Complete ‚úÖ\n- **M√≥dulos 9-10**: Agents e Projeto 1 ‚úÖ\n\n### üöÄ Pr√≥ximo M√≥dulo (12):\nNo pr√≥ximo m√≥dulo vamos fazer o **deploy** deste sistema usando **Streamlit**! Vai ficar liiindo! üåü\n\n**Dica do Pedro**: Guarde este notebook! Ele ser√° a base para nosso app web no pr√≥ximo m√≥dulo!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-11_img_07.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exerc√≠cio Final: Desafio Completo!\n\n**Seu desafio final**: Criar uma conversa **completa** que use **TODAS** as ferramentas do sistema!\n\n### üìã Checklist do Desafio:\n- [ ] Fazer uma pergunta sobre documentos (RAG)\n- [ ] Pedir um c√°lculo matem√°tico\n- [ ] Solicitar uma an√°lise de dados  \n- [ ] Buscar informa√ß√£o externa (web)\n- [ ] Referenciar conversa anterior (mem√≥ria)\n\n### üí° Exemplo de Conversa Completa:\n1. \"O que √© LangChain?\"\n2. \"Quantos componentes principais ele tem ao quadrado?\"\n3. \"Fa√ßa uma an√°lise estat√≠stica dos dados\"\n4. \"Qual o pre√ßo do Bitcoin hoje?\"\n5. \"Baseado em tudo que conversamos, qual seria o ROI de investir em IA?\"\n\n**Bora tentar?** üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ SEU DESAFIO FINAL AQUI!\n",
        "# Crie uma sequ√™ncia de perguntas que teste todo o sistema\n",
        "\n",
        "print(\"üéØ DESAFIO FINAL - Testando TUDO!\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Lista de perguntas para teste completo\n",
        "desafio_perguntas = [\n",
        "    \"Explique o que √© Machine Learning segundo os documentos\",\n",
        "    \"Calcule 15 elevado ao quadrado dividido por 3\",\n",
        "    \"Fa√ßa uma an√°lise completa dos dados dispon√≠veis\",\n",
        "    \"Baseado no que aprendemos sobre ML, qual algoritmo usar para prever vendas?\"\n",
        "]\n",
        "\n",
        "# Execute o desafio\n",
        "for i, pergunta in enumerate(desafio_perguntas, 1):\n",
        "    print(f\"\\nüî• PERGUNTA {i}: {pergunta}\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    resposta = agent_master.chat(pergunta)\n",
        "    print(f\"ü§ñ RESPOSTA: {resposta}\")\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "print(\"\\nüéâ DESAFIO CONCLU√çDO!\")\n",
        "print(\"üìä Status final do sistema:\")\n",
        "print(agent_master.get_system_status())"
      ]
    }
  ]
}