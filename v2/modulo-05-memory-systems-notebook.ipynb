{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† M√≥dulo 5: Memory Systems - A Mem√≥ria dos Nossos Bots!\n\n### *\"Como fazer seu ChatBot lembrar das conversas anteriores (e n√£o repetir a mesma pergunta 300 vezes!)\"*\n\n---\n\nEa√≠, pessoal! Tudo tranquilo? üöÄ\n\nT√°, mas o que diabos √© um **Memory System**? Imagina que voc√™ t√° conversando com seu amigo no WhatsApp e de repente ele esquece TUDO que voc√™s falaram 2 segundos atr√°s. Irritante, n√©?\n\n√â exatamente isso que acontece com os LLMs por padr√£o - eles s√£o como aquele peixinho Dory do Nemo: sem mem√≥ria!\n\nNeste m√≥dulo vamos aprender:\n- ‚úÖ Por que LLMs s√£o \"sem mem√≥ria\"\n- ‚úÖ Tipos de Memory no LangChain\n- ‚úÖ Como implementar cada tipo\n- ‚úÖ Quando usar cada um\n- ‚úÖ Dicas pr√°ticas para produ√ß√£o\n\n**Dica do Pedro**: Memory √© o que transforma um bot \"burro\" em um assistente inteligente!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§î Por que precisamos de Memory?\n\nT√°, vamos come√ßar com o b√°sico: **LLMs s√£o stateless**!\n\nIsso significa que cada vez que voc√™ faz uma pergunta, √© como se fosse a primeira vez que voc√™ conversa com ele. √â tipo assim:\n\n```\nVoc√™: \"Meu nome √© Jo√£o\"\nBot: \"Prazer, Jo√£o!\"\n\nVoc√™: \"Qual √© o meu nome?\"\nBot: \"Desculpa, n√£o sei seu nome\" ü§¶‚Äç‚ôÇÔ∏è\n```\n\nA **mem√≥ria** resolve isso mantendo o contexto da conversa. √â como dar um caderninho pro bot anotar tudo!\n\n### Analogia do Restaurante üçï\n\nImagina um gar√ßom que:\n- **Sem mem√≥ria**: Pergunta seu pedido a cada 2 minutos\n- **Com mem√≥ria**: Lembra do seu pedido e suas prefer√™ncias\n\nQual voc√™ prefere? √ìbvio, n√©!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Bora come√ßar! Primeiro, vamos instalar e importar tudo que precisamos\n",
        "!pip install langchain langchain-google-genai python-dotenv matplotlib -q\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Imports do LangChain\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.memory import (\n",
        "    ConversationBufferMemory,\n",
        "    ConversationBufferWindowMemory,\n",
        "    ConversationSummaryMemory,\n",
        "    ConversationSummaryBufferMemory\n",
        ")\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.schema import BaseMessage, HumanMessage, AIMessage\n",
        "\n",
        "print(\"‚úÖ Bibliotecas carregadas! Bora pro show!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Configurando nossa API do Google (lembra dos m√≥dulos anteriores?)\n",
        "load_dotenv()\n",
        "\n",
        "# Se n√£o tiver a API key, descomenta a linha abaixo e coloca sua chave\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = \"sua-api-key-aqui\"\n",
        "\n",
        "# Nosso modelo padr√£o do curso\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(\"ü§ñ Modelo configurado! Gemini 2.0 Flash pronto pra a√ß√£o!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Visualizando o Problema da Mem√≥ria\n\nVamos criar um gr√°fico pra mostrar como funciona a conversa **SEM** mem√≥ria:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vamos visualizar o problema da falta de mem√≥ria\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Gr√°fico 1: Sem Mem√≥ria\n",
        "conversas = ['Conversa 1', 'Conversa 2', 'Conversa 3', 'Conversa 4']\n",
        "contexto_sem_memoria = [1, 1, 1, 1]  # Sempre volta ao zero\n",
        "contexto_com_memoria = [1, 2, 3, 4]  # Acumula conhecimento\n",
        "\n",
        "ax1.bar(conversas, contexto_sem_memoria, color='red', alpha=0.7)\n",
        "ax1.set_title('üö´ SEM Mem√≥ria\\n(Cada conversa √© isolada)', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Contexto Dispon√≠vel')\n",
        "ax1.set_ylim(0, 5)\n",
        "\n",
        "# Gr√°fico 2: Com Mem√≥ria\n",
        "ax2.bar(conversas, contexto_com_memoria, color='green', alpha=0.7)\n",
        "ax2.set_title('‚úÖ COM Mem√≥ria\\n(Contexto acumulativo)', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Contexto Dispon√≠vel')\n",
        "ax2.set_ylim(0, 5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìà Viu a diferen√ßa? Com mem√≥ria, o bot fica cada vez mais esperto!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Arquitetura dos Memory Systems\n\n```mermaid\ngraph TD\n    A[üë§ Usu√°rio] --> B[üí¨ Nova Mensagem]\n    B --> C[üß† Memory System]\n    C --> D[üìö Contexto Hist√≥rico]\n    D --> E[ü§ñ LLM]\n    E --> F[üìù Resposta]\n    F --> G[üíæ Salvar na Mem√≥ria]\n    G --> C\n    F --> A\n```\n\n### Como funciona na pr√°tica:\n\n1. **Usu√°rio** envia mensagem\n2. **Memory System** recupera hist√≥rico\n3. **LLM** recebe mensagem + contexto\n4. **Resposta** √© gerada\n5. **Tudo √© salvo** na mem√≥ria\n\n**Dica do Pedro**: √â tipo um loop infinito de aprendizado!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Tipos de Memory no LangChain\n\nO LangChain tem v√°rios tipos de mem√≥ria, cada um pra uma situa√ß√£o:\n\n### 1. üóÉÔ∏è ConversationBufferMemory\n- **O que faz**: Guarda TUDO da conversa\n- **Pr√≥s**: Contexto completo\n- **Contras**: Pode ficar gigante\n- **Quando usar**: Conversas curtas\n\n### 2. ü™ü ConversationBufferWindowMemory\n- **O que faz**: Guarda s√≥ as √∫ltimas N mensagens\n- **Pr√≥s**: Controla o tamanho\n- **Contras**: Esquece coisas antigas\n- **Quando usar**: Conversas longas com foco no recente\n\n### 3. üìã ConversationSummaryMemory\n- **O que faz**: Resume a conversa\n- **Pr√≥s**: Muito eficiente\n- **Contras**: Pode perder detalhes\n- **Quando usar**: Conversas muito longas\n\n### 4. üîÑ ConversationSummaryBufferMemory\n- **O que faz**: Mistura resumo + buffer\n- **Pr√≥s**: Melhor dos dois mundos\n- **Contras**: Mais complexo\n- **Quando usar**: Conversas longas que precisam de detalhes\n\n**Dica do Pedro**: √â como escolher o tamanho da sua mochila pra viajem!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Comparando os Tipos de Memory\n\nVamos criar uma visualiza√ß√£o pra entender as diferen√ßas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Compara√ß√£o visual dos tipos de mem√≥ria\n",
        "tipos_memoria = ['Buffer\\nCompleto', 'Buffer\\nWindow', 'Summary\\nOnly', 'Summary+\\nBuffer']\n",
        "uso_tokens = [100, 40, 20, 50]  # Exemplo de uso de tokens\n",
        "precisao_contexto = [100, 70, 60, 85]  # Precis√£o do contexto preservado\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Gr√°fico 1: Uso de Tokens\n",
        "bars1 = ax1.bar(tipos_memoria, uso_tokens, color=['red', 'orange', 'green', 'blue'], alpha=0.7)\n",
        "ax1.set_title('üí∞ Uso de Tokens (Custo)', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Tokens Utilizados')\n",
        "ax1.set_ylim(0, 120)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bar, valor in zip(bars1, uso_tokens):\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
        "             f'{valor}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Gr√°fico 2: Precis√£o do Contexto\n",
        "bars2 = ax2.bar(tipos_memoria, precisao_contexto, color=['red', 'orange', 'green', 'blue'], alpha=0.7)\n",
        "ax2.set_title('üéØ Precis√£o do Contexto', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Precis√£o (%)')\n",
        "ax2.set_ylim(0, 120)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bar, valor in zip(bars2, precisao_contexto):\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
        "             f'{valor}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Trade-off cl√°ssico: Custo vs Precis√£o!\")\n",
        "print(\"üí° A escolha depende do seu caso de uso espec√≠fico!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üóÉÔ∏è 1. ConversationBufferMemory - O Arquivo Completo\n\nVamos come√ßar com o mais simples: guardar TUDO!\n\n√â tipo aquela pessoa que guarda todos os WhatsApp desde 2010 üòÖ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Criando um ConversationBufferMemory\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Inicializando a mem√≥ria\n",
        "buffer_memory = ConversationBufferMemory(\n",
        "    return_messages=True,  # Retorna como objetos Message\n",
        "    memory_key=\"chat_history\"  # Nome da chave no contexto\n",
        ")\n",
        "\n",
        "# Criando uma chain com mem√≥ria\n",
        "conversation_buffer = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=buffer_memory,\n",
        "    verbose=True  # Pra ver o que t√° rolando nos bastidores\n",
        ")\n",
        "\n",
        "print(\"‚úÖ ConversationBufferMemory criada!\")\n",
        "print(\"üß† Esta mem√≥ria vai guardar TODA a conversa!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Testando o BufferMemory\n",
        "print(\"üó£Ô∏è Iniciando conversa com BufferMemory...\\n\")\n",
        "\n",
        "# Primeira mensagem\n",
        "resposta1 = conversation_buffer.predict(input=\"Oi! Meu nome √© Jo√£o e eu adoro pizza.\")\n",
        "print(f\"ü§ñ Bot: {resposta1}\\n\")\n",
        "\n",
        "# Segunda mensagem - vamos ver se ele lembra\n",
        "resposta2 = conversation_buffer.predict(input=\"Qual √© o meu nome e o que eu gosto de comer?\")\n",
        "print(f\"ü§ñ Bot: {resposta2}\\n\")\n",
        "\n",
        "# Terceira mensagem - mais contexto\n",
        "resposta3 = conversation_buffer.predict(input=\"Eu tamb√©m trabalho como programador Python.\")\n",
        "print(f\"ü§ñ Bot: {resposta3}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vamos ver o que tem na mem√≥ria\n",
        "print(\"üß† Conte√∫do da mem√≥ria BufferMemory:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Acessando o buffer diretamente\n",
        "historico = buffer_memory.chat_memory.messages\n",
        "\n",
        "for i, mensagem in enumerate(historico, 1):\n",
        "    tipo = \"üë§ Usu√°rio\" if mensagem.type == \"human\" else \"ü§ñ Bot\"\n",
        "    print(f\"{i}. {tipo}: {mensagem.content[:100]}...\")\n",
        "\n",
        "print(f\"\\nüìä Total de mensagens na mem√≥ria: {len(historico)}\")\n",
        "print(f\"üíæ Tamanho aproximado: {sum(len(msg.content) for msg in historico)} caracteres\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü™ü 2. ConversationBufferWindowMemory - A Janela Deslizante\n\nAgora vamos pro Buffer Window - ele mant√©m s√≥ as √∫ltimas N mensagens.\n\n√â tipo aquela mem√≥ria RAM do seu computador: mant√©m s√≥ o que √© relevante agora!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Criando um ConversationBufferWindowMemory\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "# Inicializando com janela de 4 mensagens (2 do usu√°rio + 2 do bot)\n",
        "window_memory = ConversationBufferWindowMemory(\n",
        "    k=4,  # Mant√©m as √∫ltimas 4 mensagens\n",
        "    return_messages=True,\n",
        "    memory_key=\"chat_history\"\n",
        ")\n",
        "\n",
        "# Criando uma nova chain\n",
        "conversation_window = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=window_memory,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ ConversationBufferWindowMemory criada!\")\n",
        "print(\"ü™ü Esta mem√≥ria mant√©m apenas as √∫ltimas 4 mensagens!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Testando o WindowMemory com v√°rias mensagens\n",
        "print(\"üó£Ô∏è Testando WindowMemory com janela de 4 mensagens...\\n\")\n",
        "\n",
        "mensagens_teste = [\n",
        "    \"Oi! Meu nome √© Maria.\",\n",
        "    \"Eu tenho 25 anos.\",\n",
        "    \"Trabalho como designer.\",\n",
        "    \"Adoro viajar para a praia.\",\n",
        "    \"Tenho um gato chamado Mimi.\",\n",
        "    \"Qual √© o meu nome mesmo?\"  # Vamos ver se ainda lembra!\n",
        "]\n",
        "\n",
        "for i, mensagem in enumerate(mensagens_teste, 1):\n",
        "    print(f\"üì® Mensagem {i}: {mensagem}\")\n",
        "    resposta = conversation_window.predict(input=mensagem)\n",
        "    print(f\"ü§ñ Bot: {resposta}\\n\")\n",
        "    \n",
        "    # Mostrando quantas mensagens est√£o na mem√≥ria\n",
        "    qtd_memorias = len(window_memory.chat_memory.messages)\n",
        "    print(f\"üß† Mensagens na mem√≥ria: {qtd_memorias}/4\\n\")\n",
        "    print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã 3. ConversationSummaryMemory - O Resumidor\n\nAgora a coisa fica interessante! O SummaryMemory n√£o guarda as mensagens - ele faz um **resumo**!\n\n√â tipo aquele amigo que conta a fofoca resumida: \"Ah, rolou um drama, mas o importante √© que no final deu tudo certo\" üòÇ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Criando um ConversationSummaryMemory\n",
        "from langchain.memory import ConversationSummaryMemory\n",
        "\n",
        "# Inicializando - precisa de um LLM pra fazer os resumos!\n",
        "summary_memory = ConversationSummaryMemory(\n",
        "    llm=llm,  # Usa o mesmo LLM pra resumir\n",
        "    return_messages=False,  # Retorna como string\n",
        "    memory_key=\"chat_history\"\n",
        ")\n",
        "\n",
        "# Criando uma nova chain\n",
        "conversation_summary = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=summary_memory,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ ConversationSummaryMemory criada!\")\n",
        "print(\"üìã Esta mem√≥ria faz resumos autom√°ticos da conversa!\")\n",
        "print(\"ü§ñ O pr√≥prio LLM vai resumir conforme a conversa cresce!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Testando o SummaryMemory\n",
        "print(\"üó£Ô∏è Testando SummaryMemory...\\n\")\n",
        "\n",
        "# Vamos simular uma conversa longa\n",
        "mensagens_longas = [\n",
        "    \"Oi! Meu nome √© Carlos, tenho 30 anos e sou engenheiro de software.\",\n",
        "    \"Trabalho numa startup de fintech aqui em S√£o Paulo h√° 3 anos.\",\n",
        "    \"Estou desenvolvendo um app de investimentos em Python e React.\",\n",
        "    \"O app j√° tem 10.000 usu√°rios e est√° crescendo 20% ao m√™s.\",\n",
        "    \"Estamos levantando uma rodada de investimento de R$ 2 milh√µes.\",\n",
        "    \"Me fala um resumo de tudo que conversamos at√© agora?\"\n",
        "]\n",
        "\n",
        "for i, mensagem in enumerate(mensagens_longas, 1):\n",
        "    print(f\"üì® Mensagem {i}: {mensagem}\")\n",
        "    resposta = conversation_summary.predict(input=mensagem)\n",
        "    print(f\"ü§ñ Bot: {resposta}\\n\")\n",
        "    \n",
        "    # Vamos espiar o resumo que est√° sendo mantido\n",
        "    if i > 2:  # Depois de algumas mensagens\n",
        "        resumo_atual = summary_memory.buffer\n",
        "        print(f\"üìã Resumo na mem√≥ria: {resumo_atual[:150]}...\\n\")\n",
        "    \n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ 4. ConversationSummaryBufferMemory - O H√≠brido\n\nE agora o **melhor dos dois mundos**! O SummaryBufferMemory:\n\n- Mant√©m as mensagens **recentes** completas\n- **Resume** as mensagens antigas\n\n√â tipo ter um assistente que anota tudo detalhado no dia, mas faz resumos do m√™s passado!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Criando um ConversationSummaryBufferMemory\n",
        "from langchain.memory import ConversationSummaryBufferMemory\n",
        "\n",
        "# Inicializando com limite de tokens\n",
        "summary_buffer_memory = ConversationSummaryBufferMemory(\n",
        "    llm=llm,\n",
        "    max_token_limit=200,  # Quando passar disso, resume as antigas\n",
        "    return_messages=True,\n",
        "    memory_key=\"chat_history\"\n",
        ")\n",
        "\n",
        "# Criando uma nova chain\n",
        "conversation_summary_buffer = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=summary_buffer_memory,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ ConversationSummaryBufferMemory criada!\")\n",
        "print(\"üîÑ Esta mem√≥ria combina resumo + buffer!\")\n",
        "print(\"üìä Limite: 200 tokens - depois disso resume as antigas!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Testando o SummaryBufferMemory\n",
        "print(\"üó£Ô∏è Testando SummaryBufferMemory...\\n\")\n",
        "\n",
        "mensagens_hibridas = [\n",
        "    \"Sou a Ana, m√©dica veterin√°ria de 28 anos.\",\n",
        "    \"Trabalho numa cl√≠nica veterin√°ria em Belo Horizonte desde 2020.\",\n",
        "    \"Tenho especializa√ß√£o em animais ex√≥ticos - papagaios, iguanas, etc.\",\n",
        "    \"Atendo cerca de 50 animais por semana, a maioria c√£es e gatos.\",\n",
        "    \"Estou pensando em abrir minha pr√≥pria cl√≠nica no ano que vem.\",\n",
        "    \"Qual √© a minha profiss√£o e onde trabalho?\"\n",
        "]\n",
        "\n",
        "for i, mensagem in enumerate(mensagens_hibridas, 1):\n",
        "    print(f\"üì® Mensagem {i}: {mensagem}\")\n",
        "    resposta = conversation_summary_buffer.predict(input=mensagem)\n",
        "    print(f\"ü§ñ Bot: {resposta}\\n\")\n",
        "    \n",
        "    # Verificando o estado da mem√≥ria\n",
        "    memoria_vars = summary_buffer_memory.load_memory_variables({})\n",
        "    print(f\"üß† Estado da mem√≥ria ap√≥s mensagem {i}:\")\n",
        "    if hasattr(summary_buffer_memory, 'moving_summary_buffer') and summary_buffer_memory.moving_summary_buffer:\n",
        "        print(f\"üìã Tem resumo: {summary_buffer_memory.moving_summary_buffer[:100]}...\")\n",
        "    else:\n",
        "        print(\"üìã Ainda n√£o tem resumo - s√≥ mensagens recentes\")\n",
        "    \n",
        "    print(\"-\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Compara√ß√£o Pr√°tica dos Memory Types\n\nVamos fazer um teste pr√°tico pra ver como cada tipo se comporta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Fun√ß√£o para calcular tamanho aproximado da mem√≥ria\n",
        "def calcular_tamanho_memoria(memory_obj):\n",
        "    \"\"\"Calcula o tamanho aproximado da mem√≥ria em caracteres\"\"\"\n",
        "    try:\n",
        "        # Tenta carregar as vari√°veis da mem√≥ria\n",
        "        vars_memoria = memory_obj.load_memory_variables({})\n",
        "        \n",
        "        # Soma todos os caracteres\n",
        "        tamanho_total = 0\n",
        "        for key, value in vars_memoria.items():\n",
        "            if isinstance(value, str):\n",
        "                tamanho_total += len(value)\n",
        "            elif isinstance(value, list):\n",
        "                for item in value:\n",
        "                    if hasattr(item, 'content'):\n",
        "                        tamanho_total += len(item.content)\n",
        "                    else:\n",
        "                        tamanho_total += len(str(item))\n",
        "        \n",
        "        return tamanho_total\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "# Testando com uma sequ√™ncia de mensagens\n",
        "mensagens_comparacao = [\n",
        "    \"Oi, sou o Pedro, desenvolvedore Python de 35 anos.\",\n",
        "    \"Trabalho com IA e Machine Learning h√° 8 anos.\",\n",
        "    \"J√° criei mais de 100 modelos de ML em produ√ß√£o.\",\n",
        "    \"Especialista em LangChain, FastAPI e AWS.\",\n",
        "    \"Dou aulas online e j√° treinei mais de 5000 alunos.\"\n",
        "]\n",
        "\n",
        "# Criando memorias limpas para compara√ß√£o\n",
        "memorias_teste = {\n",
        "    'Buffer': ConversationBufferMemory(return_messages=True),\n",
        "    'Window': ConversationBufferWindowMemory(k=4, return_messages=True),\n",
        "    'Summary': ConversationSummaryMemory(llm=llm),\n",
        "    'SummaryBuffer': ConversationSummaryBufferMemory(llm=llm, max_token_limit=150)\n",
        "}\n",
        "\n",
        "# Simulando as mensagens em todas as mem√≥rias\n",
        "for mensagem in mensagens_comparacao:\n",
        "    for nome, memoria in memorias_teste.items():\n",
        "        # Simula uma conversa adicionando mensagem do usu√°rio e uma resposta padr√£o\n",
        "        memoria.save_context(\n",
        "            {\"input\": mensagem}, \n",
        "            {\"output\": f\"Entendi! Obrigado por compartilhar isso, {mensagem.split()[2] if len(mensagem.split()) > 2 else 'usu√°rio'}!\"}\n",
        "        )\n",
        "\n",
        "print(\"üìä Compara√ß√£o de tamanhos de mem√≥ria ap√≥s 5 intera√ß√µes:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "tamanhos = {}\n",
        "for nome, memoria in memorias_teste.items():\n",
        "    tamanho = calcular_tamanho_memoria(memoria)\n",
        "    tamanhos[nome] = tamanho\n",
        "    print(f\"{nome:15} : {tamanho:4d} caracteres\")\n",
        "\n",
        "print(\"\\nüí° Conclus√µes:\")\n",
        "print(f\"ü•á Mais eficiente: {min(tamanhos, key=tamanhos.get)}\")\n",
        "print(f\"üìö Mais completo: {max(tamanhos, key=tamanhos.get)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Visualiza√ß√£o Final - Efici√™ncia vs Completude"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Gr√°fico de barras comparativo final\n",
        "nomes = list(tamanhos.keys())\n",
        "valores = list(tamanhos.values())\n",
        "cores = ['red', 'orange', 'green', 'blue']\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Gr√°fico de barras\n",
        "bars = plt.bar(nomes, valores, color=cores, alpha=0.7, edgecolor='black', linewidth=2)\n",
        "\n",
        "# Customiza√ß√£o\n",
        "plt.title('üìä Compara√ß√£o de Uso de Mem√≥ria\\n(Menor = Mais Eficiente)', \n",
        "          fontsize=16, fontweight='bold', pad=20)\n",
        "plt.ylabel('Caracteres Utilizados', fontsize=12, fontweight='bold')\n",
        "plt.xlabel('Tipos de Memory', fontsize=12, fontweight='bold')\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bar, valor in zip(bars, valores):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(valores)*0.01, \n",
        "             f'{valor}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
        "\n",
        "# Adicionando linha de refer√™ncia\n",
        "plt.axhline(y=np.mean(valores), color='red', linestyle='--', alpha=0.7, \n",
        "            label=f'M√©dia: {int(np.mean(valores))}')\n",
        "\n",
        "plt.legend()\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìà Liiindo! Agora voc√™ sabe exatamente qual memory usar!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí° Dicas Pr√°ticas do Pedro\n\n### üéØ Quando usar cada tipo?\n\n| Tipo | Use quando | Exemplo |\n|------|------------|--------|\n| **Buffer** | Conversas curtas e precisas | Chat de suporte |\n| **Window** | Conversas longas, contexto recente | Games, assistentes |\n| **Summary** | Conversas muito longas | Terapia, consultoria |\n| **SummaryBuffer** | Melhor dos dois mundos | Assistentes corporativos |\n\n### üöÄ Dicas de Performance:\n\n1. **Monitore o tamanho**: Use `len()` na mem√≥ria\n2. **Defina limites**: Sempre coloque `max_token_limit`\n3. **Teste em produ√ß√£o**: Cada caso √© um caso\n4. **Combine tipos**: Use diferentes mem√≥rias pra diferentes usu√°rios\n\n### ‚ö†Ô∏è Pegadinhas Comuns:\n\n- **BufferMemory** pode explodir o contexto\n- **SummaryMemory** pode perder detalhes importantes\n- **WindowMemory** esquece coisas antigas\n- Todos custam tokens! üí∞\n\n**Dica do Pedro**: Sempre teste com dados reais do seu dom√≠nio!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Exerc√≠cio 1: Implementando Memory Customizada\n\nBora criar uma mem√≥ria personalizada que atende √†s suas necessidades espec√≠ficas!\n\n**Desafio**: Criar uma mem√≥ria que:\n1. Mant√©m as √∫ltimas 3 mensagens completas\n2. Salva informa√ß√µes importantes do usu√°rio (nome, profiss√£o, etc.)\n3. Mostra um resumo das informa√ß√µes salvas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# EXERC√çCIO 1: Implemente uma MemoryCustomizada\n",
        "class MemoryCustomizada:\n",
        "    def __init__(self):\n",
        "        self.mensagens_recentes = []  # √öltimas 3 mensagens\n",
        "        self.info_usuario = {}        # Informa√ß√µes importantes\n",
        "        self.max_mensagens = 3\n",
        "    \n",
        "    def adicionar_mensagem(self, usuario_msg, bot_msg):\n",
        "        \"\"\"Adiciona uma nova troca de mensagens\"\"\"\n",
        "        # TODO: Implementar l√≥gica para:\n",
        "        # 1. Adicionar mensagem √† lista\n",
        "        # 2. Manter apenas as √∫ltimas 3\n",
        "        # 3. Extrair informa√ß√µes importantes (nome, idade, profiss√£o)\n",
        "        pass\n",
        "    \n",
        "    def get_contexto(self):\n",
        "        \"\"\"Retorna o contexto atual para o LLM\"\"\"\n",
        "        # TODO: Implementar l√≥gica para:\n",
        "        # 1. Formatar mensagens recentes\n",
        "        # 2. Incluir informa√ß√µes do usu√°rio\n",
        "        # 3. Retornar string formatada\n",
        "        pass\n",
        "\n",
        "# Teste sua implementa√ß√£o aqui:\n",
        "# memory_custom = MemoryCustomizada()\n",
        "# memory_custom.adicionar_mensagem(\"Oi, sou Jo√£o\", \"Prazer, Jo√£o!\")\n",
        "# print(memory_custom.get_contexto())\n",
        "\n",
        "print(\"üèóÔ∏è Seu turno! Implemente a MemoryCustomizada acima\")\n",
        "print(\"üí° Dica: Use regex ou split() para extrair informa√ß√µes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéÆ Exerc√≠cio 2: Sistema de Memory Inteligente\n\n**Desafio Avan√ßado**: Criar um sistema que **escolhe automaticamente** o tipo de mem√≥ria baseado no contexto!\n\n**Regras**:\n- Se conversa < 5 mensagens ‚Üí BufferMemory\n- Se conversa entre 5-15 mensagens ‚Üí WindowMemory\n- Se conversa > 15 mensagens ‚Üí SummaryBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# EXERC√çCIO 2: Sistema Inteligente de Memory\n",
        "class MemoryInteligente:\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "        self.contador_mensagens = 0\n",
        "        self.memory_atual = None\n",
        "        self.tipo_atual = None\n",
        "    \n",
        "    def escolher_memory_tipo(self):\n",
        "        \"\"\"Escolhe o tipo de mem√≥ria baseado no n√∫mero de mensagens\"\"\"\n",
        "        # TODO: Implementar l√≥gica de escolha\n",
        "        # Retorna: 'buffer', 'window', ou 'summary_buffer'\n",
        "        pass\n",
        "    \n",
        "    def processar_mensagem(self, input_msg):\n",
        "        \"\"\"Processa uma nova mensagem com a mem√≥ria apropriada\"\"\"\n",
        "        # TODO: Implementar l√≥gica para:\n",
        "        # 1. Incrementar contador\n",
        "        # 2. Escolher tipo de mem√≥ria\n",
        "        # 3. Migrar dados se necess√°rio\n",
        "        # 4. Processar mensagem\n",
        "        pass\n",
        "    \n",
        "    def migrar_memoria(self, memoria_antiga, tipo_novo):\n",
        "        \"\"\"Migra dados entre diferentes tipos de mem√≥ria\"\"\"\n",
        "        # TODO: Implementar migra√ß√£o de dados\n",
        "        pass\n",
        "\n",
        "# Teste seu sistema aqui:\n",
        "# memory_smart = MemoryInteligente(llm)\n",
        "# for i in range(20):\n",
        "#     resultado = memory_smart.processar_mensagem(f\"Mensagem {i+1}\")\n",
        "#     print(f\"Mensagem {i+1}: Usando {memory_smart.tipo_atual}\")\n",
        "\n",
        "print(\"üß† Desafio avan√ßado! Crie um sistema que se adapta automaticamente\")\n",
        "print(\"üéØ Objetivo: Otimizar performance baseado no tamanho da conversa\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Casos de Uso Reais\n\nVamos ver onde cada tipo de mem√≥ria brilha na vida real:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Simulando casos de uso reais\n",
        "casos_uso = {\n",
        "    \"üè• Suporte M√©dico\": {\n",
        "        \"memory\": \"SummaryBuffer\",\n",
        "        \"motivo\": \"Precisa lembrar hist√≥rico m√©dico completo + sintomas recentes\",\n",
        "        \"exemplo\": \"Paciente com diabetes menciona novos sintomas\"\n",
        "    },\n",
        "    \"üõí E-commerce\": {\n",
        "        \"memory\": \"Window\",\n",
        "        \"motivo\": \"Foco nos produtos vistos recentemente\",\n",
        "        \"exemplo\": \"Cliente comparando smartphones nas √∫ltimas mensagens\"\n",
        "    },\n",
        "    \"üìö Tutor Educacional\": {\n",
        "        \"memory\": \"Buffer\",\n",
        "        \"motivo\": \"Conversas curtas e focadas em exerc√≠cios espec√≠ficos\",\n",
        "        \"exemplo\": \"Explicando um conceito de matem√°tica\"\n",
        "    },\n",
        "    \"üíº Assistente Executivo\": {\n",
        "        \"memory\": \"SummaryBuffer\",\n",
        "        \"motivo\": \"Precisa lembrar decis√µes passadas + contexto atual\",\n",
        "        \"exemplo\": \"Acompanhando projeto de 6 meses com reuni√µes semanais\"\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"üéØ CASOS DE USO REAIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for caso, info in casos_uso.items():\n",
        "    print(f\"\\n{caso}\")\n",
        "    print(f\"   Memory: {info['memory']}\")\n",
        "    print(f\"   Por qu√™: {info['motivo']}\")\n",
        "    print(f\"   Exemplo: {info['exemplo']}\")\n",
        "\n",
        "print(\"\\nüí° A escolha da mem√≥ria pode fazer ou quebrar seu produto!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÆ Preparando para os Pr√≥ximos M√≥dulos\n\nLiiiindo! Agora que dominamos Memory Systems, vamos ver como isso se conecta com o que vem por a√≠:\n\n### üóÇÔ∏è M√≥dulo 6 - Document Loading\n- **Conex√£o**: Vamos usar mem√≥ria para lembrar de documentos processados\n- **Prepara√ß√£o**: Memory vai guardar contexto de m√∫ltiplos documentos\n\n### üîç M√≥dulo 7 - Vector Store\n- **Conex√£o**: Memory + Vector Store = busca sem√¢ntica com contexto\n- **Prepara√ß√£o**: Combinar mem√≥ria conversacional com busca em documentos\n\n### ü§ñ M√≥dulo 8 - RAG\n- **Conex√£o**: Memory √© ESSENCIAL no RAG para conversas contextuais\n- **Prepara√ß√£o**: \"Lembre do que discutimos sobre este documento\"\n\n**Dica do Pedro**: Memory √© a base para construir assistentes inteligentes de verdade!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Preview do que vem no pr√≥ximo m√≥dulo\n",
        "print(\"üîÆ PREVIEW - PR√ìXIMO M√ìDULO\")\n",
        "print(\"=\" * 40)\n",
        "print(\"üìö Document Loading & Splitters\")\n",
        "print(\"\")\n",
        "print(\"Vamos aprender a:\")\n",
        "print(\"‚Ä¢ Carregar PDFs, Word, websites\")\n",
        "print(\"‚Ä¢ Dividir documentos grandes\")\n",
        "print(\"‚Ä¢ Combinar com Memory Systems\")\n",
        "print(\"‚Ä¢ Preparar dados para RAG\")\n",
        "print(\"\")\n",
        "print(\"üöÄ Com Memory + Documents = Assistente que lembra E aprende!\")\n",
        "\n",
        "# Salvando um exemplo de memory para usar no pr√≥ximo m√≥dulo\n",
        "import pickle\n",
        "\n",
        "# Criando uma mem√≥ria de exemplo para carregar no pr√≥ximo m√≥dulo\n",
        "memory_exemplo = ConversationBufferMemory(return_messages=True)\n",
        "memory_exemplo.save_context(\n",
        "    {\"input\": \"Vou analisar alguns documentos sobre IA\"}, \n",
        "    {\"output\": \"Perfeito! Vou lembrar que voc√™ est√° interessado em documentos sobre IA!\"}\n",
        ")\n",
        "\n",
        "print(\"üíæ Mem√≥ria de exemplo salva para o pr√≥ximo m√≥dulo!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéä Resumo Final - O que Aprendemos\n\n### ‚úÖ Conceitos Dominados:\n\n1. **üß† Por que Memory √© Essencial**\n   - LLMs s√£o stateless por padr√£o\n   - Memory transforma bots em assistentes\n\n2. **üóÉÔ∏è ConversationBufferMemory**\n   - Guarda tudo\n   - Perfeito para conversas curtas\n\n3. **ü™ü ConversationBufferWindowMemory**\n   - Mant√©m √∫ltimas N mensagens\n   - Controla o tamanho do contexto\n\n4. **üìã ConversationSummaryMemory**\n   - Resume conversas automaticamente\n   - Muito eficiente em tokens\n\n5. **üîÑ ConversationSummaryBufferMemory**\n   - Melhor dos dois mundos\n   - Buffer recente + resumo antigo\n\n### üéØ Quando Usar Cada Um:\n\n| Cen√°rio | Memory Ideal | Por qu√™ |\n|---------|-------------|--------|\n| Chat suporte | Buffer | Conversas curtas e precisas |\n| Game/App | Window | Contexto recente mais importante |\n| Consultoria | Summary | Conversas muito longas |\n| Assistente corporativo | SummaryBuffer | Equilibrio perfeito |\n\n### üöÄ Pr√≥ximos Passos:\n- M√≥dulo 6: Document Loading (como dar \"conhecimento\" pro bot)\n- M√≥dulo 7: Vector Store (busca sem√¢ntica inteligente) \n- M√≥dulo 8: RAG (combinando tudo!)\n\n**Dica Final do Pedro**: Memory √© o primeiro passo para criar assistentes que realmente **entendem** e **lembram**. No pr√≥ximo m√≥dulo vamos dar \"conhecimento\" pra eles!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-05_img_01.png)"
      ]
    }
  ]
}