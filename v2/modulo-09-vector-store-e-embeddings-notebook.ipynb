{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† Vector Store e Embeddings: A Mem√≥ria Inteligente da IA\n\n**M√≥dulo 9 - Curso LangChain v0.3**\n\n*Por Pedro Guth*\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-09_img_01.png)\n\nBora entender como a IA consegue \"lembrar\" e encontrar informa√ß√µes relevantes de forma inteligente! üöÄ\n\nAt√© agora no nosso curso j√° vimos:\n- Como conversar com LLMs (ChatModel)\n- Como criar prompts inteligentes (Prompt Templates) \n- Como carregar e dividir documentos (Document Loading e Splitters)\n\nAgora vamos aprender como fazer a IA \"lembrar\" dessas informa√ß√µes de forma eficiente!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§î T√°, mas o que √© um Vector Store?\n\nImagina que voc√™ tem uma biblioteca gigante com milh√µes de livros. Como voc√™ encontraria rapidamente todos os livros sobre \"culin√°ria italiana\"?\n\nUm **Vector Store** √© como um bibliotec√°rio super inteligente que:\n1. L√™ cada livro e entende o \"significado\" dele\n2. Organiza os livros n√£o por ordem alfab√©tica, mas por **similaridade de conte√∫do**\n3. Quando voc√™ pergunta algo, ele encontra os livros mais relevantes instantaneamente\n\n### Como funciona na pr√°tica:\n- Cada texto √© convertido em **n√∫meros** (vetores)\n- Textos similares ficam \"pr√≥ximos\" no espa√ßo matem√°tico\n- Busca por similaridade ao inv√©s de palavras exatas\n\n**Dica!** Vector Stores s√£o essenciais para RAG (Retrieval Augmented Generation) que vamos ver no pr√≥ximo m√≥dulo!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ E o que s√£o Embeddings?\n\n**Embeddings** s√£o a m√°gica por tr√°s dos Vector Stores!\n\nPensa assim: como voc√™ explicaria para um computador a diferen√ßa entre \"cachorro\" e \"gato\"? \n\nEmbeddings fazem exatamente isso - eles convertem **palavras e textos em n√∫meros** que capturam o significado sem√¢ntico.\n\n### Exemplo conceitual:\n- \"Rei\" - \"Homem\" + \"Mulher\" = \"Rainha\"\n- \"Paris\" - \"Fran√ßa\" + \"Brasil\" = \"Bras√≠lia\"\n\n### Representa√ß√£o matem√°tica:\n$$\\text{Embedding} = [0.1, -0.3, 0.7, 0.2, \\ldots, 0.5]$$\n\nCada texto vira um vetor com centenas ou milhares de dimens√µes!\n\n**Dica!** Similaridade √© calculada usando dist√¢ncia coseno: $$\\text{similarity} = \\frac{A \\cdot B}{|A| \\times |B|}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos come√ßar instalando as bibliotecas que vamos usar\n",
        "!pip install langchain langchain-community langchain-openai faiss-cpu sentence-transformers python-dotenv\n",
        "\n",
        "# Imports b√°sicos\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Bibliotecas instaladas com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Setup do Ambiente LangChain\n\nAgora vamos configurar nosso ambiente para trabalhar com embeddings no LangChain. Vamos usar modelos gratuitos para come√ßar!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports do LangChain para embeddings e vector stores\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Vamos usar um modelo de embedding gratuito e bom em portugu√™s\n",
        "print(\"üîÑ Carregando modelo de embeddings...\")\n",
        "embeddings_model = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Modelo carregado! Este modelo entende portugu√™s e mais 49 idiomas!\")\n",
        "print(f\"Dimens√µes do vetor: {len(embeddings_model.embed_query('teste'))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Primeiro Experimento: Visualizando Embeddings\n\nVamos ver como palavras similares ficam pr√≥ximas no espa√ßo vetorial!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos testar com algumas palavras relacionadas\n",
        "palavras = [\n",
        "    \"cachorro\", \"gato\", \"animal\", \"pet\",\n",
        "    \"carro\", \"bicicleta\", \"transporte\", \"ve√≠culo\",\n",
        "    \"pizza\", \"macarr√£o\", \"comida\", \"restaurante\",\n",
        "    \"programa√ß√£o\", \"c√≥digo\", \"python\", \"desenvolvimento\"\n",
        "]\n",
        "\n",
        "print(\"üîÑ Gerando embeddings para as palavras...\")\n",
        "embeddings_list = []\n",
        "for palavra in palavras:\n",
        "    embedding = embeddings_model.embed_query(palavra)\n",
        "    embeddings_list.append(embedding)\n",
        "    \n",
        "# Convertendo para numpy array para facilitar os c√°lculos\n",
        "embeddings_array = np.array(embeddings_list)\n",
        "print(f\"‚úÖ Gerados {len(embeddings_list)} embeddings de {len(embeddings_list[0])} dimens√µes cada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos reduzir as dimens√µes para conseguir visualizar em 2D\n",
        "pca = PCA(n_components=2)\n",
        "embeddings_2d = pca.fit_transform(embeddings_array)\n",
        "\n",
        "# Criando o gr√°fico\n",
        "plt.figure(figsize=(12, 8))\n",
        "colors = ['red', 'red', 'red', 'red',      # animais\n",
        "         'blue', 'blue', 'blue', 'blue',   # transporte\n",
        "         'green', 'green', 'green', 'green', # comida\n",
        "         'orange', 'orange', 'orange', 'orange'] # programa√ß√£o\n",
        "\n",
        "for i, (palavra, cor) in enumerate(zip(palavras, colors)):\n",
        "    plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1], c=cor, s=100)\n",
        "    plt.annotate(palavra, (embeddings_2d[i, 0], embeddings_2d[i, 1]), \n",
        "                xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
        "\n",
        "plt.title('Visualiza√ß√£o de Embeddings - Palavras Similares Ficam Pr√≥ximas!', fontsize=14)\n",
        "plt.xlabel('Dimens√£o 1')\n",
        "plt.ylabel('Dimens√£o 2')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend(['Animais', 'Transporte', 'Comida', 'Programa√ß√£o'])\n",
        "plt.show()\n",
        "\n",
        "print(\"üéØ Liiindo! Veja como palavras do mesmo contexto ficam agrupadas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Calculando Similaridade\n\nAgora vamos calcular a similaridade entre palavras usando a **dist√¢ncia coseno**. Quanto mais pr√≥ximo de 1, mais similares s√£o as palavras!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculando matriz de similaridade\n",
        "similarity_matrix = cosine_similarity(embeddings_array)\n",
        "\n",
        "# Vamos ver alguns exemplos interessantes\n",
        "print(\"üîç SIMILARIDADES MAIS INTERESSANTES:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for i in range(len(palavras)):\n",
        "    for j in range(i+1, len(palavras)):\n",
        "        sim = similarity_matrix[i][j]\n",
        "        if sim > 0.5:  # S√≥ mostra similaridades altas\n",
        "            print(f\"{palavras[i]:12} ‚Üî {palavras[j]:12} | Similaridade: {sim:.3f}\")\n",
        "\n",
        "print(\"\\nüí° Valores pr√≥ximos de 1 = muito similares\")\n",
        "print(\"üí° Valores pr√≥ximos de 0 = pouco similares\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üóÉÔ∏è Criando nosso Primeiro Vector Store\n\nAgora vamos criar um Vector Store de verdade! Vamos simular uma base de conhecimento sobre tecnologia.\n\nLembra do m√≥dulo anterior onde aprendemos sobre Document Loading? Agora vamos usar esses conceitos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar alguns documentos sobre tecnologia\n",
        "documentos_texto = [\n",
        "    \"Python √© uma linguagem de programa√ß√£o interpretada, de alto n√≠vel e de prop√≥sito geral.\",\n",
        "    \"Machine Learning √© um ramo da intelig√™ncia artificial que usa algoritmos para aprender padr√µes.\",\n",
        "    \"O LangChain √© um framework para desenvolvimento de aplica√ß√µes com Large Language Models.\",\n",
        "    \"JavaScript √© a linguagem de programa√ß√£o mais popular para desenvolvimento web frontend.\",\n",
        "    \"Deep Learning usa redes neurais artificiais com m√∫ltiplas camadas para resolver problemas complexos.\",\n",
        "    \"React √© uma biblioteca JavaScript para constru√ß√£o de interfaces de usu√°rio interativas.\",\n",
        "    \"Natural Language Processing permite que computadores entendam e processem linguagem humana.\",\n",
        "    \"AWS √© a plataforma de computa√ß√£o em nuvem mais popular do mundo.\",\n",
        "    \"Docker √© uma plataforma que usa containers para facilitar o deployment de aplica√ß√µes.\",\n",
        "    \"Git √© um sistema de controle de vers√£o distribu√≠do usado para gerenciar c√≥digo fonte.\"\n",
        "]\n",
        "\n",
        "# Convertendo textos em objetos Document (como vimos no m√≥dulo anterior)\n",
        "documents = []\n",
        "for i, texto in enumerate(documentos_texto):\n",
        "    doc = Document(\n",
        "        page_content=texto,\n",
        "        metadata={\"id\": i, \"categoria\": \"tecnologia\"}\n",
        "    )\n",
        "    documents.append(doc)\n",
        "\n",
        "print(f\"‚úÖ Criados {len(documents)} documentos para indexar no vector store\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Agora vamos criar nosso Vector Store usando FAISS\n",
        "print(\"üîÑ Criando Vector Store...\")\n",
        "print(\"Isso pode demorar um pouquinho na primeira vez...\")\n",
        "\n",
        "# FAISS √© uma biblioteca super eficiente para busca por similaridade\n",
        "vector_store = FAISS.from_documents(\n",
        "    documents=documents,\n",
        "    embedding=embeddings_model\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Vector Store criado com sucesso!\")\n",
        "print(f\"üìö Indexados {len(documents)} documentos\")\n",
        "print(\"üéØ Agora podemos fazer buscas sem√¢nticas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Fazendo Buscas Sem√¢nticas\n\nAgora vem a parte mais legal! Vamos fazer perguntas e ver como o Vector Store encontra documentos relevantes baseado no **significado**, n√£o apenas nas palavras exatas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos fazer algumas consultas interessantes\n",
        "consultas = [\n",
        "    \"Como funciona intelig√™ncia artificial?\",\n",
        "    \"Qual linguagem usar para sites?\", \n",
        "    \"Como fazer deploy de aplica√ß√µes?\",\n",
        "    \"Ferramentas para gerenciar c√≥digo\",\n",
        "    \"Desenvolvimento de interfaces web\"\n",
        "]\n",
        "\n",
        "for consulta in consultas:\n",
        "    print(f\"\\nüîç BUSCA: '{consulta}'\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Busca pelos 2 documentos mais similares\n",
        "    docs_similares = vector_store.similarity_search(consulta, k=2)\n",
        "    \n",
        "    for i, doc in enumerate(docs_similares, 1):\n",
        "        print(f\"{i}. {doc.page_content}\")\n",
        "        \n",
        "    print(\"\\nüí° Veja como encontrou documentos relevantes mesmo sem usar as palavras exatas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Busca com Scores de Similaridade\n\nVamos ver exatamente **qu√£o similares** s√£o os documentos encontrados atrav√©s dos scores de similaridade."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fazendo busca com scores de similaridade\n",
        "consulta_teste = \"programa√ß√£o e desenvolvimento de software\"\n",
        "\n",
        "print(f\"üéØ AN√ÅLISE DETALHADA DA BUSCA: '{consulta_teste}'\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# similarity_search_with_score retorna documentos E seus scores\n",
        "docs_com_score = vector_store.similarity_search_with_score(consulta_teste, k=5)\n",
        "\n",
        "for i, (doc, score) in enumerate(docs_com_score, 1):\n",
        "    print(f\"\\n{i}. SCORE: {score:.4f}\")\n",
        "    print(f\"   TEXTO: {doc.page_content}\")\n",
        "    \n",
        "    # Vamos interpretar o score\n",
        "    if score < 0.5:\n",
        "        interpretacao = \"üü¢ Muito relevante\"\n",
        "    elif score < 1.0:\n",
        "        interpretacao = \"üü° Relevante\"\n",
        "    else:\n",
        "        interpretacao = \"üî¥ Pouco relevante\"\n",
        "    \n",
        "    print(f\"   RELEV√ÇNCIA: {interpretacao}\")\n",
        "\n",
        "print(\"\\nüìä No FAISS, scores MENORES = mais similares (√© uma dist√¢ncia!)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö° Diferentes Tipos de Vector Stores\n\nExistem v√°rios tipos de Vector Stores, cada um com suas vantagens:\n\n### üìã Principais op√ß√µes no LangChain:\n- **FAISS**: R√°pido, local, √≥timo para prototipagem\n- **Chroma**: Persistente, f√°cil de usar\n- **Pinecone**: Gerenciado, escal√°vel (pago)\n- **Weaviate**: Open source, recursos avan√ßados\n- **Qdrant**: Russo, muito r√°pido\n\n**Dica!** Para produ√ß√£o, considere options que persistem dados automaticamente!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos tamb√©m testar com Chroma (se dispon√≠vel)\n",
        "try:\n",
        "    from langchain_community.vectorstores import Chroma\n",
        "    \n",
        "    print(\"üîÑ Testando Chroma Vector Store...\")\n",
        "    \n",
        "    # Criando vector store com Chroma\n",
        "    chroma_store = Chroma.from_documents(\n",
        "        documents=documents[:3],  # S√≥ os primeiros 3 para testar\n",
        "        embedding=embeddings_model\n",
        "    )\n",
        "    \n",
        "    # Testando uma busca\n",
        "    resultado = chroma_store.similarity_search(\"linguagem de programa√ß√£o\", k=2)\n",
        "    \n",
        "    print(\"‚úÖ Chroma funcionando!\")\n",
        "    print(\"üîç Resultado da busca no Chroma:\")\n",
        "    for doc in resultado:\n",
        "        print(f\"   ‚Ä¢ {doc.page_content}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Chroma n√£o dispon√≠vel: {e}\")\n",
        "    print(\"üí° Isso √© normal! FAISS j√° √© suficiente para aprender\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ Persistindo e Carregando Vector Stores\n\nNa vida real, voc√™ n√£o quer recriar seu Vector Store toda vez! Vamos aprender a salvar e carregar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvando nosso Vector Store\n",
        "import os\n",
        "\n",
        "# Criando diret√≥rio para salvar\n",
        "save_directory = \"meu_vector_store\"\n",
        "if not os.path.exists(save_directory):\n",
        "    os.makedirs(save_directory)\n",
        "\n",
        "print(\"üíæ Salvando Vector Store...\")\n",
        "\n",
        "# FAISS permite salvar localmente\n",
        "vector_store.save_local(save_directory)\n",
        "\n",
        "print(f\"‚úÖ Vector Store salvo em: {save_directory}\")\n",
        "print(f\"üìÅ Arquivos criados: {os.listdir(save_directory)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Carregando Vector Store salvo\n",
        "print(\"üìÇ Carregando Vector Store salvo...\")\n",
        "\n",
        "# Carregando de volta\n",
        "vector_store_carregado = FAISS.load_local(\n",
        "    save_directory,\n",
        "    embeddings_model,\n",
        "    allow_dangerous_deserialization=True  # Necess√°rio para vers√µes mais recentes\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Vector Store carregado com sucesso!\")\n",
        "\n",
        "# Testando se funciona\n",
        "teste = vector_store_carregado.similarity_search(\"intelig√™ncia artificial\", k=1)\n",
        "print(f\"üß™ Teste: {teste[0].page_content}\")\n",
        "\n",
        "print(\"\\nüéØ Liiindo! Agora voc√™ pode salvar e carregar seus Vector Stores!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Adicionando Novos Documentos\n\nVector Stores n√£o s√£o est√°ticos! Voc√™ pode adicionar novos documentos dinamicamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos adicionar alguns documentos novos\n",
        "novos_textos = [\n",
        "    \"Kubernetes √© uma plataforma de orquestra√ß√£o de containers open-source.\",\n",
        "    \"FastAPI √© um framework web moderno e r√°pido para construir APIs com Python.\",\n",
        "    \"Pandas √© uma biblioteca Python essencial para an√°lise e manipula√ß√£o de dados.\"\n",
        "]\n",
        "\n",
        "# Convertendo em Documents\n",
        "novos_docs = []\n",
        "for i, texto in enumerate(novos_textos):\n",
        "    doc = Document(\n",
        "        page_content=texto,\n",
        "        metadata={\"id\": len(documents) + i, \"categoria\": \"tecnologia\", \"novo\": True}\n",
        "    )\n",
        "    novos_docs.append(doc)\n",
        "\n",
        "print(f\"‚ûï Adicionando {len(novos_docs)} novos documentos...\")\n",
        "\n",
        "# Adicionando ao vector store existente\n",
        "vector_store.add_documents(novos_docs)\n",
        "\n",
        "print(\"‚úÖ Documentos adicionados com sucesso!\")\n",
        "\n",
        "# Testando busca com os novos documentos\n",
        "resultado = vector_store.similarity_search(\"an√°lise de dados\", k=2)\n",
        "print(\"\\nüîç Testando busca com novos documentos:\")\n",
        "for doc in resultado:\n",
        "    print(f\"   ‚Ä¢ {doc.page_content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé® Visualizando o Vector Store Completo\n\nVamos criar uma visualiza√ß√£o legal de todo nosso vector store para entender como os documentos se organizam no espa√ßo vetorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos buscar todos os embeddings do nosso vector store\n",
        "# Para isso, vamos fazer uma busca bem gen√©rica que retorne muitos documentos\n",
        "todos_docs = vector_store.similarity_search(\"tecnologia programa√ß√£o\", k=20)\n",
        "\n",
        "print(f\"üìä Coletando embeddings de {len(todos_docs)} documentos...\")\n",
        "\n",
        "# Gerando embeddings de todos os documentos para visualizar\n",
        "doc_embeddings = []\n",
        "doc_labels = []\n",
        "\n",
        "for doc in todos_docs:\n",
        "    # Pegando s√≥ as primeiras palavras para o label\n",
        "    label = ' '.join(doc.page_content.split()[:3]) + '...'\n",
        "    doc_labels.append(label)\n",
        "    \n",
        "    # Gerando embedding\n",
        "    embedding = embeddings_model.embed_query(doc.page_content)\n",
        "    doc_embeddings.append(embedding)\n",
        "\n",
        "# Reduzindo dimensionalidade para visualizar\n",
        "doc_embeddings_array = np.array(doc_embeddings)\n",
        "pca_docs = PCA(n_components=2)\n",
        "docs_2d = pca_docs.fit_transform(doc_embeddings_array)\n",
        "\n",
        "print(\"‚úÖ Embeddings coletados! Criando visualiza√ß√£o...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando visualiza√ß√£o dos documentos no espa√ßo vetorial\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Definindo cores baseadas no tipo de tecnologia\n",
        "cores_por_tema = []\n",
        "for label in doc_labels:\n",
        "    if any(word in label.lower() for word in ['python', 'javascript', 'linguagem']):\n",
        "        cores_por_tema.append('red')\n",
        "    elif any(word in label.lower() for word in ['machine', 'deep', 'artificial', 'natural']):\n",
        "        cores_por_tema.append('blue')\n",
        "    elif any(word in label.lower() for word in ['react', 'web', 'interface']):\n",
        "        cores_por_tema.append('green')\n",
        "    elif any(word in label.lower() for word in ['aws', 'docker', 'kubernetes']):\n",
        "        cores_por_tema.append('orange')\n",
        "    else:\n",
        "        cores_por_tema.append('gray')\n",
        "\n",
        "# Plotando os pontos\n",
        "for i, (x, y) in enumerate(docs_2d):\n",
        "    plt.scatter(x, y, c=cores_por_tema[i], s=100, alpha=0.7)\n",
        "    plt.annotate(doc_labels[i], (x, y), xytext=(5, 5), \n",
        "                textcoords='offset points', fontsize=8, \n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))\n",
        "\n",
        "plt.title('Mapa do Vector Store - Documentos Similares Ficam Pr√≥ximos!', fontsize=16)\n",
        "plt.xlabel('Dimens√£o 1 (PCA)', fontsize=12)\n",
        "plt.ylabel('Dimens√£o 2 (PCA)', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Criando legenda\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [\n",
        "    Patch(facecolor='red', label='Linguagens de Programa√ß√£o'),\n",
        "    Patch(facecolor='blue', label='Intelig√™ncia Artificial'),\n",
        "    Patch(facecolor='green', label='Desenvolvimento Web'),\n",
        "    Patch(facecolor='orange', label='Infraestrutura/Cloud'),\n",
        "    Patch(facecolor='gray', label='Outros')\n",
        "]\n",
        "plt.legend(handles=legend_elements, loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéØ Liiindo! Veja como documentos similares se agrupam naturalmente!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõ†Ô∏è Exerc√≠cio Pr√°tico 1: Criando seu Vector Store\n\nAgora √© sua vez! Vamos criar um vector store sobre um tema diferente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ EXERC√çCIO: Complete o c√≥digo abaixo\n",
        "# Crie um vector store sobre culin√°ria brasileira\n",
        "\n",
        "# 1. Crie uma lista com pelo menos 5 frases sobre culin√°ria brasileira\n",
        "culinaria_textos = [\n",
        "    # Adicione suas frases aqui!\n",
        "    \"Feijoada √© um dos pratos mais tradicionais da culin√°ria brasileira.\",\n",
        "    # ... adicione mais 4 frases\n",
        "]\n",
        "\n",
        "# 2. Converta em Documents\n",
        "# Seu c√≥digo aqui...\n",
        "\n",
        "# 3. Crie o vector store\n",
        "# Seu c√≥digo aqui...\n",
        "\n",
        "# 4. Teste com uma busca sobre \"sobremesa brasileira\"\n",
        "# Seu c√≥digo aqui...\n",
        "\n",
        "print(\"üçΩÔ∏è Complete este exerc√≠cio para praticar!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîó Integrando com Chains (Prepara√ß√£o para RAG)\n\nLembra das Chains que vimos no m√≥dulo 6? Agora vamos conectar vector stores com chains, preparando o terreno para RAG no pr√≥ximo m√≥dulo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando uma chain simples que usa vector store\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# Fun√ß√£o simples para buscar documentos relevantes\n",
        "def buscar_documentos(query):\n",
        "    docs = vector_store.similarity_search(query, k=2)\n",
        "    # Juntando o conte√∫do dos documentos\n",
        "    contexto = \"\\n\".join([doc.page_content for doc in docs])\n",
        "    return contexto\n",
        "\n",
        "# Criando um template que usa o contexto do vector store\n",
        "template = \"\"\"Com base no seguinte contexto sobre tecnologia:\n",
        "\n",
        "CONTEXTO:\n",
        "{contexto}\n",
        "\n",
        "PERGUNTA: {pergunta}\n",
        "\n",
        "Responda de forma clara e baseada no contexto fornecido.\n",
        "RESPOSTA:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"contexto\", \"pergunta\"]\n",
        ")\n",
        "\n",
        "print(\"üîó Chain preparada para usar com vector store!\")\n",
        "print(\"üí° No pr√≥ximo m√≥dulo vamos ver como fazer isso com LLMs de verdade!\")\n",
        "\n",
        "# Testando a busca\n",
        "pergunta_teste = \"O que √© Python?\"\n",
        "contexto_encontrado = buscar_documentos(pergunta_teste)\n",
        "\n",
        "print(f\"\\nüîç Para a pergunta: '{pergunta_teste}'\")\n",
        "print(f\"üìö Contexto encontrado:\\n{contexto_encontrado}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Configura√ß√µes Avan√ßadas de Vector Stores\n\nVamos ver algumas configura√ß√µes mais avan√ßadas que voc√™ pode usar para otimizar seus vector stores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando diferentes algoritmos de busca\n",
        "print(\"üî¨ COMPARANDO DIFERENTES ALGORITMOS DE BUSCA\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "query_teste = \"desenvolvimento de aplica√ß√µes web\"\n",
        "\n",
        "# 1. Busca padr√£o por similaridade\n",
        "docs_similarity = vector_store.similarity_search(query_teste, k=3)\n",
        "print(\"\\n1Ô∏è‚É£ SIMILARITY SEARCH (padr√£o):\")\n",
        "for i, doc in enumerate(docs_similarity, 1):\n",
        "    texto_resumido = doc.page_content[:50] + \"...\"\n",
        "    print(f\"   {i}. {texto_resumido}\")\n",
        "\n",
        "# 2. Busca com MMR (Maximum Marginal Relevance)\n",
        "# MMR balanceia relev√¢ncia e diversidade\n",
        "try:\n",
        "    docs_mmr = vector_store.max_marginal_relevance_search(query_teste, k=3)\n",
        "    print(\"\\n2Ô∏è‚É£ MMR SEARCH (mais diverso):\")\n",
        "    for i, doc in enumerate(docs_mmr, 1):\n",
        "        texto_resumido = doc.page_content[:50] + \"...\"\n",
        "        print(f\"   {i}. {texto_resumido}\")\n",
        "except:\n",
        "    print(\"\\n2Ô∏è‚É£ MMR n√£o dispon√≠vel nesta vers√£o\")\n",
        "\n",
        "print(\"\\nüí° MMR √© √∫til quando voc√™ quer resultados relevantes MAS diversos!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä M√©tricas e Avalia√ß√£o de Vector Stores\n\nComo saber se seu vector store est√° funcionando bem? Vamos criar algumas m√©tricas simples!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando fun√ß√£o para avaliar qualidade das buscas\n",
        "def avaliar_vector_store(vector_store, queries_teste, respostas_esperadas):\n",
        "    \"\"\"\n",
        "    Avalia a qualidade de um vector store\n",
        "    \"\"\"\n",
        "    scores = []\n",
        "    \n",
        "    print(\"üìä AVALIANDO QUALIDADE DO VECTOR STORE\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    for i, (query, palavras_esperadas) in enumerate(zip(queries_teste, respostas_esperadas)):\n",
        "        # Busca o documento mais relevante\n",
        "        docs = vector_store.similarity_search(query, k=1)\n",
        "        \n",
        "        if docs:\n",
        "            documento_encontrado = docs[0].page_content.lower()\n",
        "            \n",
        "            # Conta quantas palavras-chave esperadas aparecem no resultado\n",
        "            palavras_encontradas = 0\n",
        "            for palavra in palavras_esperadas:\n",
        "                if palavra.lower() in documento_encontrado:\n",
        "                    palavras_encontradas += 1\n",
        "            \n",
        "            score = palavras_encontradas / len(palavras_esperadas)\n",
        "            scores.append(score)\n",
        "            \n",
        "            print(f\"\\nüîç Query {i+1}: '{query}'\")\n",
        "            print(f\"üìÑ Documento: {docs[0].page_content[:60]}...\")\n",
        "            print(f\"üéØ Score: {score:.2f} ({palavras_encontradas}/{len(palavras_esperadas)} palavras-chave)\")\n",
        "        else:\n",
        "            scores.append(0)\n",
        "    \n",
        "    score_medio = sum(scores) / len(scores) if scores else 0\n",
        "    print(f\"\\nüìä SCORE M√âDIO DO VECTOR STORE: {score_medio:.2f}\")\n",
        "    \n",
        "    return score_medio, scores\n",
        "\n",
        "# Definindo queries de teste\n",
        "queries_teste = [\n",
        "    \"linguagem para programar\",\n",
        "    \"intelig√™ncia artificial e aprendizado\", \n",
        "    \"desenvolvimento web frontend\"\n",
        "]\n",
        "\n",
        "# Palavras que esperamos encontrar em cada resposta\n",
        "respostas_esperadas = [\n",
        "    [\"python\", \"javascript\", \"linguagem\"],\n",
        "    [\"machine\", \"learning\", \"artificial\", \"deep\"],\n",
        "    [\"javascript\", \"react\", \"web\", \"frontend\"]\n",
        "]\n",
        "\n",
        "# Executando avalia√ß√£o\n",
        "score_final, scores_individuais = avaliar_vector_store(vector_store, queries_teste, respostas_esperadas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exerc√≠cio Final: Vector Store Completo\n\nHora do exerc√≠cio final! Vamos criar um vector store completo do zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ EXERC√çCIO FINAL: Vector Store sobre Esportes\n",
        "# Sua miss√£o: criar um sistema completo de busca sobre esportes\n",
        "\n",
        "print(\"üèÜ EXERC√çCIO FINAL: Sistema de Busca sobre Esportes\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nüìù TAREFAS:\")\n",
        "print(\"1. Criar pelo menos 8 documentos sobre diferentes esportes\")\n",
        "print(\"2. Criar o vector store\")\n",
        "print(\"3. Fazer 3 buscas diferentes\")\n",
        "print(\"4. Salvar o vector store\")\n",
        "print(\"5. Adicionar 2 novos documentos\")\n",
        "print(\"6. Testar uma busca final\")\n",
        "\n",
        "# Comece aqui!\n",
        "# Dica: use esportes como futebol, basquete, t√™nis, nata√ß√£o, etc.\n",
        "\n",
        "# 1. Seus documentos sobre esportes:\n",
        "esportes_docs = [\n",
        "    # Complete com pelo menos 8 frases sobre esportes!\n",
        "]\n",
        "\n",
        "print(\"\\nüöÄ Complete este exerc√≠cio para dominar vector stores!\")\n",
        "print(\"üí° Dica: pense em diferentes aspectos - regras, equipamentos, hist√≥ria...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéä Resumo e Pr√≥ximos Passos\n\n**Parab√©ns! Voc√™ dominou Vector Stores e Embeddings! üéâ**\n\n### üìö O que aprendemos:\n- ‚úÖ **Embeddings**: Como transformar texto em vetores num√©ricos\n- ‚úÖ **Vector Stores**: Como armazenar e buscar por similaridade sem√¢ntica\n- ‚úÖ **FAISS**: Vector store r√°pido para prototipagem\n- ‚úÖ **Busca Sem√¢ntica**: Encontrar documentos por significado, n√£o palavras exatas\n- ‚úÖ **Persist√™ncia**: Salvar e carregar vector stores\n- ‚úÖ **M√©tricas**: Avaliar a qualidade das buscas\n\n### üîÑ Conex√£o com o curso:\n- **M√≥dulos anteriores**: Usamos Documents do m√≥dulo 8\n- **Pr√≥ximo m√≥dulo**: RAG (Retrieval Augmented Generation) - onde vamos conectar vector stores com LLMs!\n\n### üéØ **No pr√≥ximo m√≥dulo (RAG)** vamos:\n- Conectar vector stores com Gemini/ChatGPT\n- Fazer perguntas e obter respostas baseadas em nossos documentos\n- Criar um sistema completo de Q&A\n\n**Dica!** Vector Stores s√£o a base de quase todas as aplica√ß√µes modernas de IA que trabalham com documentos!\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-09_img_02.png)"
      ]
    }
  ]
}