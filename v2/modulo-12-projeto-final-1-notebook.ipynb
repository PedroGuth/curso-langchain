{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🚀 Projeto Final 1: Assistente de Análise de Documentos com RAG e Agents\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-12_img_01.png)\n\n---\n\n**Bora colocar a mão na massa!** 🎯\n\nTá, chegamos no momento mais esperado do curso! Depois de aprender todos os conceitos do LangChain v0.3, vamos criar nosso primeiro projeto completo. É tipo quando você aprende a dirigir e finalmente pega a estrada - aqui vamos juntar **TUDO** que vimos até agora!\n\n## O que vamos construir?\n\nUm **Assistente Inteligente de Análise de Documentos** que vai:\n- 📄 **Carregar e processar** documentos (PDF, TXT, etc.)\n- 🧠 **Usar RAG** para responder perguntas sobre os documentos\n- 🔧 **Agents com ferramentas** para análises avançadas\n- 📊 **Gerar resumos e insights** automáticos\n- 💾 **Memória conversacional** para contexto\n\nÉ como ter um assistente pessoal que lê seus documentos e responde qualquer pergunta sobre eles!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Objetivos do Projeto\n\n**Por que esse projeto é importante?**\n\nSimples: vamos integrar **TODOS** os módulos que estudamos:\n\n- ✅ **ChatModel**: Gemini 2.0 Flash como nosso cérebro\n- ✅ **LCEL**: Chains elegantes e eficientes\n- ✅ **Prompt Templates**: Templates profissionais\n- ✅ **Output Parsers**: Respostas estruturadas\n- ✅ **Memory Systems**: Conversação com contexto\n- ✅ **Document Loading**: Carregar qualquer documento\n- ✅ **Vector Stores**: Busca semântica eficiente\n- ✅ **RAG**: Respostas baseadas nos documentos\n- ✅ **Agents & Tools**: Funcionalidades avançadas\n\n**Dica!** Este projeto vai ser nosso \"portfólio\" - algo que você pode mostrar e usar no trabalho!\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-12_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Primeiro, vamos instalar tudo que precisamos\n",
        "# É como preparar a cozinha antes de fazer um bolo!\n",
        "\n",
        "!pip install langchain==0.3.* -q\n",
        "!pip install langchain-google-genai -q\n",
        "!pip install langchain-community -q\n",
        "!pip install chromadb -q\n",
        "!pip install pypdf -q\n",
        "!pip install python-dotenv -q\n",
        "!pip install matplotlib -q\n",
        "!pip install wordcloud -q\n",
        "!pip install pandas -q\n",
        "\n",
        "print(\"📦 Todas as dependências instaladas com sucesso!\")\n",
        "print(\"🎯 Bora começar nosso projeto!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports necessários - nossa \"caixa de ferramentas\"\n",
        "import os\n",
        "from getpass import getpass\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# LangChain Core\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
        "\n",
        "# LangChain Components\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.agents import create_react_agent, AgentExecutor\n",
        "from langchain.tools import Tool\n",
        "\n",
        "# Para estruturar nossas respostas\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "print(\"🔧 Imports carregados!\")\n",
        "print(\"📚 Vamos usar TUDO que aprendemos no curso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔑 Configuração Inicial\n\n**Tá, mas antes de começar...**\n\nPrecisamos configurar nossa **API Key do Google AI**. É como a chave do carro - sem ela, não saímos do lugar!\n\nLembra do **Módulo 2** onde configuramos o ChatModel? Vamos fazer igualzinho, mas agora de forma mais robusta para o projeto.\n\n**Dica!** Se você não tem a API Key ainda, pega no [Google AI Studio](https://makersuite.google.com/app/apikey) - é grátis!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuração da API Key\n",
        "# Método mais seguro para projetos reais!\n",
        "\n",
        "def configurar_api_key():\n",
        "    \"\"\"Configura a API Key do Google de forma segura\"\"\"\n",
        "    \n",
        "    # Tenta pegar da variável de ambiente primeiro\n",
        "    api_key = os.getenv('GOOGLE_API_KEY')\n",
        "    \n",
        "    if not api_key:\n",
        "        print(\"🔑 API Key não encontrada nas variáveis de ambiente\")\n",
        "        print(\"Digite sua Google AI API Key:\")\n",
        "        api_key = getpass(\"API Key: \")\n",
        "        \n",
        "        # Salva na sessão atual\n",
        "        os.environ['GOOGLE_API_KEY'] = api_key\n",
        "    \n",
        "    return api_key\n",
        "\n",
        "# Configura nossa API\n",
        "api_key = configurar_api_key()\n",
        "print(\"✅ API Key configurada com sucesso!\")\n",
        "print(\"🚀 Pronto para usar o Gemini 2.0 Flash!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializando nossos componentes principais\n",
        "# É como montar a equipe dos Vingadores!\n",
        "\n",
        "# 1. ChatModel - Nosso cérebro principal (Módulo 2)\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0.3,  # Um pouco de criatividade, mas controlada\n",
        "    google_api_key=api_key\n",
        ")\n",
        "\n",
        "# 2. Embeddings - Para busca semântica (Módulo 9)\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    google_api_key=api_key\n",
        ")\n",
        "\n",
        "# 3. Text Splitter - Para quebrar documentos (Módulo 8)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
        ")\n",
        "\n",
        "# 4. Memory - Para lembrar da conversa (Módulo 7)\n",
        "memory = ConversationBufferWindowMemory(\n",
        "    k=5,  # Lembra das últimas 5 interações\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "print(\"🧠 LLM inicializado - Gemini 2.0 Flash pronto!\")\n",
        "print(\"🔍 Embeddings configurados para busca semântica!\")\n",
        "print(\"✂️ Text Splitter pronto para processar documentos!\")\n",
        "print(\"💾 Memória configurada para conversação!\")\n",
        "print(\"\")\n",
        "print(\"🎯 Todos os componentes principais prontos!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Arquitetura do Projeto\n\n**Tá, mas como tudo isso vai funcionar junto?**\n\nVou explicar nossa arquitetura como se fosse uma **empresa bem organizada**:\n\n```mermaid\ngraph TD\n    A[Usuário] --> B[Interface Principal]\n    B --> C[Gerenciador de Documentos]\n    B --> D[Sistema RAG]\n    B --> E[Agent Coordinator]\n    \n    C --> F[Document Loader]\n    C --> G[Text Splitter]\n    G --> H[Vector Store]\n    \n    D --> H\n    D --> I[Retriever]\n    I --> J[LLM + RAG Chain]\n    \n    E --> K[Análise Tool]\n    E --> L[Resumo Tool]\n    E --> M[Visualização Tool]\n    \n    J --> N[Resposta Final]\n    K --> N\n    L --> N\n    M --> N\n```\n\n**Cada parte tem sua função:**\n- 📄 **Gerenciador de Documentos**: Recebe e processa arquivos\n- 🔍 **Sistema RAG**: Busca informações relevantes\n- 🤖 **Agent Coordinator**: Decide qual ferramenta usar\n- 🛠️ **Tools**: Executam tarefas específicas\n\n**Dica!** É como ter um assistente que sabe exatamente onde buscar cada informação!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📄 Classe para Estruturar Respostas\n\n**Lembra do Módulo 5 sobre Output Parsers?**\n\nVamos usar **Pydantic** para estruturar nossas respostas. É como ter um **formulário** que garante que o LLM sempre responde do jeito certo!\n\nTipo quando você vai no médico e ele tem aquela fichinha padronizada - aqui é a mesma coisa!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estruturas para respostas organizadas\n",
        "# É como criar \"formulários\" para o LLM preencher!\n",
        "\n",
        "class DocumentSummary(BaseModel):\n",
        "    \"\"\"Estrutura para resumos de documentos\"\"\"\n",
        "    titulo: str = Field(description=\"Título ou tópico principal do documento\")\n",
        "    resumo_executivo: str = Field(description=\"Resumo em 2-3 frases\")\n",
        "    pontos_principais: List[str] = Field(description=\"Lista dos pontos mais importantes\")\n",
        "    palavras_chave: List[str] = Field(description=\"Palavras-chave principais\")\n",
        "    conclusoes: str = Field(description=\"Principais conclusões\")\n",
        "\n",
        "class DocumentAnalysis(BaseModel):\n",
        "    \"\"\"Estrutura para análise detalhada\"\"\"\n",
        "    tipo_documento: str = Field(description=\"Tipo de documento (relatório, artigo, etc.)\")\n",
        "    complexidade: str = Field(description=\"Nível de complexidade (baixo/médio/alto)\")\n",
        "    temas_abordados: List[str] = Field(description=\"Principais temas\")\n",
        "    publico_alvo: str = Field(description=\"Público-alvo sugerido\")\n",
        "    qualidade_informacao: int = Field(description=\"Qualidade de 1-10\")\n",
        "    recomendacoes: List[str] = Field(description=\"Recomendações de uso\")\n",
        "\n",
        "# Criando os parsers\n",
        "summary_parser = PydanticOutputParser(pydantic_object=DocumentSummary)\n",
        "analysis_parser = PydanticOutputParser(pydantic_object=DocumentAnalysis)\n",
        "\n",
        "print(\"📋 Estruturas de dados criadas!\")\n",
        "print(\"✅ Output Parsers configurados!\")\n",
        "print(\"🎯 Agora nossas respostas serão sempre organizadas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🏗️ Construindo o Gerenciador de Documentos\n\n**Agora vamos criar nosso primeiro componente principal!**\n\nO **Gerenciador de Documentos** vai fazer tudo que aprendemos nos **Módulos 8 e 9**:\n- Carregar arquivos (PDF, TXT)\n- Quebrar em chunks inteligentes\n- Criar embeddings\n- Armazenar no Vector Store\n\nÉ como ter uma **biblioteca inteligente** que organiza todos os livros e sabe exatamente onde encontrar qualquer informação!\n\n**Dica!** Vamos usar ChromaDB como nosso vector store - é rápido e funciona local!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gerenciador de Documentos - Nossa \"biblioteca inteligente\"\n",
        "\n",
        "class DocumentManager:\n",
        "    \"\"\"Gerencia todos os documentos do projeto\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.vector_store = None\n",
        "        self.documents = []\n",
        "        self.document_info = []\n",
        "        \n",
        "    def carregar_documento(self, caminho_arquivo, tipo_arquivo=\"auto\"):\n",
        "        \"\"\"Carrega um documento (PDF ou TXT)\"\"\"\n",
        "        \n",
        "        print(f\"📄 Carregando documento: {caminho_arquivo}\")\n",
        "        \n",
        "        try:\n",
        "            # Detecta o tipo automaticamente\n",
        "            if tipo_arquivo == \"auto\":\n",
        "                if caminho_arquivo.lower().endswith('.pdf'):\n",
        "                    loader = PyPDFLoader(caminho_arquivo)\n",
        "                elif caminho_arquivo.lower().endswith('.txt'):\n",
        "                    loader = TextLoader(caminho_arquivo, encoding='utf-8')\n",
        "                else:\n",
        "                    raise ValueError(\"Tipo de arquivo não suportado\")\n",
        "            \n",
        "            # Carrega o documento\n",
        "            docs = loader.load()\n",
        "            \n",
        "            # Adiciona metadados\n",
        "            for doc in docs:\n",
        "                doc.metadata['arquivo'] = caminho_arquivo\n",
        "                doc.metadata['tipo'] = tipo_arquivo\n",
        "            \n",
        "            self.documents.extend(docs)\n",
        "            \n",
        "            print(f\"✅ Documento carregado: {len(docs)} páginas/seções\")\n",
        "            return docs\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao carregar documento: {str(e)}\")\n",
        "            return None\n",
        "    \n",
        "    def processar_documentos(self):\n",
        "        \"\"\"Processa todos os documentos carregados\"\"\"\n",
        "        \n",
        "        if not self.documents:\n",
        "            print(\"⚠️ Nenhum documento carregado!\")\n",
        "            return\n",
        "        \n",
        "        print(\"🔄 Processando documentos...\")\n",
        "        \n",
        "        # Quebra em chunks (Módulo 8)\n",
        "        chunks = text_splitter.split_documents(self.documents)\n",
        "        print(f\"✂️ Documentos divididos em {len(chunks)} chunks\")\n",
        "        \n",
        "        # Cria o vector store (Módulo 9)\n",
        "        self.vector_store = Chroma.from_documents(\n",
        "            documents=chunks,\n",
        "            embedding=embeddings,\n",
        "            collection_name=\"documentos_projeto\"\n",
        "        )\n",
        "        \n",
        "        print(\"🔍 Vector Store criado com embeddings!\")\n",
        "        print(f\"📚 {len(chunks)} chunks indexados e prontos para busca!\")\n",
        "        \n",
        "        return chunks\n",
        "    \n",
        "    def buscar_documentos(self, query, k=5):\n",
        "        \"\"\"Busca documentos relevantes para uma query\"\"\"\n",
        "        \n",
        "        if not self.vector_store:\n",
        "            print(\"⚠️ Vector Store não foi criado ainda!\")\n",
        "            return []\n",
        "        \n",
        "        # Busca semântica\n",
        "        results = self.vector_store.similarity_search(query, k=k)\n",
        "        return results\n",
        "\n",
        "# Instancia nosso gerenciador\n",
        "doc_manager = DocumentManager()\n",
        "\n",
        "print(\"📚 Gerenciador de Documentos criado!\")\n",
        "print(\"🎯 Pronto para carregar e processar arquivos!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📝 Criando um Documento de Exemplo\n\n**Vamos criar um documento de teste para não ficar na teoria!**\n\nComo não temos um arquivo físico aqui, vou criar um **documento de exemplo** sobre IA e tecnologia. É como ter um \"documento de demonstração\" para testar nosso sistema!\n\n**Dica!** Em um projeto real, você carregaria PDFs ou TXTs que já existem!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando um documento de exemplo para testar nosso sistema\n",
        "# É como criar um \"dataset\" de demonstração!\n",
        "\n",
        "documento_exemplo = \"\"\"\n",
        "RELATÓRIO: INTELIGÊNCIA ARTIFICIAL NO BRASIL 2024\n",
        "\n",
        "RESUMO EXECUTIVO\n",
        "A Inteligência Artificial (IA) tem transformado significativamente o cenário tecnológico brasileiro. \n",
        "Este relatório apresenta uma análise abrangente do estado atual da IA no país, destacando \n",
        "avanços, desafios e oportunidades futuras.\n",
        "\n",
        "INTRODUÇÃO\n",
        "O Brasil está emergindo como um player importante no cenário global de IA. Com investimentos \n",
        "crescentes em pesquisa e desenvolvimento, o país tem demonstrado capacidade de inovação \n",
        "em diversas áreas tecnológicas.\n",
        "\n",
        "PRINCIPAIS AVANÇOS\n",
        "1. Investimentos em Startups: O setor de IA recebeu mais de R$ 2 bilhões em investimentos em 2023.\n",
        "2. Pesquisa Acadêmica: Universidades brasileiras publicaram mais de 1.500 artigos científicos sobre IA.\n",
        "3. Aplicações Práticas: Implementação de IA em saúde, agricultura, fintech e educação.\n",
        "4. Políticas Públicas: Criação do Marco Legal da IA e incentivos governamentais.\n",
        "\n",
        "DESAFIOS IDENTIFICADOS\n",
        "- Falta de profissionais qualificados\n",
        "- Infraestrutura de dados limitada\n",
        "- Questões regulatórias em desenvolvimento\n",
        "- Desigualdade no acesso à tecnologia\n",
        "\n",
        "SETORES EM DESTAQUE\n",
        "\n",
        "Saúde:\n",
        "A IA está revolucionando diagnósticos médicos, com sistemas capazes de detectar \n",
        "doenças com 95% de precisão. Telemedicina e análise de imagens médicas são \n",
        "as principais aplicações.\n",
        "\n",
        "Agricultura:\n",
        "O agronegócio brasileiro utiliza IA para otimização de plantios, previsão de safras \n",
        "e manejo sustentável. Drones e sensores IoT coletam dados para análises preditivas.\n",
        "\n",
        "Fintech:\n",
        "Bancos digitais e fintechs usam IA para análise de crédito, detecção de fraudes \n",
        "e personalização de serviços financeiros.\n",
        "\n",
        "PERSPECTIVAS FUTURAS\n",
        "Espera-se que o mercado de IA no Brasil cresça 40% ao ano nos próximos 5 anos. \n",
        "Investimentos em educação e capacitação são essenciais para sustentar esse crescimento.\n",
        "\n",
        "RECOMENDAÇÕES\n",
        "1. Ampliar programas de capacitação em IA\n",
        "2. Melhorar infraestrutura de dados\n",
        "3. Fomentar parcerias público-privadas\n",
        "4. Desenvolver regulamentação adequada\n",
        "5. Promover inclusão digital\n",
        "\n",
        "CONCLUSÃO\n",
        "O Brasil possui potencial significativo para se tornar uma referência em IA na América Latina. \n",
        "Com investimentos adequados e políticas públicas efetivas, o país pode aproveitar \n",
        "as oportunidades desta revolução tecnológica.\n",
        "\"\"\"\n",
        "\n",
        "# Salvando o documento em um arquivo temporário\n",
        "with open('relatorio_ia_brasil.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(documento_exemplo)\n",
        "\n",
        "print(\"📄 Documento de exemplo criado: 'relatorio_ia_brasil.txt'\")\n",
        "print(f\"📏 Tamanho: {len(documento_exemplo)} caracteres\")\n",
        "print(\"🎯 Pronto para testar nosso sistema!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando nosso Gerenciador de Documentos\n",
        "# Hora do show! 🎭\n",
        "\n",
        "print(\"🚀 Testando o carregamento de documentos...\")\n",
        "print(\"\" + \"=\"*50)\n",
        "\n",
        "# Carrega o documento\n",
        "docs = doc_manager.carregar_documento('relatorio_ia_brasil.txt')\n",
        "\n",
        "if docs:\n",
        "    print(f\"\\n📊 Informações do documento:\")\n",
        "    print(f\"   - Número de seções: {len(docs)}\")\n",
        "    print(f\"   - Caracteres totais: {sum(len(doc.page_content) for doc in docs)}\")\n",
        "    print(f\"   - Primeira linha: {docs[0].page_content[:100]}...\")\n",
        "\n",
        "print(\"\\n🔄 Processando documento...\")\n",
        "chunks = doc_manager.processar_documentos()\n",
        "\n",
        "if chunks:\n",
        "    print(f\"\\n✅ Processamento concluído!\")\n",
        "    print(f\"   - Chunks criados: {len(chunks)}\")\n",
        "    print(f\"   - Vector Store: ativo\")\n",
        "    print(f\"   - Embeddings: gerados\")\n",
        "\n",
        "print(\"\\n🎯 Sistema pronto para responder perguntas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔍 Sistema RAG - Recuperação e Geração\n\n**Agora vem a parte mais legal!**\n\nLembra do **Módulo 10 sobre RAG**? Vamos implementar nosso sistema completo que:\n1. 🔍 **Busca** informações relevantes no documento\n2. 🧠 **Gera** respostas baseadas no contexto encontrado\n3. 📋 **Estrutura** a resposta de forma organizada\n\nÉ como ter um **assistente pessoal** que leu todos os seus documentos e pode responder qualquer pergunta sobre eles!\n\n**Dica!** Vamos usar **LCEL** (Módulo 3) para criar chains elegantes e eficientes!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sistema RAG completo - O cérebro do nosso assistente!\n",
        "# Combinando Módulos 3, 4, 5 e 10\n",
        "\n",
        "class RAGSystem:\n",
        "    \"\"\"Sistema completo de RAG para nosso assistente\"\"\"\n",
        "    \n",
        "    def __init__(self, document_manager, llm):\n",
        "        self.doc_manager = document_manager\n",
        "        self.llm = llm\n",
        "        self.setup_chains()\n",
        "    \n",
        "    def setup_chains(self):\n",
        "        \"\"\"Configura todas as chains do sistema\"\"\"\n",
        "        \n",
        "        # 1. Chain para respostas gerais (Módulo 4 - Prompt Templates)\n",
        "        self.qa_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "        Você é um assistente especializado em análise de documentos.\n",
        "        \n",
        "        CONTEXTO DOS DOCUMENTOS:\n",
        "        {context}\n",
        "        \n",
        "        PERGUNTA DO USUÁRIO:\n",
        "        {question}\n",
        "        \n",
        "        INSTRUÇÕES:\n",
        "        - Use APENAS as informações do contexto fornecido\n",
        "        - Se a informação não estiver no contexto, diga que não foi encontrada\n",
        "        - Seja claro, objetivo e profissional\n",
        "        - Cite trechos relevantes quando apropriado\n",
        "        - Forneça uma resposta completa e útil\n",
        "        \n",
        "        RESPOSTA:\n",
        "        \"\"\")\n",
        "        \n",
        "        # 2. Chain para resumos estruturados\n",
        "        self.summary_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "        Analise o documento fornecido e crie um resumo estruturado.\n",
        "        \n",
        "        DOCUMENTO:\n",
        "        {document}\n",
        "        \n",
        "        {format_instructions}\n",
        "        \"\"\")\n",
        "        \n",
        "        # 3. Chain para análise detalhada\n",
        "        self.analysis_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "        Faça uma análise detalhada do documento fornecido.\n",
        "        \n",
        "        DOCUMENTO:\n",
        "        {document}\n",
        "        \n",
        "        {format_instructions}\n",
        "        \"\"\")\n",
        "        \n",
        "        # Criando as chains com LCEL (Módulo 3)\n",
        "        self.qa_chain = (\n",
        "            {\"context\": self.retrieve_context, \"question\": RunnablePassthrough()}\n",
        "            | self.qa_prompt\n",
        "            | self.llm\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "        \n",
        "        self.summary_chain = (\n",
        "            {\n",
        "                \"document\": RunnablePassthrough(),\n",
        "                \"format_instructions\": lambda _: summary_parser.get_format_instructions()\n",
        "            }\n",
        "            | self.summary_prompt\n",
        "            | self.llm\n",
        "            | summary_parser\n",
        "        )\n",
        "        \n",
        "        self.analysis_chain = (\n",
        "            {\n",
        "                \"document\": RunnablePassthrough(),\n",
        "                \"format_instructions\": lambda _: analysis_parser.get_format_instructions()\n",
        "            }\n",
        "            | self.analysis_prompt\n",
        "            | self.llm\n",
        "            | analysis_parser\n",
        "        )\n",
        "    \n",
        "    def retrieve_context(self, question):\n",
        "        \"\"\"Busca contexto relevante nos documentos\"\"\"\n",
        "        \n",
        "        if not self.doc_manager.vector_store:\n",
        "            return \"Nenhum documento foi carregado.\"\n",
        "        \n",
        "        # Busca documentos relevantes\n",
        "        relevant_docs = self.doc_manager.buscar_documentos(question, k=3)\n",
        "        \n",
        "        # Combina o contexto\n",
        "        context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
        "        return context\n",
        "    \n",
        "    def responder_pergunta(self, pergunta):\n",
        "        \"\"\"Responde uma pergunta usando RAG\"\"\"\n",
        "        return self.qa_chain.invoke(pergunta)\n",
        "    \n",
        "    def gerar_resumo(self, documento=None):\n",
        "        \"\"\"Gera resumo estruturado do documento\"\"\"\n",
        "        if documento is None:\n",
        "            documento = \"\\n\".join([doc.page_content for doc in self.doc_manager.documents])\n",
        "        \n",
        "        return self.summary_chain.invoke(documento)\n",
        "    \n",
        "    def gerar_analise(self, documento=None):\n",
        "        \"\"\"Gera análise detalhada do documento\"\"\"\n",
        "        if documento is None:\n",
        "            documento = \"\\n\".join([doc.page_content for doc in self.doc_manager.documents])\n",
        "        \n",
        "        return self.analysis_chain.invoke(documento)\n",
        "\n",
        "# Instancia nosso sistema RAG\n",
        "rag_system = RAGSystem(doc_manager, llm)\n",
        "\n",
        "print(\"🧠 Sistema RAG criado com sucesso!\")\n",
        "print(\"✅ Chains configuradas:\")\n",
        "print(\"   - 🔍 Q&A Chain (perguntas e respostas)\")\n",
        "print(\"   - 📋 Summary Chain (resumos estruturados)\")\n",
        "print(\"   - 📊 Analysis Chain (análise detalhada)\")\n",
        "print(\"🎯 Sistema pronto para usar!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧪 Testando o Sistema RAG\n\n**Hora de testar nosso sistema!**\n\nVamos fazer algumas perguntas sobre o documento e ver como nosso **RAG** se comporta. É como fazer uma \"entrevista\" com nosso assistente!\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-12_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando o sistema RAG com perguntas sobre o documento\n",
        "# É como fazer um \"teste de mesa\" do nosso assistente!\n",
        "\n",
        "print(\"🧪 TESTANDO SISTEMA RAG\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Lista de perguntas para testar\n",
        "perguntas_teste = [\n",
        "    \"Quanto foi investido em startups de IA no Brasil em 2023?\",\n",
        "    \"Quais são os principais desafios da IA no Brasil?\",\n",
        "    \"Como a IA está sendo usada na agricultura brasileira?\",\n",
        "    \"Qual é a perspectiva de crescimento do mercado de IA?\",\n",
        "    \"Quais são as recomendações do relatório?\"\n",
        "]\n",
        "\n",
        "# Testa cada pergunta\n",
        "for i, pergunta in enumerate(perguntas_teste, 1):\n",
        "    print(f\"\\n🤔 PERGUNTA {i}: {pergunta}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    try:\n",
        "        resposta = rag_system.responder_pergunta(pergunta)\n",
        "        print(f\"🤖 RESPOSTA: {resposta}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro: {str(e)}\")\n",
        "    \n",
        "    print(\"-\" * 40)\n",
        "\n",
        "print(\"\\n✅ Teste do sistema RAG concluído!\")\n",
        "print(\"🎯 O assistente está funcionando perfeitamente!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando a geração de resumo estruturado\n",
        "# Usando nosso Output Parser do Módulo 5!\n",
        "\n",
        "print(\"📋 GERANDO RESUMO ESTRUTURADO\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "try:\n",
        "    resumo = rag_system.gerar_resumo()\n",
        "    \n",
        "    print(f\"📄 TÍTULO: {resumo.titulo}\")\n",
        "    print(f\"\\n📝 RESUMO EXECUTIVO:\\n{resumo.resumo_executivo}\")\n",
        "    \n",
        "    print(f\"\\n🎯 PONTOS PRINCIPAIS:\")\n",
        "    for i, ponto in enumerate(resumo.pontos_principais, 1):\n",
        "        print(f\"   {i}. {ponto}\")\n",
        "    \n",
        "    print(f\"\\n🔑 PALAVRAS-CHAVE: {', '.join(resumo.palavras_chave)}\")\n",
        "    \n",
        "    print(f\"\\n💡 CONCLUSÕES:\\n{resumo.conclusoes}\")\n",
        "    \n",
        "    print(\"\\n✅ Resumo estruturado gerado com sucesso!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Erro ao gerar resumo: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🛠️ Criando Ferramentas para o Agent\n\n**Agora vamos usar o que aprendemos no Módulo 11!**\n\nVamos criar **Tools** especializadas que nosso **Agent** pode usar. É como dar uma \"caixa de ferramentas\" para o assistente!\n\nCada ferramenta vai ter uma **especialidade**:\n- 📊 **Análise de Dados**: Estatísticas sobre o documento\n- 🎨 **Visualização**: Gráficos e nuvem de palavras\n- 📋 **Relatórios**: Resumos e análises estruturadas\n\n**Dica!** É como ter especialistas diferentes trabalhando em equipe!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando ferramentas especializadas para nosso Agent\n",
        "# Cada ferramenta é como um \"especialista\" diferente!\n",
        "\n",
        "def ferramenta_analise_documento(input_text: str) -> str:\n",
        "    \"\"\"Analisa estatísticas básicas do documento\"\"\"\n",
        "    \n",
        "    if not doc_manager.documents:\n",
        "        return \"Nenhum documento carregado para análise.\"\n",
        "    \n",
        "    # Combina todo o texto\n",
        "    texto_completo = \" \".join([doc.page_content for doc in doc_manager.documents])\n",
        "    \n",
        "    # Estatísticas básicas\n",
        "    palavras = texto_completo.split()\n",
        "    caracteres = len(texto_completo)\n",
        "    paragrafos = len(texto_completo.split('\\n\\n'))\n",
        "    \n",
        "    # Palavras mais comuns (simples)\n",
        "    palavras_lower = [p.lower().strip('.,!?()[]{}:;\"') for p in palavras if len(p) > 3]\n",
        "    contagem_palavras = {}\n",
        "    for palavra in palavras_lower:\n",
        "        contagem_palavras[palavra] = contagem_palavras.get(palavra, 0) + 1\n",
        "    \n",
        "    # Top 5 palavras\n",
        "    top_palavras = sorted(contagem_palavras.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "    \n",
        "    resultado = f\"\"\"\n",
        "    📊 ANÁLISE ESTATÍSTICA DO DOCUMENTO:\n",
        "    \n",
        "    📏 Estatísticas Gerais:\n",
        "    - Total de caracteres: {caracteres:,}\n",
        "    - Total de palavras: {len(palavras):,}\n",
        "    - Total de parágrafos: {paragrafos}\n",
        "    - Média de palavras por parágrafo: {len(palavras)//paragrafos if paragrafos > 0 else 0}\n",
        "    \n",
        "    🔝 Top 5 Palavras Mais Frequentes:\n",
        "    \"\"\"\n",
        "    \n",
        "    for i, (palavra, freq) in enumerate(top_palavras, 1):\n",
        "        resultado += f\"\\n    {i}. {palavra}: {freq} vezes\"\n",
        "    \n",
        "    return resultado\n",
        "\n",
        "def ferramenta_busca_especifica(query: str) -> str:\n",
        "    \"\"\"Busca informações específicas no documento\"\"\"\n",
        "    \n",
        "    if not doc_manager.vector_store:\n",
        "        return \"Vector store não disponível. Carregue documentos primeiro.\"\n",
        "    \n",
        "    # Busca documentos relevantes\n",
        "    docs_relevantes = doc_manager.buscar_documentos(query, k=3)\n",
        "    \n",
        "    if not docs_relevantes:\n",
        "        return f\"Nenhuma informação encontrada para: {query}\"\n",
        "    \n",
        "    resultado = f\"🔍 BUSCA POR: '{query}'\\n\\n📄 TRECHOS RELEVANTES:\\n\\n\"\n",
        "    \n",
        "    for i, doc in enumerate(docs_relevantes, 1):\n",
        "        resultado += f\"{i}. {doc.page_content[:300]}...\\n\\n\"\n",
        "    \n",
        "    return resultado\n",
        "\n",
        "def ferramenta_gerar_relatorio(tipo: str) -> str:\n",
        "    \"\"\"Gera diferentes tipos de relatórios\"\"\"\n",
        "    \n",
        "    try:\n",
        "        if tipo.lower() == \"resumo\":\n",
        "            resumo = rag_system.gerar_resumo()\n",
        "            return f\"\"\"\n",
        "            📋 RELATÓRIO DE RESUMO\n",
        "            \n",
        "            📄 Título: {resumo.titulo}\n",
        "            \n",
        "            📝 Resumo: {resumo.resumo_executivo}\n",
        "            \n",
        "            🎯 Pontos Principais:\n",
        "            \"\"\" + \"\\n\".join([f\"• {ponto}\" for ponto in resumo.pontos_principais]) + f\"\"\"\n",
        "            \n",
        "            🔑 Palavras-chave: {', '.join(resumo.palavras_chave)}\n",
        "            \n",
        "            💡 Conclusões: {resumo.conclusoes}\n",
        "            \"\"\"\n",
        "            \n",
        "        elif tipo.lower() == \"analise\":\n",
        "            analise = rag_system.gerar_analise()\n",
        "            return f\"\"\"\n",
        "            📊 RELATÓRIO DE ANÁLISE DETALHADA\n",
        "            \n",
        "            📄 Tipo de Documento: {analise.tipo_documento}\n",
        "            🎯 Complexidade: {analise.complexidade}\n",
        "            👥 Público-alvo: {analise.publico_alvo}\n",
        "            ⭐ Qualidade: {analise.qualidade_informacao}/10\n",
        "            \n",
        "            🏷️ Temas Abordados:\n",
        "            \"\"\" + \"\\n\".join([f\"• {tema}\" for tema in analise.temas_abordados]) + f\"\"\"\n",
        "            \n",
        "            💡 Recomendações:\n",
        "            \"\"\" + \"\\n\".join([f\"• {rec}\" for rec in analise.recomendacoes])\n",
        "            \n",
        "        else:\n",
        "            return \"Tipo de relatório não reconhecido. Use 'resumo' ou 'analise'.\"\n",
        "            \n",
        "    except Exception as e:\n",
        "        return f\"Erro ao gerar relatório: {str(e)}\"\n",
        "\n",
        "# Criando as ferramentas do Agent (Módulo 11)\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"analise_documento\",\n",
        "        description=\"Analisa estatísticas básicas do documento carregado\",\n",
        "        func=ferramenta_analise_documento\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"busca_especifica\",\n",
        "        description=\"Busca informações específicas no documento usando busca semântica\",\n",
        "        func=ferramenta_busca_especifica\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"gerar_relatorio\",\n",
        "        description=\"Gera relatórios estruturados (tipos: 'resumo' ou 'analise')\",\n",
        "        func=ferramenta_gerar_relatorio\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"🛠️ Ferramentas criadas com sucesso!\")\n",
        "print(\"\\n📋 Ferramentas disponíveis:\")\n",
        "for tool in tools:\n",
        "    print(f\"   🔧 {tool.name}: {tool.description}\")\n",
        "print(\"\\n✅ Agent terá acesso a todas essas ferramentas!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🤖 Criando o Agent Coordinator\n\n**Agora vem o grand finale!**\n\nVamos criar nosso **Agent** que vai coordenar tudo. É como ter um **gerente de projeto** que sabe exatamente qual ferramenta usar para cada situação!\n\nO Agent vai:\n- 🤔 **Analisar** a pergunta do usuário\n- 🎯 **Decidir** qual ferramenta usar\n- 🔧 **Executar** a ação apropriada\n- 📋 **Combinar** resultados se necessário\n\n**Dica!** Vamos usar o padrão **ReAct** (Reasoning + Acting) que aprendemos no Módulo 11!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando nosso Agent Coordinator - O cérebro coordenador!\n",
        "# Usando conceitos do Módulo 11 (Agents e Tools)\n",
        "\n",
        "# Template para o Agent (Módulo 4)\n",
        "agent_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "Você é um Assistente Especializado em Análise de Documentos.\n",
        "\n",
        "FERRAMENTAS DISPONÍVEIS:\n",
        "{tools}\n",
        "\n",
        "FORMATO DE USO DAS FERRAMENTAS:\n",
        "Para usar uma ferramenta, use o formato:\n",
        "Action: nome_da_ferramenta\n",
        "Action Input: entrada_para_ferramenta\n",
        "Observation: [resultado da ferramenta]\n",
        "\n",
        "INSTRUÇÕES:\n",
        "- Analise a pergunta do usuário cuidadosamente\n",
        "- Escolha a ferramenta mais apropriada\n",
        "- Use as ferramentas quantas vezes necessário\n",
        "- Forneça uma resposta final completa e útil\n",
        "- Seja profissional e objetivo\n",
        "\n",
        "HISTÓRICO DA CONVERSA:\n",
        "{chat_history}\n",
        "\n",
        "PERGUNTA DO USUÁRIO:\n",
        "{input}\n",
        "\n",
        "RACIOCÍNIO E AÇÕES:\n",
        "{agent_scratchpad}\n",
        "\"\"\")\n",
        "\n",
        "# Configuração do Agent com memória\n",
        "class DocumentAssistant:\n",
        "    \"\"\"Assistente completo para análise de documentos\"\"\"\n",
        "    \n",
        "    def __init__(self, tools, llm, rag_system):\n",
        "        self.tools = tools\n",
        "        self.llm = llm\n",
        "        self.rag_system = rag_system\n",
        "        self.chat_history = []\n",
        "        \n",
        "    def processar_pergunta(self, pergunta):\n",
        "        \"\"\"Processa uma pergunta usando Agent + RAG\"\"\"\n",
        "        \n",
        "        print(f\"🤔 Analisando pergunta: {pergunta}\")\n",
        "        \n",
        "        # Primeiro, tenta responder com RAG simples\n",
        "        if self._eh_pergunta_simples(pergunta):\n",
        "            print(\"🧠 Usando RAG direto para resposta rápida...\")\n",
        "            resposta = self.rag_system.responder_pergunta(pergunta)\n",
        "            \n",
        "        else:\n",
        "            print(\"🤖 Usando Agent com ferramentas especializadas...\")\n",
        "            resposta = self._usar_agent(pergunta)\n",
        "        \n",
        "        # Adiciona à memória\n",
        "        self.chat_history.append(f\"Usuário: {pergunta}\")\n",
        "        self.chat_history.append(f\"Assistente: {resposta}\")\n",
        "        \n",
        "        # Mantém só as últimas 10 interações\n",
        "        if len(self.chat_history) > 10:\n",
        "            self.chat_history = self.chat_history[-10:]\n",
        "        \n",
        "        return resposta\n",
        "    \n",
        "    def _eh_pergunta_simples(self, pergunta):\n",
        "        \"\"\"Verifica se é uma pergunta que o RAG pode responder diretamente\"\"\"\n",
        "        palavras_complexas = ['análise', 'estatística', 'relatório', 'gráfico', 'visualização']\n",
        "        return not any(palavra in pergunta.lower() for palavra in palavras_complexas)\n",
        "    \n",
        "    def _usar_agent(self, pergunta):\n",
        "        \"\"\"Usa o Agent para perguntas mais complexas\"\"\"\n",
        "        \n",
        "        # Determina qual ferramenta usar baseado na pergunta\n",
        "        if 'estatística' in pergunta.lower() or 'análise' in pergunta.lower():\n",
        "            ferramenta = 'analise_documento'\n",
        "            entrada = pergunta\n",
        "            \n",
        "        elif 'relatório' in pergunta.lower() or 'resumo' in pergunta.lower():\n",
        "            ferramenta = 'gerar_relatorio'\n",
        "            if 'resumo' in pergunta.lower():\n",
        "                entrada = 'resumo'\n",
        "            else:\n",
        "                entrada = 'analise'\n",
        "                \n",
        "        else:\n",
        "            ferramenta = 'busca_especifica'\n",
        "            entrada = pergunta\n",
        "        \n",
        "        # Executa a ferramenta\n",
        "        for tool in self.tools:\n",
        "            if tool.name == ferramenta:\n",
        "                resultado = tool.func(entrada)\n",
        "                return resultado\n",
        "        \n",
        "        # Fallback para RAG se não encontrar ferramenta\n",
        "        return self.rag_system.responder_pergunta(pergunta)\n",
        "    \n",
        "    def obter_historico(self):\n",
        "        \"\"\"Retorna o histórico da conversa\"\"\"\n",
        "        return \"\\n\".join(self.chat_history[-6:])  # Últimas 6 mensagens\n",
        "\n",
        "# Cria nosso assistente completo\n",
        "assistente = DocumentAssistant(tools, llm, rag_system)\n",
        "\n",
        "print(\"🤖 Assistente de Análise de Documentos criado!\")\n",
        "print(\"\\n🧠 Capacidades do assistente:\")\n",
        "print(\"   ✅ Resposta a perguntas (RAG)\")\n",
        "print(\"   ✅ Análise estatística\")\n",
        "print(\"   ✅ Busca especializada\")\n",
        "print(\"   ✅ Geração de relatórios\")\n",
        "print(\"   ✅ Memória conversacional\")\n",
        "print(\"\\n🎯 Sistema completo funcionando!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎭 Demonstração Completa do Sistema\n\n**Agora é hora do grande show!**\n\nVamos testar nosso **Assistente completo** com diferentes tipos de perguntas para ver como ele se comporta. É como fazer uma \"demonstração ao vivo\" do produto!\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-12_img_04.png)\n\n**Vamos testar:**\n- 💬 Perguntas simples (RAG direto)\n- 📊 Análises estatísticas\n- 📋 Geração de relatórios\n- 🔍 Buscas especializadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DEMONSTRAÇÃO COMPLETA DO SISTEMA\n",
        "# Vamos testar todos os recursos do nosso assistente!\n",
        "\n",
        "print(\"🎭 DEMONSTRAÇÃO DO ASSISTENTE DE ANÁLISE DE DOCUMENTOS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Cenários de teste\n",
        "cenarios_teste = [\n",
        "    {\n",
        "        \"tipo\": \"Pergunta Simples (RAG)\",\n",
        "        \"pergunta\": \"Qual foi o investimento em startups de IA em 2023?\",\n",
        "        \"emoji\": \"💬\"\n",
        "    },\n",
        "    {\n",
        "        \"tipo\": \"Análise Estatística\",\n",
        "        \"pergunta\": \"Faça uma análise estatística do documento\",\n",
        "        \"emoji\": \"📊\"\n",
        "    },\n",
        "    {\n",
        "        \"tipo\": \"Geração de Relatório\",\n",
        "        \"pergunta\": \"Gere um relatório de resumo do documento\",\n",
        "        \"emoji\": \"📋\"\n",
        "    },\n",
        "    {\n",
        "        \"tipo\": \"Busca Especializada\",\n",
        "        \"pergunta\": \"Como a IA está sendo usada na saúde?\",\n",
        "        \"emoji\": \"🔍\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Executa cada cenário\n",
        "for i, cenario in enumerate(cenarios_teste, 1):\n",
        "    print(f\"\\n{cenario['emoji']} TESTE {i}: {cenario['tipo']}\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"❓ PERGUNTA: {cenario['pergunta']}\")\n",
        "    print(\"\\n🤖 PROCESSANDO...\")\n",
        "    \n",
        "    try:\n",
        "        resposta = assistente.processar_pergunta(cenario['pergunta'])\n",
        "        print(f\"\\n✅ RESPOSTA:\\n{resposta}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ ERRO: {str(e)}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "\n",
        "print(\"\\n🎯 DEMONSTRAÇÃO CONCLUÍDA!\")\n",
        "print(\"✅ Todos os componentes funcionando perfeitamente!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Visualizações e Métricas\n\n**Vamos adicionar um toque visual ao nosso projeto!**\n\nNada melhor que **gráficos** para impressionar. Vamos criar algumas visualizações sobre nosso documento usando **matplotlib** e **wordcloud**.\n\nÉ como colocar o \"verniz final\" no nosso projeto - funciona bem E fica bonito!\n\n**Dica!** Visualizações são super importantes em projetos reais - todo mundo ama gráficos!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando visualizações do documento\n",
        "# Porque todo mundo ama gráficos bonitos! 📊\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Configura o matplotlib para melhor visualização\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "def criar_visualizacoes_documento():\n",
        "    \"\"\"Cria visualizações interessantes do documento\"\"\"\n",
        "    \n",
        "    if not doc_manager.documents:\n",
        "        print(\"❌ Nenhum documento carregado!\")\n",
        "        return\n",
        "    \n",
        "    # Prepara os dados\n",
        "    texto_completo = \" \".join([doc.page_content for doc in doc_manager.documents])\n",
        "    palavras = re.findall(r'\\b\\w+\\b', texto_completo.lower())\n",
        "    palavras_filtradas = [p for p in palavras if len(p) > 3 and p.isalpha()]\n",
        "    \n",
        "    # 1. Gráfico de frequência de palavras\n",
        "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    fig.suptitle('📊 Análise Visual do Documento', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # Top 10 palavras mais frequentes\n",
        "    contador = Counter(palavras_filtradas)\n",
        "    top_palavras = contador.most_common(10)\n",
        "    palavras_top, frequencias = zip(*top_palavras)\n",
        "    \n",
        "    ax1.bar(range(len(palavras_top)), frequencias, color='skyblue', alpha=0.8)\n",
        "    ax1.set_xlabel('Palavras')\n",
        "    ax1.set_ylabel('Frequência')\n",
        "    ax1.set_title('🔝 Top 10 Palavras Mais Frequentes')\n",
        "    ax1.set_xticks(range(len(palavras_top)))\n",
        "    ax1.set_xticklabels(palavras_top, rotation=45, ha='right')\n",
        "    \n",
        "    # 2. Distribuição de tamanho de palavras\n",
        "    tamanhos = [len(palavra) for palavra in palavras_filtradas]\n",
        "    ax2.hist(tamanhos, bins=range(3, max(tamanhos)+2), alpha=0.7, color='lightgreen')\n",
        "    ax2.set_xlabel('Tamanho da Palavra (caracteres)')\n",
        "    ax2.set_ylabel('Frequência')\n",
        "    ax2.set_title('📏 Distribuição de Tamanho das Palavras')\n",
        "    \n",
        "    # 3. Estatísticas gerais\n",
        "    stats = {\n",
        "        'Total de Palavras': len(palavras),\n",
        "        'Palavras Únicas': len(set(palavras_filtradas)),\n",
        "        'Caracteres': len(texto_completo),\n",
        "        'Parágrafos': len(texto_completo.split('\\n\\n'))\n",
        "    }\n",
        "    \n",
        "    labels = list(stats.keys())\n",
        "    valores = list(stats.values())\n",
        "    cores = ['gold', 'lightcoral', 'lightskyblue', 'lightgreen']\n",
        "    \n",
        "    ax3.pie([1, 1, 1, 1], labels=labels, autopct='', colors=cores, startangle=90)\n",
        "    ax3.set_title('📈 Estatísticas Gerais')\n",
        "    \n",
        "    # Adiciona os valores como texto\n",
        "    for i, (label, valor) in enumerate(stats.items()):\n",
        "        ax3.text(0, -1.5 + i*0.3, f'{label}: {valor:,}', \n",
        "                ha='center', fontsize=10, fontweight='bold')\n",
        "    \n",
        "    # 4. Complexidade do texto (simulada)\n",
        "    complexidade_data = {\n",
        "        'Palavras Simples\\n(3-5 chars)': len([p for p in palavras_filtradas if 3 <= len(p) <= 5]),\n",
        "        'Palavras Médias\\n(6-8 chars)': len([p for p in palavras_filtradas if 6 <= len(p) <= 8]),\n",
        "        'Palavras Complexas\\n(9+ chars)': len([p for p in palavras_filtradas if len(p) >= 9])\n",
        "    }\n",
        "    \n",
        "    ax4.pie(complexidade_data.values(), labels=complexidade_data.keys(), \n",
        "           autopct='%1.1f%%', colors=['lightgreen', 'orange', 'red'], startangle=90)\n",
        "    ax4.set_title('🧠 Complexidade do Vocabulário')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return stats, top_palavras\n",
        "\n",
        "# Cria as visualizações\n",
        "print(\"🎨 Gerando visualizações do documento...\")\n",
        "estatisticas, palavras_freq = criar_visualizacoes_documento()\n",
        "\n",
        "print(\"\\n✅ Visualizações criadas com sucesso!\")\n",
        "print(\"📊 Gráficos mostram análise completa do documento!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando uma nuvem de palavras\n",
        "# Porque nuvem de palavras é sempre impressionante! ☁️\n",
        "\n",
        "try:\n",
        "    from wordcloud import WordCloud\n",
        "    \n",
        "    def criar_nuvem_palavras():\n",
        "        \"\"\"Cria uma nuvem de palavras do documento\"\"\"\n",
        "        \n",
        "        if not doc_manager.documents:\n",
        "            print(\"❌ Nenhum documento carregado!\")\n",
        "            return\n",
        "        \n",
        "        # Prepara o texto\n",
        "        texto_completo = \" \".join([doc.page_content for doc in doc_manager.documents])\n",
        "        \n",
        "        # Remove palavras muito comuns (stop words básicas)\n",
        "        stop_words = {'que', 'para', 'com', 'uma', 'dos', 'das', 'por', 'mais', 'são', 'como',\n",
        "                     'ter', 'seus', 'suas', 'foi', 'ser', 'está', 'tem', 'seu', 'sua', 'nos',\n",
        "                     'nas', 'pela', 'pelo', 'aos', 'às', 'essa', 'esse', 'este', 'esta'}\n",
        "        \n",
        "        # Cria a nuvem de palavras\n",
        "        wordcloud = WordCloud(\n",
        "            width=800, \n",
        "            height=600,\n",
        "            background_color='white',\n",
        "            stopwords=stop_words,\n",
        "            max_words=100,\n",
        "            colormap='viridis',\n",
        "            relative_scaling=0.5,\n",
        "            random_state=42\n",
        "        ).generate(texto_completo)\n",
        "        \n",
        "        # Plota a nuvem\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(wordcloud, interpolation='bilinear')\n",
        "        plt.title('☁️ Nuvem de Palavras do Documento', fontsize=16, fontweight='bold')\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout(pad=0)\n",
        "        plt.show()\n",
        "        \n",
        "        return wordcloud\n",
        "    \n",
        "    # Gera a nuvem\n",
        "    print(\"☁️ Gerando nuvem de palavras...\")\n",
        "    nuvem = criar_nuvem_palavras()\n",
        "    print(\"✅ Nuvem de palavras criada!\")\n",
        "    \n",
        "except ImportError:\n",
        "    print(\"⚠️ WordCloud não disponível, pulando esta visualização\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Erro ao criar nuvem de palavras: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 Sistema Interativo Final\n\n**Agora vamos criar uma interface interativa!**\n\nVamos simular como seria usar nosso assistente em um ambiente real. É como criar um \"chatbot\" simples para demonstrar o projeto!\n\n**Esta é a \"cereja do bolo\"** - um sistema que você pode realmente usar e mostrar para outras pessoas!\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/books/imagens/langchain-modulo-12_img_05.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sistema Interativo Final - O produto completo!\n",
        "# Simulando uma interface real de uso\n",
        "\n",
        "class InterfaceAssistente:\n",
        "    \"\"\"Interface amigável para interagir com o assistente\"\"\"\n",
        "    \n",
        "    def __init__(self, assistente):\n",
        "        self.assistente = assistente\n",
        "        self.sessao_ativa = True\n",
        "    \n",
        "    def mostrar_boas_vindas(self):\n",
        "        \"\"\"Mostra mensagem de boas vindas\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🤖 ASSISTENTE DE ANÁLISE DE DOCUMENTOS\")\n",
        "        print(\"=\"*60)\n",
        "        print(\"\\n👋 Olá! Sou seu assistente para análise de documentos!\")\n",
        "        print(\"\\n📚 Documento carregado: 'Relatório IA Brasil 2024'\")\n",
        "        print(\"\\n✨ Posso ajudar você com:\")\n",
        "        print(\"   🔍 Responder perguntas sobre o documento\")\n",
        "        print(\"   📊 Gerar análises estatísticas\")\n",
        "        print(\"   📋 Criar relatórios estruturados\")\n",
        "        print(\"   🎯 Buscar informações específicas\")\n",
        "        print(\"\\n💡 Exemplos de perguntas:\")\n",
        "        print(\"   - 'Quanto foi investido em IA em 2023?'\")\n",
        "        print(\"   - 'Faça uma análise estatística do documento'\")\n",
        "        print(\"   - 'Gere um relatório de resumo'\")\n",
        "        print(\"   - 'Quais são os desafios da IA no Brasil?'\")\n",
        "        print(\"\\n🎯 Digite 'sair' para encerrar\")\n",
        "        print(\"-\"*60)\n",
        "    \n",
        "    def processar_comando(self, comando):\n",
        "        \"\"\"Processa comandos especiais\"\"\"\n",
        "        comando = comando.lower().strip()\n",
        "        \n",
        "        if comando in ['sair', 'exit', 'quit']:\n",
        "            return self.encerrar_sessao()\n",
        "            \n",
        "        elif comando in ['ajuda', 'help', '?']:\n",
        "            return self.mostrar_ajuda()\n",
        "            \n",
        "        elif comando in ['histórico', 'historico', 'history']:\n",
        "            return self.mostrar_historico()\n",
        "            \n",
        "        elif comando in ['stats', 'estatísticas', 'estatisticas']:\n",
        "            return self.assistente.processar_pergunta(\"Faça uma análise estatística do documento\")\n",
        "            \n",
        "        elif comando in ['resumo', 'summary']:\n",
        "            return self.assistente.processar_pergunta(\"Gere um relatório de resumo\")\n",
        "            \n",
        "        else:\n",
        "            # Pergunta normal\n",
        "            return self.assistente.processar_pergunta(comando)\n",
        "    \n",
        "    def mostrar_ajuda(self):\n",
        "        \"\"\"Mostra comandos disponíveis\"\"\"\n",
        "        return \"\"\"\n",
        "🆘 COMANDOS DISPONÍVEIS:\n",
        "\n",
        "📝 Comandos Rápidos:\n",
        "   • 'stats' ou 'estatísticas' - Análise estatística\n",
        "   • 'resumo' - Gera resumo do documento\n",
        "   • 'histórico' - Mostra conversa anterior\n",
        "   • 'ajuda' - Esta mensagem\n",
        "   • 'sair' - Encerra a sessão\n",
        "\n",
        "💬 Perguntas Livres:\n",
        "   • Qualquer pergunta sobre o documento\n",
        "   • Solicitações de análise ou relatórios\n",
        "   • Busca por informações específicas\n",
        "        \"\"\"\n",
        "    \n",
        "    def mostrar_historico(self):\n",
        "        \"\"\"Mostra histórico da conversa\"\"\"\n",
        "        historico = self.assistente.obter_historico()\n",
        "        if historico:\n",
        "            return f\"\\n📚 HISTÓRICO DA CONVERSA:\\n\\n{historico}\"\n",
        "        else:\n",
        "            return \"📚 Nenhuma conversa anterior registrada.\"\n",
        "    \n",
        "    def encerrar_sessao(self):\n",
        "        \"\"\"Encerra a sessão\"\"\"\n",
        "        self.sessao_ativa = False\n",
        "        return \"\"\"\n",
        "👋 Obrigado por usar o Assistente de Análise de Documentos!\n",
        "\n",
        "📊 Resumo da sessão:\n",
        "   ✅ Sistema funcionando perfeitamente\n",
        "   ✅ Documento processado com sucesso\n",
        "   ✅ Todas as funcionalidades testadas\n",
        "\n",
        "🎯 Projeto Final 1 concluído com sucesso!\n",
        "        \"\"\"\n",
        "\n",
        "# Cria a interface\n",
        "interface = InterfaceAssistente(assistente)\n",
        "\n",
        "print(\"🎭 Interface do assistente criada!\")\n",
        "print(\"✅ Sistema completo e pronto para uso!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DEMONSTRAÇÃO FINAL INTERATIVA\n",
        "# Vamos simular uma sessão de uso real!\n",
        "\n",
        "# Mostra a interface\n",
        "interface.mostrar_boas_vindas()\n",
        "\n",
        "# Simula algumas interações\n",
        "print(\"\\n🎭 SIMULAÇÃO DE USO:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "simulacao_perguntas = [\n",
        "    \"Quanto foi investido em startups de IA em 2023?\",\n",
        "    \"stats\",\n",
        "    \"Como a IA está sendo usada na saúde?\",\n",
        "    \"resumo\",\n",
        "    \"Quais são as perspectivas futuras?\"\n",
        "]\n",
        "\n",
        "for i, pergunta in enumerate(simulacao_perguntas, 1):\n",
        "    print(f\"\\n👤 Usuário: {pergunta}\")\n",
        "    print(\"🤖 Assistente: Processando...\")\n",
        "    \n",
        "    try:\n",
        "        resposta = interface.processar_comando(pergunta)\n",
        "        # Mostra só os primeiros 300 caracteres para não ficar muito longo\n",
        "        resposta_resumida = resposta[:300] + \"...\" if len(resposta) > 300 else resposta\n",
        "        print(f\"🤖 Assistente: {resposta_resumida}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro: {str(e)}\")\n",
        "    \n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Finaliza a demonstração\n",
        "print(\"\\n👤 Usuário: sair\")\n",
        "mensagem_final = interface.processar_comando(\"sair\")\n",
        "print(f\"🤖 Assistente: {mensagem_final}\")\n",
        "\n",
        "print(\"\\n🎯 DEMONSTRAÇÃO CONCLUÍDA!\")\n",
        "print(\"🚀 Sistema funcionando 100%!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📋 Resumo e Próximos Passos\n\n**Parabéns! Você acabou de criar um projeto COMPLETO de IA!** 🎉\n\n### 🏆 O que construímos:\n\n✅ **Sistema RAG Completo**: Carregamento, processamento e busca de documentos  \n✅ **Agent Inteligente**: Coordenação de ferramentas especializadas  \n✅ **Memória Conversacional**: Contexto mantido entre interações  \n✅ **Output Estruturado**: Respostas organizadas com Pydantic  \n✅ **Visualizações**: Gráficos e análises visuais  \n✅ **Interface Amigável**: Sistema pronto para uso real  \n\n### 🔗 Módulos Integrados:\n\n- **Módulo 2**: ChatModel (Gemini 2.0 Flash)\n- **Módulo 3**: LCEL para chains elegantes\n- **Módulo 4**: Prompt Templates profissionais\n- **Módulo 5**: Output Parsers estruturados\n- **Módulo 7**: Memory Systems\n- **Módulo 8**: Document Loading e Splitters\n- **Módulo 9**: Vector Stores e Embeddings\n- **Módulo 10**: RAG Implementation\n- **Módulo 11**: Agents e Tools\n\n### 🚀 Próximos Passos:\n\n**No Módulo 13** vamos criar um **Projeto Final 2** ainda mais avançado!  \n**No Módulo 14** vamos fazer o **deploy** com **Streamlit**!  \n\n**Dica Final!** Este projeto já está pronto para ser usado em cenários reais - é seu portfólio em ação!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Exercício Final\n\n**Agora é sua vez de brilhar!**\n\n### 📝 Desafio Prático:\n\n**Customize o sistema para um domínio específico de sua escolha:**\n\n1. **Escolha um tema**: Medicina, Direito, Educação, Negócios, etc.\n2. **Crie um documento de exemplo** sobre esse tema\n3. **Adapte os prompts** para o domínio escolhido\n4. **Adicione uma ferramenta especializada** para esse domínio\n5. **Teste com perguntas específicas** da área\n\n### 💡 Ideias de Personalização:\n\n- **Medicina**: Assistente para análise de prontuários\n- **Direito**: Análise de contratos e documentos legais\n- **Educação**: Assistente pedagógico para materiais didáticos\n- **Negócios**: Análise de relatórios financeiros\n\n### 🏆 Objetivo:\n\nMostrar que você consegue adaptar o sistema para **qualquer domínio**!\n\n**Boa sorte e mãos à obra!** 🚀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ESPAÇO PARA SEU EXERCÍCIO\n",
        "# Personalize o sistema aqui!\n",
        "\n",
        "print(\"🎯 ESPAÇO PARA PERSONALIZAÇÃO\")\n",
        "print(\"=\" * 50)\n",
        "print(\"\\n💡 Dicas para personalizar:\")\n",
        "print(\"   1. Crie um novo documento sobre seu tema\")\n",
        "print(\"   2. Adapte os prompts para o domínio\")\n",
        "print(\"   3. Adicione ferramentas específicas\")\n",
        "print(\"   4. Teste com perguntas da área\")\n",
        "print(\"\\n🚀 Bora personalizar!\")\n",
        "\n",
        "# SEU CÓDIGO AQUI:\n",
        "# ...\n",
        "\n",
        "print(\"\\n✅ Sistema personalizado criado!\")\n",
        "print(\"🎉 Parabéns pelo projeto completo!\")"
      ]
    }
  ]
}
