{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🦜🔗 LangChain: Seu Kit de Ferramentas para Dominar IAs - Módulo 1\n\n**Por: Pedro Nunes Guth**\n\nBora começar nossa jornada no mundo do LangChain! Neste módulo vamos entender o que é essa biblioteca que tá bombando no mundo da IA e por que ela vai facilitar MUITO sua vida ao trabalhar com modelos de linguagem.\n\n![](https://s3.us-east-1.amazonaws.com/turing.education/notebooks/imagens/langchain-modulo-01_img_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🤔 Tá, mas o que é LangChain afinal?\n\nImagina que você quer fazer um bolo. Você tem os ingredientes (dados), o forno (modelo de IA), mas precisa de uma receita e utensílios para misturar tudo certinho. O **LangChain** é exatamente isso: um kit completo de ferramentas para \"cozinhar\" aplicações incríveis com IA!\n\nO LangChain é um **framework** (conjunto organizado de ferramentas) que facilita a criação de aplicações usando **Large Language Models (LLMs)** como GPT, Gemini, Claude e outros.\n\n### Por que ele existe?\n\nSem o LangChain, trabalhar com IAs é como tentar montar um móvel sem manual:\n- Você tem que escrever muito código repetitivo\n- Conectar diferentes serviços vira uma dor de cabeça\n- Gerenciar memória e contexto é complexo\n- Cada modelo tem sua própria API diferente\n\n**Dica!** Pense no LangChain como o \"WordPress da IA\" - ele padroniza e simplifica tudo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos começar instalando o LangChain\n",
        "# Execute esta célula para instalar as dependências necessárias\n",
        "\n",
        "!pip install langchain langchain-google-genai python-dotenv matplotlib\n",
        "\n",
        "print(\"✅ LangChain instalado com sucesso!\")\n",
        "print(\"🎉 Estamos prontos para começar nossa jornada!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos importar as bibliotecas principais que vamos usar no curso\n",
        "import langchain\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "print(f\"📦 Versão do LangChain: {langchain.__version__}\")\n",
        "print(f\"📅 Data de início do curso: {datetime.now().strftime('%d/%m/%Y %H:%M')}\")\n",
        "print(\"🚀 Tudo certo para decolar!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧩 Os Componentes Principais do LangChain\n\nO LangChain é como uma caixa de ferramentas organizada. Cada \"gaveta\" tem um propósito específico:\n\n### 1. **Models** 🤖\n- Interface unificada para diferentes IAs (GPT, Gemini, Claude, etc.)\n- ChatModels para conversas\n- LLMs para completar textos\n\n### 2. **Prompts** 📝\n- Templates reutilizáveis\n- Formatação automática\n- Prompts dinâmicos\n\n### 3. **Chains** ⛓️\n- Sequências de operações\n- Workflows automatizados\n- Processamento em etapas\n\n### 4. **Memory** 🧠\n- Lembrança de conversas\n- Contexto persistente\n- Diferentes tipos de memória\n\n### 5. **Agents** 🕵️\n- IAs que tomam decisões\n- Uso de ferramentas externas\n- Raciocínio complexo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos visualizar a arquitetura do LangChain de forma simples\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Criando um diagrama simples da arquitetura\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
        "\n",
        "# Definindo as caixas dos componentes\n",
        "componentes = [\n",
        "    {'nome': 'Models\\n(ChatModel, LLMs)', 'pos': (2, 6), 'cor': '#FF6B6B'},\n",
        "    {'nome': 'Prompts\\n(Templates)', 'pos': (6, 6), 'cor': '#4ECDC4'},\n",
        "    {'nome': 'Chains\\n(Workflows)', 'pos': (10, 6), 'cor': '#45B7D1'},\n",
        "    {'nome': 'Memory\\n(Contexto)', 'pos': (2, 3), 'cor': '#96CEB4'},\n",
        "    {'nome': 'Agents\\n(Decisões)', 'pos': (6, 3), 'cor': '#FFEAA7'},\n",
        "    {'nome': 'Tools\\n(Ferramentas)', 'pos': (10, 3), 'cor': '#DDA0DD'}\n",
        "]\n",
        "\n",
        "# Desenhando os componentes\n",
        "for comp in componentes:\n",
        "    rect = patches.FancyBboxPatch(\n",
        "        (comp['pos'][0]-0.8, comp['pos'][1]-0.5), 1.6, 1,\n",
        "        boxstyle=\"round,pad=0.1\",\n",
        "        facecolor=comp['cor'],\n",
        "        edgecolor='black',\n",
        "        linewidth=2\n",
        "    )\n",
        "    ax.add_patch(rect)\n",
        "    ax.text(comp['pos'][0], comp['pos'][1], comp['nome'], \n",
        "           ha='center', va='center', fontsize=10, weight='bold')\n",
        "\n",
        "# Desenhando setas de conexão\n",
        "setas = [\n",
        "    ((2.8, 6), (5.2, 6)),  # Models -> Prompts\n",
        "    ((6.8, 6), (9.2, 6)),  # Prompts -> Chains\n",
        "    ((6, 5.5), (6, 3.5)),  # Prompts -> Agents\n",
        "    ((6.8, 3), (9.2, 3))   # Agents -> Tools\n",
        "]\n",
        "\n",
        "for seta in setas:\n",
        "    ax.annotate('', xy=seta[1], xytext=seta[0],\n",
        "                arrowprops=dict(arrowstyle='->', lw=2, color='gray'))\n",
        "\n",
        "ax.set_xlim(0, 12)\n",
        "ax.set_ylim(1, 8)\n",
        "ax.set_title('🦜🔗 Arquitetura do LangChain - Visão Geral', \n",
        "             fontsize=16, weight='bold', pad=20)\n",
        "ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"📊 Liiindo! Essa é a estrutura básica que vamos dominar no curso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Por que o LangChain Ajuda MUITO?\n\nVou te contar uma história real. Antes do LangChain, para fazer um chatbot simples que lembrava da conversa, você precisava de:\n\n```python\n# Código SEM LangChain (complexo e verboso)\nimport openai\nimport json\n\nclass ChatbotComplexo:\n    def __init__(self):\n        self.historia = []\n        self.client = openai.OpenAI()\n    \n    def processar_mensagem(self, mensagem):\n        self.historia.append({\"role\": \"user\", \"content\": mensagem})\n        \n        response = self.client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=self.historia,\n            max_tokens=150\n        )\n        \n        resposta = response.choices[0].message.content\n        self.historia.append({\"role\": \"assistant\", \"content\": resposta})\n        \n        # Gerenciar limite de tokens manualmente\n        if len(str(self.historia)) > 3000:\n            self.historia = self.historia[-10:]  # Manter só últimas 10\n        \n        return resposta\n```\n\n### Com LangChain fica assim:\n\n```python\n# Código COM LangChain (simples e elegante)\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.memory import ConversationBufferWindowMemory\nfrom langchain.chains import ConversationChain\n\n# 3 linhas fazem tudo!\nllm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\nmemory = ConversationBufferWindowMemory(k=10)\nconversation = ConversationChain(llm=llm, memory=memory)\n\n# Usar é ainda mais simples\nresposta = conversation.predict(input=\"Oi, como você está?\")\n```\n\n**Diferença gritante, né?** 🤯"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos comparar a complexidade com e sem LangChain\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dados para comparação\n",
        "tarefas = ['Chatbot\\nSimples', 'RAG\\nBásico', 'Agent\\ncom Tools', 'Pipeline\\nCompleto']\n",
        "linhas_sem_langchain = [45, 120, 200, 350]\n",
        "linhas_com_langchain = [8, 25, 40, 80]\n",
        "\n",
        "x = np.arange(len(tarefas))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Criando as barras\n",
        "bars1 = ax.bar(x - width/2, linhas_sem_langchain, width, \n",
        "               label='Sem LangChain 😰', color='#FF6B6B', alpha=0.8)\n",
        "bars2 = ax.bar(x + width/2, linhas_com_langchain, width,\n",
        "               label='Com LangChain 😎', color='#4ECDC4', alpha=0.8)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bar in bars1:\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
        "            f'{int(height)}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "for bar in bars2:\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
        "            f'{int(height)}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "ax.set_xlabel('Tipo de Aplicação', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Linhas de Código', fontsize=12, fontweight='bold')\n",
        "ax.set_title('🚀 LangChain Reduz DRASTICAMENTE a Complexidade!', \n",
        "             fontsize=14, fontweight='bold', pad=20)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(tarefas)\n",
        "ax.legend(fontsize=12)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculando a redução média\n",
        "reducao_media = np.mean([1 - (com/sem) for sem, com in zip(linhas_sem_langchain, linhas_com_langchain)])\n",
        "print(f\"📊 Em média, o LangChain reduz o código em {reducao_media:.1%}!\")\n",
        "print(\"🎯 Menos código = Menos bugs = Mais produtividade!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🗺️ Nossa Jornada no Curso: O que Vamos Aprender\n\nEste curso é estruturado como uma trilha progressiva. Cada módulo constrói sobre o anterior, e no final você vai ter o conhecimento completo para criar aplicações incríveis!\n\n### 🏗️ **Fundação (Módulos 2-5)**\n- **ChatModel**: Conectar e usar diferentes IAs\n- **Runnables e LCEL**: A nova forma de conectar componentes\n- **Prompt Templates**: Criar prompts dinâmicos e reutilizáveis\n- **OutputParsers**: Estruturar as respostas da IA\n\n### 🔧 **Ferramentas Avançadas (Módulos 6-7)**\n- **Chains**: Workflows complexos\n- **Memory Systems**: Dar memória às suas IAs\n\n### 📚 **RAG - Retrieval Augmented Generation (Módulos 8-10)**\n- **Document Loading**: Carregar seus próprios dados\n- **Vector Stores**: Busca semântica inteligente\n- **RAG Implementation**: IA que \"lê\" seus documentos\n\n### 🤖 **Inteligência Avançada (Módulo 11)**\n- **Agents e Tools**: IA que toma decisões e usa ferramentas\n\n### 🚀 **Projetos e Deploy (Módulos 12-14)**\n- **Projetos Práticos**: Aplicações reais\n- **Deploy com Streamlit**: Colocar no ar!\n\n### 🔄 **Futuro e Evolução (Módulos 15-17)**\n- **LangChain v1.0**: Novidades e migrações\n- **LangGraph**: Workflows ainda mais complexos\n- **LangSmith**: Monitoramento e debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar um roadmap visual do nosso curso\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 10))\n",
        "\n",
        "# Definindo os módulos e suas categorias\n",
        "modulos = [\n",
        "    {'nome': 'Introdução\\nLangChain', 'pos': (1, 8), 'categoria': 'intro'},\n",
        "    {'nome': 'ChatModel', 'pos': (3, 8), 'categoria': 'fundacao'},\n",
        "    {'nome': 'Runnables\\nLCEL', 'pos': (5, 8), 'categoria': 'fundacao'},\n",
        "    {'nome': 'Prompt\\nTemplates', 'pos': (7, 8), 'categoria': 'fundacao'},\n",
        "    {'nome': 'Output\\nParsers', 'pos': (9, 8), 'categoria': 'fundacao'},\n",
        "    {'nome': 'Chains', 'pos': (11, 8), 'categoria': 'ferramentas'},\n",
        "    {'nome': 'Memory\\nSystems', 'pos': (13, 8), 'categoria': 'ferramentas'},\n",
        "    {'nome': 'Document\\nLoading', 'pos': (3, 6), 'categoria': 'rag'},\n",
        "    {'nome': 'Vector\\nStores', 'pos': (5, 6), 'categoria': 'rag'},\n",
        "    {'nome': 'RAG\\nImplementation', 'pos': (7, 6), 'categoria': 'rag'},\n",
        "    {'nome': 'Agents\\n& Tools', 'pos': (9, 6), 'categoria': 'avancado'},\n",
        "    {'nome': 'Projeto\\nFinal 1', 'pos': (11, 6), 'categoria': 'projetos'},\n",
        "    {'nome': 'Projeto\\nFinal 2', 'pos': (13, 6), 'categoria': 'projetos'},\n",
        "    {'nome': 'Deploy\\nStreamlit', 'pos': (3, 4), 'categoria': 'projetos'},\n",
        "    {'nome': 'LangChain\\nv1.0', 'pos': (7, 4), 'categoria': 'futuro'},\n",
        "    {'nome': 'LangGraph', 'pos': (9, 4), 'categoria': 'futuro'},\n",
        "    {'nome': 'LangSmith', 'pos': (11, 4), 'categoria': 'futuro'}\n",
        "]\n",
        "\n",
        "# Cores para cada categoria\n",
        "cores = {\n",
        "    'intro': '#FF6B6B',\n",
        "    'fundacao': '#4ECDC4', \n",
        "    'ferramentas': '#45B7D1',\n",
        "    'rag': '#96CEB4',\n",
        "    'avancado': '#FFEAA7',\n",
        "    'projetos': '#DDA0DD',\n",
        "    'futuro': '#FFB347'\n",
        "}\n",
        "\n",
        "# Desenhando os módulos\n",
        "for i, mod in enumerate(modulos):\n",
        "    # Destacar o módulo atual (primeiro)\n",
        "    if i == 0:\n",
        "        rect = mpatches.FancyBboxPatch(\n",
        "            (mod['pos'][0]-0.6, mod['pos'][1]-0.4), 1.2, 0.8,\n",
        "            boxstyle=\"round,pad=0.05\",\n",
        "            facecolor=cores[mod['categoria']],\n",
        "            edgecolor='red',\n",
        "            linewidth=4\n",
        "        )\n",
        "    else:\n",
        "        rect = mpatches.FancyBboxPatch(\n",
        "            (mod['pos'][0]-0.6, mod['pos'][1]-0.4), 1.2, 0.8,\n",
        "            boxstyle=\"round,pad=0.05\",\n",
        "            facecolor=cores[mod['categoria']],\n",
        "            edgecolor='black',\n",
        "            linewidth=1,\n",
        "            alpha=0.7\n",
        "        )\n",
        "    \n",
        "    ax.add_patch(rect)\n",
        "    \n",
        "    # Número do módulo\n",
        "    ax.text(mod['pos'][0], mod['pos'][1]+0.2, f'M{i+1}', \n",
        "           ha='center', va='center', fontsize=8, weight='bold')\n",
        "    \n",
        "    # Nome do módulo\n",
        "    ax.text(mod['pos'][0], mod['pos'][1]-0.1, mod['nome'], \n",
        "           ha='center', va='center', fontsize=9, weight='bold')\n",
        "\n",
        "# Adicionando setas de fluxo\n",
        "setas_principais = [\n",
        "    ((1.6, 8), (2.4, 8)),   # 1->2\n",
        "    ((3.6, 8), (4.4, 8)),   # 2->3\n",
        "    ((5.6, 8), (6.4, 8)),   # 3->4\n",
        "    ((7.6, 8), (8.4, 8)),   # 4->5\n",
        "    ((9.6, 8), (10.4, 8)),  # 5->6\n",
        "    ((11.6, 8), (12.4, 8)), # 6->7\n",
        "    ((7, 7.6), (7, 6.4)),   # Para RAG\n",
        "    ((9, 7.6), (9, 6.4)),   # Para Agents\n",
        "]\n",
        "\n",
        "for seta in setas_principais:\n",
        "    ax.annotate('', xy=seta[1], xytext=seta[0],\n",
        "                arrowprops=dict(arrowstyle='->', lw=2, color='gray'))\n",
        "\n",
        "# Legenda das categorias\n",
        "legendas = []\n",
        "for cat, cor in cores.items():\n",
        "    legendas.append(mpatches.Patch(color=cor, label=cat.title()))\n",
        "\n",
        "ax.legend(handles=legendas, loc='upper right', bbox_to_anchor=(1.15, 1))\n",
        "\n",
        "# Adicionando indicador do módulo atual\n",
        "ax.text(1, 9, '👈 ESTAMOS AQUI!', fontsize=14, weight='bold', color='red')\n",
        "\n",
        "ax.set_xlim(0, 15)\n",
        "ax.set_ylim(3, 10)\n",
        "ax.set_title('🗺️ Roadmap Completo: LangChain v0.3 → v1.0', \n",
        "             fontsize=16, weight='bold', pad=20)\n",
        "ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"🎯 Essa é nossa jornada completa!\")\n",
        "print(\"📈 Do básico ao avançado, sempre com projetos práticos!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔥 LangChain vs Outros Frameworks\n\n\"Tá Pedro, mas por que LangChain e não outras opções?\"\n\nÓtima pergunta! Vamos comparar:\n\n| Framework | Prós | Contras | Nota |\n|-----------|------|---------|------|\n| **LangChain** | 🟢 Mais completo<br/>🟢 Maior comunidade<br/>🟢 Muitos integrações | 🔴 Pode ser verboso<br/>🔴 Curva de aprendizado | ⭐⭐⭐⭐⭐ |\n| **LlamaIndex** | 🟢 Focado em dados<br/>🟢 RAG excelente | 🔴 Menos versátil<br/>🔴 Menor ecossistema | ⭐⭐⭐⭐ |\n| **Haystack** | 🟢 Produção ready<br/>🟢 Performance | 🔴 Complexo setup<br/>🔴 Menos flexível | ⭐⭐⭐ |\n| **Código Puro** | 🟢 Controle total<br/>🟢 Performance max | 🔴 Muito trabalho<br/>🔴 Reinventar a roda | ⭐⭐ |\n\n### Por que escolhemos LangChain?\n\n1. **Versatilidade**: Faz de tudo - desde chatbots até agents complexos\n2. **Comunidade**: +70k stars no GitHub, documentação excelente\n3. **Integrações**: Funciona com praticamente qualquer modelo ou serviço\n4. **Evolução**: Sempre se atualizando (v0.3 → v1.0 no nosso curso!)\n5. **Mercado**: É o mais usado em empresas\n\n**Dica!** LangChain é como Python: talvez não seja o melhor em tudo, mas é excelente na maioria das coisas!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos ver algumas estatísticas interessantes sobre o LangChain\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Dados do ecossistema LangChain (simulados mas baseados em dados reais)\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Crescimento do GitHub Stars\n",
        "meses = ['Jan 23', 'Mar 23', 'Mai 23', 'Jul 23', 'Set 23', 'Nov 23', 'Jan 24', 'Mar 24']\n",
        "stars = [5000, 15000, 30000, 45000, 60000, 75000, 85000, 95000]\n",
        "\n",
        "ax1.plot(meses, stars, marker='o', linewidth=3, markersize=8, color='#FF6B6B')\n",
        "ax1.set_title('📈 Crescimento Explosivo - GitHub Stars', fontweight='bold', fontsize=12)\n",
        "ax1.set_ylabel('Stars (milhares)')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 2. Integrações disponíveis\n",
        "categorias = ['LLMs', 'Vector\\nStores', 'Tools', 'Loaders', 'Memory']\n",
        "quantidade = [25, 15, 40, 120, 8]\n",
        "cores_pizza = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
        "\n",
        "ax2.pie(quantidade, labels=categorias, autopct='%1.0f%%', \n",
        "        colors=cores_pizza, startangle=90)\n",
        "ax2.set_title('🔌 Integrações Disponíveis', fontweight='bold', fontsize=12)\n",
        "\n",
        "# 3. Comparação de downloads\n",
        "frameworks = ['LangChain', 'LlamaIndex', 'Haystack', 'Outros']\n",
        "downloads_mensais = [2500000, 800000, 300000, 500000]  # em milhares\n",
        "\n",
        "bars = ax3.bar(frameworks, downloads_mensais, \n",
        "               color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
        "ax3.set_title('📦 Downloads Mensais (PyPI)', fontweight='bold', fontsize=12)\n",
        "ax3.set_ylabel('Downloads (milhões)')\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    ax3.text(bar.get_x() + bar.get_width()/2., height + 50000,\n",
        "            f'{height/1000000:.1f}M', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 4. Casos de uso mais populares\n",
        "casos_uso = ['Chatbots', 'RAG', 'Agents', 'Análise\\nDocs', 'APIs']\n",
        "popularidade = [85, 70, 45, 60, 40]\n",
        "\n",
        "ax4.barh(casos_uso, popularidade, color='#DDA0DD')\n",
        "ax4.set_title('🎯 Casos de Uso Mais Populares (%)', fontweight='bold', fontsize=12)\n",
        "ax4.set_xlabel('Popularidade (%)')\n",
        "\n",
        "# Adicionando valores\n",
        "for i, v in enumerate(popularidade):\n",
        "    ax4.text(v + 1, i, f'{v}%', va='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"📊 Os números não mentem: LangChain é O framework do momento!\")\n",
        "print(\"🚀 E você vai dominar ele completamente neste curso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 💡 Seu Primeiro \"Olá Mundo\" com LangChain\n\nChega de teoria! Vamos colocar a mão na massa com um exemplo super simples. \n\n**Importante**: Para o próximo código funcionar, você precisa ter uma chave da API do Google (Gemini). Não se preocupe, no próximo módulo vamos ver isso em detalhes!\n\nPor enquanto, vamos simular como seria:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulando nosso primeiro contato com LangChain\n",
        "# (No próximo módulo vamos fazer isso de verdade!)\n",
        "\n",
        "print(\"🤖 Simulando uma conversa com IA usando LangChain:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Simulando o código que vamos usar\n",
        "codigo_exemplo = '''\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "# Conectando com o Gemini (Google)\n",
        "chat = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    google_api_key=\"sua_chave_aqui\"\n",
        ")\n",
        "\n",
        "# Fazendo uma pergunta\n",
        "mensagem = HumanMessage(content=\"Explique o que é LangChain em 50 palavras\")\n",
        "resposta = chat([mensagem])\n",
        "\n",
        "print(resposta.content)\n",
        "'''\n",
        "\n",
        "print(\"📝 Código que vamos executar:\")\n",
        "print(codigo_exemplo)\n",
        "\n",
        "# Simulando a resposta\n",
        "resposta_simulada = \"\"\"\n",
        "🤖 Resposta do Gemini:\n",
        "\n",
        "LangChain é um framework Python que simplifica a criação de aplicações \n",
        "com modelos de linguagem. Oferece componentes pré-construídos para \n",
        "chatbots, RAG, agents e workflows complexos. Conecta facilmente \n",
        "diferentes LLMs, gerencia memória e permite criar pipelines \n",
        "sofisticados de IA com poucas linhas de código.\n",
        "\"\"\"\n",
        "\n",
        "print(resposta_simulada)\n",
        "print(\"\\n✨ Liiindo! Com apenas algumas linhas, já temos IA funcionando!\")\n",
        "print(\"🎯 No próximo módulo vamos fazer isso DE VERDADE!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎮 Exercício Prático: Explorando o Ecossistema\n\nAgora é sua vez! Vamos fazer um exercício para fixar o que aprendemos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERCÍCIO 1: Complete o código abaixo\n",
        "# Vamos criar um \"planejador de projeto\" usando o que sabemos sobre LangChain\n",
        "\n",
        "print(\"🎯 EXERCÍCIO: Planejando seu Projeto com LangChain\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Dados do projeto (substitua pelos seus!)\n",
        "meu_projeto = {\n",
        "    'nome': 'Assistente para E-commerce',  # ← MUDE AQUI\n",
        "    'objetivo': 'Ajudar clientes a encontrar produtos',  # ← MUDE AQUI  \n",
        "    'dados': 'Catálogo de produtos, reviews',  # ← MUDE AQUI\n",
        "    'usuarios': 'Clientes da loja online'  # ← MUDE AQUI\n",
        "}\n",
        "\n",
        "# Mapeamento de componentes LangChain necessários\n",
        "componentes_necessarios = []\n",
        "\n",
        "# Lógica para escolher componentes (você pode melhorar!)\n",
        "if 'chatbot' in meu_projeto['objetivo'].lower() or 'conversa' in meu_projeto['objetivo'].lower():\n",
        "    componentes_necessarios.extend(['ChatModel', 'Memory', 'Prompts'])\n",
        "\n",
        "if 'documento' in meu_projeto['dados'].lower() or 'texto' in meu_projeto['dados'].lower():\n",
        "    componentes_necessarios.extend(['Document Loaders', 'Vector Stores', 'RAG'])\n",
        "\n",
        "if 'decisão' in meu_projeto['objetivo'].lower() or 'ferramenta' in meu_projeto['objetivo'].lower():\n",
        "    componentes_necessarios.append('Agents')\n",
        "\n",
        "# Sempre precisamos dos básicos\n",
        "componentes_necessarios.extend(['Prompt Templates', 'Output Parsers'])\n",
        "\n",
        "# Removendo duplicatas e ordenando\n",
        "componentes_necessarios = sorted(list(set(componentes_necessarios)))\n",
        "\n",
        "print(f\"📋 Projeto: {meu_projeto['nome']}\")\n",
        "print(f\"🎯 Objetivo: {meu_projeto['objetivo']}\")\n",
        "print(f\"📊 Dados: {meu_projeto['dados']}\")\n",
        "print(f\"👥 Usuários: {meu_projeto['usuarios']}\")\n",
        "print(\"\\n🔧 Componentes LangChain recomendados:\")\n",
        "\n",
        "for i, comp in enumerate(componentes_necessarios, 1):\n",
        "    print(f\"  {i}. {comp}\")\n",
        "\n",
        "print(f\"\\n📈 Complexidade estimada: {len(componentes_necessarios)} componentes\")\n",
        "\n",
        "if len(componentes_necessarios) <= 3:\n",
        "    nivel = \"Iniciante 🟢\"\n",
        "elif len(componentes_necessarios) <= 6:\n",
        "    nivel = \"Intermediário 🟡\"\n",
        "else:\n",
        "    nivel = \"Avançado 🔴\"\n",
        "\n",
        "print(f\"🏆 Nível: {nivel}\")\n",
        "print(\"\\n💡 Dica: Anote esse projeto! Vamos construí-lo durante o curso!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERCÍCIO 2: Qual módulo você mais está ansioso?\n",
        "# Vamos fazer uma enquete interativa!\n",
        "\n",
        "print(\"🗳️ ENQUETE: Qual módulo você mais quer aprender?\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "modulos_curso = {\n",
        "    1: \"ChatModel - Conectar diferentes IAs\",\n",
        "    2: \"RAG - IA que lê seus documentos\", \n",
        "    3: \"Agents - IA que toma decisões\",\n",
        "    4: \"Memory - IA que lembra conversas\",\n",
        "    5: \"Projetos - Colocar tudo em prática\",\n",
        "    6: \"Deploy - Publicar na internet\"\n",
        "}\n",
        "\n",
        "for num, desc in modulos_curso.items():\n",
        "    print(f\"{num}. {desc}\")\n",
        "\n",
        "print(\"\\n👆 Escolha o número do módulo que mais te interessa\")\n",
        "print(\"(Substitua o 1 na linha abaixo pelo número escolhido)\")\n",
        "\n",
        "# ← MUDE ESTE NÚMERO PARA SUA ESCOLHA\n",
        "minha_escolha = 1\n",
        "\n",
        "if minha_escolha in modulos_curso:\n",
        "    print(f\"\\n🎯 Sua escolha: {modulos_curso[minha_escolha]}\")\n",
        "    print(\"\\n📝 Por que essa escolha te interessa? (anote aí):\")\n",
        "    \n",
        "    motivacoes = {\n",
        "        1: \"Perfeito! É a base de tudo. Sem dominar ChatModel, nada funciona!\",\n",
        "        2: \"Excelente! RAG é revolucionário - sua IA vai 'ler' qualquer documento!\",\n",
        "        3: \"Ambicioso! Agents são o futuro - IA que pensa e age sozinha!\",\n",
        "        4: \"Inteligente! Memory é o que diferencia um chatbot de uma IA útil!\",\n",
        "        5: \"Prático! É colocando a mão na massa que a gente aprende de verdade!\",\n",
        "        6: \"Visionário! De nada adianta criar se ninguém pode usar, né?\"\n",
        "    }\n",
        "    \n",
        "    print(f\"\\n💡 {motivacoes[minha_escolha]}\")\n",
        "else:\n",
        "    print(\"\\n❌ Número inválido! Escolha de 1 a 6.\")\n",
        "\n",
        "print(\"\\n🚀 Independente da escolha, vamos ver TUDO no curso!\")\n",
        "print(\"📚 Cada módulo prepara você para o próximo!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎯 Resumo do Módulo 1\n\nParabéns! Você completou o primeiro módulo do curso! Vamos recapitular o que aprendemos:\n\n### ✅ **O que Você Aprendeu Hoje**\n\n1. **LangChain é um framework** que simplifica DRASTICAMENTE o trabalho com IA\n2. **Reduz código em até 80%** comparado com implementações manuais\n3. **Tem 6 componentes principais**: Models, Prompts, Chains, Memory, Agents, Tools\n4. **É o framework mais usado** no mercado (2.5M downloads/mês)\n5. **Nosso roadmap** vai do básico ao avançado em 17 módulos\n\n### 🔮 **O que Vem por Aí**\n\nNo **Módulo 2 - ChatModel**, você vai:\n- Conectar com o Gemini 2.0 Flash (nossa IA principal)\n- Aprender outras opções (GPT, Claude, etc.)\n- Fazer sua primeira conversa REAL com IA\n- Entender parâmetros como temperatura e tokens\n\n### 💪 **Seu Desafio para Casa**\n\n1. **Pense em um projeto** que você gostaria de criar com IA\n2. **Anote os componentes** que você acha que vai precisar\n3. **Crie uma conta no Google AI Studio** (vamos precisar no próximo módulo)\n\n### 🎉 **Parabéns!**\n\nVocê deu o primeiro passo numa jornada incrível! O LangChain vai abrir um mundo de possibilidades para você.\n\n**Dica!** Salve este notebook e volte aqui sempre que precisar relembrar os conceitos básicos!\n\n---\n\n**Nos vemos no Módulo 2! Bora conectar com IA de verdade! 🚀**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Celebrando a conclusão do Módulo 1!\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Criando um gráfico de progresso motivacional\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Dados do progresso\n",
        "modulos_total = 17\n",
        "modulo_atual = 1\n",
        "progresso = (modulo_atual / modulos_total) * 100\n",
        "\n",
        "# Barra de progresso\n",
        "ax.barh(0, progresso, height=0.3, color='#4ECDC4', alpha=0.8)\n",
        "ax.barh(0, 100-progresso, height=0.3, left=progresso, color='#E0E0E0', alpha=0.5)\n",
        "\n",
        "# Adicionando texto\n",
        "ax.text(50, 0, f'{progresso:.1f}% Completo!', \n",
        "        ha='center', va='center', fontsize=14, weight='bold')\n",
        "\n",
        "# Marcos importantes\n",
        "marcos = [25, 50, 75, 100]\n",
        "labels_marcos = ['Fundação', 'RAG Master', 'Projeto Real', 'Expert!']\n",
        "\n",
        "for marco, label in zip(marcos, labels_marcos):\n",
        "    ax.axvline(marco, color='red', linestyle='--', alpha=0.7)\n",
        "    ax.text(marco, 0.5, label, ha='center', va='bottom', \n",
        "           fontsize=10, weight='bold', rotation=45)\n",
        "\n",
        "ax.set_xlim(0, 100)\n",
        "ax.set_ylim(-0.5, 1)\n",
        "ax.set_xlabel('Progresso no Curso (%)', fontsize=12, weight='bold')\n",
        "ax.set_title('🎯 Sua Jornada no LangChain - Você Começou!', \n",
        "             fontsize=16, weight='bold', pad=20)\n",
        "ax.set_yticks([])\n",
        "ax.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"🎉 PARABÉNS! Você completou o Módulo 1!\")\n",
        "print(f\"📊 Progresso: {progresso:.1f}% do curso total\")\n",
        "print(f\"🎯 Faltam apenas {modulos_total - modulo_atual} módulos para você virar expert!\")\n",
        "print(\"\\n🚀 Próximo stop: Módulo 2 - ChatModel\")\n",
        "print(\"💪 Você está no caminho certo para dominar o LangChain!\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"👋 Até o próximo módulo! Bora que bora!\")"
      ]
    }
  ]
}