{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîç LangSmith: O \"Detective Sherlock Holmes\" das suas Aplica√ß√µes LangChain!\n\n## M√≥dulo 15 - Curso LangChain v0.2\n\nE a√≠, pessoal! Pedro Guth aqui! üöÄ\n\nT√°, depois de construirmos projetos incr√≠veis com LangChain e LangGraph, chegou a hora de responder uma pergunta crucial: **\"Como diabos eu monitoro e otimizo essas aplica√ß√µes em produ√ß√£o?\"**\n\n√â a√≠ que entra o **LangSmith** - pense nele como o Sherlock Holmes das suas aplica√ß√µes de IA! üïµÔ∏è‚Äç‚ôÇÔ∏è\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-15_img_01.png)\n\n### O que voc√™ vai aprender hoje:\n- üîç O que √© LangSmith e por que voc√™ PRECISA dele\n- üìä Como fazer observabilidade completa das suas chains\n- üêõ Debug avan√ßado de aplica√ß√µes LangChain\n- üìà M√©tricas e an√°lises que importam\n- üí° Otimiza√ß√£o baseada em dados reais\n\nBora descobrir os segredos por tr√°s das suas aplica√ß√µes! üîç"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§î T√°, mas o que √© LangSmith?\n\nImagina que voc√™ √© um chef de um restaurante super movimentado. Voc√™ criou receitas incr√≠veis (suas chains do LangChain), mas agora precisa saber:\n\n- **Qual prato est√° demorando mais para ficar pronto?** (Lat√™ncia das chains)\n- **Onde os gar√ßons est√£o errando os pedidos?** (Onde suas chains falham)\n- **Qual ingrediente est√° custando mais caro?** (Custo dos tokens)\n- **Os clientes est√£o satisfeitos?** (Qualidade das respostas)\n\n**LangSmith √© como ter c√¢meras, cron√¥metros e um sistema de qualidade em toda sua cozinha!** üë®‚Äçüç≥\n\n### Principais recursos:\n1. **Tracing**: Rastreia cada passo das suas chains\n2. **Evaluation**: Avalia qualidade das respostas\n3. **Monitoring**: Monitora performance em tempo real\n4. **Debugging**: Identifica gargalos e erros\n5. **Dataset Management**: Gerencia dados de teste\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Primeiro, vamos instalar as depend√™ncias necess√°rias\n",
        "!pip install langsmith langchain langchain-google-genai python-dotenv\n",
        "\n",
        "# Imports necess√°rios\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import datetime\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# LangChain imports (j√° conhecemos do curso!)\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "\n",
        "# LangSmith imports - A novidade!\n",
        "from langsmith import Client\n",
        "from langsmith.evaluation import evaluate\n",
        "from langsmith.schemas import Dataset, Example\n",
        "\n",
        "print(\"üì¶ Depend√™ncias instaladas com sucesso!\")\n",
        "print(\"üéØ Vamos explorar o LangSmith!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configura√ß√£o das vari√°veis de ambiente\n",
        "load_dotenv()\n",
        "\n",
        "# Configura√ß√£o do Google AI (j√° conhecemos!)\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "if not GOOGLE_API_KEY:\n",
        "    GOOGLE_API_KEY = input(\"üîë Digite sua Google API Key: \")\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
        "\n",
        "# Configura√ß√£o do LangSmith - NOVO!\n",
        "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "if not LANGCHAIN_API_KEY:\n",
        "    print(\"\\nüÜï Para usar LangSmith, voc√™ precisa de uma conta em https://smith.langchain.com\")\n",
        "    LANGCHAIN_API_KEY = input(\"üîë Digite sua LangChain API Key (ou ENTER para pular): \")\n",
        "    if LANGCHAIN_API_KEY:\n",
        "        os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
        "\n",
        "# Configura√ß√µes do LangSmith\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"  # Ativa o tracing\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-course-module-15\"  # Nome do projeto\n",
        "\n",
        "print(\"‚úÖ Configura√ß√£o conclu√≠da!\")\n",
        "print(f\"üìä Projeto LangSmith: {os.environ.get('LANGCHAIN_PROJECT', 'N√£o configurado')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Criando uma Chain para Monitorar\n\nVamos criar uma chain simples que j√° usamos no curso - um assistente que explica conceitos t√©cnicos. Mas agora, com LangSmith, vamos poder ver **tudo** que acontece por debaixo dos panos!\n\n**Dica do Pedro**: √â como ter raio-X da sua aplica√ß√£o! ü©ª"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando nosso modelo (j√° conhecemos do m√≥dulo 2!)\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=1000\n",
        ")\n",
        "\n",
        "# Prompt template (m√≥dulo 3!)\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"\n",
        "    Voc√™ √© um professor de tecnologia brasileiro, did√°tico e descontra√≠do.\n",
        "    Explique conceitos t√©cnicos de forma simples, usando analogias do cotidiano.\n",
        "    Seja informal mas preciso.\n",
        "    \"\"\"),\n",
        "    (\"user\", \"Explique o conceito: {conceito}\")\n",
        "])\n",
        "\n",
        "# Parser de sa√≠da (m√≥dulo 3!)\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# Nossa chain completa (m√≥dulo 4!)\n",
        "explicador_chain = prompt | llm | parser\n",
        "\n",
        "print(\"üîó Chain criada com sucesso!\")\n",
        "print(\"üì° Agora com monitoramento LangSmith ativo!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Primeira Execu√ß√£o com Tracing\n\nT√°, agora vem a m√°gica! Quando executarmos nossa chain, o LangSmith vai **automaticamente** capturar:\n\n- ‚è±Ô∏è **Tempo de execu√ß√£o** de cada etapa\n- üí∞ **Tokens consumidos** (entrada e sa√≠da)\n- üîÑ **Fluxo completo** da execu√ß√£o\n- ‚ùå **Erros** (se houver)\n- üìä **Metadados** diversos\n\n√â como ter um **GPS** mostrando todo o trajeto da sua chain! üó∫Ô∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos testar nossa chain com diferentes conceitos\n",
        "conceitos_teste = [\n",
        "    \"Machine Learning\",\n",
        "    \"API REST\",\n",
        "    \"Docker\",\n",
        "    \"Microservi√ßos\"\n",
        "]\n",
        "\n",
        "print(\"üîç Executando chains com monitoramento LangSmith...\\n\")\n",
        "\n",
        "resultados = []\n",
        "\n",
        "for i, conceito in enumerate(conceitos_teste, 1):\n",
        "    print(f\"üìö {i}/4 - Explicando: {conceito}\")\n",
        "    \n",
        "    # Aqui a m√°gica acontece! LangSmith captura tudo automaticamente\n",
        "    try:\n",
        "        resultado = explicador_chain.invoke({\"conceito\": conceito})\n",
        "        resultados.append({\n",
        "            \"conceito\": conceito,\n",
        "            \"explicacao\": resultado[:200] + \"...\",  # Primeiros 200 chars\n",
        "            \"status\": \"‚úÖ Sucesso\"\n",
        "        })\n",
        "        print(f\"   {resultado[:100]}...\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        resultados.append({\n",
        "            \"conceito\": conceito,\n",
        "            \"explicacao\": f\"Erro: {str(e)}\",\n",
        "            \"status\": \"‚ùå Erro\"\n",
        "        })\n",
        "        print(f\"   ‚ùå Erro: {e}\")\n",
        "    \n",
        "    print(\"   üìä Trace enviado para LangSmith!\\n\")\n",
        "\n",
        "print(\"üéâ Todas as execu√ß√µes conclu√≠das!\")\n",
        "print(\"üîó Acesse https://smith.langchain.com para ver os traces!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Visualizando M√©tricas B√°sicas\n\nAgora vamos criar algumas visualiza√ß√µes b√°sicas para entender o que est√° acontecendo. √â como fazer um **raio-X** das nossas execu√ß√µes!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# Simulando dados de performance (em produ√ß√£o, voc√™ pegaria do LangSmith)\n",
        "conceitos = [r['conceito'] for r in resultados]\n",
        "tempos_execucao = np.random.uniform(0.5, 3.0, len(conceitos))  # Simulando tempos\n",
        "tokens_usados = np.random.randint(100, 500, len(conceitos))    # Simulando tokens\n",
        "\n",
        "# Gr√°fico de tempos de execu√ß√£o\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Gr√°fico 1: Tempo de execu√ß√£o\n",
        "bars1 = ax1.bar(range(len(conceitos)), tempos_execucao, \n",
        "                color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4'])\n",
        "ax1.set_xlabel('Conceitos Explicados')\n",
        "ax1.set_ylabel('Tempo (segundos)')\n",
        "ax1.set_title('‚è±Ô∏è Tempo de Execu√ß√£o por Conceito', fontsize=14, fontweight='bold')\n",
        "ax1.set_xticks(range(len(conceitos)))\n",
        "ax1.set_xticklabels([c[:10]+'...' if len(c) > 10 else c for c in conceitos], rotation=45)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bar, tempo in zip(bars1, tempos_execucao):\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
        "             f'{tempo:.1f}s', ha='center', va='bottom')\n",
        "\n",
        "# Gr√°fico 2: Tokens utilizados\n",
        "bars2 = ax2.bar(range(len(conceitos)), tokens_usados,\n",
        "                color=['#FFB6C1', '#98FB98', '#87CEEB', '#DDA0DD'])\n",
        "ax2.set_xlabel('Conceitos Explicados')\n",
        "ax2.set_ylabel('Tokens Utilizados')\n",
        "ax2.set_title('ü™ô Tokens Consumidos por Conceito', fontsize=14, fontweight='bold')\n",
        "ax2.set_xticks(range(len(conceitos)))\n",
        "ax2.set_xticklabels([c[:10]+'...' if len(c) > 10 else c for c in conceitos], rotation=45)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bar, tokens in zip(bars2, tokens_usados):\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
        "             f'{tokens}', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä M√©tricas simuladas geradas!\")\n",
        "print(\"üí° Em produ√ß√£o, esses dados viriam diretamente do LangSmith!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Client LangSmith: Acessando Dados Programaticamente\n\nT√°, agora vamos ver como acessar os dados do LangSmith de forma program√°tica. √â como ter **acesso VIP** aos bastidores! üé≠\n\n**Dica do Pedro**: Com o cliente, voc√™ pode criar dashboards personalizados, alertas autom√°ticos e muito mais!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inicializando o cliente LangSmith\n",
        "try:\n",
        "    client = Client()\n",
        "    print(\"‚úÖ Cliente LangSmith conectado com sucesso!\")\n",
        "    \n",
        "    # Verificando informa√ß√µes do projeto atual\n",
        "    project_name = os.environ.get(\"LANGCHAIN_PROJECT\", \"default\")\n",
        "    print(f\"üìä Projeto atual: {project_name}\")\n",
        "    \n",
        "    # Fun√ß√£o para listar execu√ß√µes recentes\n",
        "    def listar_execucoes_recentes(limit=5):\n",
        "        \"\"\"Lista as execu√ß√µes mais recentes do projeto\"\"\"\n",
        "        try:\n",
        "            runs = client.list_runs(\n",
        "                project_name=project_name,\n",
        "                limit=limit\n",
        "            )\n",
        "            \n",
        "            print(f\"\\nüîç √öltimas {limit} execu√ß√µes:\")\n",
        "            print(\"-\" * 80)\n",
        "            \n",
        "            for i, run in enumerate(runs, 1):\n",
        "                status_icon = \"‚úÖ\" if run.status == \"success\" else \"‚ùå\"\n",
        "                print(f\"{i}. {status_icon} {run.name} | ID: {str(run.id)[:8]}...\")\n",
        "                if hasattr(run, 'start_time') and run.start_time:\n",
        "                    print(f\"   üìÖ Executado em: {run.start_time.strftime('%H:%M:%S')}\")\n",
        "                if hasattr(run, 'execution_order'):\n",
        "                    print(f\"   ‚ö° Ordem: {run.execution_order}\")\n",
        "                print()\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è N√£o foi poss√≠vel listar execu√ß√µes: {e}\")\n",
        "            print(\"üí° Verifique se voc√™ tem execu√ß√µes no projeto atual\")\n",
        "    \n",
        "    # Listando execu√ß√µes\n",
        "    listar_execucoes_recentes()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erro ao conectar com LangSmith: {e}\")\n",
        "    print(\"üí° Verifique se sua LANGCHAIN_API_KEY est√° configurada corretamente\")\n",
        "    client = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Arquitetura do LangSmith\n\nVamos entender como o LangSmith funciona por baixo dos panos. √â como conhecer a **arquitetura** de uma cidade inteligente! üèôÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "# Diagrama da arquitetura LangSmith\n",
        "mermaid_diagram = \"\"\"\n",
        "```mermaid\n",
        "graph TD\n",
        "    A[üîó Sua Aplica√ß√£o LangChain] --> B[üì° LangSmith Tracer]\n",
        "    B --> C[‚òÅÔ∏è LangSmith Cloud]\n",
        "    \n",
        "    C --> D[üìä Dashboard Web]\n",
        "    C --> E[üîç API Client]\n",
        "    C --> F[üìà Analytics Engine]\n",
        "    \n",
        "    D --> G[üëÅÔ∏è Visualiza√ß√£o de Traces]\n",
        "    D --> H[üìã Relat√≥rios]\n",
        "    \n",
        "    E --> I[ü§ñ Automa√ß√µes]\n",
        "    E --> J[üö® Alertas]\n",
        "    \n",
        "    F --> K[üìä M√©tricas]\n",
        "    F --> L[üéØ Insights]\n",
        "    \n",
        "    style A fill:#e1f5fe\n",
        "    style C fill:#f3e5f5\n",
        "    style D fill:#e8f5e8\n",
        "```\n",
        "\"\"\"\n",
        "\n",
        "print(\"üèóÔ∏è Arquitetura do LangSmith:\")\n",
        "print(mermaid_diagram)\n",
        "\n",
        "print(\"\\nüìã Componentes principais:\")\n",
        "print(\"1. üì° Tracer: Captura automaticamente todas as execu√ß√µes\")\n",
        "print(\"2. ‚òÅÔ∏è Cloud: Armazena e processa os dados\")\n",
        "print(\"3. üìä Dashboard: Interface visual para an√°lise\")\n",
        "print(\"4. üîç API: Acesso program√°tico aos dados\")\n",
        "print(\"5. üìà Analytics: Processamento e insights autom√°ticos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß™ Evaluation: Testando Qualidade\n\nUma das funcionalidades mais **poderosas** do LangSmith √© a capacidade de avaliar a qualidade das suas chains automaticamente!\n\n√â como ter um **corretor autom√°tico** que nunca erra! üìù\n\n**Dica do Pedro**: Em produ√ß√£o, voc√™ pode configurar avalia√ß√µes autom√°ticas para cada deploy!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando um dataset de teste\n",
        "def criar_dataset_teste():\n",
        "    \"\"\"Cria um dataset para avaliar nossa chain explicadora\"\"\"\n",
        "    \n",
        "    exemplos_teste = [\n",
        "        {\n",
        "            \"conceito\": \"Intelig√™ncia Artificial\",\n",
        "            \"explicacao_esperada\": \"Sistema que simula intelig√™ncia humana\"\n",
        "        },\n",
        "        {\n",
        "            \"conceito\": \"Blockchain\",\n",
        "            \"explicacao_esperada\": \"Tecnologia de registro distribu√≠do e imut√°vel\"\n",
        "        },\n",
        "        {\n",
        "            \"conceito\": \"Cloud Computing\",\n",
        "            \"explicacao_esperada\": \"Computa√ß√£o usando recursos remotos via internet\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    return exemplos_teste\n",
        "\n",
        "# Fun√ß√£o de avalia√ß√£o personalizada\n",
        "def avaliar_qualidade_explicacao(run, example):\n",
        "    \"\"\"Avalia se a explica√ß√£o cont√©m elementos essenciais\"\"\"\n",
        "    \n",
        "    explicacao = run.outputs.get(\"output\", \"\").lower()\n",
        "    conceito = example.inputs.get(\"conceito\", \"\").lower()\n",
        "    \n",
        "    # Crit√©rios simples de avalia√ß√£o\n",
        "    pontuacao = 0\n",
        "    feedback = []\n",
        "    \n",
        "    # 1. Menciona o conceito?\n",
        "    if any(palavra in explicacao for palavra in conceito.split()):\n",
        "        pontuacao += 0.3\n",
        "        feedback.append(\"‚úÖ Menciona o conceito\")\n",
        "    else:\n",
        "        feedback.append(\"‚ùå N√£o menciona claramente o conceito\")\n",
        "    \n",
        "    # 2. Tem analogia ou exemplo?\n",
        "    palavras_analogia = [\"como\", \"igual\", \"assim\", \"exemplo\", \"imagina\", \"pense\"]\n",
        "    if any(palavra in explicacao for palavra in palavras_analogia):\n",
        "        pontuacao += 0.3\n",
        "        feedback.append(\"‚úÖ Usa analogias/exemplos\")\n",
        "    else:\n",
        "        feedback.append(\"‚ö†Ô∏è Poderia usar mais analogias\")\n",
        "    \n",
        "    # 3. Tamanho adequado?\n",
        "    if 50 <= len(explicacao) <= 500:\n",
        "        pontuacao += 0.2\n",
        "        feedback.append(\"‚úÖ Tamanho adequado\")\n",
        "    else:\n",
        "        feedback.append(\"‚ö†Ô∏è Tamanho inadequado\")\n",
        "    \n",
        "    # 4. Tom informal?\n",
        "    palavras_informais = [\"n√©\", \"t√°\", \"galera\", \"pessoal\", \"cara\", \"mano\"]\n",
        "    if any(palavra in explicacao for palavra in palavras_informais):\n",
        "        pontuacao += 0.2\n",
        "        feedback.append(\"‚úÖ Tom informal\")\n",
        "    else:\n",
        "        feedback.append(\"‚ö†Ô∏è Poderia ser mais informal\")\n",
        "    \n",
        "    return {\n",
        "        \"key\": \"qualidade_explicacao\",\n",
        "        \"score\": pontuacao,\n",
        "        \"comment\": \" | \".join(feedback)\n",
        "    }\n",
        "\n",
        "# Testando nossa fun√ß√£o de avalia√ß√£o\n",
        "exemplos = criar_dataset_teste()\n",
        "print(\"üß™ Dataset de teste criado!\")\n",
        "print(f\"üìä {len(exemplos)} exemplos preparados para avalia√ß√£o\")\n",
        "\n",
        "# Simulando uma avalia√ß√£o\n",
        "print(\"\\nüî¨ Exemplo de avalia√ß√£o:\")\n",
        "class MockRun:\n",
        "    def __init__(self, output):\n",
        "        self.outputs = {\"output\": output}\n",
        "\n",
        "class MockExample:\n",
        "    def __init__(self, conceito):\n",
        "        self.inputs = {\"conceito\": conceito}\n",
        "\n",
        "# Testando com uma explica√ß√£o simulada\n",
        "mock_run = MockRun(\"Intelig√™ncia Artificial √© como ter um rob√¥ super inteligente que pensa como a gente, n√©? √â tecnologia que simula o c√©rebro humano.\")\n",
        "mock_example = MockExample(\"Intelig√™ncia Artificial\")\n",
        "\n",
        "resultado_avaliacao = avaliar_qualidade_explicacao(mock_run, mock_example)\n",
        "print(f\"üìä Pontua√ß√£o: {resultado_avaliacao['score']:.1f}/1.0\")\n",
        "print(f\"üí¨ Feedback: {resultado_avaliacao['comment']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Debugging Avan√ßado\n\nUma das coisas mais **Liiiindas** do LangSmith √© a capacidade de fazer debug detalhado das suas chains!\n\n√â como ter **lupa de detective** para encontrar bugs! üîç\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-15_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vamos criar uma chain mais complexa para demonstrar debugging\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.schema.runnable import RunnableLambda\n",
        "\n",
        "# Chain com m√∫ltiplas etapas (como vimos no m√≥dulo 4!)\n",
        "def extrair_palavras_chave(conceito: str) -> dict:\n",
        "    \"\"\"Extrai palavras-chave do conceito para an√°lise\"\"\"\n",
        "    palavras = conceito.lower().split()\n",
        "    \n",
        "    # Simulando algum processamento\n",
        "    import time\n",
        "    time.sleep(0.1)  # Simula processamento\n",
        "    \n",
        "    return {\n",
        "        \"conceito_original\": conceito,\n",
        "        \"palavras_chave\": palavras,\n",
        "        \"num_palavras\": len(palavras),\n",
        "        \"complexidade\": \"alta\" if len(palavras) > 2 else \"baixa\"\n",
        "    }\n",
        "\n",
        "def personalizar_prompt(dados: dict) -> dict:\n",
        "    \"\"\"Personaliza o prompt baseado na complexidade\"\"\"\n",
        "    conceito = dados[\"conceito_original\"]\n",
        "    complexidade = dados[\"complexidade\"]\n",
        "    \n",
        "    if complexidade == \"alta\":\n",
        "        estilo = \"Esse conceito √© complexo, ent√£o seja bem did√°tico e use v√°rias analogias.\"\n",
        "    else:\n",
        "        estilo = \"Conceito simples, pode ser mais direto mas ainda informal.\"\n",
        "    \n",
        "    return {\n",
        "        \"conceito\": conceito,\n",
        "        \"estilo_instrucao\": estilo,\n",
        "        **dados  # Mant√©m dados originais\n",
        "    }\n",
        "\n",
        "# Prompt din√¢mico\n",
        "prompt_avancado = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"\n",
        "    Voc√™ √© um professor de tecnologia brasileiro, did√°tico e descontra√≠do.\n",
        "    {estilo_instrucao}\n",
        "    Explique conceitos t√©cnicos de forma simples, usando analogias do cotidiano.\n",
        "    Seja informal mas preciso.\n",
        "    \"\"\"),\n",
        "    (\"user\", \"Explique o conceito: {conceito}\")\n",
        "])\n",
        "\n",
        "# Chain completa com debugging\n",
        "chain_com_debug = (\n",
        "    RunnableLambda(extrair_palavras_chave) |\n",
        "    RunnableLambda(personalizar_prompt) |\n",
        "    prompt_avancado |\n",
        "    llm |\n",
        "    parser\n",
        ")\n",
        "\n",
        "print(\"üîß Chain avan√ßada criada com m√∫ltiplas etapas!\")\n",
        "print(\"üîç Cada etapa ser√° trackeada pelo LangSmith!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testando a chain avan√ßada\n",
        "conceitos_debug = [\n",
        "    \"API\",  # Simples\n",
        "    \"Machine Learning Ops\",  # Complexo\n",
        "    \"GraphQL\"  # M√©dio\n",
        "]\n",
        "\n",
        "print(\"üîç Testando chain avan√ßada com debugging detalhado...\\n\")\n",
        "\n",
        "for conceito in conceitos_debug:\n",
        "    print(f\"üß† Processando: {conceito}\")\n",
        "    \n",
        "    try:\n",
        "        # Execu√ß√£o com tracing autom√°tico\n",
        "        resultado = chain_com_debug.invoke(conceito)\n",
        "        \n",
        "        print(f\"   ‚úÖ Processado com sucesso!\")\n",
        "        print(f\"   üìù Resposta: {resultado[:100]}...\")\n",
        "        print(f\"   üìä Trace completo enviado para LangSmith!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ùå Erro durante processamento: {e}\")\n",
        "        print(f\"   üîç Erro tamb√©m trackeado no LangSmith!\")\n",
        "    \n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(\"\\nüéâ Debugging completo!\")\n",
        "print(\"üí° Agora voc√™ pode ver no LangSmith:\")\n",
        "print(\"   - Tempo de cada etapa da chain\")\n",
        "print(\"   - Input/Output de cada fun√ß√£o\")\n",
        "print(\"   - Erros detalhados (se houver)\")\n",
        "print(\"   - Fluxo completo de execu√ß√£o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä An√°lise de Performance\n\nVamos criar um dashboard simples para analisar a performance das nossas chains. √â como ter um **painel de controle** da sua aplica√ß√£o! üéõÔ∏è\n\n**Dica do Pedro**: Esses tipos de an√°lise s√£o essenciais para otimizar custos e performance em produ√ß√£o!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Simulando dados de performance ao longo do tempo\n",
        "# Em produ√ß√£o, esses dados viriam do LangSmith API\n",
        "\n",
        "# Gerando dados simulados para uma semana\n",
        "dias = 7\n",
        "horas_por_dia = 24\n",
        "total_pontos = dias * horas_por_dia\n",
        "\n",
        "# Timestamps\n",
        "agora = datetime.now()\n",
        "timestamps = [agora - timedelta(hours=i) for i in range(total_pontos, 0, -1)]\n",
        "\n",
        "# M√©tricas simuladas\n",
        "np.random.seed(42)  # Para resultados consistentes\n",
        "\n",
        "# Lat√™ncia (com padr√£o di√°rio)\n",
        "latencia_base = 1.5\n",
        "latencia = []\n",
        "for i, ts in enumerate(timestamps):\n",
        "    # Maior lat√™ncia durante hor√°rio comercial (9-18h)\n",
        "    hora = ts.hour\n",
        "    if 9 <= hora <= 18:\n",
        "        fator_hora = 1.3  # 30% mais lento\n",
        "    else:\n",
        "        fator_hora = 0.8  # 20% mais r√°pido\n",
        "    \n",
        "    # Adiciona ru√≠do aleat√≥rio\n",
        "    ruido = np.random.normal(0, 0.2)\n",
        "    lat = latencia_base * fator_hora + ruido\n",
        "    latencia.append(max(0.1, lat))  # M√≠nimo 0.1s\n",
        "\n",
        "# Taxa de sucesso\n",
        "taxa_sucesso = np.random.uniform(0.92, 0.99, total_pontos)\n",
        "\n",
        "# Custo (tokens)\n",
        "custo_por_hora = np.random.poisson(150, total_pontos)  # M√©dia 150 tokens/hora\n",
        "\n",
        "print(f\"üìä Dados simulados gerados para {dias} dias\")\n",
        "print(f\"‚è±Ô∏è Lat√™ncia m√©dia: {np.mean(latencia):.2f}s\")\n",
        "print(f\"‚úÖ Taxa de sucesso m√©dia: {np.mean(taxa_sucesso):.1%}\")\n",
        "print(f\"üí∞ Tokens m√©dios/hora: {np.mean(custo_por_hora):.0f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dashboard de Performance\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('üéõÔ∏è Dashboard de Performance - LangSmith Analytics', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. Lat√™ncia ao longo do tempo\n",
        "ax1.plot(timestamps, latencia, color='#FF6B6B', linewidth=1.5, alpha=0.8)\n",
        "ax1.fill_between(timestamps, latencia, alpha=0.3, color='#FF6B6B')\n",
        "ax1.set_title('‚è±Ô∏è Lat√™ncia das Execu√ß√µes', fontweight='bold')\n",
        "ax1.set_ylabel('Tempo (segundos)')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Linha de m√©dia\n",
        "media_latencia = np.mean(latencia)\n",
        "ax1.axhline(y=media_latencia, color='red', linestyle='--', alpha=0.8, \n",
        "           label=f'M√©dia: {media_latencia:.2f}s')\n",
        "ax1.legend()\n",
        "\n",
        "# 2. Taxa de sucesso\n",
        "# Agrupando por dia para melhor visualiza√ß√£o\n",
        "dias_unicos = list(set(ts.date() for ts in timestamps))\n",
        "dias_unicos.sort()\n",
        "\n",
        "taxa_por_dia = []\n",
        "for dia in dias_unicos:\n",
        "    indices_dia = [i for i, ts in enumerate(timestamps) if ts.date() == dia]\n",
        "    taxa_dia = np.mean([taxa_sucesso[i] for i in indices_dia])\n",
        "    taxa_por_dia.append(taxa_dia)\n",
        "\n",
        "bars = ax2.bar(range(len(dias_unicos)), [t*100 for t in taxa_por_dia], \n",
        "               color='#4ECDC4', alpha=0.8)\n",
        "ax2.set_title('‚úÖ Taxa de Sucesso por Dia', fontweight='bold')\n",
        "ax2.set_ylabel('Taxa de Sucesso (%)')\n",
        "ax2.set_ylim(90, 100)\n",
        "ax2.set_xticks(range(len(dias_unicos)))\n",
        "ax2.set_xticklabels([dia.strftime('%d/%m') for dia in dias_unicos], rotation=45)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bar, taxa in zip(bars, taxa_por_dia):\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
        "             f'{taxa:.1%}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 3. Distribui√ß√£o de lat√™ncia (histograma)\n",
        "ax3.hist(latencia, bins=30, color='#45B7D1', alpha=0.7, edgecolor='black')\n",
        "ax3.set_title('üìä Distribui√ß√£o de Lat√™ncia', fontweight='bold')\n",
        "ax3.set_xlabel('Tempo (segundos)')\n",
        "ax3.set_ylabel('Frequ√™ncia')\n",
        "ax3.axvline(x=media_latencia, color='red', linestyle='--', \n",
        "           label=f'M√©dia: {media_latencia:.2f}s')\n",
        "ax3.axvline(x=np.percentile(latencia, 95), color='orange', linestyle='--', \n",
        "           label=f'P95: {np.percentile(latencia, 95):.2f}s')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Custo acumulado (tokens)\n",
        "custo_acumulado = np.cumsum(custo_por_hora)\n",
        "ax4.plot(timestamps, custo_acumulado, color='#96CEB4', linewidth=2)\n",
        "ax4.fill_between(timestamps, custo_acumulado, alpha=0.3, color='#96CEB4')\n",
        "ax4.set_title('üí∞ Tokens Acumulados', fontweight='bold')\n",
        "ax4.set_ylabel('Total de Tokens')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "# Formata√ß√£o dos eixos X para mostrar datas\n",
        "for ax in [ax1, ax4]:\n",
        "    ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Resumo das m√©tricas\n",
        "print(\"\\nüìà RESUMO DAS M√âTRICAS:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"‚è±Ô∏è  Lat√™ncia M√©dia: {np.mean(latencia):.2f}s\")\n",
        "print(f\"üöÄ Lat√™ncia P95: {np.percentile(latencia, 95):.2f}s\")\n",
        "print(f\"‚úÖ Taxa de Sucesso: {np.mean(taxa_sucesso):.1%}\")\n",
        "print(f\"üí∞ Total de Tokens: {custo_acumulado[-1]:,}\")\n",
        "print(f\"üìä Execu√ß√µes Simuladas: {len(latencia)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Casos de Uso Reais do LangSmith\n\nT√°, agora vamos ver onde o LangSmith **realmente brilha** no mundo real! S√£o cen√°rios que voc√™ vai enfrentar quando colocar suas aplica√ß√µes em produ√ß√£o.\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-15_img_04.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí° Cen√°rios Pr√°ticos\n\n### 1. üè• Sistema de Atendimento M√©dico\n**Problema**: Um hospital usa LangChain para classificar sintomas dos pacientes\n**LangSmith ajuda**:\n- Monitora precis√£o das classifica√ß√µes\n- Detecta quando modelo est√° errando muito\n- Rastreia tempo de resposta (cr√≠tico em emerg√™ncias)\n- Avalia qualidade das respostas m√©dicas\n\n### 2. üõí E-commerce com Chatbot\n**Problema**: Loja online com assistente virtual para vendas\n**LangSmith ajuda**:\n- Analisa quais produtos geram mais d√∫vidas\n- Monitora taxa de convers√£o por conversa\n- Detecta quando chatbot n√£o est√° ajudando\n- Otimiza prompts baseado em dados reais\n\n### 3. üìö Plataforma Educacional\n**Problema**: Sistema que gera explica√ß√µes personalizadas\n**LangSmith ajuda**:\n- Avalia did√°tica das explica√ß√µes\n- Monitora engagement dos alunos\n- Detecta t√≥picos mais dif√≠ceis\n- A/B testing de diferentes approaches\n\n**Dica do Pedro**: Em cada caso, LangSmith transforma dados em insights acion√°veis! üìä"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulando um sistema de alertas inteligentes\n",
        "# Isso √© algo que voc√™ faria em produ√ß√£o com LangSmith\n",
        "\n",
        "class SistemaAlertas:\n",
        "    def __init__(self):\n",
        "        self.thresholds = {\n",
        "            'latencia_max': 3.0,      # 3 segundos\n",
        "            'taxa_sucesso_min': 0.95,  # 95%\n",
        "            'custo_hora_max': 1000,     # 1000 tokens/hora\n",
        "            'taxa_erro_max': 0.05       # 5%\n",
        "        }\n",
        "        self.alertas_ativos = []\n",
        "    \n",
        "    def verificar_metricas(self, metricas):\n",
        "        \"\"\"Verifica se alguma m√©trica ultrapassou o threshold\"\"\"\n",
        "        alertas = []\n",
        "        \n",
        "        # Verifica lat√™ncia\n",
        "        if metricas['latencia_media'] > self.thresholds['latencia_max']:\n",
        "            alertas.append({\n",
        "                'tipo': 'üêå LAT√äNCIA ALTA',\n",
        "                'valor': f\"{metricas['latencia_media']:.2f}s\",\n",
        "                'threshold': f\"{self.thresholds['latencia_max']}s\",\n",
        "                'severidade': 'ALTA' if metricas['latencia_media'] > 5.0 else 'M√âDIA'\n",
        "            })\n",
        "        \n",
        "        # Verifica taxa de sucesso\n",
        "        if metricas['taxa_sucesso'] < self.thresholds['taxa_sucesso_min']:\n",
        "            alertas.append({\n",
        "                'tipo': '‚ùå TAXA DE ERRO ALTA',\n",
        "                'valor': f\"{metricas['taxa_sucesso']:.1%}\",\n",
        "                'threshold': f\"{self.thresholds['taxa_sucesso_min']:.1%}\",\n",
        "                'severidade': 'CR√çTICA' if metricas['taxa_sucesso'] < 0.90 else 'ALTA'\n",
        "            })\n",
        "        \n",
        "        # Verifica custo\n",
        "        if metricas['tokens_por_hora'] > self.thresholds['custo_hora_max']:\n",
        "            alertas.append({\n",
        "                'tipo': 'üí∏ CUSTO ALTO',\n",
        "                'valor': f\"{metricas['tokens_por_hora']:,} tokens/hora\",\n",
        "                'threshold': f\"{self.thresholds['custo_hora_max']:,} tokens/hora\",\n",
        "                'severidade': 'M√âDIA'\n",
        "            })\n",
        "        \n",
        "        return alertas\n",
        "    \n",
        "    def gerar_relatorio_alertas(self, alertas):\n",
        "        \"\"\"Gera relat√≥rio formatado dos alertas\"\"\"\n",
        "        if not alertas:\n",
        "            return \"‚úÖ Todas as m√©tricas est√£o dentro dos par√¢metros normais!\"\n",
        "        \n",
        "        relatorio = \"üö® ALERTAS DETECTADOS:\\n\"\n",
        "        relatorio += \"=\" * 60 + \"\\n\"\n",
        "        \n",
        "        for alerta in alertas:\n",
        "            relatorio += f\"\\n{alerta['tipo']} - {alerta['severidade']}\\n\"\n",
        "            relatorio += f\"   üìä Valor atual: {alerta['valor']}\\n\"\n",
        "            relatorio += f\"   üéØ Threshold: {alerta['threshold']}\\n\"\n",
        "            relatorio += \"-\" * 40 + \"\\n\"\n",
        "        \n",
        "        return relatorio\n",
        "\n",
        "# Testando o sistema de alertas\n",
        "sistema_alertas = SistemaAlertas()\n",
        "\n",
        "# Cen√°rio 1: M√©tricas normais\n",
        "metricas_normais = {\n",
        "    'latencia_media': 1.2,\n",
        "    'taxa_sucesso': 0.98,\n",
        "    'tokens_por_hora': 200\n",
        "}\n",
        "\n",
        "print(\"üìä CEN√ÅRIO 1 - Opera√ß√£o Normal:\")\n",
        "alertas1 = sistema_alertas.verificar_metricas(metricas_normais)\n",
        "print(sistema_alertas.gerar_relatorio_alertas(alertas1))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# Cen√°rio 2: Problemas detectados\n",
        "metricas_problemas = {\n",
        "    'latencia_media': 4.5,\n",
        "    'taxa_sucesso': 0.89,\n",
        "    'tokens_por_hora': 1500\n",
        "}\n",
        "\n",
        "print(\"üìä CEN√ÅRIO 2 - Problemas Detectados:\")\n",
        "alertas2 = sistema_alertas.verificar_metricas(metricas_problemas)\n",
        "print(sistema_alertas.gerar_relatorio_alertas(alertas2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèãÔ∏è‚Äç‚ôÄÔ∏è Exerc√≠cio Pr√°tico 1: Criando seu Sistema de Monitoramento\n\nBora botar a m√£o na massa! Voc√™ vai criar uma chain personalizada e implementar seu pr√≥prio sistema de monitoramento.\n\n**Desafio**: Implemente uma chain que classifica sentimentos de reviews e monitore sua performance!\n\n**Dica do Pedro**: Pense como um DevOps - quais m√©tricas s√£o realmente importantes? ü§î"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 1: Sistema de An√°lise de Sentimentos com Monitoramento\n",
        "# Complete o c√≥digo abaixo!\n",
        "\n",
        "# 1. Crie um prompt para an√°lise de sentimentos\n",
        "prompt_sentimentos = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"\n",
        "    Voc√™ √© um especialista em an√°lise de sentimentos.\n",
        "    Classifique o sentimento do texto em: POSITIVO, NEGATIVO ou NEUTRO.\n",
        "    Seja preciso e consistente.\n",
        "    Responda apenas com a classifica√ß√£o seguida de um score de 0-10.\n",
        "    Formato: \"POSITIVO - 8\" ou \"NEGATIVO - 3\"\n",
        "    \"\"\"),\n",
        "    (\"user\", \"Analise o sentimento deste texto: {texto}\")\n",
        "])\n",
        "\n",
        "# 2. Crie a chain de an√°lise\n",
        "# SEU C√ìDIGO AQUI:\n",
        "chain_sentimentos = None  # Substitua por sua implementa√ß√£o\n",
        "\n",
        "# 3. Dataset de teste\n",
        "reviews_teste = [\n",
        "    \"Produto excelente! Superou todas as expectativas\",\n",
        "    \"Terr√≠vel, n√£o funcionou nem um dia\",\n",
        "    \"Ok, cumpre o que promete\",\n",
        "    \"Incr√≠vel! Recomendo para todos\",\n",
        "    \"P√©ssimo atendimento, produto com defeito\",\n",
        "    \"Funciona bem, mas poderia ser melhor\"\n",
        "]\n",
        "\n",
        "# 4. Implemente uma fun√ß√£o de avalia√ß√£o\n",
        "def avaliar_classificacao_sentimento(resultado, texto_original):\n",
        "    \"\"\"Avalia a qualidade da classifica√ß√£o de sentimento\"\"\"\n",
        "    # SEU C√ìDIGO AQUI:\n",
        "    # Dicas:\n",
        "    # - Verifique se o formato est√° correto\n",
        "    # - Valide se a classifica√ß√£o faz sentido\n",
        "    # - Retorne um score de 0-1\n",
        "    pass\n",
        "\n",
        "# 5. Execute os testes\n",
        "print(\"üéØ EXERC√çCIO 1: An√°lise de Sentimentos\")\n",
        "print(\"Implemente o c√≥digo acima e teste sua chain!\")\n",
        "print(\"\\nüìù Checklist:\")\n",
        "print(\"[ ] Chain de sentimentos criada\")\n",
        "print(\"[ ] Fun√ß√£o de avalia√ß√£o implementada\")\n",
        "print(\"[ ] Testes executados com sucesso\")\n",
        "print(\"[ ] M√©tricas coletadas e analisadas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéì Exerc√≠cio Pr√°tico 2: Dashboard Personalizado\n\nAgora vamos criar um dashboard personalizado para monitorar m√∫ltiplas chains em tempo real!\n\n**Desafio**: Implemente um sistema que monitore 3 tipos diferentes de chains e gere alertas inteligentes.\n\n**Dica do Pedro**: Pense em como diferentes tipos de aplica√ß√£o precisam de m√©tricas diferentes!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXERC√çCIO 2: Dashboard Multi-Chain\n",
        "# Complete a implementa√ß√£o!\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "\n",
        "class DashboardMultiChain:\n",
        "    def __init__(self):\n",
        "        self.chains_data = {\n",
        "            'chat_bot': {\n",
        "                'name': 'ü§ñ ChatBot Atendimento',\n",
        "                'metricas': [],\n",
        "                'color': '#FF6B6B'\n",
        "            },\n",
        "            'classificador': {\n",
        "                'name': 'üè∑Ô∏è Classificador Sentimentos', \n",
        "                'metricas': [],\n",
        "                'color': '#4ECDC4'\n",
        "            },\n",
        "            'resumidor': {\n",
        "                'name': 'üìù Resumidor Textos',\n",
        "                'metricas': [],\n",
        "                'color': '#45B7D1'\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    def adicionar_metrica(self, chain_name, latencia, taxa_sucesso, tokens):\n",
        "        \"\"\"Adiciona nova m√©trica para uma chain\"\"\"\n",
        "        # SEU C√ìDIGO AQUI:\n",
        "        # Implemente a l√≥gica para adicionar m√©tricas\n",
        "        pass\n",
        "    \n",
        "    def gerar_dashboard(self):\n",
        "        \"\"\"Gera dashboard visual com todas as chains\"\"\"\n",
        "        # SEU C√ìDIGO AQUI:\n",
        "        # Crie gr√°ficos comparativos entre as chains\n",
        "        # Dicas:\n",
        "        # - Use subplots para m√∫ltiplas visualiza√ß√µes\n",
        "        # - Compare lat√™ncia entre chains\n",
        "        # - Mostre evolu√ß√£o temporal\n",
        "        # - Destaque chains com problemas\n",
        "        pass\n",
        "    \n",
        "    def detectar_anomalias(self):\n",
        "        \"\"\"Detecta anomalias nas m√©tricas das chains\"\"\"\n",
        "        # SEU C√ìDIGO AQUI:\n",
        "        # Implemente detec√ß√£o de anomalias\n",
        "        # Dicas:\n",
        "        # - Use desvio padr√£o para detectar outliers\n",
        "        # - Compare com m√©dias hist√≥ricas\n",
        "        # - Gere alertas espec√≠ficos por tipo de chain\n",
        "        pass\n",
        "\n",
        "# Simula√ß√£o de dados para teste\n",
        "dashboard = DashboardMultiChain()\n",
        "\n",
        "# Gerando dados simulados\n",
        "np.random.seed(42)\n",
        "for i in range(24):  # 24 horas de dados\n",
        "    # ChatBot - mais usado durante dia\n",
        "    dashboard.adicionar_metrica('chat_bot', \n",
        "                               np.random.uniform(0.8, 2.5),\n",
        "                               np.random.uniform(0.92, 0.98),\n",
        "                               np.random.randint(200, 800))\n",
        "    \n",
        "    # Classificador - performance mais est√°vel\n",
        "    dashboard.adicionar_metrica('classificador',\n",
        "                               np.random.uniform(0.3, 1.0),\n",
        "                               np.random.uniform(0.95, 0.99),\n",
        "                               np.random.randint(50, 200))\n",
        "    \n",
        "    # Resumidor - mais pesado\n",
        "    dashboard.adicionar_metrica('resumidor',\n",
        "                               np.random.uniform(2.0, 5.0),\n",
        "                               np.random.uniform(0.88, 0.96),\n",
        "                               np.random.randint(300, 1000))\n",
        "\n",
        "print(\"üìä EXERC√çCIO 2: Dashboard Multi-Chain\")\n",
        "print(\"Complete a implementa√ß√£o da classe DashboardMultiChain!\")\n",
        "print(\"\\nüìù Checklist:\")\n",
        "print(\"[ ] M√©todo adicionar_metrica implementado\")\n",
        "print(\"[ ] Dashboard visual criado\")\n",
        "print(\"[ ] Sistema de detec√ß√£o de anomalias\")\n",
        "print(\"[ ] Alertas espec√≠ficos por tipo de chain\")\n",
        "print(\"[ ] Compara√ß√µes entre chains\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÆ LangSmith vs Outras Ferramentas\n\nT√°, mas por que LangSmith e n√£o outras op√ß√µes? Vamos fazer uma **compara√ß√£o honesta**! ü•ä\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-15_img_05.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compara√ß√£o visual das ferramentas de monitoramento\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Dados da compara√ß√£o\n",
        "ferramentas = {\n",
        "    'LangSmith': {\n",
        "        'integra√ß√£o_langchain': 10,\n",
        "        'facilidade_uso': 9,\n",
        "        'recursos_debugging': 10,\n",
        "        'custo': 6,\n",
        "        'personaliza√ß√£o': 8\n",
        "    },\n",
        "    'Weights & Biases': {\n",
        "        'integra√ß√£o_langchain': 7,\n",
        "        'facilidade_uso': 8,\n",
        "        'recursos_debugging': 7,\n",
        "        'custo': 7,\n",
        "        'personaliza√ß√£o': 9\n",
        "    },\n",
        "    'MLflow': {\n",
        "        'integra√ß√£o_langchain': 6,\n",
        "        'facilidade_uso': 7,\n",
        "        'recursos_debugging': 6,\n",
        "        'custo': 10,  # Open source\n",
        "        'personaliza√ß√£o': 8\n",
        "    },\n",
        "    'Datadog': {\n",
        "        'integra√ß√£o_langchain': 5,\n",
        "        'facilidade_uso': 8,\n",
        "        'recursos_debugging': 8,\n",
        "        'custo': 4,\n",
        "        'personaliza√ß√£o': 7\n",
        "    }\n",
        "}\n",
        "\n",
        "# Gr√°fico radar para compara√ß√£o\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Configura√ß√£o do gr√°fico radar\n",
        "criterios = list(ferramentas['LangSmith'].keys())\n",
        "num_criterios = len(criterios)\n",
        "\n",
        "# √Çngulos para cada crit√©rio\n",
        "angulos = np.linspace(0, 2 * np.pi, num_criterios, endpoint=False).tolist()\n",
        "angulos += angulos[:1]  # Fecha o c√≠rculo\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 10), subplot_kw=dict(projection='polar'))\n",
        "\n",
        "cores = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
        "\n",
        "for i, (ferramenta, dados) in enumerate(ferramentas.items()):\n",
        "    valores = list(dados.values())\n",
        "    valores += valores[:1]  # Fecha o c√≠rculo\n",
        "    \n",
        "    ax.plot(angulos, valores, 'o-', linewidth=2, \n",
        "           label=ferramenta, color=cores[i])\n",
        "    ax.fill(angulos, valores, alpha=0.25, color=cores[i])\n",
        "\n",
        "# Configura√ß√µes do gr√°fico\n",
        "ax.set_xticks(angulos[:-1])\n",
        "ax.set_xticklabels([c.replace('_', ' ').title() for c in criterios])\n",
        "ax.set_ylim(0, 10)\n",
        "ax.set_yticks(range(0, 11, 2))\n",
        "ax.set_title('ü•ä Compara√ß√£o de Ferramentas de Monitoramento\\n(Escala 0-10)', \n",
        "             size=16, fontweight='bold', pad=20)\n",
        "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
        "ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéØ AN√ÅLISE DAS FERRAMENTAS:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"üèÜ LangSmith:\")\n",
        "print(\"   ‚úÖ Integra√ß√£o nativa com LangChain\")\n",
        "print(\"   ‚úÖ Debugging espec√≠fico para chains\")\n",
        "print(\"   ‚úÖ Tracing autom√°tico\")\n",
        "print(\"   ‚ùå Mais caro que alternativas open-source\")\n",
        "print(\"\\nü•à Weights & Biases:\")\n",
        "print(\"   ‚úÖ Excelente para ML em geral\")\n",
        "print(\"   ‚úÖ Muito flex√≠vel\")\n",
        "print(\"   ‚ùå Curva de aprendizado maior\")\n",
        "print(\"\\nü•â MLflow:\")\n",
        "print(\"   ‚úÖ Open source e gratuito\")\n",
        "print(\"   ‚úÖ Comunidade ativa\")\n",
        "print(\"   ‚ùå Menos espec√≠fico para LLMs\")\n",
        "print(\"\\nüíº Datadog:\")\n",
        "print(\"   ‚úÖ Monitoramento enterprise\")\n",
        "print(\"   ‚úÖ Infraestrutura robusta\")\n",
        "print(\"   ‚ùå Muito caro\")\n",
        "print(\"   ‚ùå Menos foco em LLMs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Pr√≥ximos Passos e Melhores Pr√°ticas\n\nT√°, agora que voc√™ j√° sabe **tudo** sobre LangSmith, vamos falar sobre como usar isso na pr√°tica! √â hora de partir para o **pr√≥ximo n√≠vel**! üöÄ\n\n**Dica do Pedro**: A diferen√ßa entre um desenvolvedor junior e senior √© saber monitorar e otimizar suas aplica√ß√µes!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã Checklist de Implementa√ß√£o em Produ√ß√£o\n\n### üéØ Antes de ir para produ√ß√£o:\n\n#### 1. **Setup B√°sico** ‚úÖ\n- [ ] Conta LangSmith configurada\n- [ ] Vari√°veis de ambiente definidas\n- [ ] Projetos organizados por ambiente (dev/staging/prod)\n- [ ] API keys seguras\n\n#### 2. **Monitoramento** üìä\n- [ ] Tracing ativo em todas as chains\n- [ ] M√©tricas de lat√™ncia configuradas\n- [ ] Monitoramento de custos (tokens)\n- [ ] Alertas autom√°ticos configurados\n\n#### 3. **Qualidade** üéØ\n- [ ] Datasets de avalia√ß√£o criados\n- [ ] Crit√©rios de qualidade definidos\n- [ ] Testes automatizados implementados\n- [ ] Processo de review das respostas\n\n#### 4. **Otimiza√ß√£o** ‚ö°\n- [ ] Dashboards de performance\n- [ ] An√°lise de gargalos\n- [ ] A/B testing de prompts\n- [ ] Otimiza√ß√£o baseada em dados\n\n### üî• Dicas Avan√ßadas:\n\n1. **Organize por contexto**: Crie projetos separados para cada aplica√ß√£o\n2. **Tags inteligentes**: Use tags para categorizar execu√ß√µes\n3. **Filtros poderosos**: Configure filtros para an√°lises espec√≠ficas\n4. **Relat√≥rios autom√°ticos**: Configure reports semanais\n5. **Integra√ß√£o CI/CD**: Inclua avalia√ß√µes no seu pipeline\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-15_img_06.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Template de configura√ß√£o para produ√ß√£o\n",
        "# Use isso como base para seus projetos!\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "class ConfigLangSmithProd:\n",
        "    \"\"\"Configura√ß√£o completa do LangSmith para produ√ß√£o\"\"\"\n",
        "    \n",
        "    def __init__(self, ambiente=\"dev\"):\n",
        "        self.ambiente = ambiente\n",
        "        self.configurar_ambiente()\n",
        "    \n",
        "    def configurar_ambiente(self):\n",
        "        \"\"\"Configura vari√°veis baseadas no ambiente\"\"\"\n",
        "        \n",
        "        # Configura√ß√µes base\n",
        "        os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "        os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "        \n",
        "        # Configura√ß√µes por ambiente\n",
        "        if self.ambiente == \"dev\":\n",
        "            os.environ[\"LANGCHAIN_PROJECT\"] = f\"meu-projeto-dev-{datetime.now().strftime('%Y%m')}\"\n",
        "            self.sample_rate = 1.0  # 100% das execu√ß√µes\n",
        "            \n",
        "        elif self.ambiente == \"staging\":\n",
        "            os.environ[\"LANGCHAIN_PROJECT\"] = f\"meu-projeto-staging-{datetime.now().strftime('%Y%m')}\"\n",
        "            self.sample_rate = 0.5  # 50% das execu√ß√µes\n",
        "            \n",
        "        elif self.ambiente == \"prod\":\n",
        "            os.environ[\"LANGCHAIN_PROJECT\"] = f\"meu-projeto-prod-{datetime.now().strftime('%Y%m')}\"\n",
        "            self.sample_rate = 0.1  # 10% das execu√ß√µes (para reduzir custos)\n",
        "        \n",
        "        print(f\"üöÄ LangSmith configurado para {self.ambiente}\")\n",
        "        print(f\"üìä Projeto: {os.environ.get('LANGCHAIN_PROJECT')}\")\n",
        "        print(f\"üìà Sample rate: {self.sample_rate*100}%\")\n",
        "    \n",
        "    def configurar_tags_padrao(self, chain_name, versao=\"1.0\"):\n",
        "        \"\"\"Define tags padr√£o para organiza√ß√£o\"\"\"\n",
        "        tags = {\n",
        "            \"ambiente\": self.ambiente,\n",
        "            \"chain_name\": chain_name,\n",
        "            \"versao\": versao,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "        return tags\n",
        "    \n",
        "    def health_check(self):\n",
        "        \"\"\"Verifica se a configura√ß√£o est√° ok\"\"\"\n",
        "        checks = {\n",
        "            \"LANGCHAIN_API_KEY\": bool(os.getenv(\"LANGCHAIN_API_KEY\")),\n",
        "            \"LANGCHAIN_PROJECT\": bool(os.getenv(\"LANGCHAIN_PROJECT\")),\n",
        "            \"LANGCHAIN_TRACING_V2\": os.getenv(\"LANGCHAIN_TRACING_V2\") == \"true\"\n",
        "        }\n",
        "        \n",
        "        print(\"üè• Health Check LangSmith:\")\n",
        "        for check, status in checks.items():\n",
        "            icon = \"‚úÖ\" if status else \"‚ùå\"\n",
        "            print(f\"   {icon} {check}: {status}\")\n",
        "        \n",
        "        return all(checks.values())\n",
        "\n",
        "# Testando a configura√ß√£o\n",
        "print(\"üîß Testando configura√ß√£o de produ√ß√£o...\\n\")\n",
        "\n",
        "for env in [\"dev\", \"staging\", \"prod\"]:\n",
        "    print(f\"\\n{'='*30} {env.upper()} {'='*30}\")\n",
        "    config = ConfigLangSmithProd(env)\n",
        "    tags = config.configurar_tags_padrao(\"chat-bot-vendas\", \"2.1\")\n",
        "    print(f\"üè∑Ô∏è  Tags sugeridas: {tags}\")\n",
        "    config.health_check()\n",
        "\n",
        "print(\"\\nüí° Use essa configura√ß√£o como base para seus projetos!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéä Resum√£o Final: O que Aprendemos?\n\n**Parab√©ns!** üéâ Voc√™ chegou ao final do nosso curso LangChain v0.2! \n\nForam **15 m√≥dulos** de muito aprendizado, e agora voc√™ tem todo o conhecimento para construir aplica√ß√µes LLM **profissionais**!\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-15_img_07.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèÜ Sua Jornada Completa\n\n### üéØ Do M√≥dulo 1 ao 15 - O que dominamos:\n\n**üèóÔ∏è Fundamentos (M√≥dulos 1-4)**\n- ‚úÖ LangChain architecture e conceitos\n- ‚úÖ ChatModels e Runnables/LCEL\n- ‚úÖ Prompt Templates e Output Parsers\n- ‚úÖ Chains e composi√ß√£o\n\n**üß† Sistemas Inteligentes (M√≥dulos 5-8)**\n- ‚úÖ Memory Systems para contexto\n- ‚úÖ Document Loading e Splitters\n- ‚úÖ Vector Stores e Embeddings\n- ‚úÖ RAG Implementation completa\n\n**ü§ñ Agentes e Projetos (M√≥dulos 9-12)**\n- ‚úÖ Agents e Tools poderosos\n- ‚úÖ Projetos pr√°ticos completos\n- ‚úÖ Deploy com Streamlit\n\n**üöÄ N√≠vel Avan√ßado (M√≥dulos 13-15)**\n- ‚úÖ LangChain v1.0 e compara√ß√µes\n- ‚úÖ LangGraph para workflows complexos\n- ‚úÖ **LangSmith para observabilidade** üëà VOC√ä EST√Å AQUI!\n\n### üéØ Hoje voc√™ aprendeu:\n- üîç **Observabilidade completa** com LangSmith\n- üìä **M√©tricas e monitoramento** em tempo real\n- üêõ **Debugging avan√ßado** de chains\n- üìà **Otimiza√ß√£o baseada em dados**\n- üö® **Sistemas de alertas** inteligentes\n- üí° **Melhores pr√°ticas** para produ√ß√£o\n\n**Dica final do Pedro**: Agora voc√™ tem todas as ferramentas para construir aplica√ß√µes LLM **profissionais** e **escal√°veis**! üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéâ PARAB√âNS! Voc√™ concluiu o curso!\n",
        "# Vamos celebrar com um resumo visual da sua jornada\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Dados da jornada de aprendizado\n",
        "modulos = [\n",
        "    \"Introdu√ß√£o\", \"ChatModel\", \"Prompts\", \"Chains\", \"Memory\",\n",
        "    \"Documents\", \"Vectors\", \"RAG\", \"Agents\", \"Projeto 1\",\n",
        "    \"Projeto 2\", \"Deploy\", \"v1.0\", \"LangGraph\", \"LangSmith\"\n",
        "]\n",
        "\n",
        "# Skills acumuladas (simula√ß√£o)\n",
        "skills_acumuladas = np.array([5, 15, 25, 35, 45, 55, 65, 75, 85, 90, 95, 98, 100, 105, 110])\n",
        "\n",
        "# Gr√°fico da evolu√ß√£o\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))\n",
        "\n",
        "# Gr√°fico 1: Evolu√ß√£o das habilidades\n",
        "ax1.plot(range(len(modulos)), skills_acumuladas, 'o-', \n",
        "         linewidth=3, markersize=8, color='#FF6B6B')\n",
        "ax1.fill_between(range(len(modulos)), skills_acumuladas, \n",
        "                 alpha=0.3, color='#FF6B6B')\n",
        "\n",
        "# Destacando marcos importantes\n",
        "marcos = [3, 7, 11, 14]  # Chains, RAG, Deploy, LangSmith\n",
        "for marco in marcos:\n",
        "    ax1.scatter(marco, skills_acumuladas[marco], s=200, \n",
        "               color='gold', edgecolor='orange', linewidth=2, zorder=5)\n",
        "    ax1.annotate('üèÜ', xy=(marco, skills_acumuladas[marco]), \n",
        "                xytext=(0, 15), textcoords='offset points', \n",
        "                ha='center', fontsize=16)\n",
        "\n",
        "ax1.set_title('üöÄ Sua Jornada de Aprendizado - LangChain v0.2', \n",
        "              fontsize=16, fontweight='bold', pad=20)\n",
        "ax1.set_xlabel('M√≥dulos do Curso')\n",
        "ax1.set_ylabel('N√≠vel de Habilidade')\n",
        "ax1.set_xticks(range(len(modulos)))\n",
        "ax1.set_xticklabels(modulos, rotation=45, ha='right')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim(0, 120)\n",
        "\n",
        "# Adicionando anota√ß√µes de fases\n",
        "ax1.axvspan(-0.5, 3.5, alpha=0.1, color='blue', label='üèóÔ∏è Fundamentos')\n",
        "ax1.axvspan(3.5, 7.5, alpha=0.1, color='green', label='üß† Sistemas Inteligentes')\n",
        "ax1.axvspan(7.5, 11.5, alpha=0.1, color='orange', label='ü§ñ Projetos Pr√°ticos')\n",
        "ax1.axvspan(11.5, 14.5, alpha=0.1, color='red', label='üöÄ N√≠vel Avan√ßado')\n",
        "ax1.legend(loc='upper left')\n",
        "\n",
        "# Gr√°fico 2: Distribui√ß√£o de conhecimentos\n",
        "conhecimentos = {\n",
        "    'LangChain Core': 95,\n",
        "    'RAG Systems': 90,\n",
        "    'Agents & Tools': 85,\n",
        "    'Production Deploy': 80,\n",
        "    'LangGraph': 75,\n",
        "    'LangSmith': 90,\n",
        "    'Best Practices': 88\n",
        "}\n",
        "\n",
        "areas = list(conhecimentos.keys())\n",
        "scores = list(conhecimentos.values())\n",
        "colors = plt.cm.Set3(np.linspace(0, 1, len(areas)))\n",
        "\n",
        "bars = ax2.barh(areas, scores, color=colors)\n",
        "ax2.set_title('üìä Seu N√≠vel de Conhecimento por √Årea', \n",
        "              fontsize=14, fontweight='bold', pad=20)\n",
        "ax2.set_xlabel('N√≠vel de Profici√™ncia (%)')\n",
        "ax2.set_xlim(0, 100)\n",
        "\n",
        "# Adicionando valores nas barras\n",
        "for bar, score in zip(bars, scores):\n",
        "    width = bar.get_width()\n",
        "    ax2.text(width + 1, bar.get_y() + bar.get_height()/2, \n",
        "             f'{score}%', ha='left', va='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Mensagem final\n",
        "print(\"üéä\" * 50)\n",
        "print(\"üéâ PARAB√âNS! CURSO CONCLU√çDO COM SUCESSO! üéâ\")\n",
        "print(\"üéä\" * 50)\n",
        "print()\n",
        "print(\"üèÜ CONQUISTAS DESBLOQUEADAS:\")\n",
        "print(\"   ‚úÖ LangChain Expert\")\n",
        "print(\"   ‚úÖ RAG Systems Master\")\n",
        "print(\"   ‚úÖ Production Ready Developer\")\n",
        "print(\"   ‚úÖ LangSmith Monitoring Pro\")\n",
        "print(\"   ‚úÖ LangGraph Workflow Architect\")\n",
        "print()\n",
        "print(\"üöÄ PR√ìXIMOS PASSOS:\")\n",
        "print(\"   1. Aplique o conhecimento em projetos reais\")\n",
        "print(\"   2. Compartilhe seu aprendizado com a comunidade\")\n",
        "print(\"   3. Continue explorando novas funcionalidades\")\n",
        "print(\"   4. Mentore outros desenvolvedores\")\n",
        "print()\n",
        "print(\"üí° LEMBRE-SE: O aprendizado nunca para!\")\n",
        "print(\"üôã‚Äç‚ôÇÔ∏è Pedro Guth - Obrigado por essa jornada incr√≠vel!\")\n",
        "print(\"üéä\" * 50)"
      ]
    }
  ]
}