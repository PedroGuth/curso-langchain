{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Deploy e Produ√ß√£o com Streamlit: Da Ideia √† Realidade!\n\n**M√≥dulo 12 - Curso LangChain v0.2**\n\nOpa, pessoal! Pedro Guth aqui! üôã‚Äç‚ôÇÔ∏è\n\nT√°, mas depois de construir aqueles projetos incr√≠veis dos m√≥dulos 10 e 11, o que fazemos? Deixamos eles guardadinhos no notebook? **N√ÉO!** Chegou a hora de botar na rua e mostrar pro mundo!\n\n√â como ter uma receita incr√≠vel de brigadeiro (nosso app LangChain) e ficar s√≥ fazendo pra voc√™ mesmo. O neg√≥cio √© abrir uma doceria (fazer o deploy) e deixar todo mundo provar!\n\n**Neste m√≥dulo vamos aprender:**\n- O que √© Streamlit e por que ele √© perfeito pro nosso caso\n- Como transformar nossos projetos LangChain em apps web\n- Deploy local, em nuvem e no Streamlit Cloud\n- Boas pr√°ticas de produ√ß√£o\n- Monitoramento e debugging\n\nBora fazer nossos apps voarem! üõ´"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì± O que √© Streamlit e Por Que Ele √© Nosso Melhor Amigo?\n\nStreamlit √© como um **m√°gico da programa√ß√£o**! Voc√™ escreve Python puro e ele transforma em uma aplica√ß√£o web linda, responsiva e funcional.\n\n**Analogia do Pedro:** √â como ter um gar√ßom cinco estrelas que pega sua comida caseira (c√≥digo Python) e serve ela num restaurante chique (interface web) sem voc√™ precisar saber sobre pratos, garfos ou decora√ß√£o!\n\n### Por que Streamlit + LangChain √© uma dupla imbat√≠vel?\n\n1. **Simplicidade**: Zero HTML, CSS ou JavaScript necess√°rio\n2. **Reatividade**: Mudou algo? A interface atualiza automaticamente\n3. **Compatibilidade**: Funciona perfeitamente com todos os componentes LangChain\n4. **Deploy f√°cil**: Streamlit Cloud √© gratuito e simples\n\n**Dica do Pedro:** Streamlit √© ideal para MVPs, prot√≥tipos e at√© aplica√ß√µes robustas de produ√ß√£o!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Primeiro, vamos instalar tudo que precisamos\n",
        "# Execute isso apenas uma vez!\n",
        "\n",
        "!pip install streamlit langchain langchain-google-genai python-dotenv pandas plotly\n",
        "!pip install watchdog # Para hot-reload durante desenvolvimento"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Imports essenciais para nossos projetos\n",
        "import streamlit as st\n",
        "import os\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import time\n",
        "import json\n",
        "\n",
        "# LangChain imports (nossos velhos conhecidos dos m√≥dulos anteriores)\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema import HumanMessage, AIMessage\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "print(\"üì¶ Bibliotecas carregadas com sucesso!\")\n",
        "print(f\"üî• Streamlit vers√£o: {st.__version__}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Anatomia de um App Streamlit\n\nTodo app Streamlit tem uma estrutura b√°sica. √â como montar um sandu√≠che: p√£o (estrutura), recheio (funcionalidades) e temperos (estilo).\n\n### Estrutura B√°sica:\n\n```python\nimport streamlit as st\n\n# Configura√ß√£o da p√°gina (sempre primeiro!)\nst.set_page_config(page_title=\"Meu App\", page_icon=\"üöÄ\")\n\n# T√≠tulo principal\nst.title(\"Meu App LangChain\")\n\n# Sidebar (barra lateral)\nwith st.sidebar:\n    st.header(\"Configura√ß√µes\")\n\n# Conte√∫do principal\nst.write(\"Ol√° mundo!\")\n```\n\n**Dica do Pedro:** Sempre use `st.set_page_config()` como primeira linha! √â como colocar o nome na porta antes de abrir a loja."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Fluxo de Deploy: Do Notebook ao Mundo\n\nVou mostrar o fluxo completo de como tiramos nosso c√≥digo do Jupyter e transformamos numa aplica√ß√£o web rodando na internet!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Vamos criar um diagrama do fluxo de deploy\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.patches import FancyBboxPatch\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "# Etapas do processo\n",
        "steps = [\n",
        "    (1, 7, \"üìì\\nJupyter\\nNotebook\"),\n",
        "    (3, 7, \"üìù\\nC√≥digo\\nStreamlit\"),\n",
        "    (5, 7, \"üîß\\nTeste\\nLocal\"),\n",
        "    (7, 7, \"üìÇ\\nGitHub\\nRepo\"),\n",
        "    (9, 7, \"‚òÅÔ∏è\\nStreamlit\\nCloud\"),\n",
        "    (11, 7, \"üåê\\nApp\\nProdu√ß√£o\")\n",
        "]\n",
        "\n",
        "# Desenhar as caixas e textos\n",
        "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DDA0DD']\n",
        "\n",
        "for i, (x, y, text) in enumerate(steps):\n",
        "    # Caixa\n",
        "    box = FancyBboxPatch((x-0.7, y-1), 1.4, 2, \n",
        "                         boxstyle=\"round,pad=0.1\", \n",
        "                         facecolor=colors[i], \n",
        "                         edgecolor='black', \n",
        "                         linewidth=2)\n",
        "    ax.add_patch(box)\n",
        "    \n",
        "    # Texto\n",
        "    ax.text(x, y, text, ha='center', va='center', \n",
        "           fontsize=10, fontweight='bold')\n",
        "    \n",
        "    # Setas (exceto na √∫ltima)\n",
        "    if i < len(steps) - 1:\n",
        "        ax.arrow(x+0.7, y, 1.6, 0, head_width=0.3, head_length=0.2, \n",
        "                fc='black', ec='black', linewidth=2)\n",
        "\n",
        "# Configura√ß√µes do gr√°fico\n",
        "ax.set_xlim(0, 12)\n",
        "ax.set_ylim(5, 9)\n",
        "ax.set_title('üöÄ Fluxo de Deploy: Da Ideia √† Produ√ß√£o!', \n",
        "             fontsize=16, fontweight='bold', pad=20)\n",
        "ax.axis('off')\n",
        "\n",
        "# Tempo estimado\n",
        "ax.text(6, 5.5, '‚è±Ô∏è Tempo total: 30-60 minutos', \n",
        "        ha='center', fontsize=12, style='italic',\n",
        "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightblue'))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéØ Este √© nosso mapa do tesouro! Cada etapa nos leva mais perto da produ√ß√£o!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üè† Criando Nosso Primeiro App: Chatbot LangChain\n\nVamos pegar nosso conhecimento dos m√≥dulos anteriores e criar um chatbot completo em Streamlit!\n\n**Lembrando dos m√≥dulos passados:**\n- M√≥dulo 2: ChatModel e LCEL ‚úÖ\n- M√≥dulo 3: PromptTemplate ‚úÖ\n- M√≥dulo 5: Memory Systems ‚úÖ\n\nAgora vamos juntar tudo numa interface linda!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Vamos criar nosso primeiro app Streamlit!\n",
        "# Este c√≥digo ser√° salvo como um arquivo .py depois\n",
        "\n",
        "app_code = '''\n",
        "import streamlit as st\n",
        "import os\n",
        "from datetime import datetime\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "# Configura√ß√£o da p√°gina (SEMPRE PRIMEIRO!)\n",
        "st.set_page_config(\n",
        "    page_title=\"ü§ñ ChatBot LangChain\",\n",
        "    page_icon=\"ü§ñ\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# T√≠tulo principal com estilo\n",
        "st.title(\"ü§ñ ChatBot Inteligente com LangChain\")\n",
        "st.markdown(\"*Desenvolvido com LangChain v0.2 + Streamlit*\")\n",
        "\n",
        "# Sidebar para configura√ß√µes\n",
        "with st.sidebar:\n",
        "    st.header(\"‚öôÔ∏è Configura√ß√µes\")\n",
        "    \n",
        "    # Input da API Key\n",
        "    api_key = st.text_input(\n",
        "        \"Google API Key\", \n",
        "        type=\"password\",\n",
        "        help=\"Insira sua chave da API do Google Gemini\"\n",
        "    )\n",
        "    \n",
        "    # Par√¢metros do modelo\n",
        "    temperature = st.slider(\"üå°Ô∏è Temperatura\", 0.0, 1.0, 0.7)\n",
        "    max_tokens = st.number_input(\"üìù Max Tokens\", 100, 2000, 500)\n",
        "    \n",
        "    # Bot√£o para limpar conversa\n",
        "    if st.button(\"üóëÔ∏è Limpar Conversa\"):\n",
        "        st.session_state.messages = []\n",
        "        st.rerun()\n",
        "\n",
        "# Inicializa√ß√£o do estado da sess√£o\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Fun√ß√£o para inicializar o modelo\n",
        "@st.cache_resource\n",
        "def init_model(api_key, temp, max_tok):\n",
        "    return ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.0-flash-exp\",\n",
        "        google_api_key=api_key,\n",
        "        temperature=temp,\n",
        "        max_tokens=max_tok\n",
        "    )\n",
        "\n",
        "# Interface principal\n",
        "if api_key:\n",
        "    try:\n",
        "        # Inicializar modelo\n",
        "        llm = init_model(api_key, temperature, max_tokens)\n",
        "        \n",
        "        # Exibir hist√≥rico de mensagens\n",
        "        for message in st.session_state.messages:\n",
        "            with st.chat_message(message[\"role\"]):\n",
        "                st.markdown(message[\"content\"])\n",
        "        \n",
        "        # Input do usu√°rio\n",
        "        if prompt := st.chat_input(\"Digite sua mensagem...\"):\n",
        "            # Adicionar mensagem do usu√°rio\n",
        "            st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "            \n",
        "            with st.chat_message(\"user\"):\n",
        "                st.markdown(prompt)\n",
        "            \n",
        "            # Gerar resposta\n",
        "            with st.chat_message(\"assistant\"):\n",
        "                with st.spinner(\"Pensando...\"):\n",
        "                    response = llm.invoke(prompt)\n",
        "                    st.markdown(response.content)\n",
        "            \n",
        "            # Adicionar resposta ao hist√≥rico\n",
        "            st.session_state.messages.append({\n",
        "                \"role\": \"assistant\", \n",
        "                \"content\": response.content\n",
        "            })\n",
        "    \n",
        "    except Exception as e:\n",
        "        st.error(f\"‚ùå Erro: {str(e)}\")\n",
        "        st.info(\"üí° Verifique sua API Key e tente novamente.\")\n",
        "\n",
        "else:\n",
        "    st.warning(\"‚ö†Ô∏è Por favor, insira sua Google API Key na barra lateral.\")\n",
        "    st.info(\"üìã Voc√™ pode obter uma chave gratuita em: https://makersuite.google.com/app/apikey\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"**üéì Curso LangChain v0.2 - M√≥dulo 12: Deploy com Streamlit**\")\n",
        "'''\n",
        "\n",
        "# Salvar o c√≥digo em um arquivo\n",
        "with open('chatbot_app.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "print(\"‚úÖ App criado! Arquivo salvo como 'chatbot_app.py'\")\n",
        "print(\"üöÄ Para testar localmente, execute: streamlit run chatbot_app.py\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-12_img_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Componentes Essenciais do Streamlit\n\nStreamlit tem v√°rios componentes que s√£o como pe√ßas de LEGO - cada um tem sua fun√ß√£o espec√≠fica!\n\n### Os Campe√µes da Interface:\n\n1. **`st.chat_message()`**: Para interfaces de chat\n2. **`st.sidebar`**: Barra lateral para controles\n3. **`st.columns()`**: Layout em colunas\n4. **`st.tabs()`**: Abas organizadas\n5. **`st.expander()`**: Se√ß√µes expans√≠veis\n6. **`st.spinner()`**: Indicadores de carregamento\n\n**Analogia do Pedro:** √â como ter uma caixa de ferramentas completa - cada ferramenta serve pra uma coisa espec√≠fica, mas juntas constroem a casa toda!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Vamos criar um demonstrativo dos principais componentes\n",
        "components_demo = '''\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "st.set_page_config(page_title=\"üß© Demo Componentes\", layout=\"wide\")\n",
        "\n",
        "st.title(\"üß© Showcase de Componentes Streamlit\")\n",
        "\n",
        "# Tabs principais\n",
        "tab1, tab2, tab3 = st.tabs([\"üìä Dados\", \"üí¨ Chat\", \"üéÆ Interativos\"])\n",
        "\n",
        "with tab1:\n",
        "    st.header(\"üìä Visualiza√ß√£o de Dados\")\n",
        "    \n",
        "    # Colunas\n",
        "    col1, col2 = st.columns(2)\n",
        "    \n",
        "    with col1:\n",
        "        st.subheader(\"üìà Gr√°fico\")\n",
        "        data = pd.DataFrame({\n",
        "            'x': range(10),\n",
        "            'y': np.random.randn(10)\n",
        "        })\n",
        "        st.line_chart(data.set_index('x'))\n",
        "    \n",
        "    with col2:\n",
        "        st.subheader(\"üìã Tabela\")\n",
        "        st.dataframe(data, use_container_width=True)\n",
        "\n",
        "with tab2:\n",
        "    st.header(\"üí¨ Interface de Chat\")\n",
        "    \n",
        "    # Exemplo de chat\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.write(\"Ol√°! Como voc√™ est√°?\")\n",
        "    \n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.write(\"Oi! Estou √≥timo, obrigado por perguntar! üòä\")\n",
        "\n",
        "with tab3:\n",
        "    st.header(\"üéÆ Componentes Interativos\")\n",
        "    \n",
        "    # Inputs diversos\n",
        "    name = st.text_input(\"Seu nome\")\n",
        "    age = st.slider(\"Sua idade\", 0, 100, 25)\n",
        "    \n",
        "    if st.button(\"üéâ Cumprimentar\"):\n",
        "        with st.spinner(\"Preparando cumprimento...\"):\n",
        "            time.sleep(1)\n",
        "        st.success(f\"Ol√° {name}! {age} anos √© uma √≥tima idade! üéä\")\n",
        "\n",
        "# Sidebar\n",
        "with st.sidebar:\n",
        "    st.header(\"‚öôÔ∏è Controles\")\n",
        "    theme = st.selectbox(\"Tema\", [\"Claro\", \"Escuro\"])\n",
        "    \n",
        "    with st.expander(\"‚ÑπÔ∏è Sobre este demo\"):\n",
        "        st.write(\"Este √© um exemplo dos principais componentes do Streamlit!\")\n",
        "\n",
        "# M√©tricas\n",
        "st.header(\"üìä M√©tricas\")\n",
        "col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "with col1:\n",
        "    st.metric(\"Usu√°rios\", \"1,234\", \"+12%\")\n",
        "with col2:\n",
        "    st.metric(\"Conversas\", \"5,678\", \"+23%\")\n",
        "with col3:\n",
        "    st.metric(\"Tokens\", \"89,012\", \"+5%\")\n",
        "with col4:\n",
        "    st.metric(\"Satisfa√ß√£o\", \"98%\", \"+2%\")\n",
        "'''\n",
        "\n",
        "# Salvar demo\n",
        "with open('components_demo.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(components_demo)\n",
        "\n",
        "print(\"üß© Demo de componentes criado! Execute: streamlit run components_demo.py\")\n",
        "print(\"üí° Este demo mostra os principais componentes que voc√™ vai usar!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Sistema de Estado e Cache no Streamlit\n\nT√°, mas tem um detalhe importante: Streamlit **re-executa todo o script** a cada intera√ß√£o!\n\n**Analogia do Pedro:** √â como se voc√™ fosse um peixinho Dory - a cada clique, ele esquece tudo e come√ßa do zero. Por isso precisamos do `st.session_state` (nossa mem√≥ria) e `st.cache` (nosso bloquinho de anota√ß√µes)!\n\n### Estado da Sess√£o (`st.session_state`):\n- Armazena dados entre re-execu√ß√µes\n- Como uma mem√≥ria persistente\n- Essencial para apps com estado\n\n### Cache (`st.cache_data` e `st.cache_resource`):\n- Evita rec√°lculos desnecess√°rios\n- `st.cache_data`: Para dados (DataFrames, listas, etc.)\n- `st.cache_resource`: Para recursos (modelos, conex√µes DB)\n\n**Dica do Pedro:** Sempre use cache para modelos LangChain! Eles s√£o pesados de carregar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Demonstra√ß√£o do sistema de estado e cache\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Simula√ß√£o do ciclo de vida do Streamlit\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Gr√°fico 1: Problema sem cache\n",
        "steps = ['Usu√°rio\\nInterage', 'Script\\nRe-executa', 'Modelo\\nReinicializa', 'Lento\\nüò¢']\n",
        "times_no_cache = [0.1, 0.2, 5.0, 0.1]  # Tempo em segundos\n",
        "colors_bad = ['#FF6B6B', '#FF8E8E', '#FFB1B1', '#FFD4D4']\n",
        "\n",
        "bars1 = ax1.bar(steps, times_no_cache, color=colors_bad)\n",
        "ax1.set_title('‚ùå Sem Cache: Lento e Ineficiente', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Tempo (segundos)')\n",
        "ax1.set_ylim(0, 6)\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for bar, time in zip(bars1, times_no_cache):\n",
        "    height = bar.get_height()\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
        "             f'{time}s', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Gr√°fico 2: Com cache\n",
        "times_with_cache = [0.1, 0.2, 0.1, 0.1]  # Muito mais r√°pido!\n",
        "colors_good = ['#4ECDC4', '#6BD0C7', '#88D4CA', '#A5D8CD']\n",
        "\n",
        "bars2 = ax2.bar(steps, times_with_cache, color=colors_good)\n",
        "ax2.set_title('‚úÖ Com Cache: R√°pido e Eficiente', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Tempo (segundos)')\n",
        "ax2.set_ylim(0, 6)\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for bar, time in zip(bars2, times_with_cache):\n",
        "    height = bar.get_height()\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
        "             f'{time}s', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Texto explicativo\n",
        "fig.suptitle('üöÄ Por que Cache √© Essencial no Streamlit', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üí° Moral da hist√≥ria: Cache = Felicidade dos usu√°rios!\")\n",
        "print(\"üèéÔ∏è Com cache: 5.4s ‚Üí 0.5s (mais de 10x mais r√°pido!)\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-12_img_02.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Exemplo pr√°tico de como usar estado e cache corretamente\n",
        "optimized_app = '''\n",
        "import streamlit as st\n",
        "import time\n",
        "from datetime import datetime\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "st.set_page_config(page_title=\"‚ö° App Otimizado\", page_icon=\"‚ö°\")\n",
        "\n",
        "st.title(\"‚ö° App LangChain Otimizado\")\n",
        "st.markdown(\"*Exemplo de uso correto de cache e estado*\")\n",
        "\n",
        "# ‚úÖ CACHE CORRETO: Modelo LangChain\n",
        "@st.cache_resource\n",
        "def init_llm(api_key):\n",
        "    \"\"\"Inicializa o modelo apenas uma vez por sess√£o\"\"\"\n",
        "    print(f\"üîÑ Inicializando modelo... {datetime.now()}\")\n",
        "    return ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.0-flash-exp\",\n",
        "        google_api_key=api_key,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "# ‚úÖ CACHE CORRETO: Dados processados\n",
        "@st.cache_data\n",
        "def process_heavy_data():\n",
        "    \"\"\"Simula processamento pesado de dados\"\"\"\n",
        "    print(f\"üìä Processando dados... {datetime.now()}\")\n",
        "    time.sleep(2)  # Simula processamento lento\n",
        "    return {\"processed_at\": datetime.now().strftime(\"%H:%M:%S\")}\n",
        "\n",
        "# ‚úÖ ESTADO DA SESS√ÉO: Inicializa√ß√£o correta\n",
        "if \"counter\" not in st.session_state:\n",
        "    st.session_state.counter = 0\n",
        "\n",
        "if \"history\" not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "\n",
        "# Interface\n",
        "with st.sidebar:\n",
        "    api_key = st.text_input(\"API Key\", type=\"password\")\n",
        "    \n",
        "    if st.button(\"üîÑ Recarregar Modelo\"):\n",
        "        st.cache_resource.clear()\n",
        "        st.success(\"Cache do modelo limpo!\")\n",
        "\n",
        "# Demonstra√ß√£o de cache\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    st.subheader(\"ü§ñ Modelo (Cached)\")\n",
        "    if api_key:\n",
        "        with st.spinner(\"Carregando modelo...\"):\n",
        "            llm = init_llm(api_key)\n",
        "        st.success(\"Modelo carregado! (Note que da 2¬™ vez √© instant√¢neo)\")\n",
        "    else:\n",
        "        st.warning(\"Insira a API Key\")\n",
        "\n",
        "with col2:\n",
        "    st.subheader(\"üìä Dados (Cached)\")\n",
        "    if st.button(\"Processar Dados Pesados\"):\n",
        "        with st.spinner(\"Processando...\"):\n",
        "            data = process_heavy_data()\n",
        "        st.json(data)\n",
        "        st.info(\"Dados processados! (Clique novamente - ser√° instant√¢neo)\")\n",
        "\n",
        "# Demonstra√ß√£o de estado\n",
        "st.subheader(\"üî¢ Estado da Sess√£o\")\n",
        "if st.button(\"‚ûï Incrementar Contador\"):\n",
        "    st.session_state.counter += 1\n",
        "    st.session_state.history.append(datetime.now().strftime(\"%H:%M:%S\"))\n",
        "\n",
        "st.write(f\"**Contador:** {st.session_state.counter}\")\n",
        "if st.session_state.history:\n",
        "    st.write(\"**Hist√≥rico:**\", \", \".join(st.session_state.history[-5:]))\n",
        "\n",
        "# Dicas de otimiza√ß√£o\n",
        "with st.expander(\"üí° Dicas de Otimiza√ß√£o\"):\n",
        "    st.markdown(\"\"\"\n",
        "    ‚úÖ **Fa√ßa:**\n",
        "    - Use `@st.cache_resource` para modelos LangChain\n",
        "    - Use `@st.cache_data` para processamento de dados\n",
        "    - Inicialize `st.session_state` com verifica√ß√£o\n",
        "    - Mantenha estado entre intera√ß√µes\n",
        "    \n",
        "    ‚ùå **N√£o fa√ßa:**\n",
        "    - Carregue modelos sem cache\n",
        "    - Processe dados pesados a cada intera√ß√£o\n",
        "    - Esque√ßa de verificar se chave existe no session_state\n",
        "    \"\"\")\n",
        "'''\n",
        "\n",
        "# Salvar app otimizado\n",
        "with open('optimized_app.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(optimized_app)\n",
        "\n",
        "print(\"‚ö° App otimizado criado! Execute: streamlit run optimized_app.py\")\n",
        "print(\"üèÜ Este app mostra as melhores pr√°ticas de performance!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üåê Deploy no Streamlit Cloud: Gratuito e F√°cil!\n\nAgora vem a parte mais emocionante: colocar nosso app na internet de gra√ßa! üéâ\n\n**Streamlit Cloud** √© como ter um gar√ßom que pega sua comida (c√≥digo) e serve para o mundo inteiro sem voc√™ pagar nada!\n\n### Pr√©-requisitos:\n1. ‚úÖ Conta no GitHub\n2. ‚úÖ Reposit√≥rio p√∫blico com seu c√≥digo\n3. ‚úÖ Arquivo `requirements.txt`\n4. ‚úÖ Arquivo principal `.py`\n\n### Estrutura do projeto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Vamos criar uma estrutura completa de projeto para deploy\n",
        "import os\n",
        "\n",
        "# Criar estrutura de pastas\n",
        "project_structure = {\n",
        "    'my-langchain-app/': {\n",
        "        'app.py': 'Arquivo principal do Streamlit',\n",
        "        'requirements.txt': 'Depend√™ncias do projeto',\n",
        "        'README.md': 'Documenta√ß√£o do projeto',\n",
        "        '.gitignore': 'Arquivos a ignorar no Git',\n",
        "        'config/': {\n",
        "            'config.py': 'Configura√ß√µes do app'\n",
        "        },\n",
        "        'utils/': {\n",
        "            'helpers.py': 'Fun√ß√µes auxiliares'\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Mostrar estrutura visualmente\n",
        "def print_tree(d, indent=0):\n",
        "    for key, value in d.items():\n",
        "        if isinstance(value, dict):\n",
        "            print('  ' * indent + f\"üìÅ {key}\")\n",
        "            print_tree(value, indent + 1)\n",
        "        else:\n",
        "            print('  ' * indent + f\"üìÑ {key} - {value}\")\n",
        "\n",
        "print(\"üèóÔ∏è Estrutura Recomendada do Projeto:\")\n",
        "print(\"=\" * 40)\n",
        "print_tree(project_structure)\n",
        "\n",
        "print(\"\\nüí° Dica do Pedro: Mantenha tudo organizado! √â como arrumar o guarda-roupa - facilita a vida depois!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Criar arquivos essenciais para deploy\n",
        "\n",
        "# 1. requirements.txt\n",
        "requirements_content = '''streamlit>=1.28.0\n",
        "langchain>=0.2.0\n",
        "langchain-google-genai>=1.0.0\n",
        "python-dotenv>=1.0.0\n",
        "pandas>=2.0.0\n",
        "plotly>=5.15.0\n",
        "'''\n",
        "\n",
        "# 2. .gitignore\n",
        "gitignore_content = '''# Byte-compiled / optimized / DLL files\n",
        "__pycache__/\n",
        "*.py[cod]\n",
        "*$py.class\n",
        "\n",
        "# Distribution / packaging\n",
        ".Python\n",
        "build/\n",
        "develop-eggs/\n",
        "dist/\n",
        "downloads/\n",
        "eggs/\n",
        ".eggs/\n",
        "lib/\n",
        "lib64/\n",
        "parts/\n",
        "sdist/\n",
        "var/\n",
        "wheels/\n",
        "*.egg-info/\n",
        ".installed.cfg\n",
        "*.egg\n",
        "\n",
        "# Environment variables\n",
        ".env\n",
        ".venv\n",
        "env/\n",
        "venv/\n",
        "\n",
        "# IDE\n",
        ".vscode/\n",
        ".idea/\n",
        "\n",
        "# OS\n",
        ".DS_Store\n",
        "Thumbs.db\n",
        "\n",
        "# Streamlit\n",
        ".streamlit/\n",
        "'''\n",
        "\n",
        "# 3. README.md\n",
        "readme_content = '''# ü§ñ ChatBot LangChain com Streamlit\n",
        "\n",
        "Um chatbot inteligente desenvolvido com LangChain v0.2 e Streamlit.\n",
        "\n",
        "## üöÄ Como usar\n",
        "\n",
        "1. Acesse o app: [LINK_DO_SEU_APP]\n",
        "2. Insira sua Google API Key na barra lateral\n",
        "3. Comece a conversar!\n",
        "\n",
        "## üõ†Ô∏è Tecnologias\n",
        "\n",
        "- **LangChain v0.2**: Framework para aplica√ß√µes com LLM\n",
        "- **Streamlit**: Interface web interativa\n",
        "- **Google Gemini**: Modelo de linguagem\n",
        "\n",
        "## üì¶ Instala√ß√£o Local\n",
        "\n",
        "```bash\n",
        "git clone https://github.com/SEU_USUARIO/SEU_REPO.git\n",
        "cd SEU_REPO\n",
        "pip install -r requirements.txt\n",
        "streamlit run app.py\n",
        "```\n",
        "\n",
        "## üéì Sobre\n",
        "\n",
        "Desenvolvido durante o Curso LangChain v0.2 - M√≥dulo 12: Deploy com Streamlit\n",
        "'''\n",
        "\n",
        "# Salvar arquivos\n",
        "files_to_create = {\n",
        "    'requirements.txt': requirements_content,\n",
        "    '.gitignore': gitignore_content,\n",
        "    'README.md': readme_content\n",
        "}\n",
        "\n",
        "for filename, content in files_to_create.items():\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(content)\n",
        "    print(f\"‚úÖ {filename} criado!\")\n",
        "\n",
        "print(\"\\nüéâ Arquivos de configura√ß√£o criados com sucesso!\")\n",
        "print(\"üìã Pr√≥ximos passos:\")\n",
        "print(\"   1. Criar reposit√≥rio no GitHub\")\n",
        "print(\"   2. Fazer push dos arquivos\")\n",
        "print(\"   3. Conectar no Streamlit Cloud\")\n",
        "print(\"   4. Deploy autom√°tico! üöÄ\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîí Gerenciamento de Segredos e Vari√°veis de Ambiente\n\n**ATEN√á√ÉO!** Nunca, jamais, em hip√≥tese alguma coloque API Keys no c√≥digo! üö®\n\n√â como deixar a chave de casa na porta com um bilhetinho \"entre √† vontade\"!\n\n### M√©todos seguros:\n\n1. **`st.secrets`**: Para Streamlit Cloud\n2. **Vari√°veis de ambiente**: Para deploy local\n3. **`.env` files**: Para desenvolvimento\n4. **Input do usu√°rio**: Deixar usu√°rio inserir\n\n**Dica do Pedro:** No Streamlit Cloud, use a aba \"Secrets\" nas configura√ß√µes do app. √â como ter um cofre digital!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# App com gerenciamento seguro de API Keys\n",
        "secure_app = '''\n",
        "import streamlit as st\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "st.set_page_config(page_title=\"üîê App Seguro\", page_icon=\"üîê\")\n",
        "\n",
        "st.title(\"üîê App com Seguran√ßa de API Keys\")\n",
        "\n",
        "# Fun√ß√£o para obter API Key de forma segura\n",
        "def get_api_key():\n",
        "    \"\"\"Obt√©m API Key de forma segura em diferentes ambientes\"\"\"\n",
        "    \n",
        "    # 1. Tentar Streamlit Secrets (produ√ß√£o)\n",
        "    try:\n",
        "        if \"google_api_key\" in st.secrets:\n",
        "            return st.secrets[\"google_api_key\"]\n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    # 2. Tentar vari√°vel de ambiente\n",
        "    env_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "    if env_key:\n",
        "        return env_key\n",
        "    \n",
        "    # 3. Se n√£o encontrou, retorna None\n",
        "    return None\n",
        "\n",
        "# Inicializar modelo de forma segura\n",
        "@st.cache_resource\n",
        "def init_secure_llm(api_key):\n",
        "    return ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.0-flash-exp\",\n",
        "        google_api_key=api_key\n",
        "    )\n",
        "\n",
        "# Interface principal\n",
        "api_key = get_api_key()\n",
        "\n",
        "if not api_key:\n",
        "    st.warning(\"üîë API Key n√£o encontrada!\")\n",
        "    \n",
        "    st.info(\"\"\"\n",
        "    **Como configurar a API Key:**\n",
        "    \n",
        "    üè† **Desenvolvimento Local:**\n",
        "    1. Crie arquivo `.env` com: `GOOGLE_API_KEY=sua_chave_aqui`\n",
        "    2. Ou defina vari√°vel de ambiente no seu OS\n",
        "    \n",
        "    ‚òÅÔ∏è **Streamlit Cloud:**\n",
        "    1. V√° nas configura√ß√µes do app\n",
        "    2. Aba \"Secrets\"\n",
        "    3. Adicione: `google_api_key = \"sua_chave_aqui\"`\n",
        "    \"\"\")\n",
        "    \n",
        "    # Fallback: permitir input manual (s√≥ para desenvolvimento)\n",
        "    with st.expander(\"üö® Inserir API Key manualmente (apenas para testes)\"):\n",
        "        manual_key = st.text_input(\n",
        "            \"API Key (N√ÉO use em produ√ß√£o!)\", \n",
        "            type=\"password\"\n",
        "        )\n",
        "        if manual_key:\n",
        "            api_key = manual_key\n",
        "            st.warning(\"‚ö†Ô∏è Usando API Key manual. N√£o recomendado para produ√ß√£o!\")\n",
        "\n",
        "# Se temos API Key, inicializar app\n",
        "if api_key:\n",
        "    try:\n",
        "        llm = init_secure_llm(api_key)\n",
        "        st.success(\"üîê API Key configurada com seguran√ßa!\")\n",
        "        \n",
        "        # Interface do chat\n",
        "        if \"secure_messages\" not in st.session_state:\n",
        "            st.session_state.secure_messages = []\n",
        "        \n",
        "        # Exibir mensagens\n",
        "        for msg in st.session_state.secure_messages:\n",
        "            with st.chat_message(msg[\"role\"]):\n",
        "                st.write(msg[\"content\"])\n",
        "        \n",
        "        # Input do usu√°rio\n",
        "        if prompt := st.chat_input(\"Digite sua mensagem segura...\"):\n",
        "            # Adicionar mensagem do usu√°rio\n",
        "            st.session_state.secure_messages.append({\n",
        "                \"role\": \"user\", \n",
        "                \"content\": prompt\n",
        "            })\n",
        "            \n",
        "            with st.chat_message(\"user\"):\n",
        "                st.write(prompt)\n",
        "            \n",
        "            # Gerar resposta\n",
        "            with st.chat_message(\"assistant\"):\n",
        "                with st.spinner(\"Processando com seguran√ßa...\"):\n",
        "                    response = llm.invoke(prompt)\n",
        "                    st.write(response.content)\n",
        "            \n",
        "            # Adicionar resposta\n",
        "            st.session_state.secure_messages.append({\n",
        "                \"role\": \"assistant\", \n",
        "                \"content\": response.content\n",
        "            })\n",
        "    \n",
        "    except Exception as e:\n",
        "        st.error(f\"‚ùå Erro na inicializa√ß√£o: {str(e)}\")\n",
        "        st.info(\"Verifique se sua API Key est√° v√°lida.\")\n",
        "\n",
        "# Footer com informa√ß√µes de seguran√ßa\n",
        "with st.expander(\"üõ°Ô∏è Informa√ß√µes de Seguran√ßa\"):\n",
        "    st.markdown(\"\"\"\n",
        "    **Boas pr√°ticas de seguran√ßa:**\n",
        "    \n",
        "    ‚úÖ **Fa√ßa:**\n",
        "    - Use Streamlit Secrets em produ√ß√£o\n",
        "    - Use vari√°veis de ambiente em desenvolvimento\n",
        "    - Adicione `.env` no `.gitignore`\n",
        "    - Monitore uso da API\n",
        "    \n",
        "    ‚ùå **Nunca:**\n",
        "    - Hardcode API Keys no c√≥digo\n",
        "    - Commite arquivos `.env`\n",
        "    - Compartilhe keys em canais inseguros\n",
        "    - Deixe keys sem rota√ß√£o\n",
        "    \"\"\")\n",
        "'''\n",
        "\n",
        "# Salvar app seguro\n",
        "with open('secure_app.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(secure_app)\n",
        "\n",
        "print(\"üîê App seguro criado! Execute: streamlit run secure_app.py\")\n",
        "print(\"üõ°Ô∏è Este app mostra como gerenciar API Keys com seguran√ßa!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-12_img_03.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Monitoramento e Analytics\n\nT√°, mas depois que o app est√° no ar, como sabemos se t√° tudo funcionando? √â como ter uma padaria e n√£o saber se o p√£o est√° saindo quentinho!\n\n### M√©tricas importantes para apps LangChain:\n\n1. **Performance**: Tempo de resposta, uso de tokens\n2. **Uso**: N√∫mero de usu√°rios, conversas, mensagens\n3. **Erros**: Falhas, timeouts, problemas de API\n4. **Qualidade**: Feedback dos usu√°rios, satisfa√ß√£o\n\n**Dica do Pedro:** Implemente m√©tricas desde o primeiro dia! √â muito mais f√°cil que tentar descobrir depois o que deu errado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Criar dashboard de monitoramento simples\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Simular dados de uso do app\n",
        "np.random.seed(42)\n",
        "\n",
        "# Dados dos √∫ltimos 30 dias\n",
        "dates = [datetime.now() - timedelta(days=x) for x in range(30, 0, -1)]\n",
        "users = np.random.poisson(50, 30)  # M√©dia de 50 usu√°rios por dia\n",
        "conversations = users * np.random.uniform(1.5, 3.0, 30)  # 1.5-3 conversas por usu√°rio\n",
        "tokens_used = conversations * np.random.uniform(100, 500, 30)  # 100-500 tokens por conversa\n",
        "response_times = np.random.gamma(2, 0.5, 30)  # Tempo de resposta em segundos\n",
        "\n",
        "# Criar dashboard\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Gr√°fico 1: Usu√°rios por dia\n",
        "ax1.plot(dates, users, marker='o', linewidth=2, color='#4ECDC4')\n",
        "ax1.set_title('üë• Usu√°rios Ativos por Dia', fontweight='bold')\n",
        "ax1.set_ylabel('N√∫mero de Usu√°rios')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Gr√°fico 2: Conversas por dia\n",
        "ax2.bar(range(len(conversations)), conversations, color='#45B7D1', alpha=0.7)\n",
        "ax2.set_title('üí¨ Conversas por Dia', fontweight='bold')\n",
        "ax2.set_ylabel('N√∫mero de Conversas')\n",
        "ax2.set_xlabel('√öltimos 30 dias')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Gr√°fico 3: Tokens consumidos\n",
        "ax3.fill_between(range(len(tokens_used)), tokens_used, alpha=0.6, color='#96CEB4')\n",
        "ax3.set_title('üî§ Tokens Consumidos por Dia', fontweight='bold')\n",
        "ax3.set_ylabel('N√∫mero de Tokens')\n",
        "ax3.set_xlabel('√öltimos 30 dias')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Gr√°fico 4: Tempo de resposta\n",
        "ax4.hist(response_times, bins=10, color='#FFEAA7', alpha=0.7, edgecolor='black')\n",
        "ax4.set_title('‚ö° Distribui√ß√£o do Tempo de Resposta', fontweight='bold')\n",
        "ax4.set_xlabel('Tempo (segundos)')\n",
        "ax4.set_ylabel('Frequ√™ncia')\n",
        "ax4.axvline(np.mean(response_times), color='red', linestyle='--', \n",
        "           label=f'M√©dia: {np.mean(response_times):.1f}s')\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('üìä Dashboard de Monitoramento - App LangChain', \n",
        "             fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# M√©tricas resumidas\n",
        "total_users = sum(users)\n",
        "total_conversations = sum(conversations)\n",
        "total_tokens = sum(tokens_used)\n",
        "avg_response_time = np.mean(response_times)\n",
        "\n",
        "print(\"üìà RESUMO DOS √öLTIMOS 30 DIAS:\")\n",
        "print(f\"üë• Total de usu√°rios: {total_users:,.0f}\")\n",
        "print(f\"üí¨ Total de conversas: {total_conversations:,.0f}\")\n",
        "print(f\"üî§ Total de tokens: {total_tokens:,.0f}\")\n",
        "print(f\"‚ö° Tempo m√©dio de resposta: {avg_response_time:.1f}s\")\n",
        "print(f\"üí∞ Custo estimado (tokens): ${total_tokens * 0.000002:.2f}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# App com sistema de monitoramento integrado\n",
        "monitoring_app = '''\n",
        "import streamlit as st\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "st.set_page_config(page_title=\"üìä App Monitorado\", page_icon=\"üìä\", layout=\"wide\")\n",
        "\n",
        "# Fun√ß√µes de monitoramento\n",
        "def log_event(event_type, data=None):\n",
        "    \"\"\"Log events para an√°lise posterior\"\"\"\n",
        "    if \"events_log\" not in st.session_state:\n",
        "        st.session_state.events_log = []\n",
        "    \n",
        "    event = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"type\": event_type,\n",
        "        \"data\": data or {}\n",
        "    }\n",
        "    \n",
        "    st.session_state.events_log.append(event)\n",
        "    \n",
        "    # Manter apenas os √∫ltimos 100 eventos\n",
        "    if len(st.session_state.events_log) > 100:\n",
        "        st.session_state.events_log = st.session_state.events_log[-100:]\n",
        "\n",
        "def get_stats():\n",
        "    \"\"\"Calcular estat√≠sticas de uso\"\"\"\n",
        "    if \"events_log\" not in st.session_state:\n",
        "        return {}\n",
        "    \n",
        "    events = st.session_state.events_log\n",
        "    \n",
        "    return {\n",
        "        \"total_events\": len(events),\n",
        "        \"total_messages\": len([e for e in events if e[\"type\"] == \"message_sent\"]),\n",
        "        \"total_errors\": len([e for e in events if e[\"type\"] == \"error\"]),\n",
        "        \"avg_response_time\": sum([e[\"data\"].get(\"response_time\", 0) for e in events if \"response_time\" in e[\"data\"]]) / max(1, len([e for e in events if \"response_time\" in e[\"data\"]]))\n",
        "    }\n",
        "\n",
        "@st.cache_resource\n",
        "def init_llm(api_key):\n",
        "    return ChatGoogleGenerativeAI(\n",
        "        model=\"gemini-2.0-flash-exp\",\n",
        "        google_api_key=api_key\n",
        "    )\n",
        "\n",
        "# Layout principal\n",
        "col1, col2 = st.columns([3, 1])\n",
        "\n",
        "with col1:\n",
        "    st.title(\"üìä App LangChain com Monitoramento\")\n",
        "    \n",
        "    # Log da inicializa√ß√£o\n",
        "    log_event(\"app_loaded\")\n",
        "    \n",
        "    # Interface do chat\n",
        "    api_key = st.text_input(\"API Key\", type=\"password\")\n",
        "    \n",
        "    if api_key:\n",
        "        try:\n",
        "            llm = init_llm(api_key)\n",
        "            \n",
        "            # Inicializar mensagens\n",
        "            if \"monitored_messages\" not in st.session_state:\n",
        "                st.session_state.monitored_messages = []\n",
        "            \n",
        "            # Exibir mensagens\n",
        "            for msg in st.session_state.monitored_messages:\n",
        "                with st.chat_message(msg[\"role\"]):\n",
        "                    st.write(msg[\"content\"])\n",
        "            \n",
        "            # Input do usu√°rio\n",
        "            if prompt := st.chat_input(\"Digite sua mensagem...\"):\n",
        "                start_time = time.time()\n",
        "                \n",
        "                # Log da mensagem enviada\n",
        "                log_event(\"message_sent\", {\n",
        "                    \"message_length\": len(prompt),\n",
        "                    \"user_id\": \"user_001\"  # Em produ√ß√£o, use ID real\n",
        "                })\n",
        "                \n",
        "                # Adicionar mensagem do usu√°rio\n",
        "                st.session_state.monitored_messages.append({\n",
        "                    \"role\": \"user\", \n",
        "                    \"content\": prompt\n",
        "                })\n",
        "                \n",
        "                with st.chat_message(\"user\"):\n",
        "                    st.write(prompt)\n",
        "                \n",
        "                # Gerar resposta\n",
        "                with st.chat_message(\"assistant\"):\n",
        "                    try:\n",
        "                        with st.spinner(\"Processando...\"):\n",
        "                            response = llm.invoke(prompt)\n",
        "                            response_time = time.time() - start_time\n",
        "                            \n",
        "                            st.write(response.content)\n",
        "                            \n",
        "                            # Log da resposta\n",
        "                            log_event(\"response_generated\", {\n",
        "                                \"response_time\": response_time,\n",
        "                                \"response_length\": len(response.content),\n",
        "                                \"tokens_estimated\": len(prompt.split()) + len(response.content.split())\n",
        "                            })\n",
        "                            \n",
        "                            # Adicionar resposta\n",
        "                            st.session_state.monitored_messages.append({\n",
        "                                \"role\": \"assistant\", \n",
        "                                \"content\": response.content\n",
        "                            })\n",
        "                    \n",
        "                    except Exception as e:\n",
        "                        st.error(f\"Erro: {str(e)}\")\n",
        "                        log_event(\"error\", {\n",
        "                            \"error_type\": type(e).__name__,\n",
        "                            \"error_message\": str(e)\n",
        "                        })\n",
        "        \n",
        "        except Exception as e:\n",
        "            st.error(f\"Erro na inicializa√ß√£o: {str(e)}\")\n",
        "            log_event(\"initialization_error\", {\"error\": str(e)})\n",
        "    \n",
        "    else:\n",
        "        st.warning(\"Insira sua API Key para come√ßar.\")\n",
        "\n",
        "with col2:\n",
        "    st.subheader(\"üìà Monitoramento\")\n",
        "    \n",
        "    # Estat√≠sticas em tempo real\n",
        "    stats = get_stats()\n",
        "    \n",
        "    if stats:\n",
        "        st.metric(\"üìù Mensagens\", stats[\"total_messages\"])\n",
        "        st.metric(\"‚ö° Tempo M√©dio\", f\"{stats['avg_response_time']:.1f}s\")\n",
        "        st.metric(\"‚ùå Erros\", stats[\"total_errors\"])\n",
        "        \n",
        "        # Indicador de sa√∫de\n",
        "        error_rate = stats[\"total_errors\"] / max(1, stats[\"total_events\"])\n",
        "        if error_rate < 0.05:\n",
        "            st.success(\"üü¢ Sistema Saud√°vel\")\n",
        "        elif error_rate < 0.15:\n",
        "            st.warning(\"üü° Aten√ß√£o Necess√°ria\")\n",
        "        else:\n",
        "            st.error(\"üî¥ Sistema Inst√°vel\")\n",
        "    \n",
        "    # Log recente\n",
        "    with st.expander(\"üìã Log Recente\"):\n",
        "        if \"events_log\" in st.session_state:\n",
        "            recent_events = st.session_state.events_log[-10:]\n",
        "            for event in reversed(recent_events):\n",
        "                timestamp = datetime.fromisoformat(event[\"timestamp\"]).strftime(\"%H:%M:%S\")\n",
        "                st.text(f\"{timestamp} - {event['type']}\")\n",
        "    \n",
        "    # Controles\n",
        "    if st.button(\"üîÑ Atualizar Stats\"):\n",
        "        st.rerun()\n",
        "    \n",
        "    if st.button(\"üóëÔ∏è Limpar Logs\"):\n",
        "        st.session_state.events_log = []\n",
        "        st.success(\"Logs limpos!\")\n",
        "\n",
        "# Footer com informa√ß√µes do sistema\n",
        "st.markdown(\"---\")\n",
        "col1, col2, col3 = st.columns(3)\n",
        "with col1:\n",
        "    st.caption(f\"‚è∞ √öltima atualiza√ß√£o: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "with col2:\n",
        "    st.caption(\"üöÄ Status: Online\")\n",
        "with col3:\n",
        "    st.caption(\"üìä Monitoramento: Ativo\")\n",
        "'''\n",
        "\n",
        "# Salvar app com monitoramento\n",
        "with open('monitoring_app.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(monitoring_app)\n",
        "\n",
        "print(\"üìä App com monitoramento criado! Execute: streamlit run monitoring_app.py\")\n",
        "print(\"üìà Este app coleta m√©tricas em tempo real para an√°lise!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üè≠ Boas Pr√°ticas para Produ√ß√£o\n\nColocar um app em produ√ß√£o √© como abrir um restaurante - n√£o basta saber cozinhar, tem que pensar em higiene, atendimento, custos e muito mais!\n\n### Checklist de Produ√ß√£o:\n\n#### ‚úÖ **Seguran√ßa:**\n- API Keys em secrets/vari√°veis de ambiente\n- Rate limiting para evitar abuso\n- Valida√ß√£o de inputs do usu√°rio\n- HTTPS obrigat√≥rio\n\n#### ‚úÖ **Performance:**\n- Cache adequado (`@st.cache_resource`, `@st.cache_data`)\n- Lazy loading de modelos\n- Timeouts para requests\n- Compress√£o de assets\n\n#### ‚úÖ **Monitoramento:**\n- Logging estruturado\n- M√©tricas de uso\n- Alertas de erro\n- Health checks\n\n#### ‚úÖ **Experi√™ncia do Usu√°rio:**\n- Loading states\n- Error handling gracioso\n- Interface responsiva\n- Feedback visual\n\n**Dica do Pedro:** Teste sempre com dados reais antes do lan√ßamento!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-12_img_04.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üö® Tratamento de Erros e Debugging\n\nMurphy sempre aparece na produ√ß√£o! \"Se algo pode dar errado, vai dar errado na hora mais inoportuna\" üòÖ\n\n### Estrat√©gias de Error Handling:\n\n1. **Try-Catch abrangente**\n2. **Fallbacks inteligentes**\n3. **Mensagens de erro amig√°veis**\n4. **Logging detalhado para debugging**\n\n**Analogia do Pedro:** √â como ter um plano B, C e D quando voc√™ vai viajar. O avi√£o atrasou? Pega o √¥nibus. √înibus quebrou? Vai de carro. Carro n√£o pega? Chama um Uber!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# App com tratamento robusto de erros\n",
        "robust_app = '''\n",
        "import streamlit as st\n",
        "import logging\n",
        "import traceback\n",
        "from datetime import datetime\n",
        "import time\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Configurar logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "st.set_page_config(page_title=\"üõ°Ô∏è App Robusto\", page_icon=\"üõ°Ô∏è\")\n",
        "\n",
        "class ErrorHandler:\n",
        "    \"\"\"Classe para gerenciar erros de forma centralizada\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def log_error(error, context=\"\"):\n",
        "        \"\"\"Log detalhado de erros\"\"\"\n",
        "        error_info = {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"error_type\": type(error).__name__,\n",
        "            \"error_message\": str(error),\n",
        "            \"context\": context,\n",
        "            \"traceback\": traceback.format_exc()\n",
        "        }\n",
        "        \n",
        "        logger.error(f\"Error in {context}: {error_info}\")\n",
        "        \n",
        "        # Salvar no session state para debug\n",
        "        if \"error_log\" not in st.session_state:\n",
        "            st.session_state.error_log = []\n",
        "        \n",
        "        st.session_state.error_log.append(error_info)\n",
        "        \n",
        "        # Manter apenas os √∫ltimos 10 erros\n",
        "        if len(st.session_state.error_log) > 10:\n",
        "            st.session_state.error_log = st.session_state.error_log[-10:]\n",
        "    \n",
        "    @staticmethod\n",
        "    def show_user_friendly_error(error_type):\n",
        "        \"\"\"Exibir erro amig√°vel para o usu√°rio\"\"\"\n",
        "        error_messages = {\n",
        "            \"api_key_error\": {\n",
        "                \"title\": \"üîë Problema com API Key\",\n",
        "                \"message\": \"Sua API Key parece estar inv√°lida ou expirada.\",\n",
        "                \"solution\": \"Verifique se a chave est√° correta e tem permiss√µes adequadas.\"\n",
        "            },\n",
        "            \"network_error\": {\n",
        "                \"title\": \"üåê Problema de Conex√£o\",\n",
        "                \"message\": \"N√£o conseguimos conectar com o servi√ßo de IA.\",\n",
        "                \"solution\": \"Verifique sua conex√£o e tente novamente em alguns segundos.\"\n",
        "            },\n",
        "            \"rate_limit_error\": {\n",
        "                \"title\": \"‚è∞ Muitas Requisi√ß√µes\",\n",
        "                \"message\": \"Voc√™ atingiu o limite de requisi√ß√µes por minuto.\",\n",
        "                \"solution\": \"Aguarde alguns segundos antes de tentar novamente.\"\n",
        "            },\n",
        "            \"generic_error\": {\n",
        "                \"title\": \"üö® Erro Inesperado\",\n",
        "                \"message\": \"Algo deu errado, mas n√£o se preocupe!\",\n",
        "                \"solution\": \"Tente novamente ou entre em contato com o suporte.\"\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        error_info = error_messages.get(error_type, error_messages[\"generic_error\"])\n",
        "        \n",
        "        st.error(error_info[\"title\"])\n",
        "        st.write(error_info[\"message\"])\n",
        "        st.info(f\"üí° **Solu√ß√£o:** {error_info['solution']}\")\n",
        "\n",
        "@st.cache_resource\n",
        "def init_llm_with_retry(api_key, max_retries=3):\n",
        "    \"\"\"Inicializar LLM com retry autom√°tico\"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            logger.info(f\"Attempting to initialize LLM (attempt {attempt + 1})\")\n",
        "            return ChatGoogleGenerativeAI(\n",
        "                model=\"gemini-2.0-flash-exp\",\n",
        "                google_api_key=api_key,\n",
        "                timeout=30  # Timeout de 30 segundos\n",
        "            )\n",
        "        except Exception as e:\n",
        "            ErrorHandler.log_error(e, f\"LLM initialization attempt {attempt + 1}\")\n",
        "            if attempt == max_retries - 1:\n",
        "                raise e\n",
        "            time.sleep(2 ** attempt)  # Backoff exponencial\n",
        "\n",
        "def safe_llm_invoke(llm, prompt, timeout=30):\n",
        "    \"\"\"Invoke LLM com timeout e error handling\"\"\"\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        response = llm.invoke(prompt)\n",
        "        response_time = time.time() - start_time\n",
        "        \n",
        "        if response_time > timeout:\n",
        "            raise TimeoutError(f\"Response took {response_time:.1f}s (timeout: {timeout}s)\")\n",
        "        \n",
        "        return response, response_time\n",
        "    \n",
        "    except Exception as e:\n",
        "        ErrorHandler.log_error(e, \"LLM invoke\")\n",
        "        \n",
        "        # Classificar tipo de erro\n",
        "        error_message = str(e).lower()\n",
        "        if \"api\" in error_message and (\"key\" in error_message or \"auth\" in error_message):\n",
        "            raise Exception(\"api_key_error\")\n",
        "        elif \"network\" in error_message or \"connection\" in error_message:\n",
        "            raise Exception(\"network_error\")\n",
        "        elif \"rate\" in error_message or \"quota\" in error_message:\n",
        "            raise Exception(\"rate_limit_error\")\n",
        "        else:\n",
        "            raise Exception(\"generic_error\")\n",
        "\n",
        "# Interface principal\n",
        "st.title(\"üõ°Ô∏è App LangChain Ultra Robusto\")\n",
        "st.markdown(\"*Com tratamento de erros profissional*\")\n",
        "\n",
        "# Sidebar para configura√ß√µes e debug\n",
        "with st.sidebar:\n",
        "    st.header(\"‚öôÔ∏è Configura√ß√µes\")\n",
        "    \n",
        "    api_key = st.text_input(\"Google API Key\", type=\"password\")\n",
        "    \n",
        "    # Debug mode\n",
        "    debug_mode = st.checkbox(\"üêõ Modo Debug\")\n",
        "    \n",
        "    if debug_mode and \"error_log\" in st.session_state:\n",
        "        st.subheader(\"üö® Log de Erros\")\n",
        "        for i, error in enumerate(reversed(st.session_state.error_log[-5:])):\n",
        "            with st.expander(f\"Erro {len(st.session_state.error_log) - i}\"):\n",
        "                st.write(f\"**Tipo:** {error['error_type']}\")\n",
        "                st.write(f\"**Mensagem:** {error['error_message']}\")\n",
        "                st.write(f\"**Contexto:** {error['context']}\")\n",
        "                st.write(f\"**Timestamp:** {error['timestamp']}\")\n",
        "\n",
        "# Chat interface\n",
        "if api_key:\n",
        "    try:\n",
        "        with st.spinner(\"üîÑ Inicializando sistema...\"):\n",
        "            llm = init_llm_with_retry(api_key)\n",
        "        \n",
        "        st.success(\"‚úÖ Sistema inicializado com sucesso!\")\n",
        "        \n",
        "        # Inicializar mensagens\n",
        "        if \"robust_messages\" not in st.session_state:\n",
        "            st.session_state.robust_messages = []\n",
        "        \n",
        "        # Exibir mensagens\n",
        "        for msg in st.session_state.robust_messages:\n",
        "            with st.chat_message(msg[\"role\"]):\n",
        "                st.write(msg[\"content\"])\n",
        "                if \"response_time\" in msg:\n",
        "                    st.caption(f\"‚è±Ô∏è {msg['response_time']:.1f}s\")\n",
        "        \n",
        "        # Input do usu√°rio com valida√ß√£o\n",
        "        if prompt := st.chat_input(\"Digite sua mensagem (m√°x. 1000 caracteres)...\"):\n",
        "            # Validar input\n",
        "            if len(prompt) > 1000:\n",
        "                st.error(\"‚ùå Mensagem muito longa! M√°ximo 1000 caracteres.\")\n",
        "            elif len(prompt.strip()) == 0:\n",
        "                st.warning(\"‚ö†Ô∏è Mensagem vazia! Digite algo interessante.\")\n",
        "            else:\n",
        "                # Adicionar mensagem do usu√°rio\n",
        "                st.session_state.robust_messages.append({\n",
        "                    \"role\": \"user\", \n",
        "                    \"content\": prompt\n",
        "                })\n",
        "                \n",
        "                with st.chat_message(\"user\"):\n",
        "                    st.write(prompt)\n",
        "                \n",
        "                # Gerar resposta com error handling\n",
        "                with st.chat_message(\"assistant\"):\n",
        "                    try:\n",
        "                        with st.spinner(\"ü§ñ Processando com seguran√ßa...\"):\n",
        "                            response, response_time = safe_llm_invoke(llm, prompt)\n",
        "                            \n",
        "                            st.write(response.content)\n",
        "                            st.caption(f\"‚è±Ô∏è Respondido em {response_time:.1f}s\")\n",
        "                            \n",
        "                            # Adicionar resposta\n",
        "                            st.session_state.robust_messages.append({\n",
        "                                \"role\": \"assistant\", \n",
        "                                \"content\": response.content,\n",
        "                                \"response_time\": response_time\n",
        "                            })\n",
        "                    \n",
        "                    except Exception as e:\n",
        "                        error_type = str(e)\n",
        "                        ErrorHandler.show_user_friendly_error(error_type)\n",
        "                        \n",
        "                        # Sugerir a√ß√µes\n",
        "                        col1, col2 = st.columns(2)\n",
        "                        with col1:\n",
        "                            if st.button(\"üîÑ Tentar Novamente\"):\n",
        "                                st.rerun()\n",
        "                        with col2:\n",
        "                            if st.button(\"üóëÔ∏è Limpar Chat\"):\n",
        "                                st.session_state.robust_messages = []\n",
        "                                st.rerun()\n",
        "    \n",
        "    except Exception as e:\n",
        "        ErrorHandler.log_error(e, \"App initialization\")\n",
        "        st.error(\"üö® Erro na inicializa√ß√£o do sistema\")\n",
        "        st.write(\"N√£o conseguimos inicializar o sistema. Verifique sua API Key.\")\n",
        "        \n",
        "        if debug_mode:\n",
        "            st.code(traceback.format_exc())\n",
        "\n",
        "else:\n",
        "    st.warning(\"‚ö†Ô∏è Por favor, insira sua Google API Key na barra lateral.\")\n",
        "    \n",
        "    # Informa√ß√µes de ajuda\n",
        "    with st.expander(\"‚ÑπÔ∏è Como obter uma API Key\"):\n",
        "        st.markdown(\"\"\"\n",
        "        1. Acesse: [Google AI Studio](https://makersuite.google.com/app/apikey)\n",
        "        2. Fa√ßa login com sua conta Google\n",
        "        3. Clique em \"Create API Key\"\n",
        "        4. Copie a chave e cole na barra lateral\n",
        "        \"\"\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"\"\"\n",
        "üõ°Ô∏è **Sistema Robusto Ativo** | \n",
        "üîß Error Handling Profissional | \n",
        "üìä Logging Detalhado | \n",
        "‚ö° Auto-Recovery\n",
        "\"\"\")\n",
        "'''\n",
        "\n",
        "# Salvar app robusto\n",
        "with open('robust_app.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(robust_app)\n",
        "\n",
        "print(\"üõ°Ô∏è App ultra robusto criado! Execute: streamlit run robust_app.py\")\n",
        "print(\"üöÄ Este app √© pronto para produ√ß√£o com error handling profissional!\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exerc√≠cio Pr√°tico: Deploy Completo\n\nAgora √© sua vez! Vamos fazer um exerc√≠cio completo de deploy.\n\n### **Desafio: Crie e Fa√ßa Deploy de um App RAG**\n\n**Objetivo:** Criar um app que use RAG (do m√≥dulo 8) com interface Streamlit e fazer deploy no Streamlit Cloud.\n\n**Requisitos:**\n1. ‚úÖ Interface de upload de documentos\n2. ‚úÖ Sistema de chat com contexto\n3. ‚úÖ Gerenciamento seguro de API Keys\n4. ‚úÖ Sistema b√°sico de monitoramento\n5. ‚úÖ Error handling robusto\n6. ‚úÖ Deploy no Streamlit Cloud\n\n**Dica do Pedro:** Use tudo que aprendemos nos m√≥dulos anteriores!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Template para o exerc√≠cio - App RAG completo\n",
        "rag_app_template = '''\n",
        "import streamlit as st\n",
        "import tempfile\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Imports LangChain (ajuste conforme necess√°rio)\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"üìö RAG App - Chat com Documentos\",\n",
        "    page_icon=\"üìö\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "st.title(\"üìö Chat Inteligente com seus Documentos\")\n",
        "st.markdown(\"*Powered by LangChain v0.2 + Streamlit*\")\n",
        "\n",
        "# TODO: Implementar as funcionalidades\n",
        "# 1. Sidebar com configura√ß√µes e upload\n",
        "# 2. Processamento de documentos\n",
        "# 3. Sistema de chat RAG\n",
        "# 4. Monitoramento b√°sico\n",
        "# 5. Error handling\n",
        "\n",
        "with st.sidebar:\n",
        "    st.header(\"‚öôÔ∏è Configura√ß√µes\")\n",
        "    \n",
        "    # API Key\n",
        "    api_key = st.text_input(\"Google API Key\", type=\"password\")\n",
        "    \n",
        "    st.header(\"üìÑ Upload de Documentos\")\n",
        "    \n",
        "    # Upload de arquivos\n",
        "    uploaded_files = st.file_uploader(\n",
        "        \"Escolha seus arquivos\",\n",
        "        accept_multiple_files=True,\n",
        "        type=[\"pdf\", \"txt\"]\n",
        "    )\n",
        "    \n",
        "    # TODO: Implementar processamento dos arquivos\n",
        "    if uploaded_files:\n",
        "        st.success(f\"{len(uploaded_files)} arquivo(s) carregado(s)!\")\n",
        "\n",
        "# Interface principal\n",
        "if not api_key:\n",
        "    st.warning(\"‚ö†Ô∏è Insira sua API Key na barra lateral para come√ßar.\")\n",
        "    \n",
        "    # Instru√ß√µes\n",
        "    st.markdown(\"\"\"\n",
        "    ## üöÄ Como usar este app:\n",
        "    \n",
        "    1. **Configure sua API Key** na barra lateral\n",
        "    2. **Fa√ßa upload** dos seus documentos (PDF ou TXT)\n",
        "    3. **Aguarde** o processamento\n",
        "    4. **Converse** com seus documentos!\n",
        "    \n",
        "    ### üí° Dicas:\n",
        "    - Use documentos em portugu√™s para melhores resultados\n",
        "    - Fa√ßa perguntas espec√≠ficas sobre o conte√∫do\n",
        "    - O sistema lembra do contexto da conversa\n",
        "    \"\"\")\n",
        "    \n",
        "else:\n",
        "    # TODO: Implementar l√≥gica principal do RAG\n",
        "    st.info(\"üèóÔ∏è Implementar: Sistema RAG completo\")\n",
        "    \n",
        "    # Placeholder para a interface de chat\n",
        "    if \"rag_messages\" not in st.session_state:\n",
        "        st.session_state.rag_messages = []\n",
        "    \n",
        "    # Chat placeholder\n",
        "    if prompt := st.chat_input(\"Pergunte algo sobre seus documentos...\"):\n",
        "        st.write(f\"Voc√™ perguntou: {prompt}\")\n",
        "        st.info(\"üöß Implementar: Sistema de RAG\")\n",
        "\n",
        "# Footer\n",
        "st.markdown(\"---\")\n",
        "st.markdown(\"\"\"\n",
        "üéì **Exerc√≠cio do Curso LangChain v0.2 - M√≥dulo 12** | \n",
        "üìö RAG Implementation | \n",
        "üöÄ Streamlit Deploy\n",
        "\"\"\")\n",
        "'''\n",
        "\n",
        "# Salvar template do exerc√≠cio\n",
        "with open('rag_app_exercise.py', 'w', encoding='utf-8') as f:\n",
        "    f.write(rag_app_template)\n",
        "\n",
        "print(\"üìö Template do exerc√≠cio RAG criado!\")\n",
        "print(\"üéØ Seu desafio: Completar a implementa√ß√£o e fazer deploy!\")\n",
        "print(\"\")\n",
        "print(\"üìã Checklist do exerc√≠cio:\")\n",
        "print(\"   ‚ñ° Implementar upload e processamento de documentos\")\n",
        "print(\"   ‚ñ° Criar sistema de embeddings e vector store\")\n",
        "print(\"   ‚ñ° Implementar chain de RAG\")\n",
        "print(\"   ‚ñ° Adicionar interface de chat\")\n",
        "print(\"   ‚ñ° Implementar error handling\")\n",
        "print(\"   ‚ñ° Adicionar monitoramento b√°sico\")\n",
        "print(\"   ‚ñ° Fazer deploy no Streamlit Cloud\")\n",
        "print(\"   ‚ñ° Testar em produ√ß√£o\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-12_img_05.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Segundo Exerc√≠cio: Otimiza√ß√£o de Performance\n\n**Desafio Avan√ßado:** Pegue qualquer app que criamos hoje e otimize sua performance!\n\n### **Metas de Performance:**\n- ‚ö° Tempo de resposta < 3 segundos\n- üöÄ Carregamento inicial < 5 segundos  \n- üíæ Uso eficiente de cache\n- üìä M√©tricas de performance vis√≠veis\n\n### **T√©cnicas para usar:**\n1. **Lazy loading** de modelos\n2. **Streaming de respostas**\n3. **Cache inteligente**\n4. **Batch processing**\n5. **Progress indicators**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Exemplo de otimiza√ß√µes avan√ßadas\n",
        "optimization_tips = {\n",
        "    \"Cache Strategies\": [\n",
        "        \"Use @st.cache_resource para modelos LLM\",\n",
        "        \"Use @st.cache_data para processamento de dados\",\n",
        "        \"Implemente cache TTL para dados din√¢micos\",\n",
        "        \"Cache embeddings de documentos\"\n",
        "    ],\n",
        "    \"Performance Tricks\": [\n",
        "        \"Lazy load: carregue modelos apenas quando necess√°rio\",\n",
        "        \"Streaming: mostre respostas em tempo real\",\n",
        "        \"Batch processing: processe m√∫ltiplos itens juntos\",\n",
        "        \"Async operations: quando poss√≠vel\"\n",
        "    ],\n",
        "    \"UX Improvements\": [\n",
        "        \"Progress bars para opera√ß√µes longas\",\n",
        "        \"Skeleton loaders durante carregamento\",\n",
        "        \"Feedback visual imediato\",\n",
        "        \"Error boundaries para falhas graciosamente\"\n",
        "    ],\n",
        "    \"Monitoring\": [\n",
        "        \"M√©tricas de tempo de resposta\",\n",
        "        \"Contadores de cache hit/miss\",\n",
        "        \"Monitoramento de memoria\",\n",
        "        \"Alertas autom√°ticos para problemas\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"üöÄ GUIA DE OTIMIZA√á√ÉO DE PERFORMANCE\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for category, tips in optimization_tips.items():\n",
        "    print(f\"\\nüìä {category}:\")\n",
        "    for i, tip in enumerate(tips, 1):\n",
        "        print(f\"   {i}. {tip}\")\n",
        "\n",
        "print(\"\\nüí° Dica do Pedro: Performance n√£o √© opcional em produ√ß√£o!\")\n",
        "print(\"‚è∞ Usu√°rios abandonam apps que demoram mais de 3 segundos para responder.\")\n",
        "\n",
        "# Criar um exemplo de c√≥digo otimizado\n",
        "performance_example = '''\n",
        "# Exemplo de implementa√ß√£o com streaming\n",
        "import streamlit as st\n",
        "\n",
        "def stream_response(llm, prompt):\n",
        "    \"\"\"Simular streaming de resposta\"\"\"\n",
        "    response = llm.invoke(prompt)\n",
        "    \n",
        "    # Simular streaming palavra por palavra\n",
        "    words = response.content.split()\n",
        "    \n",
        "    placeholder = st.empty()\n",
        "    displayed_text = \"\"\n",
        "    \n",
        "    for i, word in enumerate(words):\n",
        "        displayed_text += word + \" \"\n",
        "        placeholder.write(displayed_text + \"‚ñå\")  # Cursor piscando\n",
        "        time.sleep(0.05)  # Simular delay\n",
        "    \n",
        "    placeholder.write(displayed_text)  # Texto final\n",
        "    return response.content\n",
        "\n",
        "# Use assim no seu app:\n",
        "# stream_response(llm, user_input)\n",
        "'''\n",
        "\n",
        "print(f\"\\nüé¨ Exemplo de Streaming:\")\n",
        "print(performance_example)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà M√©tricas de Sucesso e KPIs\n\nComo saber se nosso app est√° bombando? N√£o √© s√≥ pelo feeling - precisamos de dados!\n\n**Analogia do Pedro:** √â como ter uma lanchonete - voc√™ precisa saber quantos clientes vieram, quanto gastaram, se voltaram e se recomendaram pra outros!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Criar dashboard de KPIs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Simular KPIs de um app em produ√ß√£o\n",
        "np.random.seed(42)\n",
        "\n",
        "# Dados dos √∫ltimos 30 dias\n",
        "days = list(range(1, 31))\n",
        "daily_users = np.random.poisson(100, 30) + np.linspace(80, 120, 30)  # Crescimento\n",
        "session_duration = np.random.gamma(2, 3, 30)  # Em minutos\n",
        "satisfaction_score = np.random.beta(8, 2, 30) * 5  # Nota de 0 a 5\n",
        "error_rate = np.random.beta(1, 20, 30) * 100  # Porcentagem\n",
        "\n",
        "# Dashboard 2x2\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 10))\n",
        "\n",
        "# 1. Usu√°rios Ativos Di√°rios\n",
        "ax1.plot(days, daily_users, marker='o', linewidth=3, color='#3498db', markersize=6)\n",
        "ax1.fill_between(days, daily_users, alpha=0.3, color='#3498db')\n",
        "ax1.set_title('üë• Usu√°rios Ativos Di√°rios (DAU)', fontsize=14, fontweight='bold')\n",
        "ax1.set_ylabel('Usu√°rios')\n",
        "ax1.set_xlabel('Dia do M√™s')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.text(0.02, 0.98, f'M√©dia: {daily_users.mean():.0f}/dia', \n",
        "         transform=ax1.transAxes, verticalalignment='top',\n",
        "         bbox=dict(boxstyle='round', facecolor='lightblue'))\n",
        "\n",
        "# 2. Dura√ß√£o da Sess√£o\n",
        "colors = ['#e74c3c' if x < 2 else '#f39c12' if x < 5 else '#27ae60' for x in session_duration]\n",
        "bars = ax2.bar(days, session_duration, color=colors, alpha=0.7)\n",
        "ax2.set_title('‚è±Ô∏è Dura√ß√£o M√©dia da Sess√£o', fontsize=14, fontweight='bold')\n",
        "ax2.set_ylabel('Minutos')\n",
        "ax2.set_xlabel('Dia do M√™s')\n",
        "ax2.axhline(y=5, color='red', linestyle='--', alpha=0.7, label='Meta: 5min')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Score de Satisfa√ß√£o\n",
        "ax3.scatter(days, satisfaction_score, s=100, alpha=0.7, \n",
        "           c=satisfaction_score, cmap='RdYlGn', vmin=0, vmax=5)\n",
        "ax3.plot(days, satisfaction_score, alpha=0.5, color='gray')\n",
        "ax3.set_title('‚≠ê Score de Satisfa√ß√£o (0-5)', fontsize=14, fontweight='bold')\n",
        "ax3.set_ylabel('Score')\n",
        "ax3.set_xlabel('Dia do M√™s')\n",
        "ax3.set_ylim(0, 5)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "ax3.text(0.02, 0.02, f'M√©dia: {satisfaction_score.mean():.1f}/5', \n",
        "         transform=ax3.transAxes, verticalalignment='bottom',\n",
        "         bbox=dict(boxstyle='round', facecolor='lightgreen'))\n",
        "\n",
        "# 4. Taxa de Erro\n",
        "ax4.fill_between(days, error_rate, alpha=0.6, color='#e74c3c')\n",
        "ax4.plot(days, error_rate, linewidth=2, color='#c0392b')\n",
        "ax4.set_title('üö® Taxa de Erro (%)', fontsize=14, fontweight='bold')\n",
        "ax4.set_ylabel('Porcentagem')\n",
        "ax4.set_xlabel('Dia do M√™s')\n",
        "ax4.axhline(y=5, color='orange', linestyle='--', alpha=0.7, label='Limite: 5%')\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('üìä Dashboard de KPIs - App LangChain em Produ√ß√£o', \n",
        "             fontsize=18, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Resumo executivo\n",
        "print(\"üìä RESUMO EXECUTIVO - √öLTIMOS 30 DIAS\")\n",
        "print(\"=\" * 45)\n",
        "print(f\"üë• Usu√°rios √∫nicos: {daily_users.sum():,.0f}\")\n",
        "print(f\"‚è±Ô∏è Tempo m√©dio de sess√£o: {session_duration.mean():.1f} minutos\")\n",
        "print(f\"‚≠ê Satisfa√ß√£o m√©dia: {satisfaction_score.mean():.1f}/5.0\")\n",
        "print(f\"üö® Taxa de erro m√©dia: {error_rate.mean():.1f}%\")\n",
        "print(f\"üìà Crescimento de usu√°rios: {((daily_users[-7:].mean() / daily_users[:7].mean() - 1) * 100):+.1f}%\")\n",
        "\n",
        "# Status geral\n",
        "overall_health = \"üü¢ Excelente\" if error_rate.mean() < 2 and satisfaction_score.mean() > 4 else \"üü° Bom\" if error_rate.mean() < 5 and satisfaction_score.mean() > 3 else \"üî¥ Aten√ß√£o\"\n",
        "print(f\"\\nüè• Status geral do sistema: {overall_health}\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-vers√£o-v0.2-modulo-12_img_06.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéì Resumo: Da Ideia √† Produ√ß√£o!\n\nParab√©ns! Voc√™ completou a jornada do deploy! üéâ\n\n### **O que voc√™ aprendeu hoje:**\n\n1. **üèóÔ∏è Fundamentos do Streamlit**\n   - Componentes essenciais\n   - Sistema de estado e cache\n   - Layouts e interfaces\n\n2. **üîê Seguran√ßa e Boas Pr√°ticas**\n   - Gerenciamento de API Keys\n   - Vari√°veis de ambiente\n   - Error handling robusto\n\n3. **‚òÅÔ∏è Deploy em Produ√ß√£o**\n   - Streamlit Cloud gratuito\n   - Estrutura de projeto\n   - Configura√ß√£o de secrets\n\n4. **üìä Monitoramento e Analytics**\n   - KPIs importantes\n   - Logging estruturado\n   - Dashboard de m√©tricas\n\n5. **‚ö° Otimiza√ß√£o de Performance**\n   - Cache inteligente\n   - Streaming de respostas\n   - UX responsiva\n\n### **Pr√≥ximos passos:**\n- **M√≥dulo 13**: Compara√ß√£o LangChain v0.2 vs v1.0\n- **M√≥dulo 14**: Introdu√ß√£o ao LangGraph\n- **M√≥dulo 15**: LangSmith para produ√ß√£o\n\n**Dica do Pedro:** Agora voc√™ tem todas as ferramentas para colocar suas ideias LangChain na internet! N√£o tenha medo de experimentar e mostrar pro mundo o que voc√™ consegue criar! üöÄ"
      ]
    }
  ]
}