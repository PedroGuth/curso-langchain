{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Projeto Final 2: Sistema Inteligente de An√°lise de Documentos com Multi-Agentes\n\n**M√≥dulo 13 - LangChain v0.3**\n\n*Pedro Guth - Expert em IA & AWS*\n\n---\n\nT√°, chegamos no segundo projeto final! Se no primeiro projeto criamos um assistente simples, agora vamos partir pro **n√≠vel hardcore**: um sistema multi-agente que analisa documentos, extrai insights e ainda gera relat√≥rios automaticamente!\n\n√â tipo ter uma equipe de consultores trabalhando pros seus documentos 24/7! üìä"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ O que vamos construir?\n\nImagina que voc√™ tem uma pilha de documentos (PDFs, textos, relat√≥rios) e precisa:\n\n1. **Extrair informa√ß√µes-chave** automaticamente\n2. **Analisar sentimentos** e tend√™ncias \n3. **Gerar resumos executivos**\n4. **Criar visualiza√ß√µes** dos dados encontrados\n5. **Responder perguntas** sobre qualquer documento\n\n√â como ter um **ChatGPT turbinado** que n√£o s√≥ conversa, mas tamb√©m vira analista de dados!\n\n**Dica!** Este projeto combina TUDO que vimos: RAG, Agents, Memory, Chains e muito mais!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è Arquitetura do Sistema\n\nNosso sistema ter√° **4 agentes especialistas**:\n\n```mermaid\ngraph TD\n    A[Documento] --> B[Agente Extrator]\n    B --> C[Agente Analisador]\n    B --> D[Agente Visualizador]\n    B --> E[Agente Perguntador]\n    C --> F[Relat√≥rio Final]\n    D --> F\n    E --> F\n```\n\nCada agente tem uma **especialidade**, tipo uma empresa de consultoria onde cada um faz sua parte!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Primeiro, vamos instalar e importar tudo que precisamos\n!pip install langchain langchain-google-genai chromadb pypdf python-docx matplotlib seaborn wordcloud textstat plotly -q\n\nprint(\"üéâ Instala√ß√£o conclu√≠da! Bora pro c√≥digo!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Imports essenciais\nimport os\nimport re\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom datetime import datetime\nimport json\n\n# LangChain imports\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.prompts import ChatPromptTemplate, PromptTemplate\nfrom langchain.schema import BaseOutputParser\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.document_loaders import PyPDFLoader, TextLoader\nfrom langchain.vectorstores import Chroma\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\nfrom langchain.chains import RetrievalQA\nfrom langchain.agents import initialize_agent, Tool, AgentType\nfrom langchain.memory import ConversationBufferMemory\n\nprint(\"üìö Todas as bibliotecas importadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîë Configura√ß√£o Inicial\n\nAntes de come√ßar, precisamos configurar nossa chave da API do Google. √â como dar a chave do carro pro nosso sistema dirigir sozinho!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Configura√ß√£o da API Key\nfrom google.colab import userdata\n\n# Se estiver no Colab, use a linha abaixo:\napi_key = userdata.get('GOOGLE_API_KEY')\n\n# Se estiver rodando local, descomente e coloque sua chave:\n# api_key = \"sua_chave_aqui\"\n\nos.environ[\"GOOGLE_API_KEY\"] = api_key\n\n# Inicializando nosso modelo principal\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.0-flash-exp\",\n    temperature=0.3,  # Meio termo entre criatividade e precis√£o\n    google_api_key=api_key\n)\n\nprint(\"ü§ñ LLM configurado! Gemini 2.0 Flash pronto pra trabalhar!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÑ Carregamento e Processamento de Documentos\n\nVamos criar um sistema que consegue ler diferentes tipos de documento. √â tipo ensinar nosso sistema a ler portugu√™s, ingl√™s, PDF, Word... tudo!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class DocumentProcessor:\n    def __init__(self):\n        self.text_splitter = RecursiveCharacterTextSplitter(\n            chunk_size=1000,\n            chunk_overlap=200,\n            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"]\n        )\n        self.documents = []\n        self.chunks = []\n    \n    def load_text_file(self, file_path):\n        \"\"\"Carrega arquivo de texto simples\"\"\"\n        try:\n            with open(file_path, 'r', encoding='utf-8') as file:\n                content = file.read()\n            return content\n        except:\n            print(f\"‚ùå Erro ao carregar {file_path}\")\n            return None\n    \n    def process_text(self, text, source=\"texto\"):\n        \"\"\"Processa texto em chunks menores\"\"\"\n        if text:\n            # Cria chunks do texto\n            chunks = self.text_splitter.split_text(text)\n            \n            # Adiciona metadados a cada chunk\n            processed_chunks = []\n            for i, chunk in enumerate(chunks):\n                processed_chunks.append({\n                    'content': chunk,\n                    'source': source,\n                    'chunk_id': i,\n                    'word_count': len(chunk.split())\n                })\n            \n            self.chunks.extend(processed_chunks)\n            return processed_chunks\n        return []\n\n# Vamos criar um exemplo de documento para testar\nsample_text = \"\"\"\nRelat√≥rio de Vendas - Q4 2024\n\nEste relat√≥rio apresenta uma an√°lise detalhada do desempenho de vendas do quarto trimestre de 2024.\n\nResumo Executivo:\nAs vendas do Q4 2024 apresentaram um crescimento significativo de 25% em rela√ß√£o ao mesmo per√≠odo do ano anterior. \nO setor de tecnologia liderou o crescimento, representando 40% do faturamento total.\n\nPrincipais M√©tricas:\n- Receita total: R$ 2.5 milh√µes\n- Crescimento: +25% YoY\n- Novos clientes: 150\n- Taxa de reten√ß√£o: 85%\n\nDesafios Identificados:\n1. Concorr√™ncia acirrada no mercado de software\n2. Necessidade de melhorar o atendimento ao cliente\n3. Expans√£o para novos mercados geogr√°ficos\n\nOportunidades:\n1. Lan√ßamento de novos produtos em 2025\n2. Parcerias estrat√©gicas com empresas de tecnologia\n3. Investimento em marketing digital\n\nConclus√£o:\nO Q4 2024 foi um per√≠odo de forte crescimento, mas √© necess√°rio focar na reten√ß√£o de clientes e expans√£o de mercado para 2025.\n\"\"\"\n\n# Processando nosso documento de exemplo\nprocessor = DocumentProcessor()\nchunks = processor.process_text(sample_text, \"relatorio_vendas_q4\")\n\nprint(f\"üìä Documento processado com sucesso!\")\nprint(f\"üìù Total de chunks: {len(chunks)}\")\nprint(f\"üìÑ Primeiro chunk: {chunks[0]['content'][:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Sistema de Embeddings e Vector Store\n\nAgora vamos transformar nossos textos em **vetores matem√°ticos**. √â como dar uma \"impress√£o digital\" pra cada peda√ßo de texto, permitindo que o sistema encontre informa√ß√µes relacionadas rapidinho!\n\n**Dica!** Lembra do M√≥dulo 9? Estamos usando exatamente os conceitos de Vector Store que aprendemos l√°!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Configurando embeddings e vector store\nembeddings = GoogleGenerativeAIEmbeddings(\n    model=\"models/embedding-001\",\n    google_api_key=api_key\n)\n\n# Preparando textos e metadados para o Chroma\ntexts = [chunk['content'] for chunk in chunks]\nmetadatas = [{'source': chunk['source'], 'chunk_id': chunk['chunk_id']} for chunk in chunks]\n\n# Criando o vector store\nvectorstore = Chroma.from_texts(\n    texts=texts,\n    embedding=embeddings,\n    metadatas=metadatas,\n    collection_name=\"documentos_projeto\"\n)\n\nprint(\"üîç Vector Store criado com sucesso!\")\nprint(f\"üìä {len(texts)} documentos indexados\")\n\n# Testando uma busca\nquery = \"receita e crescimento\"\nresultados = vectorstore.similarity_search(query, k=2)\n\nprint(f\"\\nüîé Teste de busca para '{query}':\")\nfor i, doc in enumerate(resultados):\n    print(f\"Resultado {i+1}: {doc.page_content[:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ Agente 1: Extrator de Informa√ß√µes\n\nNosso primeiro agente √© especialista em **garimpar** informa√ß√µes importantes dos documentos. √â tipo aquele amigo que sempre acha o que voc√™ precisa em qualquer bagun√ßa!\n\nEle vai procurar:\n- **M√©tricas num√©ricas** (vendas, percentuais, etc.)\n- **Datas importantes**\n- **Nomes de pessoas/empresas**\n- **Palavras-chave relevantes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Template para extra√ß√£o de informa√ß√µes\nextraction_template = ChatPromptTemplate.from_messages([\n    (\"system\", \"\"\"\n    Voc√™ √© um especialista em extra√ß√£o de informa√ß√µes de documentos.\n    Sua miss√£o √© encontrar e organizar as informa√ß√µes mais importantes.\n    \n    Extraia as seguintes informa√ß√µes do texto:\n    1. M√âTRICAS NUM√âRICAS (valores, percentuais, quantidades)\n    2. DATAS E PER√çODOS importantes\n    3. NOMES (pessoas, empresas, produtos)\n    4. PALAVRAS-CHAVE relevantes\n    5. T√ìPICOS PRINCIPAIS\n    \n    Organize tudo em formato JSON claro e estruturado.\n    \"\"\"),\n    (\"human\", \"Texto para an√°lise: {texto}\")\n])\n\n# Criando nosso agente extrator\ndef extrair_informacoes(texto):\n    \"\"\"\n    Extrai informa√ß√µes estruturadas do texto\n    \"\"\"\n    chain = extraction_template | llm\n    \n    try:\n        resposta = chain.invoke({\"texto\": texto})\n        return resposta.content\n    except Exception as e:\n        return f\"Erro na extra√ß√£o: {e}\"\n\n# Testando com nosso documento\ntexto_completo = \" \".join([chunk['content'] for chunk in chunks])\ninfo_extraida = extrair_informacoes(texto_completo)\n\nprint(\"üìä INFORMA√á√ïES EXTRA√çDAS:\")\nprint(\"=\" * 50)\nprint(info_extraida)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Agente 2: Analisador de Sentimentos e Tend√™ncias\n\nEste agente √© nosso **psic√≥logo de textos**! Ele analisa:\n- **Sentimento geral** (positivo, negativo, neutro)\n- **N√≠vel de confian√ßa** das informa√ß√µes\n- **Tend√™ncias** mencionadas\n- **Pontos de aten√ß√£o** e oportunidades\n\n**Dica!** √â como ter um consultor que n√£o s√≥ l√™ os n√∫meros, mas entende as entrelinhas!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Template para an√°lise de sentimentos\nsentiment_template = ChatPromptTemplate.from_messages([\n    (\"system\", \"\"\"\n    Voc√™ √© um analista expert em sentiment analysis e an√°lise de tend√™ncias.\n    \n    Analise o texto e forne√ßa:\n    \n    1. SENTIMENT SCORE: (0-100, onde 0=muito negativo, 50=neutro, 100=muito positivo)\n    2. CONFIAN√áA: N√≠vel de certeza das informa√ß√µes (0-100)\n    3. TEND√äNCIAS IDENTIFICADAS: Crescimento, decl√≠nio, estabilidade\n    4. PALAVRAS-CHAVE EMOCIONAIS: Termos que indicam sentiment\n    5. INSIGHTS: 3 principais insights sobre o contexto\n    6. ALERTAS: Poss√≠veis pontos de aten√ß√£o\n    \n    Seja objetivo e use dados do texto para justificar sua an√°lise.\n    \"\"\"),\n    (\"human\", \"Texto para an√°lise: {texto}\")\n])\n\ndef analisar_sentimento(texto):\n    \"\"\"\n    Analisa sentimento e tend√™ncias do texto\n    \"\"\"\n    chain = sentiment_template | llm\n    \n    try:\n        resposta = chain.invoke({\"texto\": texto})\n        return resposta.content\n    except Exception as e:\n        return f\"Erro na an√°lise: {e}\"\n\n# Analisando nosso documento\nanalise_sentimento = analisar_sentimento(texto_completo)\n\nprint(\"üé≠ AN√ÅLISE DE SENTIMENTO:\")\nprint(\"=\" * 50)\nprint(analise_sentimento)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Agente 3: Gerador de Visualiza√ß√µes\n\nEste √© nosso **designer de dados**! Ele pega as informa√ß√µes extra√≠das e cria gr√°ficos lindos e informativos.\n\nVamos extrair dados num√©ricos e criar visualiza√ß√µes autom√°ticas!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vamos extrair dados num√©ricos do nosso texto para visualizar\nimport re\n\ndef extrair_dados_numericos(texto):\n    \"\"\"\n    Extrai n√∫meros, percentuais e valores do texto\n    \"\"\"\n    # Padr√µes para encontrar dados num√©ricos\n    valores_reais = re.findall(r'R\\$\\s*([\\d,\\.]+(?:\\s*(?:milh√µes?|mil))?)', texto)\n    percentuais = re.findall(r'(\\d+)%', texto)\n    numeros = re.findall(r'\\b(\\d{1,3}(?:[,\\.]\\d{3})*(?:[,\\.]\\d+)?)\\b', texto)\n    \n    return {\n        'valores_reais': valores_reais,\n        'percentuais': [int(p) for p in percentuais],\n        'numeros': numeros\n    }\n\n# Extraindo dados do nosso documento\ndados_numericos = extrair_dados_numericos(texto_completo)\nprint(\"üí∞ Dados Num√©ricos Encontrados:\")\nprint(f\"Valores em Reais: {dados_numericos['valores_reais']}\")\nprint(f\"Percentuais: {dados_numericos['percentuais']}\")\nprint(f\"Outros n√∫meros: {dados_numericos['numeros'][:10]}...\")  # Primeiros 10\n\n# Criando visualiza√ß√µes\nplt.style.use('seaborn-v0_8')\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\nfig.suptitle('üìä Dashboard Autom√°tico do Documento', fontsize=16, fontweight='bold')\n\n# Gr√°fico 1: Percentuais encontrados\nif dados_numericos['percentuais']:\n    labels = ['Crescimento', 'Reten√ß√£o', 'Market Share']\n    valores = dados_numericos['percentuais'][:3]  # Primeiros 3 percentuais\n    \n    # Garantir que temos dados suficientes\n    while len(valores) < 3:\n        valores.append(0)\n    \n    ax1.bar(labels[:len(valores)], valores, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n    ax1.set_title('üìà Principais M√©tricas (%)')\n    ax1.set_ylabel('Percentual')\n    \n    # Adicionando valores no topo das barras\n    for i, v in enumerate(valores):\n        ax1.text(i, v + 1, f'{v}%', ha='center', va='bottom', fontweight='bold')\n\n# Gr√°fico 2: Distribui√ß√£o de Sentimentos (simulado)\nsentimentos = ['Positivo', 'Neutro', 'Negativo']\nscores = [70, 20, 10]  # Baseado na an√°lise do texto\ncolors = ['#2ECC71', '#F39C12', '#E74C3C']\n\nax2.pie(scores, labels=sentimentos, colors=colors, autopct='%1.1f%%', startangle=90)\nax2.set_title('üé≠ An√°lise de Sentimento')\n\n# Gr√°fico 3: Timeline de m√©tricas (exemplo)\nmeses = ['Q1', 'Q2', 'Q3', 'Q4']\ncrescimento = [10, 15, 20, 25]  # Dados do documento\n\nax3.plot(meses, crescimento, marker='o', linewidth=3, markersize=8, color='#9B59B6')\nax3.fill_between(meses, crescimento, alpha=0.3, color='#9B59B6')\nax3.set_title('üìà Tend√™ncia de Crescimento')\nax3.set_ylabel('Crescimento (%)')\nax3.grid(True, alpha=0.3)\n\n# Gr√°fico 4: Word Cloud das palavras mais importantes\nwordcloud = WordCloud(\n    width=400, height=300,\n    background_color='white',\n    colormap='viridis',\n    max_words=50\n).generate(texto_completo)\n\nax4.imshow(wordcloud, interpolation='bilinear')\nax4.axis('off')\nax4.set_title('‚òÅÔ∏è Palavras-chave Principais')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"üé® Visualiza√ß√µes geradas automaticamente!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§î Agente 4: Sistema de Perguntas e Respostas\n\nEste √© nosso **g√™nio da l√¢mpada**! Voc√™ faz uma pergunta sobre qualquer coisa do documento e ele responde na lata!\n\nUsando RAG (Retrieval Augmented Generation) que aprendemos no M√≥dulo 10!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Criando sistema de Q&A com RAG\nqa_template = ChatPromptTemplate.from_messages([\n    (\"system\", \"\"\"\n    Voc√™ √© um assistente especialista em an√°lise de documentos.\n    Use APENAS as informa√ß√µes dos documentos fornecidos para responder.\n    \n    Se a informa√ß√£o n√£o estiver nos documentos, diga claramente:\n    \"Esta informa√ß√£o n√£o est√° dispon√≠vel nos documentos analisados.\"\n    \n    Seja preciso, cite n√∫meros quando relevante e forne√ßa contexto.\n    \"\"\"),\n    (\"human\", \"\"\"\n    Contexto dos documentos:\n    {contexto}\n    \n    Pergunta: {pergunta}\n    \n    Resposta baseada apenas no contexto:\n    \"\"\")\n])\n\ndef fazer_pergunta(pergunta, k=3):\n    \"\"\"\n    Faz uma pergunta sobre os documentos usando RAG\n    \"\"\"\n    # Busca documentos relevantes\n    docs_relevantes = vectorstore.similarity_search(pergunta, k=k)\n    \n    # Junta o contexto\n    contexto = \"\\n\\n\".join([doc.page_content for doc in docs_relevantes])\n    \n    # Cria a chain\n    chain = qa_template | llm\n    \n    try:\n        resposta = chain.invoke({\n            \"contexto\": contexto,\n            \"pergunta\": pergunta\n        })\n        return resposta.content, docs_relevantes\n    except Exception as e:\n        return f\"Erro: {e}\", []\n\n# Testando com algumas perguntas\nperguntas_teste = [\n    \"Qual foi o crescimento de vendas no Q4?\",\n    \"Quantos novos clientes foram adquiridos?\",\n    \"Quais s√£o os principais desafios identificados?\",\n    \"Qual √© a receita total mencionada?\"\n]\n\nprint(\"ü§ñ SISTEMA DE PERGUNTAS E RESPOSTAS\")\nprint(\"=\" * 60)\n\nfor pergunta in perguntas_teste:\n    print(f\"\\n‚ùì {pergunta}\")\n    resposta, docs = fazer_pergunta(pergunta)\n    print(f\"üí° {resposta}\")\n    print(\"-\" * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Sistema Multi-Agente Integrado\n\nAgora vamos juntar **todos os agentes** num sistema √∫nico! √â como orquestrar uma banda onde cada m√∫sico toca sua parte, mas o resultado final √© uma sinfonia!\n\n**Dica!** Aqui usamos os conceitos de Agents e Tools do M√≥dulo 11!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class SistemaMultiAgente:\n    def __init__(self, vectorstore, llm):\n        self.vectorstore = vectorstore\n        self.llm = llm\n        self.memory = ConversationBufferMemory(\n            memory_key=\"chat_history\",\n            return_messages=True\n        )\n        self.relatorio_final = {}\n    \n    def processar_documento_completo(self, texto):\n        \"\"\"\n        Executa an√°lise completa com todos os agentes\n        \"\"\"\n        print(\"üöÄ Iniciando an√°lise multi-agente...\")\n        \n        # Agente 1: Extra√ß√£o\n        print(\"\\nüîç Agente 1: Extraindo informa√ß√µes...\")\n        info_extraida = extrair_informacoes(texto)\n        \n        # Agente 2: An√°lise de Sentimento\n        print(\"üé≠ Agente 2: Analisando sentimentos...\")\n        analise = analisar_sentimento(texto)\n        \n        # Agente 3: Visualiza√ß√µes (j√° criamos acima)\n        print(\"üìä Agente 3: Gerando visualiza√ß√µes...\")\n        dados_viz = extrair_dados_numericos(texto)\n        \n        # Compilando relat√≥rio final\n        self.relatorio_final = {\n            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n            'informacoes_extraidas': info_extraida,\n            'analise_sentimento': analise,\n            'dados_numericos': dados_viz,\n            'sistema_qa': 'Ativo e funcionando'\n        }\n        \n        return self.relatorio_final\n    \n    def gerar_resumo_executivo(self):\n        \"\"\"\n        Gera um resumo executivo baseado em todas as an√°lises\n        \"\"\"\n        resumo_template = ChatPromptTemplate.from_messages([\n            (\"system\", \"\"\"\n            Voc√™ √© um consultor s√™nior criando um resumo executivo.\n            \n            Com base em todas as an√°lises realizadas, crie um resumo executivo\n            profissional com:\n            \n            1. S√çNTESE DOS PRINCIPAIS ACHADOS\n            2. M√âTRICAS-CHAVE\n            3. INSIGHTS ESTRAT√âGICOS\n            4. RECOMENDA√á√ïES\n            5. PR√ìXIMOS PASSOS\n            \n            Use linguagem executiva, seja conciso e foque no que importa para tomada de decis√£o.\n            \"\"\"),\n            (\"human\", \"Dados das an√°lises: {dados_completos}\")\n        ])\n        \n        chain = resumo_template | self.llm\n        \n        try:\n            resposta = chain.invoke({\n                \"dados_completos\": str(self.relatorio_final)\n            })\n            return resposta.content\n        except Exception as e:\n            return f\"Erro ao gerar resumo: {e}\"\n\n# Inicializando nosso sistema multi-agente\nsistema = SistemaMultiAgente(vectorstore, llm)\n\n# Executando an√°lise completa\nrelatorio = sistema.processar_documento_completo(texto_completo)\n\nprint(\"\\n‚úÖ An√°lise multi-agente conclu√≠da!\")\nprint(f\"üìÑ Relat√≥rio gerado √†s: {relatorio['timestamp']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã Relat√≥rio Executivo Final\n\nAgora vamos gerar o **gran finale**: um relat√≥rio executivo completo que junta tudo que nossos agentes descobriram!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Gerando o resumo executivo\nresumo_executivo = sistema.gerar_resumo_executivo()\n\nprint(\"üìä RELAT√ìRIO EXECUTIVO FINAL\")\nprint(\"=\" * 80)\nprint(resumo_executivo)\nprint(\"=\" * 80)\n\n# Salvando relat√≥rio completo em JSON\nrelatorio_completo = {\n    'documento_analisado': 'Relat√≥rio de Vendas Q4 2024',\n    'timestamp': datetime.now().isoformat(),\n    'resumo_executivo': resumo_executivo,\n    'detalhes': relatorio\n}\n\n# Salvando em arquivo\nwith open('relatorio_multiagente.json', 'w', encoding='utf-8') as f:\n    json.dump(relatorio_completo, f, ensure_ascii=False, indent=2)\n\nprint(\"\\nüíæ Relat√≥rio salvo em 'relatorio_multiagente.json'\")\nprint(\"\\nüéâ Sistema multi-agente funcionando perfeitamente!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéÆ Exerc√≠cio Pr√°tico 1\n\n**Desafio**: Crie seu pr√≥prio documento de teste!\n\n1. Escreva um texto sobre qualquer assunto (empresa, projeto, an√°lise)\n2. Inclua dados num√©ricos (percentuais, valores, datas)\n3. Execute todo o pipeline multi-agente\n4. Compare os resultados!\n\n**Dica!** Pode ser sobre sua empresa, um projeto fict√≠cio, ou at√© an√°lise de um filme!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# SEU C√ìDIGO AQUI!\n# Crie um novo documento e teste o sistema\n\nmeu_documento = \"\"\"\n# Substitua este texto pelo seu documento personalizado\n# Lembre-se de incluir:\n# - Dados num√©ricos\n# - Datas\n# - Informa√ß√µes que possam ser analisadas\n\"\"\"\n\n# Descomente as linhas abaixo quando tiver seu documento pronto:\n# novo_processor = DocumentProcessor()\n# novos_chunks = novo_processor.process_text(meu_documento, \"meu_teste\")\n# # Continue o processamento...\n\nprint(\"‚úèÔ∏è Escreva seu documento e execute a an√°lise!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Melhorias e Extens√µes\n\nNosso sistema j√° est√° **funcionando**, mas sempre d√° pra melhorar! Aqui est√£o algumas ideias pra turbinar ainda mais:\n\n### üöÄ Pr√≥ximos N√≠veis:\n\n1. **An√°lise de m√∫ltiplos documentos** simultaneamente\n2. **Compara√ß√£o temporal** (documentos de per√≠odos diferentes)\n3. **Alertas autom√°ticos** quando m√©tricas passam de limites\n4. **Integra√ß√£o com APIs** externas (bancos de dados, CRM)\n5. **Interface web** com Streamlit (que vamos ver no pr√≥ximo m√≥dulo!)\n\n**Dica!** No M√≥dulo 14 vamos transformar isso numa aplica√ß√£o web linda!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Fun√ß√£o para comparar m√∫ltiplos documentos\ndef comparar_documentos(doc1, doc2, titulo1=\"Documento 1\", titulo2=\"Documento 2\"):\n    \"\"\"\n    Compara dois documentos lado a lado\n    \"\"\"\n    print(f\"üîÑ Comparando {titulo1} vs {titulo2}\")\n    \n    # An√°lise do primeiro documento\n    info1 = extrair_informacoes(doc1)\n    sent1 = analisar_sentimento(doc1)\n    \n    # An√°lise do segundo documento\n    info2 = extrair_informacoes(doc2)\n    sent2 = analisar_sentimento(doc2)\n    \n    # Template para compara√ß√£o\n    comparacao_template = ChatPromptTemplate.from_messages([\n        (\"system\", \"\"\"\n        Voc√™ √© um analista comparativo especialista.\n        \n        Compare os dois documentos e identifique:\n        1. PRINCIPAIS DIFEREN√áAS\n        2. TEND√äNCIAS OPOSTAS\n        3. PONTOS EM COMUM\n        4. INSIGHTS COMPARATIVOS\n        5. RECOMENDA√á√ïES BASEADAS NA COMPARA√á√ÉO\n        \n        Seja espec√≠fico e use dados concretos das an√°lises.\n        \"\"\"),\n        (\"human\", \"\"\"\n        An√°lise Documento 1 ({titulo1}):\n        {analise1}\n        \n        An√°lise Documento 2 ({titulo2}):\n        {analise2}\n        \n        Fa√ßa uma compara√ß√£o detalhada:\n        \"\"\")\n    ])\n    \n    chain = comparacao_template | llm\n    \n    try:\n        resultado = chain.invoke({\n            \"titulo1\": titulo1,\n            \"titulo2\": titulo2,\n            \"analise1\": f\"{info1}\\n\\n{sent1}\",\n            \"analise2\": f\"{info2}\\n\\n{sent2}\"\n        })\n        return resultado.content\n    except Exception as e:\n        return f\"Erro na compara√ß√£o: {e}\"\n\n# Exemplo de uso (quando voc√™ tiver dois documentos)\nprint(\"üîç Fun√ß√£o de compara√ß√£o criada!\")\nprint(\"üìù Use comparar_documentos(doc1, doc2) para comparar textos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä M√©tricas de Performance do Sistema\n\nVamos medir qu√£o **eficiente** nosso sistema est√° sendo! √â importante sempre monitorar performance em sistemas de produ√ß√£o."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import time\nfrom collections import Counter\n\nclass MetricasPerformance:\n    def __init__(self):\n        self.tempos_execucao = []\n        self.tokens_processados = 0\n        self.consultas_realizadas = 0\n        self.inicio_sessao = time.time()\n    \n    def medir_tempo_execucao(self, funcao, *args, **kwargs):\n        \"\"\"Mede tempo de execu√ß√£o de uma fun√ß√£o\"\"\"\n        inicio = time.time()\n        resultado = funcao(*args, **kwargs)\n        fim = time.time()\n        \n        tempo_execucao = fim - inicio\n        self.tempos_execucao.append(tempo_execucao)\n        \n        return resultado, tempo_execucao\n    \n    def estatisticas_performance(self):\n        \"\"\"Retorna estat√≠sticas de performance\"\"\"\n        if not self.tempos_execucao:\n            return \"Nenhuma medi√ß√£o realizada ainda\"\n        \n        tempo_total_sessao = time.time() - self.inicio_sessao\n        tempo_medio = np.mean(self.tempos_execucao)\n        tempo_total_processamento = sum(self.tempos_execucao)\n        \n        stats = {\n            'tempo_sessao_total': f\"{tempo_total_sessao:.2f}s\",\n            'tempo_processamento_total': f\"{tempo_total_processamento:.2f}s\",\n            'tempo_medio_por_operacao': f\"{tempo_medio:.2f}s\",\n            'operacoes_realizadas': len(self.tempos_execucao),\n            'operacoes_por_minuto': f\"{len(self.tempos_execucao) / (tempo_total_sessao / 60):.1f}\"\n        }\n        \n        return stats\n\n# Inicializando m√©tricas\nmetricas = MetricasPerformance()\n\n# Testando performance com algumas opera√ß√µes\nprint(\"‚ö° Testando Performance do Sistema\")\nprint(\"=\" * 50)\n\n# Teste 1: Extra√ß√£o de informa√ß√µes\nresultado, tempo = metricas.medir_tempo_execucao(extrair_informacoes, texto_completo)\nprint(f\"üîç Extra√ß√£o de informa√ß√µes: {tempo:.2f}s\")\n\n# Teste 2: An√°lise de sentimento\nresultado, tempo = metricas.medir_tempo_execucao(analisar_sentimento, texto_completo)\nprint(f\"üé≠ An√°lise de sentimento: {tempo:.2f}s\")\n\n# Teste 3: Pergunta e resposta\nresultado, tempo = metricas.medir_tempo_execucao(fazer_pergunta, \"Qual foi o crescimento?\")\nprint(f\"‚ùì Pergunta e resposta: {tempo:.2f}s\")\n\n# Estat√≠sticas finais\nstats = metricas.estatisticas_performance()\nprint(\"\\nüìä ESTAT√çSTICAS DE PERFORMANCE:\")\nfor chave, valor in stats.items():\n    print(f\"{chave}: {valor}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéÆ Exerc√≠cio Final: Sistema Personalizado\n\n**Mega Desafio**: Crie um sistema multi-agente para **seu dom√≠nio espec√≠fico**!\n\nEscolha uma das op√ß√µes:\n\n1. **Sistema de RH**: Analisa curr√≠culos e perfis de candidatos\n2. **Sistema Financeiro**: Analisa relat√≥rios de investimento\n3. **Sistema de Marketing**: Analisa campanhas e resultados\n4. **Sistema Acad√™mico**: Analisa papers e pesquisas\n\n**Requisitos**:\n- Pelo menos 3 agentes especializados\n- Sistema de perguntas customizado\n- Visualiza√ß√µes espec√≠ficas do dom√≠nio\n- Relat√≥rio final personalizado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# SEU SISTEMA PERSONALIZADO AQUI!\n\n# Exemplo de estrutura:\nclass MeuSistemaEspecializado:\n    def __init__(self):\n        # Seus agentes especializados\n        pass\n    \n    def agente_especializado_1(self, texto):\n        # Seu primeiro agente especializado\n        pass\n    \n    def agente_especializado_2(self, texto):\n        # Seu segundo agente especializado  \n        pass\n    \n    def gerar_relatorio_personalizado(self):\n        # Seu relat√≥rio personalizado\n        pass\n\nprint(\"üöÄ Crie seu sistema personalizado aqui!\")\nprint(\"üí° Use como base tudo que aprendemos, mas adapte pro seu dom√≠nio!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéä Resum√£o do Projeto Final 2\n\n**Liiindo!** Voc√™ acabou de criar um sistema multi-agente completo! üéâ\n\n### üèÜ O que conquistamos:\n\n‚úÖ **Sistema Multi-Agente** com 4 especialistas\n‚úÖ **Extra√ß√£o autom√°tica** de informa√ß√µes\n‚úÖ **An√°lise de sentimento** avan√ßada\n‚úÖ **Visualiza√ß√µes autom√°ticas** dos dados\n‚úÖ **Sistema de Q&A** com RAG\n‚úÖ **Relat√≥rios executivos** autom√°ticos\n‚úÖ **M√©tricas de performance**\n\n### üîó Conceitos do LangChain utilizados:\n\n- **ChatModels** (M√≥dulo 2) ‚úÖ\n- **LCEL** (M√≥dulo 3) ‚úÖ  \n- **Prompt Templates** (M√≥dulo 4) ‚úÖ\n- **Chains** (M√≥dulo 6) ‚úÖ\n- **Memory Systems** (M√≥dulo 7) ‚úÖ\n- **Document Loading** (M√≥dulo 8) ‚úÖ\n- **Vector Stores** (M√≥dulo 9) ‚úÖ\n- **RAG** (M√≥dulo 10) ‚úÖ\n- **Agents** (M√≥dulo 11) ‚úÖ\n\n### üöÄ Pr√≥ximos passos:\n\n**M√≥dulo 14**: Vamos transformar este sistema numa **aplica√ß√£o web linda** com Streamlit!\n\n**Dica!** Guarde bem este c√≥digo, pois vamos usar como base pro deploy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Exerc√≠cio B√¥nus: Otimiza√ß√£o de Custos\n\nEm produ√ß√£o, √© importante **otimizar custos** de API. Vamos criar um sistema que monitora e otimiza o uso de tokens!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class OtimizadorCustos:\n    def __init__(self):\n        self.tokens_utilizados = 0\n        self.custo_por_token = 0.000002  # Exemplo de custo\n        self.cache_respostas = {}  # Cache simples\n    \n    def calcular_tokens_aproximados(self, texto):\n        \"\"\"Estimativa r√°pida de tokens (1 token ‚âà 4 caracteres)\"\"\"\n        return len(texto) // 4\n    \n    def verificar_cache(self, pergunta):\n        \"\"\"Verifica se j√° temos resposta em cache\"\"\"\n        return self.cache_respostas.get(pergunta)\n    \n    def adicionar_cache(self, pergunta, resposta):\n        \"\"\"Adiciona resposta ao cache\"\"\"\n        self.cache_respostas[pergunta] = resposta\n    \n    def fazer_pergunta_otimizada(self, pergunta):\n        \"\"\"Pergunta otimizada com cache\"\"\"\n        # Verifica cache primeiro\n        resposta_cache = self.verificar_cache(pergunta)\n        if resposta_cache:\n            print(f\"üíæ Resposta encontrada em cache! Economia de tokens.\")\n            return resposta_cache\n        \n        # Se n√£o tem cache, faz a pergunta\n        resposta, docs = fazer_pergunta(pergunta)\n        tokens_usados = self.calcular_tokens_aproximados(pergunta + resposta)\n        \n        # Atualiza m√©tricas\n        self.tokens_utilizados += tokens_usados\n        \n        # Salva no cache\n        self.adicionar_cache(pergunta, resposta)\n        \n        print(f\"üè∑Ô∏è Tokens utilizados: {tokens_usados}\")\n        print(f\"üí∞ Custo estimado: ${tokens_usados * self.custo_por_token:.6f}\")\n        \n        return resposta\n    \n    def relatorio_custos(self):\n        \"\"\"Relat√≥rio de custos acumulados\"\"\"\n        custo_total = self.tokens_utilizados * self.custo_por_token\n        return {\n            'tokens_total': self.tokens_utilizados,\n            'custo_total': f\"${custo_total:.6f}\",\n            'respostas_em_cache': len(self.cache_respostas),\n            'economia_potencial': f\"${len(self.cache_respostas) * 100 * self.custo_por_token:.6f}\"\n        }\n\n# Testando otimiza√ß√£o\notimizador = OtimizadorCustos()\n\nprint(\"üí∞ TESTE DE OTIMIZA√á√ÉO DE CUSTOS\")\nprint(\"=\" * 50)\n\n# Primeira pergunta\nresp1 = otimizador.fazer_pergunta_otimizada(\"Qual foi o crescimento?\")\n\n# Segunda pergunta (mesma - deve usar cache)\nresp2 = otimizador.fazer_pergunta_otimizada(\"Qual foi o crescimento?\")\n\n# Relat√≥rio final\nrelatorio = otimizador.relatorio_custos()\nprint(\"\\nüìä RELAT√ìRIO DE CUSTOS:\")\nfor chave, valor in relatorio.items():\n    print(f\"{chave}: {valor}\")\n\nprint(\"\\nüí° Sistema de cache funcionando! Economia garantida em produ√ß√£o!\")"
      ]
    }
  ]
}