{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ•¸ï¸ LangGraph: Quando o Agente Precisa de um GPS!\n\n**MÃ³dulo 14/15 - Curso LangChain v0.2**\n\nE aÃ­, galera! Chegamos ao MÃ³dulo 14 e agora vamos falar de uma parada que Ã© o **prÃ³ximo nÃ­vel** dos agents que jÃ¡ vimos!\n\nLembra dos agents que criamos no MÃ³dulo 9? Pois Ã©, eles eram legais, mas meio... como posso dizer... **desorganizados**! Era tipo aquele amigo que sai de casa sem GPS e fica rodando pela cidade sem rumo.\n\n**E o LangGraph?** Ã‰ justamente o GPS dos nossos agents! ğŸš—ğŸ“\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-versÃ£o-v0.2-modulo-14_img_01.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¤” TÃ¡, mas o que Ã© o LangGraph afinal?\n\nVou te explicar com uma analogia brasileira que vocÃª vai entender na hora!\n\nImagina que vocÃª estÃ¡ organizando um churrasco (eu sei, toda explicaÃ§Ã£o de tech no Brasil tem que ter churrasco ğŸ˜„):\n\n**Agents tradicionais** = VocÃª sozinho fazendo tudo: comprando carne, acendendo churrasqueira, fazendo farofa... Ã‰ muito trabalho e vocÃª pode se perder no meio!\n\n**LangGraph** = VocÃª com uma equipe organizada: JoÃ£o cuida da carne, Maria faz a farofa, Pedro organiza as bebidas, e **vocÃª coordena todo mundo** seguindo um plano bem definido!\n\n### O que o LangGraph faz?\n\n- **Cria fluxos complexos** de decisÃ£o para agents\n- **Gerencia estados** entre diferentes etapas  \n- **Permite loops e condiÃ§Ãµes** (coisa que agent simples nÃ£o faz direito)\n- **Controla a execuÃ§Ã£o** de mÃºltiplos agents trabalhando juntos\n- **Oferece observabilidade** total do que estÃ¡ rolando\n\n### Por que precisamos dele?\n\nLembra dos agents que criamos? Eles eram **lineares**: pergunta â†’ ferramenta â†’ resposta. \n\nMas na vida real, precisamos de fluxos tipo:\n- \"Se isso, entÃ£o aquilo\"\n- \"Tenta de novo se der erro\"\n- \"Faz essa parte, depois volta e faz aquela\"\n- \"VÃ¡rios agents trabalhando em paralelo\"\n\nÃ‰ aÃ­ que entra o **LangGraph**! ğŸ¯"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Primeiro, vamos instalar as dependÃªncias que vamos usar\n# Bora configurar nosso ambiente!\n\n!pip install -q langgraph langchain-google-genai python-dotenv matplotlib networkx\n\n# Imports bÃ¡sicos para comeÃ§ar nossa jornada\nimport os\nimport json\nfrom typing import Dict, Any, List\nfrom dotenv import load_dotenv\n\n# LangGraph imports - as estrelas do show!\nfrom langgraph.graph import Graph, StateGraph\nfrom langgraph.graph.message import add_messages\nfrom langchain_core.messages import HumanMessage, AIMessage\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\n# Para visualizar nossos grafos\nimport matplotlib.pyplot as plt\nimport networkx as nx\n\nprint(\"ğŸ“¦ Bibliotecas instaladas e importadas!\")\nprint(\"ğŸš€ Bora mergulhar no mundo do LangGraph!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ConfiguraÃ§Ã£o da API - igual fazÃ­amos antes!\nload_dotenv()\n\n# Nosso modelo que jÃ¡ conhecemos bem\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.0-flash-exp\",\n    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n    temperature=0.7\n)\n\nprint(\"ğŸ¤– Modelo configurado!\")\nprint(f\"âœ… Usando: {llm.model}\")\n\n# Teste rÃ¡pido para garantir que estÃ¡ funcionando\nresponse = llm.invoke(\"OlÃ¡! Estou aprendendo LangGraph hoje!\")\nprint(f\"\\nğŸ¯ Teste: {response.content[:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Conceitos Fundamentais do LangGraph\n\nAntes de botar a mÃ£o na massa, vamos entender os conceitos principais. Ã‰ como aprender as regras do futebol antes de entrar em campo!\n\n### 1. **Graph (Grafo)**\nÃ‰ a estrutura principal - pensa nele como o **mapa do nosso churrasco**. Define quem faz o quÃª e em que ordem.\n\n### 2. **Nodes (NÃ³s)**\nSÃ£o as **funÃ§Ãµes ou agents** que fazem o trabalho. Cada nÃ³ Ã© como uma pessoa no churrasco:\n- NÃ³ \"comprador\" â†’ vai no aÃ§ougue\n- NÃ³ \"churrasqueiro\" â†’ cuida da carne\n- NÃ³ \"organizador\" â†’ coordena tudo\n\n### 3. **Edges (Arestas)**\nSÃ£o as **conexÃµes** entre os nÃ³s. Definem o fluxo: \"depois de comprar a carne, acenda a churrasqueira\".\n\n### 4. **State (Estado)**\nÃ‰ a **memÃ³ria compartilhada** do grafo. Todo mundo no churrasco sabe: \"quantas pessoas vÃ£o vir?\", \"que horas comeÃ§ar?\", etc.\n\n### 5. **Conditional Edges (Arestas Condicionais)**\nO **if/else** do grafo: \"Se estÃ¡ chovendo, faz o churrasco na garagem, senÃ£o faz no quintal\".\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-versÃ£o-v0.2-modulo-14_img_02.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§® A MatemÃ¡tica por trÃ¡s do LangGraph\n\nVou te mostrar a teoria sem assustar! ğŸ˜…\n\nUm grafo no LangGraph pode ser representado matematicamente como:\n\n$$G = (V, E, S, F)$$\n\nOnde:\n- $V$ = conjunto de vÃ©rtices (nossos nÃ³s/funÃ§Ãµes)\n- $E$ = conjunto de arestas (conexÃµes entre nÃ³s)\n- $S$ = estado compartilhado (nossa memÃ³ria)\n- $F$ = funÃ§Ã£o de transiÃ§Ã£o de estado\n\n### FunÃ§Ã£o de TransiÃ§Ã£o de Estado\n\nCada nÃ³ executa uma funÃ§Ã£o que pode ser representada como:\n\n$$S_{novo} = f_i(S_{atual}, Input_i)$$\n\nOnde:\n- $f_i$ Ã© a funÃ§Ã£o do nÃ³ $i$\n- $S_{atual}$ Ã© o estado antes da execuÃ§Ã£o\n- $Input_i$ Ã© a entrada especÃ­fica do nÃ³\n- $S_{novo}$ Ã© o estado resultante\n\n### Algoritmo de ExecuÃ§Ã£o\n\nO LangGraph usa um algoritmo similar ao **BFS (Breadth-First Search)** com controle de estado:\n\n1. **Inicializa** estado $S_0$\n2. **Executa** nÃ³ inicial: $S_1 = f_{start}(S_0)$\n3. **Avalia** condiÃ§Ãµes de transiÃ§Ã£o\n4. **Seleciona** prÃ³ximo nÃ³ baseado em $S_{atual}$\n5. **Repete** atÃ© atingir condiÃ§Ã£o de parada\n\n**Dica do Pedro**: NÃ£o se preocupe muito com a matemÃ¡tica agora. O importante Ã© entender que o LangGraph gerencia tudo isso para vocÃª! Ã‰ como usar GPS - vocÃª nÃ£o precisa saber os algoritmos de roteamento para chegar no destino! ğŸ—ºï¸"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vamos criar nosso primeiro grafo simples!\n# ComeÃ§ando com o bÃ¡sico: um contador que toma decisÃµes\n\nfrom typing import TypedDict\n\n# Definindo o estado do nosso grafo\n# Ã‰ como definir \"que informaÃ§Ãµes todo mundo vai compartilhar\"\nclass CounterState(TypedDict):\n    count: int\n    messages: List[str]\n    should_continue: bool\n\n# FunÃ§Ã£o que incrementa o contador\ndef increment_counter(state: CounterState) -> CounterState:\n    \"\"\"Incrementa o contador e adiciona uma mensagem\"\"\"\n    new_count = state[\"count\"] + 1\n    new_message = f\"Contador agora estÃ¡ em: {new_count}\"\n    \n    return {\n        \"count\": new_count,\n        \"messages\": state[\"messages\"] + [new_message],\n        \"should_continue\": new_count < 5  # Para quando chegar em 5\n    }\n\n# FunÃ§Ã£o que decide se devemos continuar\ndef should_continue_counting(state: CounterState) -> str:\n    \"\"\"Decide se devemos continuar ou parar\"\"\"\n    if state[\"should_continue\"]:\n        return \"continue\"\n    else:\n        return \"stop\"\n\n# FunÃ§Ã£o final\ndef finish_counting(state: CounterState) -> CounterState:\n    \"\"\"Finaliza a contagem\"\"\"\n    return {\n        **state,\n        \"messages\": state[\"messages\"] + [\"ğŸ‰ Contagem finalizada!\"]\n    }\n\nprint(\"ğŸ”§ FunÃ§Ãµes do grafo criadas!\")\nprint(\"ğŸ“ Estado definido: count, messages, should_continue\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Agora vamos montar nosso grafo!\n# Ã‰ como montar um fluxograma, mas em cÃ³digo\n\nfrom langgraph.graph import StateGraph, END\n\n# Criando o grafo\nworkflow = StateGraph(CounterState)\n\n# Adicionando os nÃ³s (as \"estaÃ§Ãµes\" do nosso fluxo)\nworkflow.add_node(\"increment\", increment_counter)\nworkflow.add_node(\"finish\", finish_counting)\n\n# Definindo o ponto de entrada\nworkflow.set_entry_point(\"increment\")\n\n# Adicionando as conexÃµes condicionais\n# Ã‰ aqui que a mÃ¡gica acontece!\nworkflow.add_conditional_edges(\n    \"increment\",  # De qual nÃ³\n    should_continue_counting,  # FunÃ§Ã£o que decide\n    {\n        \"continue\": \"increment\",  # Se continuar, volta pro increment\n        \"stop\": \"finish\"         # Se parar, vai pro finish\n    }\n)\n\n# Conectando o nÃ³ final ao fim do grafo\nworkflow.add_edge(\"finish\", END)\n\n# Compilando o grafo (transformando em algo executÃ¡vel)\napp = workflow.compile()\n\nprint(\"ğŸ—ï¸ Grafo construÃ­do e compilado!\")\nprint(\"ğŸ¯ Pronto para executar nosso primeiro fluxo!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Hora de executar nosso grafo!\n# Ã‰ como apertar o play na nossa mÃ¡quina de estados\n\n# Estado inicial\ninitial_state = {\n    \"count\": 0,\n    \"messages\": [\"ğŸš€ Iniciando contagem...\"],\n    \"should_continue\": True\n}\n\nprint(\"â–¶ï¸ Executando o grafo...\\n\")\n\n# Executando o grafo\nresult = app.invoke(initial_state)\n\n# Mostrando os resultados\nprint(\"ğŸ“Š Resultado Final:\")\nprint(f\"Contador final: {result['count']}\")\nprint(f\"Deve continuar: {result['should_continue']}\")\nprint(\"\\nğŸ“ HistÃ³rico de mensagens:\")\nfor i, msg in enumerate(result['messages'], 1):\n    print(f\"{i}. {msg}\")\n\nprint(\"\\nğŸ‰ Liiindo! Nosso primeiro grafo funcionou!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ˆ Visualizando nosso Grafo\n\nUma imagem vale mais que mil palavras! Vamos ver como nosso grafo fica visualmente.\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-versÃ£o-v0.2-modulo-14_img_03.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vamos criar uma visualizaÃ§Ã£o do nosso grafo\n# Porque ver Ã© melhor que imaginar!\n\nimport matplotlib.pyplot as plt\nimport networkx as nx\nfrom matplotlib.patches import FancyBboxPatch\n\n# Criando o grÃ¡fico\nfig, ax = plt.subplots(1, 1, figsize=(12, 8))\nax.set_xlim(0, 10)\nax.set_ylim(0, 8)\nax.axis('off')\n\n# Definindo posiÃ§Ãµes dos elementos\npositions = {\n    'start': (1, 4),\n    'increment': (3, 4),\n    'decision': (5, 4),\n    'finish': (7, 4),\n    'end': (9, 4)\n}\n\n# Desenhando os nÃ³s\nfor name, (x, y) in positions.items():\n    if name == 'decision':\n        # Losango para decisÃ£o\n        diamond = FancyBboxPatch(\n            (x-0.5, y-0.3), 1, 0.6,\n            boxstyle=\"round,pad=0.1\",\n            facecolor='lightblue',\n            edgecolor='blue',\n            transform=ax.transData\n        )\n        ax.add_patch(diamond)\n        ax.text(x, y, 'Continuar?', ha='center', va='center', fontsize=10, weight='bold')\n    else:\n        # RetÃ¢ngulo para aÃ§Ãµes\n        rect = FancyBboxPatch(\n            (x-0.5, y-0.3), 1, 0.6,\n            boxstyle=\"round,pad=0.1\",\n            facecolor='lightgreen',\n            edgecolor='darkgreen',\n            transform=ax.transData\n        )\n        ax.add_patch(rect)\n        ax.text(x, y, name.title(), ha='center', va='center', fontsize=10, weight='bold')\n\n# Desenhando as setas\narrows = [\n    ((1.5, 4), (2.5, 4), 'Entrada'),\n    ((3.5, 4), (4.5, 4), ''),\n    ((5.5, 4), (6.5, 4), 'NÃ£o'),\n    ((7.5, 4), (8.5, 4), ''),\n    ((5, 4.3), (3, 4.7), 'Sim'),  # Loop de volta\n]\n\nfor (x1, y1), (x2, y2), label in arrows:\n    if label == 'Sim':  # Curva para o loop\n        ax.annotate('', xy=(x2, y2), xytext=(x1, y1),\n                   arrowprops=dict(arrowstyle='->', lw=2, color='red',\n                                 connectionstyle=\"arc3,rad=0.3\"))\n        ax.text(4, 5, label, ha='center', va='center', fontsize=9, color='red', weight='bold')\n    else:\n        ax.annotate('', xy=(x2, y2), xytext=(x1, y1),\n                   arrowprops=dict(arrowstyle='->', lw=2, color='darkblue'))\n        if label:\n            mid_x, mid_y = (x1 + x2) / 2, (y1 + y2) / 2\n            ax.text(mid_x, mid_y + 0.2, label, ha='center', va='center', \n                   fontsize=9, color='darkblue', weight='bold')\n\nax.set_title('ğŸ•¸ï¸ Estrutura do nosso LangGraph - Contador', fontsize=16, weight='bold', pad=20)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"ğŸ“Š VisualizaÃ§Ã£o criada!\")\nprint(\"ğŸ¯ Observe como o fluxo funciona: Start â†’ Increment â†’ DecisÃ£o â†’ Finish ou Loop\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¤– LangGraph com LLMs: Agora fica sÃ©rio!\n\nTÃ¡, contador Ã© legal, mas vamos fazer algo mais parecido com o que usamos no mundo real!\n\nVamos criar um grafo que usa nosso modelo LLM para:\n1. **Analisar** uma pergunta do usuÃ¡rio\n2. **Decidir** se precisa de mais informaÃ§Ãµes\n3. **Fazer perguntas** de esclarecimento se necessÃ¡rio\n4. **Gerar** a resposta final\n\nÃ‰ como ter um assistente que nÃ£o sÃ³ responde, mas **pensa no processo** de como responder melhor!\n\n### Casos de uso reais:\n- **Chatbots inteligentes** que fazem perguntas de esclarecimento\n- **Sistemas de suporte** que coletam informaÃ§Ãµes antes de ajudar\n- **Assistentes de vendas** que qualificam leads\n- **Tutores virtuais** que adaptam explicaÃ§Ãµes\n\n**Dica do Pedro**: Lembra dos agents do MÃ³dulo 9? Eles eram Ã³timos para tarefas simples, mas aqui conseguimos criar **fluxos de conversaÃ§Ã£o muito mais sofisticados**! ğŸ§ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vamos criar um assistente inteligente que pensa antes de responder!\n# Estado mais complexo para nosso chatbot\n\nfrom langchain_core.messages import BaseMessage\nfrom typing import Annotated\n\nclass ChatState(TypedDict):\n    messages: Annotated[List[BaseMessage], add_messages]\n    user_question: str\n    needs_clarification: bool\n    clarification_asked: bool\n    context_info: Dict[str, Any]\n    final_answer: str\n\n# NÃ³ 1: Analisa se a pergunta precisa de esclarecimento\ndef analyze_question(state: ChatState) -> ChatState:\n    \"\"\"Analisa se a pergunta do usuÃ¡rio precisa de mais informaÃ§Ãµes\"\"\"\n    \n    question = state[\"user_question\"]\n    \n    analysis_prompt = f\"\"\"\n    Analise esta pergunta do usuÃ¡rio: \"{question}\"\n    \n    Determine se a pergunta Ã©:\n    - CLARA: pode ser respondida diretamente\n    - AMBÃGUA: precisa de esclarecimentos\n    \n    Responda apenas com: CLARA ou AMBÃGUA\n    \"\"\"\n    \n    response = llm.invoke(analysis_prompt)\n    needs_clarification = \"AMBÃGUA\" in response.content.upper()\n    \n    return {\n        **state,\n        \"needs_clarification\": needs_clarification,\n        \"messages\": [AIMessage(content=f\"AnÃ¡lise: {'Precisa esclarecimento' if needs_clarification else 'Pergunta clara'}\")]\n    }\n\n# NÃ³ 2: Faz pergunta de esclarecimento\ndef ask_clarification(state: ChatState) -> ChatState:\n    \"\"\"Gera uma pergunta de esclarecimento para o usuÃ¡rio\"\"\"\n    \n    question = state[\"user_question\"]\n    \n    clarification_prompt = f\"\"\"\n    O usuÃ¡rio fez esta pergunta ambÃ­gua: \"{question}\"\n    \n    FaÃ§a UMA pergunta especÃ­fica para esclarecer o que ele realmente quer saber.\n    Seja direto e Ãºtil.\n    \"\"\"\n    \n    response = llm.invoke(clarification_prompt)\n    \n    return {\n        **state,\n        \"clarification_asked\": True,\n        \"messages\": state[\"messages\"] + [AIMessage(content=response.content)]\n    }\n\n# NÃ³ 3: Gera resposta final\ndef generate_final_answer(state: ChatState) -> ChatState:\n    \"\"\"Gera a resposta final baseada em todas as informaÃ§Ãµes\"\"\"\n    \n    question = state[\"user_question\"]\n    context = \"\\n\".join([msg.content for msg in state[\"messages\"] if msg.content])\n    \n    final_prompt = f\"\"\"\n    Pergunta original: \"{question}\"\n    Contexto da conversa: {context}\n    \n    ForneÃ§a uma resposta completa e Ãºtil para o usuÃ¡rio.\n    Seja claro, direto e amigÃ¡vel.\n    \"\"\"\n    \n    response = llm.invoke(final_prompt)\n    \n    return {\n        **state,\n        \"final_answer\": response.content,\n        \"messages\": state[\"messages\"] + [AIMessage(content=response.content)]\n    }\n\nprint(\"ğŸ§  NÃ³s do chatbot inteligente criados!\")\nprint(\"âœ… FunÃ§Ãµes: analyze_question, ask_clarification, generate_final_answer\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# FunÃ§Ã£o de decisÃ£o para nosso chatbot\ndef should_ask_clarification(state: ChatState) -> str:\n    \"\"\"Decide o prÃ³ximo passo baseado no estado atual\"\"\"\n    \n    # Se precisa de esclarecimento e ainda nÃ£o perguntou\n    if state[\"needs_clarification\"] and not state[\"clarification_asked\"]:\n        return \"ask_clarification\"\n    \n    # SenÃ£o, gera a resposta final\n    return \"generate_answer\"\n\n# Construindo nosso chatbot inteligente\nchatbot_workflow = StateGraph(ChatState)\n\n# Adicionando os nÃ³s\nchatbot_workflow.add_node(\"analyze\", analyze_question)\nchatbot_workflow.add_node(\"clarify\", ask_clarification)\nchatbot_workflow.add_node(\"answer\", generate_final_answer)\n\n# Definindo o fluxo\nchatbot_workflow.set_entry_point(\"analyze\")\n\n# ConexÃµes condicionais\nchatbot_workflow.add_conditional_edges(\n    \"analyze\",\n    should_ask_clarification,\n    {\n        \"ask_clarification\": \"clarify\",\n        \"generate_answer\": \"answer\"\n    }\n)\n\n# Da clarificaÃ§Ã£o sempre vai para a resposta\nchatbot_workflow.add_edge(\"clarify\", \"answer\")\n\n# Resposta final termina o fluxo\nchatbot_workflow.add_edge(\"answer\", END)\n\n# Compilando nosso chatbot\nchatbot_app = chatbot_workflow.compile()\n\nprint(\"ğŸ¤– Chatbot inteligente montado!\")\nprint(\"ğŸ¯ Fluxo: Analisa â†’ Decide â†’ Esclarece (se necessÃ¡rio) â†’ Responde\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Testando nosso chatbot inteligente!\n# Vamos ver como ele se comporta com diferentes tipos de pergunta\n\ndef test_chatbot(question: str):\n    \"\"\"Testa o chatbot com uma pergunta\"\"\"\n    \n    print(f\"\\nğŸ—£ï¸ UsuÃ¡rio: {question}\")\n    print(\"=\"*50)\n    \n    # Estado inicial\n    initial_state = {\n        \"messages\": [],\n        \"user_question\": question,\n        \"needs_clarification\": False,\n        \"clarification_asked\": False,\n        \"context_info\": {},\n        \"final_answer\": \"\"\n    }\n    \n    # Executando\n    result = chatbot_app.invoke(initial_state)\n    \n    # Mostrando o processo\n    print(\"ğŸ”„ Processo:\")\n    for i, msg in enumerate(result[\"messages\"], 1):\n        print(f\"{i}. {msg.content}\")\n    \n    print(f\"\\nğŸ¯ Precisou esclarecimento: {'Sim' if result['needs_clarification'] else 'NÃ£o'}\")\n    \n    return result\n\n# Teste 1: Pergunta clara\nprint(\"ğŸ§ª TESTE 1: Pergunta Clara\")\ntest1 = test_chatbot(\"Qual Ã© a capital do Brasil?\")\n\n# Teste 2: Pergunta ambÃ­gua\nprint(\"\\n\\nğŸ§ª TESTE 2: Pergunta AmbÃ­gua\")\ntest2 = test_chatbot(\"Como faÃ§o isso?\")\n\nprint(\"\\nğŸ‰ Testes concluÃ­dos! Veja como o chatbot se adapta ao tipo de pergunta!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š ComparaÃ§Ã£o: Agents vs LangGraph\n\nAgora que vimos os dois em aÃ§Ã£o, vamos comparar!\n\n| Aspecto | Agents (MÃ³dulo 9) | LangGraph |\n|---------|-------------------|----------|\n| **Complexidade** | Simples, linear | Complexo, ramificado |\n| **Controle de Fluxo** | Limitado | Total |\n| **Estados** | NÃ£o gerencia | Gerencia completamente |\n| **Loops** | DifÃ­cil | Nativo |\n| **MÃºltiplos Caminhos** | NÃ£o suporta | Suporta nativamente |\n| **Debugging** | DifÃ­cil | FÃ¡cil (observÃ¡vel) |\n| **Casos de Uso** | Tarefas simples | Workflows complexos |\n\n### Quando usar cada um?\n\n**Use Agents quando**:\n- Tarefa simples e direta\n- NÃ£o precisa de loops ou condiÃ§Ãµes\n- Quer algo rÃ¡pido de implementar\n\n**Use LangGraph quando**:\n- Precisa de fluxos condicionais\n- Quer controlar cada etapa\n- Precisa de loops ou retry logic\n- Quer observabilidade total\n- MÃºltiplos agents trabalhando juntos\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-versÃ£o-v0.2-modulo-14_img_04.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vamos criar um grÃ¡fico comparativo de performance\n# Simulando cenÃ¡rios diferentes\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Dados simulados de performance\nscenarios = ['Tarefa Simples', 'Fluxo Condicional', 'MÃºltiplos Loops', 'Error Handling', 'Observabilidade']\nagents_score = [9, 4, 2, 3, 2]  # Agents tradicionais\nlanggraph_score = [7, 9, 9, 8, 10]  # LangGraph\n\nx = np.arange(len(scenarios))\nwidth = 0.35\n\nfig, ax = plt.subplots(figsize=(12, 7))\nrects1 = ax.bar(x - width/2, agents_score, width, label='Agents Tradicionais', \n                color='lightcoral', alpha=0.8)\nrects2 = ax.bar(x + width/2, langgraph_score, width, label='LangGraph', \n                color='lightblue', alpha=0.8)\n\nax.set_ylabel('Score (0-10)', fontsize=12)\nax.set_title('ğŸ† Agents vs LangGraph - ComparaÃ§Ã£o de Capabilities', fontsize=14, weight='bold')\nax.set_xticks(x)\nax.set_xticklabels(scenarios, rotation=45, ha='right')\nax.legend()\nax.grid(axis='y', alpha=0.3)\n\n# Adicionando valores nas barras\ndef autolabel(rects):\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate(f'{height}',\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 3),\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom', weight='bold')\n\nautolabel(rects1)\nautolabel(rects2)\n\nplt.tight_layout()\nplt.show()\n\n# AnÃ¡lise dos resultados\nprint(\"ğŸ“Š AnÃ¡lise dos Resultados:\")\nprint(\"\\nğŸŸ¢ Agents Tradicionais sÃ£o melhores em:\")\nfor i, scenario in enumerate(scenarios):\n    if agents_score[i] > langgraph_score[i]:\n        print(f\"   â€¢ {scenario} (Score: {agents_score[i]} vs {langgraph_score[i]})\")\n\nprint(\"\\nğŸ”µ LangGraph Ã© melhor em:\")\nfor i, scenario in enumerate(scenarios):\n    if langgraph_score[i] > agents_score[i]:\n        print(f\"   â€¢ {scenario} (Score: {langgraph_score[i]} vs {agents_score[i]})\")\n\nprint(\"\\nğŸ¯ ConclusÃ£o: LangGraph vence em cenÃ¡rios complexos, Agents em tarefas simples!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ—ï¸ Projeto PrÃ¡tico: Sistema de Atendimento Inteligente\n\nBora fazer um projeto real que vocÃª pode usar no trabalho!\n\nVamos criar um **Sistema de Atendimento ao Cliente** que:\n\n1. **Classifica** o tipo de problema\n2. **Coleta** informaÃ§Ãµes necessÃ¡rias\n3. **Tenta resolver** automaticamente\n4. **Escalona** para humano se necessÃ¡rio\n\nÃ‰ tipo um **funil inteligente** que otimiza o atendimento!\n\n### Fluxo do Sistema:\n```mermaid\ngraph TD\n    A[Cliente faz pergunta] --> B[Classifica problema]\n    B --> C{Tipo de problema?}\n    C -->|TÃ©cnico| D[Coleta info tÃ©cnica]\n    C -->|Comercial| E[Coleta info comercial]\n    C -->|Suporte| F[Coleta info suporte]\n    D --> G[Tenta resolver]\n    E --> G\n    F --> G\n    G --> H{Conseguiu resolver?}\n    H -->|Sim| I[Resposta final]\n    H -->|NÃ£o| J[Escalona para humano]\n```\n\n**Dica do Pedro**: Este Ã© o tipo de sistema que grandes empresas pagam milhÃµes para ter! E vocÃª vai aprender a fazer em algumas cÃ©lulas! ğŸ’ª"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Estado do nosso sistema de atendimento\nclass SupportState(TypedDict):\n    messages: Annotated[List[BaseMessage], add_messages]\n    customer_query: str\n    problem_type: str  # 'technical', 'commercial', 'support'\n    collected_info: Dict[str, Any]\n    resolution_attempt: str\n    resolved: bool\n    escalated: bool\n    final_response: str\n\n# NÃ³ 1: Classifica o tipo de problema\ndef classify_problem(state: SupportState) -> SupportState:\n    \"\"\"Classifica o tipo de problema do cliente\"\"\"\n    \n    query = state[\"customer_query\"]\n    \n    classification_prompt = f\"\"\"\n    Classifique este problema do cliente em uma das categorias:\n    \n    Problema: \"{query}\"\n    \n    Categorias:\n    - TECHNICAL: problemas tÃ©cnicos, bugs, nÃ£o funciona\n    - COMMERCIAL: preÃ§os, planos, vendas, upgrades\n    - SUPPORT: como usar, tutoriais, dÃºvidas gerais\n    \n    Responda apenas com: TECHNICAL, COMMERCIAL ou SUPPORT\n    \"\"\"\n    \n    response = llm.invoke(classification_prompt)\n    problem_type = response.content.strip().upper()\n    \n    if problem_type not in ['TECHNICAL', 'COMMERCIAL', 'SUPPORT']:\n        problem_type = 'SUPPORT'  # Default\n    \n    return {\n        **state,\n        \"problem_type\": problem_type.lower(),\n        \"messages\": [AIMessage(content=f\"Problema classificado como: {problem_type}\")]\n    }\n\n# NÃ³ 2: Coleta informaÃ§Ãµes especÃ­ficas\ndef collect_info(state: SupportState) -> SupportState:\n    \"\"\"Coleta informaÃ§Ãµes baseadas no tipo de problema\"\"\"\n    \n    problem_type = state[\"problem_type\"]\n    query = state[\"customer_query\"]\n    \n    if problem_type == \"technical\":\n        info_prompt = f\"\"\"\n        Para resolver este problema tÃ©cnico: \"{query}\"\n        \n        Que informaÃ§Ãµes tÃ©cnicas vocÃª precisa coletar?\n        Liste 3 perguntas especÃ­ficas que ajudariam a diagnosticar.\n        \"\"\"\n    elif problem_type == \"commercial\":\n        info_prompt = f\"\"\"\n        Para esta questÃ£o comercial: \"{query}\"\n        \n        Que informaÃ§Ãµes comerciais vocÃª precisa?\n        Liste 3 perguntas sobre necessidades e orÃ§amento.\n        \"\"\"\n    else:  # support\n        info_prompt = f\"\"\"\n        Para esta dÃºvida de suporte: \"{query}\"\n        \n        Que esclarecimentos vocÃª precisa?\n        Liste 3 perguntas para entender melhor a necessidade.\n        \"\"\"\n    \n    response = llm.invoke(info_prompt)\n    \n    return {\n        **state,\n        \"collected_info\": {\"questions\": response.content},\n        \"messages\": state[\"messages\"] + [AIMessage(content=f\"InformaÃ§Ãµes coletadas para {problem_type}\")]\n    }\n\nprint(\"ğŸ¯ FunÃ§Ãµes de classificaÃ§Ã£o e coleta criadas!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# NÃ³ 3: Tenta resolver o problema\ndef attempt_resolution(state: SupportState) -> SupportState:\n    \"\"\"Tenta resolver o problema automaticamente\"\"\"\n    \n    query = state[\"customer_query\"]\n    problem_type = state[\"problem_type\"]\n    info = state[\"collected_info\"]\n    \n    resolution_prompt = f\"\"\"\n    Tente resolver este problema do cliente:\n    \n    Problema: \"{query}\"\n    Tipo: {problem_type}\n    InformaÃ§Ãµes coletadas: {info}\n    \n    ForneÃ§a uma soluÃ§Ã£o detalhada e prÃ¡tica.\n    Se nÃ£o conseguir resolver completamente, diga \"ESCALATE\".\n    \"\"\"\n    \n    response = llm.invoke(resolution_prompt)\n    \n    # Verifica se conseguiu resolver\n    resolved = \"ESCALATE\" not in response.content.upper()\n    \n    return {\n        **state,\n        \"resolution_attempt\": response.content,\n        \"resolved\": resolved,\n        \"messages\": state[\"messages\"] + [AIMessage(content=\"Tentativa de resoluÃ§Ã£o realizada\")]\n    }\n\n# NÃ³ 4: Resposta final (quando resolve)\ndef provide_final_answer(state: SupportState) -> SupportState:\n    \"\"\"Fornece a resposta final quando o problema foi resolvido\"\"\"\n    \n    resolution = state[\"resolution_attempt\"]\n    \n    final_prompt = f\"\"\"\n    Transforme esta soluÃ§Ã£o tÃ©cnica em uma resposta amigÃ¡vel para o cliente:\n    \n    SoluÃ§Ã£o: {resolution}\n    \n    Seja caloroso, claro e Ãºtil. Termine perguntando se precisa de mais alguma coisa.\n    \"\"\"\n    \n    response = llm.invoke(final_prompt)\n    \n    return {\n        **state,\n        \"final_response\": response.content,\n        \"messages\": state[\"messages\"] + [AIMessage(content=response.content)]\n    }\n\n# NÃ³ 5: Escalona para humano\ndef escalate_to_human(state: SupportState) -> SupportState:\n    \"\"\"Escalona o problema para atendimento humano\"\"\"\n    \n    query = state[\"customer_query\"]\n    problem_type = state[\"problem_type\"]\n    \n    escalation_msg = f\"\"\"\n    ğŸ¤ OlÃ¡! Vou conectar vocÃª com um de nossos especialistas.\n    \n    Seu problema ({problem_type}) serÃ¡ tratado com prioridade.\n    Tempo estimado de espera: 5-10 minutos.\n    \n    Um momento, por favor...\n    \"\"\"\n    \n    return {\n        **state,\n        \"escalated\": True,\n        \"final_response\": escalation_msg,\n        \"messages\": state[\"messages\"] + [AIMessage(content=escalation_msg)]\n    }\n\nprint(\"ğŸ”§ FunÃ§Ãµes de resoluÃ§Ã£o e escalonamento criadas!\")\nprint(\"âœ… Sistema de atendimento quase pronto!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# FunÃ§Ã£o de decisÃ£o do sistema\ndef decide_next_step(state: SupportState) -> str:\n    \"\"\"Decide se resolve ou escalona\"\"\"\n    \n    if state[\"resolved\"]:\n        return \"provide_answer\"\n    else:\n        return \"escalate\"\n\n# Montando o sistema completo\nsupport_workflow = StateGraph(SupportState)\n\n# Adicionando todos os nÃ³s\nsupport_workflow.add_node(\"classify\", classify_problem)\nsupport_workflow.add_node(\"collect\", collect_info)\nsupport_workflow.add_node(\"resolve\", attempt_resolution)\nsupport_workflow.add_node(\"answer\", provide_final_answer)\nsupport_workflow.add_node(\"escalate\", escalate_to_human)\n\n# Definindo o fluxo\nsupport_workflow.set_entry_point(\"classify\")\n\n# ConexÃµes lineares atÃ© a decisÃ£o\nsupport_workflow.add_edge(\"classify\", \"collect\")\nsupport_workflow.add_edge(\"collect\", \"resolve\")\n\n# DecisÃ£o condicional apÃ³s tentar resolver\nsupport_workflow.add_conditional_edges(\n    \"resolve\",\n    decide_next_step,\n    {\n        \"provide_answer\": \"answer\",\n        \"escalate\": \"escalate\"\n    }\n)\n\n# Ambos os finais terminam o fluxo\nsupport_workflow.add_edge(\"answer\", END)\nsupport_workflow.add_edge(\"escalate\", END)\n\n# Compilando nosso sistema de atendimento\nsupport_app = support_workflow.compile()\n\nprint(\"ğŸ¢ Sistema de Atendimento Inteligente PRONTO!\")\nprint(\"ğŸ¯ Fluxo completo montado e testado!\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Testando nosso sistema de atendimento!\n# Vamos simular diferentes tipos de problemas\n\ndef test_support_system(customer_query: str):\n    \"\"\"Testa o sistema de atendimento\"\"\"\n    \n    print(f\"\\nğŸ§ NOVO ATENDIMENTO\")\n    print(f\"Cliente: {customer_query}\")\n    print(\"=\"*60)\n    \n    # Estado inicial\n    initial_state = {\n        \"messages\": [],\n        \"customer_query\": customer_query,\n        \"problem_type\": \"\",\n        \"collected_info\": {},\n        \"resolution_attempt\": \"\",\n        \"resolved\": False,\n        \"escalated\": False,\n        \"final_response\": \"\"\n    }\n    \n    # Executando o sistema\n    result = support_app.invoke(initial_state)\n    \n    # RelatÃ³rio do atendimento\n    print(f\"\\nğŸ“Š RELATÃ“RIO DO ATENDIMENTO:\")\n    print(f\"Tipo do problema: {result['problem_type'].upper()}\")\n    print(f\"Resolvido automaticamente: {'âœ… Sim' if result['resolved'] else 'âŒ NÃ£o'}\")\n    print(f\"Escalonado: {'âœ… Sim' if result['escalated'] else 'âŒ NÃ£o'}\")\n    \n    print(f\"\\nğŸ’¬ RESPOSTA FINAL:\")\n    print(result['final_response'])\n    \n    return result\n\n# Teste 1: Problema tÃ©cnico simples\nprint(\"ğŸ§ª TESTE 1: Problema TÃ©cnico\")\ntest1 = test_support_system(\"Meu aplicativo nÃ£o estÃ¡ abrindo no celular\")\n\n# Teste 2: DÃºvida comercial\nprint(\"\\n\\nğŸ§ª TESTE 2: QuestÃ£o Comercial\")\ntest2 = test_support_system(\"Quero saber sobre os planos premium\")\n\n# Teste 3: Problema complexo (deve escalonar)\nprint(\"\\n\\nğŸ§ª TESTE 3: Problema Complexo\")\ntest3 = test_support_system(\"Perdi todos os meus dados apÃ³s a atualizaÃ§Ã£o\")\n\nprint(\"\\nğŸ‰ Sistema testado! Veja como ele se adapta a diferentes situaÃ§Ãµes!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ ExercÃ­cio PrÃ¡tico: Seu Primeiro LangGraph\n\nAgora Ã© sua vez de botar a mÃ£o na massa!\n\n### ğŸ† DESAFIO 1: Sistema de RecomendaÃ§Ã£o Inteligente\n\nCrie um LangGraph que:\n1. **Pergunta** sobre os gostos do usuÃ¡rio\n2. **Analisa** as preferÃªncias\n3. **Decide** se tem informaÃ§Ã£o suficiente\n4. **Faz mais perguntas** se necessÃ¡rio\n5. **Gera** recomendaÃ§Ãµes personalizadas\n\n#### Requisitos:\n- Use pelo menos 4 nÃ³s\n- Implemente pelo menos 1 condicional\n- Gerencie um estado com mÃºltiplas variÃ¡veis\n- Teste com diferentes cenÃ¡rios\n\n#### Dica do Pedro:\nComece simples! Defina o estado, crie as funÃ§Ãµes, monte o grafo e teste. Depois vocÃª pode incrementar! ğŸš€"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# SEU CÃ“DIGO AQUI! ğŸš€\n# Implemente o sistema de recomendaÃ§Ã£o\n\n# 1. Defina o estado (RecommendationState)\n# 2. Crie as funÃ§Ãµes dos nÃ³s\n# 3. Monte o grafo\n# 4. Teste!\n\n# Estrutura sugerida:\n# class RecommendationState(TypedDict):\n#     user_preferences: Dict[str, Any]\n#     questions_asked: int\n#     enough_info: bool\n#     recommendations: List[str]\n#     # ... outros campos que vocÃª achar necessÃ¡rio\n\n# Dica: Comece definindo que tipo de recomendaÃ§Ã£o vai fazer\n# (filmes, restaurantes, livros, etc.)\n\nprint(\"ğŸ’ª Seu desafio estÃ¡ aqui!\")\nprint(\"ğŸ¯ Implemente um sistema de recomendaÃ§Ã£o com LangGraph!\")\n\n# APAGUE ESTE COMENTÃRIO E IMPLEMENTE SUA SOLUÃ‡ÃƒO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ… ExercÃ­cio AvanÃ§ado: Multi-Agent System\n\n### ğŸš€ DESAFIO 2: Sistema de AnÃ¡lise de Texto Multi-Agente\n\nPara quem quer ir alÃ©m! Crie um sistema onde **mÃºltiplos especialistas** analisam um texto:\n\n1. **Agent AnÃ¡lise Sentimento** - Analisa se Ã© positivo/negativo\n2. **Agent ExtraÃ§Ã£o TÃ³picos** - Identifica temas principais  \n3. **Agent Resumo** - Cria um resumo\n4. **Agent Coordenador** - Combina todos os resultados\n\n#### Fluxo:\n```mermaid\ngraph TD\n    A[Texto de entrada] --> B[AnÃ¡lise Sentimento]\n    A --> C[ExtraÃ§Ã£o TÃ³picos]\n    A --> D[Resumo]\n    B --> E[Coordenador]\n    C --> E\n    D --> E\n    E --> F[RelatÃ³rio Final]\n```\n\n#### Requisitos AvanÃ§ados:\n- Processamento em paralelo (simule com sleep)\n- AgregaÃ§Ã£o inteligente dos resultados\n- Sistema de pontuaÃ§Ã£o de confianÃ§a\n- Tratamento de erros\n\n**Dica do Pedro**: Este Ã© nÃ­vel **ninja**! Se conseguir fazer, vocÃª jÃ¡ entendeu o poder real do LangGraph! ğŸ¥·"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# DESAFIO NINJA! ğŸ¥·\n# Sistema Multi-Agent de AnÃ¡lise de Texto\n\n# Sua missÃ£o (se aceitar):\n# 1. Criar mÃºltiplos agents especializados\n# 2. Fazer eles trabalharem em paralelo\n# 3. Coordenar os resultados\n# 4. Gerar um relatÃ³rio unificado\n\n# Estado sugerido:\n# class MultiAnalysisState(TypedDict):\n#     input_text: str\n#     sentiment_analysis: Dict[str, Any]\n#     topic_extraction: Dict[str, Any]\n#     summary: str\n#     confidence_scores: Dict[str, float]\n#     final_report: str\n\n# Dica: Use time.sleep() para simular processamento em paralelo\n# Dica 2: Cada agent pode ter sua prÃ³pria funÃ§Ã£o de \"confianÃ§a\"\n\nimport time\nimport random\n\nprint(\"ğŸ¥· DESAFIO NINJA ATIVADO!\")\nprint(\"ğŸ¯ Crie um sistema multi-agent para anÃ¡lise de texto!\")\nprint(\"ğŸ’ª Boa sorte, padawan!\")\n\n# SEU CÃ“DIGO AQUI!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”® O Futuro do LangGraph e prÃ³ximos passos\n\nBora falar sobre onde isso tudo vai dar e como vocÃª pode evoluir!\n\n### ğŸš€ PrÃ³ximas evoluÃ§Ãµes do LangGraph:\n\n1. **ParalelizaÃ§Ã£o Nativa** - ExecuÃ§Ã£o real em paralelo\n2. **PersistÃªncia de Estado** - Estados que sobrevivem entre execuÃ§Ãµes\n3. **Streaming Real-time** - ExecuÃ§Ã£o em tempo real\n4. **Auto-otimizaÃ§Ã£o** - Grafos que se otimizam sozinhos\n5. **IntegraÃ§Ã£o com Deploy** - Deploy direto na nuvem\n\n### ğŸ’¼ Casos de uso empresariais reais:\n\n- **Customer Journey Automation** - Jornadas personalizadas\n- **Content Moderation** - ModeraÃ§Ã£o inteligente em mÃºltiplas etapas  \n- **Sales Qualification** - QualificaÃ§Ã£o automÃ¡tica de leads\n- **Technical Support** - Suporte tÃ©cnico multinÃ­veis\n- **Data Processing Pipelines** - Pipelines de dados inteligentes\n\n### ğŸ¯ Como continuar estudando:\n\n1. **Pratique os exemplos** deste notebook\n2. **Crie seus prÃ³prios grafos** para problemas reais\n3. **Combine com o que aprendeu** nos mÃ³dulos anteriores\n4. **Experimente com diferentes LLMs**\n5. **Teste em produÃ§Ã£o** (prÃ³ximo mÃ³dulo: LangSmith!)\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-versÃ£o-v0.2-modulo-14_img_05.png)\n\n**Dica do Pedro**: LangGraph nÃ£o Ã© sÃ³ uma ferramenta, Ã© uma **nova forma de pensar** em IA! Em vez de \"o que minha IA faz?\", pergunte \"como minha IA pensa?\". Essa mudanÃ§a de mindset Ã© revolucionÃ¡ria! ğŸ§ âœ¨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Vamos criar uma visualizaÃ§Ã£o do \"futuro\" do LangGraph\n# Mostrando a evoluÃ§Ã£o de complexidade que conseguimos atingir\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Dados da evoluÃ§Ã£o de capacidades\ntechnologies = ['Scripts\\nSimples', 'Chains\\nLangChain', 'Agents\\nTradicionais', 'LangGraph\\nBÃ¡sico', 'LangGraph\\nAvanÃ§ado', 'Multi-Agent\\nSystems']\ncomplexity_score = [1, 3, 5, 7, 8, 10]\ncapabilities = [1, 4, 6, 8, 9, 10]\nmaintainability = [8, 6, 4, 7, 8, 9]\n\nx = np.arange(len(technologies))\nwidth = 0.25\n\nfig, ax = plt.subplots(figsize=(14, 8))\n\n# Barras para cada mÃ©trica\nrects1 = ax.bar(x - width, complexity_score, width, label='Complexidade de Problemas', \n                color='#FF6B6B', alpha=0.8)\nrects2 = ax.bar(x, capabilities, width, label='Capacidades', \n                color='#4ECDC4', alpha=0.8)\nrects3 = ax.bar(x + width, maintainability, width, label='Manutenibilidade', \n                color='#45B7D1', alpha=0.8)\n\n# ConfiguraÃ§Ã£o do grÃ¡fico\nax.set_xlabel('Tecnologias', fontsize=12, weight='bold')\nax.set_ylabel('Score (1-10)', fontsize=12, weight='bold')\nax.set_title('ğŸš€ EvoluÃ§Ã£o das Tecnologias de IA - De Scripts a Multi-Agents', \n             fontsize=14, weight='bold', pad=20)\nax.set_xticks(x)\nax.set_xticklabels(technologies, rotation=0, ha='center')\nax.legend(loc='upper left')\nax.grid(axis='y', alpha=0.3)\nax.set_ylim(0, 11)\n\n# Adicionando anotaÃ§Ãµes especiais\nax.annotate('ğŸ¯ Estamos aqui!', \n            xy=(4, 8.5), xytext=(4.5, 9.5),\n            arrowprops=dict(arrowstyle='->', color='red', lw=2),\n            fontsize=12, weight='bold', color='red')\n\nax.annotate('ğŸ”® O futuro!', \n            xy=(5, 10), xytext=(4.2, 10.5),\n            arrowprops=dict(arrowstyle='->', color='purple', lw=2),\n            fontsize=12, weight='bold', color='purple')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"ğŸ“ˆ EvoluÃ§Ã£o das capacidades:\")\nprint(\"ğŸ”¥ LangGraph representa um salto qualitativo!\")\nprint(\"ğŸ’ª VocÃª agora domina uma das tecnologias mais avanÃ§adas de IA!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“š Resumo do MÃ³dulo - O que aprendemos?\n\nCaraca, que jornada! Vamos recapitular tudo que vimos:\n\n### âœ… **Conceitos Fundamentais**\n- **LangGraph** = GPS para agents inteligentes\n- **Grafos dirigidos** para controle de fluxo\n- **Estados compartilhados** entre nÃ³s\n- **ExecuÃ§Ã£o condicional** baseada em lÃ³gica\n\n### âœ… **ImplementaÃ§Ãµes PrÃ¡ticas**\n- Sistema de **contador com loops**\n- **Chatbot inteligente** com anÃ¡lise contextual\n- **Sistema de atendimento** empresarial completo\n- **Fluxos condicionais** e decisÃµes automÃ¡ticas\n\n### âœ… **ComparaÃ§Ãµes e Insights**\n- **Agents vs LangGraph** - quando usar cada um\n- **Casos de uso reais** em empresas\n- **VisualizaÃ§Ãµes** de fluxos e performance\n- **PrÃ³ximos passos** na evoluÃ§Ã£o da tecnologia\n\n### ğŸ¯ **Principais DiferenÃ§as do que vimos antes:**\n\n| MÃ³dulo Anterior | LangGraph | \n|-----------------|----------|\n| Agents lineares (MÃ³dulo 9) | **Fluxos complexos e condicionais** |\n| Memory isolada (MÃ³dulo 5) | **Estado compartilhado inteligente** |\n| Chains simples (MÃ³dulo 4) | **Workflows sofisticados** |\n\n### ğŸš€ **PreparaÃ§Ã£o para o MÃ³dulo 15:**\nNo prÃ³ximo mÃ³dulo vamos aprender sobre **LangSmith** - a ferramenta que vai nos ajudar a:\n- **Monitorar** nossos LangGraphs em produÃ§Ã£o\n- **Debugar** fluxos complexos\n- **Otimizar** performance \n- **Analisar** comportamentos\n\n### ğŸ’¡ **Dica Final do Pedro:**\nLangGraph nÃ£o Ã© sÃ³ sobre fazer IA mais complexa - Ã© sobre fazer IA **mais inteligente e controlÃ¡vel**. VocÃª agora tem o poder de criar sistemas que **realmente pensam** antes de agir!\n\nE lembra: **toda expertise comeÃ§a com curiosidade**. Continue experimentando, criando e se divertindo com o que aprendeu! ğŸ‰\n\n![](/Users/pedroguth/Downloads/Projetos/Book Maker/5-Imagens/langchain---usando-versÃ£o-v0.2-modulo-14_img_06.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ParabÃ©ns! VocÃª chegou ao final do MÃ³dulo 14! ğŸ‰\n# Vamos criar um \"certificado\" visual do que vocÃª domina agora\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle, FancyBboxPatch\nimport matplotlib.patches as mpatches\n\nfig, ax = plt.subplots(1, 1, figsize=(12, 8))\nax.set_xlim(0, 10)\nax.set_ylim(0, 10)\nax.axis('off')\n\n# Fundo do certificado\ncert_bg = FancyBboxPatch(\n    (0.5, 1), 9, 8,\n    boxstyle=\"round,pad=0.1\",\n    facecolor='#f0f8ff',\n    edgecolor='#4169e1',\n    linewidth=3\n)\nax.add_patch(cert_bg)\n\n# TÃ­tulo\nax.text(5, 8.5, 'ğŸ† CERTIFICADO DE CONCLUSÃƒO', \n        ha='center', va='center', fontsize=18, weight='bold', color='#4169e1')\nax.text(5, 8, 'MÃ³dulo 14: LangGraph Mastery', \n        ha='center', va='center', fontsize=14, weight='bold', color='#2e8b57')\n\n# Linha decorativa\nax.plot([1.5, 8.5], [7.5, 7.5], color='#4169e1', linewidth=2)\n\n# CompetÃªncias adquiridas\nskills = [\n    'âœ… CriaÃ§Ã£o de Grafos Inteligentes',\n    'âœ… Gerenciamento de Estados Complexos', \n    'âœ… Fluxos Condicionais e Loops',\n    'âœ… Sistemas Multi-Agent',\n    'âœ… IntegraÃ§Ã£o com LLMs',\n    'âœ… Debugging e VisualizaÃ§Ã£o'\n]\n\ny_start = 6.5\nfor i, skill in enumerate(skills):\n    ax.text(1.5, y_start - i*0.4, skill, \n            ha='left', va='center', fontsize=11, color='#2e8b57')\n\n# EstatÃ­sticas\nax.text(5, 3.5, 'ğŸ“Š SUAS ESTATÃSTICAS:', \n        ha='center', va='center', fontsize=12, weight='bold', color='#4169e1')\n\nstats = [\n    'ğŸ§  Conceitos Aprendidos: 10+',\n    'ğŸ’» CÃ³digos Executados: 20+', \n    'ğŸ—ï¸ Projetos Criados: 3',\n    'ğŸ¯ NÃ­vel AlcanÃ§ado: AvanÃ§ado'\n]\n\ny_start = 3\nfor i, stat in enumerate(stats):\n    ax.text(5, y_start - i*0.3, stat, \n            ha='center', va='center', fontsize=10, color='#2e8b57')\n\n# Assinatura do Pedro\nax.text(5, 1.5, 'ğŸ‘¨â€ğŸ’» Pedro Nunes Guth', \n        ha='center', va='center', fontsize=12, weight='bold', color='#4169e1')\nax.text(5, 1.2, 'Instrutor Expert em IA & LangChain', \n        ha='center', va='center', fontsize=10, style='italic', color='#666')\n\nplt.title('ğŸ“ PARABÃ‰NS! VOCÃŠ DOMINA LANGGRAPH!', \n          fontsize=16, weight='bold', pad=20, color='#4169e1')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"ğŸ‰ PARABÃ‰NS! VocÃª completou o MÃ³dulo 14!\")\nprint(\"ğŸš€ Agora vocÃª domina LangGraph e pode criar sistemas de IA complexos!\")\nprint(\"ğŸ“š PrÃ³ximo desafio: MÃ³dulo 15 - LangSmith para produÃ§Ã£o!\")\nprint(\"\\nğŸ’ª Continue assim, vocÃª estÃ¡ arrasando!\")"
      ]
    }
  ]
}